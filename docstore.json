{"docstore/metadata": {"c8f20c40-73d8-4c54-9076-5ffa8bb1e6ff": {"doc_hash": "aee3744e6c0d478a02ff051c31e10a5d11f72587c42848ee7f0d862d425504e2"}, "d9433b40-a638-41c6-abd6-04ff384f1bb0": {"doc_hash": "7111fd88169a14cbc9221b6c129f704cbb27b74edb9cdc275868e8d984489529"}, "0ad4a960-bb03-4018-94d7-36e99bbc796a": {"doc_hash": "7ca191b8b99e55f692f232fb61b41bd5e4541b649b3bb14656499f3facf7b991"}, "41be2ee3-616e-498e-bc3f-43f48ad338f2": {"doc_hash": "904a669d6fb2a61ce1d9fae7a6ab0b5c9d01baab5e0977ba620cd222f4286218"}, "7521619a-5927-4eaa-b9f0-6470e648f2da": {"doc_hash": "3a3f1ae1415dc6c1ab883c6f454fa86cf379ece1f3a6d6eb5137d693d1159a16"}, "dd99aaad-2e63-432e-818d-03b771853f03": {"doc_hash": "138c707213360d1ca6dbfa22c1c7d6120e79f1d24517c2c00419474c7f0da649"}, "d64eb0eb-9bde-4fd7-b7b9-8fce3a336727": {"doc_hash": "9ee01b1b95bf946b55e2a0f12407500452f3f8a6327f2a94ea3c38abcf9e06df"}, "7a92a5ff-d836-4e14-8586-916ad2292c4e": {"doc_hash": "d0d3e201240e7ca8e508f749dcb72a706e4c054b008e7f86b1ade3dd37a9e1d4"}, "481ca465-436e-414f-96d2-2bdf47cfcc96": {"doc_hash": "1fb550db3c2b29785bc729a8fdee8537ad2a2e13472e15290129bcd77bcdd6a3"}, "e5be74c7-13ee-4ccb-ac78-ddd824c3a0aa": {"doc_hash": "01f0c5eaf43f765d1db84459684556880e58e4a02079cb2eca8dd63ca8c02ad2"}, "5752ae1a-bb91-4058-a827-536d44f0bdc1": {"doc_hash": "bcb9d27fa7783f9dfb4ef86694cc15e401ae69b8a67f7002709d6dcfc1485c7a"}, "90ccd82e-8e53-436c-9048-d2d1007d56a6": {"doc_hash": "a2a15f4f222bc31ce0e66b376448e35a0cd5e00e054a461ff6b9375ebecc7cad"}, "6def78aa-5912-43d7-8f2b-4895d1b99bbe": {"doc_hash": "590a6b173f408004ceddef1c33528fb0896d843c0aff45f1a9eba1fef7f05264"}, "988b285b-cbd2-477f-aef8-f413d0748d9f": {"doc_hash": "d3b41f283d07372406c698f8adbfadae5d2d108dff2cb5e14bf0db601ca5178d"}, "91fd8ee9-c807-46e9-88bc-7f28a267fe06": {"doc_hash": "5990ab2702c189fbfa71fdb5263f8690d24b8d6696d8455d12839295ef217378"}, "be9793ff-f0ab-408a-bcd0-7cac7bb272b6": {"doc_hash": "8f33e2658af4937446f65b0f3199fea3daf90ffca43a8596432d4215c1426350"}, "7f17c82f-8843-47a6-96ae-1ec7e1f5b9e9": {"doc_hash": "626d57f8dbe356f1034890c3be908e0784584ae8c7445627a72f1e612f00f141"}, "600f0f30-8ec4-416a-b32d-3d09ed91ad6a": {"doc_hash": "385aeee41bf3cb81e8859499d1b01f5dc673392b85da71db73a8206ff303b7a0"}, "9a315e8c-e491-453a-bb9b-d37530b9d5e0": {"doc_hash": "3f3a8fcfd4f1d7966619d628a1a56298f8f45cd1e836037bcbcbdb92edac8099"}, "96c77bb5-37ab-41ee-b781-e1c918802101": {"doc_hash": "cbd96560f3cffa770145df2df7951d1649628ebb440c3b5373d5cdb1243dbed7"}, "1a6e4334-76cb-4d88-bfd1-a8a4b447ce3c": {"doc_hash": "2a277aa4652541929aa2ca2a831d8f67e52819a6afe835d3b6aee7b4e1a928d8"}, "c7f8fe3c-0ec6-466e-b03e-cd6e0f4ad23a": {"doc_hash": "f05c50f523d4df4e1116c723cb62f1fcea8ddeda418bcfd0723e7f5b7edf3084"}, "0c66c84e-aff3-4593-b5a7-9c9b662996fd": {"doc_hash": "a495db03770bae2a4ec3a91d923155a603742ac9d2b10f6792f8b2ddf8ec401b"}, "d8fe86fd-982c-46b5-929f-6467620ada51": {"doc_hash": "2e0eb02f5e7ed5e166e117163f908ee6f7cdaaf6a52512ed1d424b909e7d49c1"}, "45ab85ea-948a-4c12-96c3-b9da323918b4": {"doc_hash": "8abf2df30a714d389bc9e61dfe54b264a95d5065e31770498233e9a1f4a64cdf"}, "76b19505-04af-4916-b635-9e7104fa2094": {"doc_hash": "45ea0bb1e667bafe15e2aa347a6f66be18a4d7634a92c391ece82908ee5cabf6"}, "b46d0766-9d98-4522-9f67-3ac63412d1af": {"doc_hash": "dc7a99988e57a4f9ceb2c353dbeb7f6e52cff2f1b9c1b18c248d25683b76427b"}, "623634bf-00d5-49b9-b3f6-661e1222180c": {"doc_hash": "b29e9940737bf66982969aad00b6346ab2574b702970d17e46ac975ab20fe00a"}, "c781fbf9-721a-472a-82e3-0a9fe31925a2": {"doc_hash": "16843c8e6b05e6651563f040555f6b48c27fa952bc3ec474766f7af7bcd5e6af"}, "3efa10be-030b-4c8c-a36a-9dd6e5702c5e": {"doc_hash": "d9a0765b644e446947d71673fc0e33ba9804d4c54945f0d986a74cf4aefd1e39"}, "97199ac2-09ca-473b-b562-72033d7c8b42": {"doc_hash": "94b0eedb8eec90204629fabeac8c429fdbfb89a4ca8e373975351b625d893063"}, "709f7dd2-1d45-4fb1-aebd-6ed0d8b31fa6": {"doc_hash": "b95e2804959c00688fea5a4db6711b1174145a0e92b1fc42b005142aa6b86582"}, "9eeb896d-fdd9-4ad3-9852-232897abf74d": {"doc_hash": "4b5a8691765d11cf6137c858f9c439998d4fa195c9d8d5ee90e3a41826714741"}, "57cf3050-a58b-4e9d-8e81-eb20214c0a14": {"doc_hash": "e324ede448e4b90d6d78554288634875431e88983c861fac7cb7b85436e3b645"}, "a1a1f3f1-4c0c-4be1-bb75-b055e2ea6d73": {"doc_hash": "276475ce3154b15274b83853f15fb250ac1b9ea75426df87b65d68685cf62244"}, "4a60e18d-c5e9-41e0-aea1-8cde3e4fa6c6": {"doc_hash": "2e3106b0fcb8ab24e25456cc88aef3790ff47af5913ca0cfb42179e8862d9d1a"}, "ef1b751e-a053-4497-b621-160efe83a575": {"doc_hash": "60cb3b50e1755636fd13efcc218d12561a64c6d917377500af2c4eea2a0eeaf7"}, "337d1891-6cb3-4a6d-a082-1561b3a62b86": {"doc_hash": "b0e755b4b90a4886d4b8116853031fdde0a33aa582914664a7877eab68525f95"}, "e804f0a0-5f5c-45bd-bd3f-f49efc2fbaa9": {"doc_hash": "83669b9b8ecf7dbefd7abf06ba97d561a6a2a667071fcb903203d9e4c64f76cd"}, "f0240adb-10f9-4204-8efc-1acc5d9fd00c": {"doc_hash": "4cec2a67e9d7130285c2cce6f2234b7a2848924bf28a7a6ebe99818890e25d62"}, "8b4bddcf-f51a-472c-b91a-d9bdf481c0eb": {"doc_hash": "21814030d1c36fca8427f8c8ed4bdf51a7c3fd199ff4b1159e14d5df1a1df3ec"}, "de65fe55-6bbf-485c-83dc-5eff71fcbb86": {"doc_hash": "dffc541904bc7952fc7067cb33d999e9ece6675567d8b72ae760c36f119a4f72"}, "59772286-a0ca-4507-8149-801ebc39c883": {"doc_hash": "5e1ba2aae4515ff053335ae1f593580edf6f46837d3c4ff6263f4cf5bc52a8ad"}, "19592e41-129a-4c72-a254-4ce51dad7d74": {"doc_hash": "9a59047d3ac60bf87008af29b4b55a2fc3cd0913bcdf71d044f03d4e08e1f72e"}, "9d66dcf9-af61-4b08-8ab9-7d8eb344bcda": {"doc_hash": "b19e1d502dc52d525fe3ae344d42b856cde56536afe5a612c05e5463a9822d83"}, "b5e2a31e-bfad-4dbd-bb50-ff28d533dffb": {"doc_hash": "081e24cb47285eda102620de23261d9696bd9e29121fad77dd6734698dda11ff"}, "75687435-3250-4ad6-99d5-c216a86ba06e": {"doc_hash": "45c941ed5edc5a348765d62e9c45b184c6a23b1abd85ed553b10bde6680dccdf"}, "35951e22-800f-4f2f-a64d-edfea511951a": {"doc_hash": "06631f919287815c8165985554c6cb2b34f994126a705a0ac19e732e51592f39"}, "000a0c47-9c20-447f-8695-3cebd0bef4cd": {"doc_hash": "b09e77eb0345aee9b761a2e0f6850aa57152ede6a439b1beabd2281590db6378"}, "0abecd52-7d22-4744-a935-922194c4634f": {"doc_hash": "2fd0e93343b4e59472d5b28cc4fdd9771d21daf6c0c5c548840c85bf5ef1898b"}, "42b3c985-24ac-4739-a052-badb887b4120": {"doc_hash": "6b64a5b4804c3476de63dc08d59ccaae39e460fcba2d4f62b0cd25da3fc9dc87"}, "82a8b0a9-13fc-4b32-9f08-4eb9edada6d0": {"doc_hash": "63fc56fd03c92436fd4c4323cb7cbc701018226fae620cea16d2a5a4cc8d2edf"}, "6a5518b7-e42f-4b9f-82f7-c67057d174c8": {"doc_hash": "4c1ab5997d6228f273891777af18aeddc639f7e7f47764918a14b723a00a1fc8"}, "32c7d192-78e1-4c81-a348-f8baeb6e15a3": {"doc_hash": "2fcd71586643dd95877a3a0a04fa931f568c01e8591395df5d451669edf0ff4a"}, "0c1c2679-3661-40c5-929b-c491e9d2fdab": {"doc_hash": "f34efd744252b758c1750dff4f3959d6f9c2f4eb81ba0eb8d5c16bd6ad688b05"}, "e7969a41-ec69-444b-9627-fa154a3ee02f": {"doc_hash": "579866c0a70121b3831732a69202cf023331cdfe676b68b04a7659843b22b0ee"}, "8d19ee5e-a7ee-4fde-a7c8-ca51a2e4a0ff": {"doc_hash": "2bf42aa908b585fcc871bc6e8d2576666d812f7183d788ce3963ed3b0ac49ff1"}, "eb5dec9a-e8e4-4c0b-a61d-0c6b3e770ad2": {"doc_hash": "32befae75f372c403e1d71f230c7dd0b79e88a5d83a500737deb8b694f623352"}, "989ea1a4-df2e-4156-b7d1-eced94ff2dbe": {"doc_hash": "a13784c58614383178a59dfe05f1f3f207cb3f39fb1dd1bbd1dbfad289ada1ca"}, "30dadaee-7bdd-4353-962c-151ec23701a9": {"doc_hash": "4df1afb6e3b23a60d0f3c44fddbfd6643c4e1ad437e5d17fdc00bb3b023ae611"}, "03d1bdff-3cb9-4a15-90c5-409b67234e83": {"doc_hash": "a82e6a0d1bf0c6730ab2fd50ee45e8636d78ac17559efa8a749a872a3167a7af"}, "88428a16-47ba-4653-9b97-5ab1e11d6a4a": {"doc_hash": "cbc466b740d59a7109f5af1cad69c17022a22fe04ecd38df0f78189acd4b3109"}, "c527156b-747d-4333-891b-4b8e17ab815a": {"doc_hash": "bc5fe85ac7db5d5ec26f73c8f463834a6ddf706783363a5542c6e879dd01afae"}, "92863689-b0d5-4155-9c18-09683a23cc31": {"doc_hash": "fcad4e78fae71ea95a6be2a2b1156d3716024bcd5ad01ce989453fe0d673ae56"}, "2c70cd47-6c99-4dae-9d4f-adc9d0fa0031": {"doc_hash": "ccd8a251a591a1918f871e5aafd691eed7b222ef3828e537f6df80ecce66813b"}, "c8d9a29b-fd87-4f92-be81-11c3020474ba": {"doc_hash": "11b38a36e70c86564410e437ddfdd62bcf7463b275d7e3fab1dd0c205efadb6c"}, "48fc9d56-5d40-428c-879a-ca3040e8d45e": {"doc_hash": "30c39fe8a90b87b313cb70e20d50ef58a854f98205264ca48d35be45df14d980"}, "288207e2-6381-45d1-9758-29a4dac1b1e3": {"doc_hash": "9095a9e3146a781075a048899ff324a0d7f1e20400b2df37a88aaf265383ee69"}, "9497395d-38eb-400c-a703-93a7eafa77cd": {"doc_hash": "c116236a06c97411e958034cfc9a735c80b3f83cf383da645803625a8163953d"}, "c1247868-be08-4b3a-9416-9cc03afc3434": {"doc_hash": "fe693eea4327f4927a68b8931d73ad3a8e79f1d34027900207f2027d75688e8e"}, "631862ad-f050-4a61-b21e-7170ea6f5774": {"doc_hash": "e7d162f37b98a68b4b9b2188684862ceef407d3427c4e68551863a0a128b3f8c"}, "1075cadc-927f-4d1e-8cc4-26c375841b14": {"doc_hash": "c84284269cafa4ac0fa2695147ff5226ad8dc7928929af7657f07c457a7cf498"}, "f795a17a-785a-45a1-b998-99633b1691c2": {"doc_hash": "00fca52535c9d75bea87dbca9ead9f917eb90fd2cde3adf084768aede1799994"}, "93f2cdda-78c3-4509-af76-3f1f256593fe": {"doc_hash": "127cbcff1fb84e2e84f834ed4ecda4958009faa661be013b89e9284b8222b310"}, "8c368563-9da2-4bf7-93c3-0cc604192ed1": {"doc_hash": "d97fa784287905b73503fba999e79d438c4683102669ab5496ff57517835ae1d"}, "2f1ac7f7-2c4f-47a3-8187-f668d3dc5b63": {"doc_hash": "de7f3daf53d748e614f04d4414ea21d70bd44f2f9e3933be02a857fdc973da58"}, "6a8d220d-28b5-4186-bf03-1e6860268fea": {"doc_hash": "6815e8aa6dab09d731b5afe0a298d1b5a2ea609d50efccd544c0065fcfac0992"}, "dfe6bee2-b884-43b0-8281-37796e171056": {"doc_hash": "d12ec9791e4f45ce700d8a143181ce3294c32ce808acca38ef64091a979df0aa"}, "38f53d92-77a5-410e-8e0c-11545258a526": {"doc_hash": "c7c3ae6cf28b73b08f67743b519e6a08acfceb7c8f855f4f15289a28caa7962c"}, "b8b088a2-270b-4a4d-9821-857fe16dafe6": {"doc_hash": "1244303f1f17fd439cd5a79bfe7261944606f28128b4d38ff8ee9b1d1581e33d"}, "7ac30887-b462-4524-9d44-bc3239a70e22": {"doc_hash": "53f90a1cf1a2348843b514d332f6e754bc797f0756ec13b3a0a5ba98b0fd6cb4"}, "62bb1acf-72bc-4109-935d-b66b090674ae": {"doc_hash": "a03c4ac1e1f7c25b9045e7133e31b170e093c887b4188bf4f13168f40f13f7c5"}, "3e142f07-f872-42a9-b6c1-5e93ba3abb66": {"doc_hash": "a35bb45b0586f63eebd56c58dbf651ed74f381a2d18d70624bfde4ff200c0828"}, "6350f339-8203-443f-b87d-1144b77b3f85": {"doc_hash": "0d2d06d2b4914a1f5dd869afee5793b94fc2d95b39b9ac7cbbaa4fb2a75aeb49"}, "7fc2c9d9-2475-4b34-805c-0c5f8443c9e0": {"doc_hash": "d16342b809f7921122ca58c841181791435dfed8e3c89a5cf547d31ca44816f6"}, "9beb6642-1959-4e77-aea5-03615c04ac7c": {"doc_hash": "84d83c5c85f885b1aae4b2fa5981e45643b97fdfa2ba81657a98584d706da669"}, "2712329b-bd59-4c30-bccf-f48c0b144ad4": {"doc_hash": "13fc56d3b4acc9db0f4e12ec283b5614a5170fbf85ffbcb4f2d69fa2f447e633"}, "5443c456-b1f3-41f0-abe6-a808180d489d": {"doc_hash": "ee44c348b34e07f213d1be642dd7c34994444eca4218d91a60385b1ff2b97a3f"}, "3d2845e8-cf5e-4aac-8a69-0bf6fee987ca": {"doc_hash": "0c79cb51af24f1ec9b2ded8f9ff32421263cc7b8e5a6b163849de8dae9d4bca9"}, "da2688ab-5fcc-4ebd-a74e-3c6d5836bf99": {"doc_hash": "9495a643c46f9596e6e53d1b636c78ef72885c4eba7f593dcbac954ab5609936"}, "7d7b5e52-baa9-48e7-b040-7c9ec7b6e6b2": {"doc_hash": "8d7316e0d5fd9afe2faced3ba53bda9166d3e9b563700d995301c1608cb9e979"}, "df3c3e60-1f52-4301-87c4-523b1def6695": {"doc_hash": "8222eaeee0fa604a8ab8261342845337fafd2a0bf223cf7edb8d60d9469a0d51"}, "e277e0a2-4e3f-45ac-ad33-df01be44018d": {"doc_hash": "a66fd9dbff65c4f951258f607d58b3699fc9c8e27071814ffaf13c50e634a119"}, "a973dd23-e3f3-4f3e-a292-a407feabc1a3": {"doc_hash": "650192c70c445b392591a876401700528a5f641530223237fd0f08c4ccdb4509"}, "39f278e4-db33-4ae3-a23c-c13178eda2d3": {"doc_hash": "95d3b99f43293aaf0f8fd278d0423b152646c971f1a696de0e09b52f8d3205fc"}, "fc39364e-5e62-4ebf-9c4c-3b9dcd83c64d": {"doc_hash": "3a8d2f44ae00d6e6d175eda76d139daed858c685e7d235c05f7cfa12488506d4"}, "7c63f636-8a45-4156-ac06-de5d332bce12": {"doc_hash": "964d1d4ce64269db1cbfd17aa2ac684f027709466570e569f32db1ddc247e1de"}, "76aeae04-d75c-4690-b7a3-7f9704bfc689": {"doc_hash": "ab4d2d9e792f9261ef2327a38285f718a875af88b7727c4ca86cad1ec136fd07"}, "80dab9ce-a5e9-4a5e-a495-e381a685ba20": {"doc_hash": "be3ec362d8c188af7f27250dba93fdbf9217f76940f1c38c3b75d3ffcb2e1806"}, "ab480b53-62fd-4490-9757-eed5fdaa0273": {"doc_hash": "2b4f8bd56310c247791d92c141191aa01f0aaaf21c67ace123226374aafab5ca"}, "702a7036-d5d9-4e7c-aba5-60bfefd6c2fa": {"doc_hash": "9fe0a7e493b17fb83b338fb50cb023d024d3d58516b373a02584e37f58e9e15a"}, "17b26881-20dd-4097-985e-c24ee1f3c120": {"doc_hash": "06e5399f814b17d1f751fab9ce2e1c9789bf41d3b83a8177bd82dbcf12e53b2c"}, "95f57c90-709a-405f-95d9-5258fcec2062": {"doc_hash": "784b9bcf63858f470e6675f1173ae6f3ed2800affc3deb09c722d2a7774d3ce2"}, "85d74f35-2f1b-474a-81c1-1d21c6312c8e": {"doc_hash": "d6053f77ac82a2db0bd1cbd22fe78de79c218b6df9be57993a2c2b8c46aed97b"}, "0ca60c14-2df3-46f3-945e-e2edd4ee447f": {"doc_hash": "02de4beb85b5a06360a162d424966d70be2e20a6894df2df98779021d560b970"}, "4baadb9f-6d9d-4d6d-af7a-7a86a5f52b07": {"doc_hash": "e9c37ebeef672f81e03e2033a7f8d8d0f4dc1ecd6646f2792b62cc812a390e68"}, "43afa818-25fd-4890-b215-f5e46b075566": {"doc_hash": "5ff23fcd7352a2b5fef00d06b246e312b99047da02ddca0d7d38183630b8e17f"}, "10307648-056f-4425-8db4-dc67a0dd31dd": {"doc_hash": "fb778143f0d1d0c4869b1de41b1796613712717d5511fe534dfae13892b7dea2"}, "482b3a87-8ad5-46ac-997b-e11a331a5642": {"doc_hash": "b070c645e87c9c60876f5ac883198764457f5fb33b0c91a09c2c7a41f519af89"}, "f56ad6b6-e701-42c2-bb5d-322d8ffd2e8a": {"doc_hash": "3f2f66539b8d281a76c0e2de929d802bbe823f3c62c68aa06b1ef1462a7528de"}, "0af5a1fa-7811-4325-ba39-c663c3b426de": {"doc_hash": "395b5d5cb3c7e875c6620029b83a8cf36e861c546d52442c1cee5c65fd6ceea5"}, "3331fb8b-ce70-447b-9eac-8c1769a43e36": {"doc_hash": "fc8b9760183bfb3248402443cfea3a043fe80b3d2a5c15a2f7d90c3337d74b87"}, "44e55030-0b1c-4d8a-875e-c0324c6ea8a3": {"doc_hash": "fc0e95c50d2cc2f3bbc6b33a6b9e4859ea84eb274b6266d81be72794a1c9d633"}, "4ae38cb6-3b35-4824-ad52-542aa50038d1": {"doc_hash": "2db97a564d8b6f1bf6de4d9883fc1a43cf9179c6ec804a6fe8d31c934fd432a9"}, "cd48b511-5077-49a1-9663-f5ca6926585f": {"doc_hash": "89778c5f273ce3a2eec36ee2b1220d379ca989fd5c78611304acdc3bbb906fbd"}, "f254afe6-2678-4459-a519-a9563ae7e5e7": {"doc_hash": "bc8e25a25050790248fa29ceb1e295c6c197ddc1cf88a5bd240f0b003342b5e7"}, "8ff13eb5-8c82-4562-a8f7-5b78c3ce5cd6": {"doc_hash": "bf3e1a409b385649a1abd4276d8a4e74d99a3a4001088b7d789fcf792f22f28b"}, "d93d4899-b249-46e6-babb-d82833e76e13": {"doc_hash": "84f231517e6ba4db217bd71608743aae7d743f71815a090f571072f2309f4197"}, "87368beb-f090-466f-a6ff-95283609823b": {"doc_hash": "9686a6913f79fcf258bf45872e3cfddcd675e46fd99f8fddc8ea83362f88b60f"}, "19498481-ce29-4b5a-8f2a-7bc44854453f": {"doc_hash": "60ab6aa7985b4e6b95e25652e2b94400145cd3bf6e1b772f1a039d63d4d4be72"}, "3d458915-f7d7-4cf7-9dc0-77bd189462a7": {"doc_hash": "25d73e27d7b3782d66133f3f00696452b90d20e13c60dbfd02454468b88f10cf"}, "e71fc53e-2cf1-4df3-adc5-f28900b5bb76": {"doc_hash": "6d6978116d576db0aedccfe89f3c46bc16f5260e6c9bd19014c63e49556108fc"}, "5d118b46-703a-4c07-af15-3e39c8c323f7": {"doc_hash": "be1946d6000798b061b98792a9ec0319e5d0fb904a093ad0a915aeccdea8c751"}, "2c55a98f-65ce-4c0e-b3f3-f3c1b12f8e3a": {"doc_hash": "c192a5e451ec97579b2d8c1decb3a912e808449d88d3812322d1371904ee1242"}, "5079b5e4-626f-4148-afc5-b5dfe7cc3d35": {"doc_hash": "080d48c3908266ce22dd442d3df55dd397488c8964ed680909a487be135a89ce"}, "dcd4ba0d-38b0-4c99-9b94-d71e5365b9ec": {"doc_hash": "0257f5ff340ec4124f1ec81eeaa7eb0691535942a80ea963a91d4d935c241191"}, "e3f734f3-fa25-40f5-a368-aedaf89b4c0e": {"doc_hash": "3b505ff3f46f11a560f67c2e7fef5f69a07ef1752df5d92c2bd7ac23b1629e47"}, "1b7a9f13-0418-45aa-8063-222e4b1d1bb3": {"doc_hash": "fcf6027ca9a5b69dd9696db34a993e40e9973bf7d2bf83104317e2b19bfc94f0"}, "e370b66c-22d3-4db3-85fe-78bf382b0e1b": {"doc_hash": "8ce60352b2ff75034a0314f288375de8ed4a6bf1014d3cb46d85c0ee58d3eca2"}, "a64a8da2-44d1-413a-aa4e-a748f1d101b4": {"doc_hash": "bd7395ef28f74d241bfb009fb75d89398cc1f47e5a0a65b51e5bf4b0aee4acab"}, "5fc3dcf5-fa78-4ee2-94a2-b2d8c6631404": {"doc_hash": "0a5782f92a712d97cc2a896d424ed2c3144844c607a69f481dc55de5e92149c8"}, "4ffe6612-a354-42f5-82a7-33c152650211": {"doc_hash": "7760203e5e1273658eab777e1838f18aeb6833b0d1d9894bbea169bac67c5417"}, "ac050d62-11cb-4213-b4a9-6238c2d16493": {"doc_hash": "ed6d936fad34ac5cc645cec9a959780d88f4d6624bc4560d3658a42b91334ff5"}, "37ff28ce-9a20-4934-8256-8fefbdba82bb": {"doc_hash": "fbb875743a91de5ad882043bfeaaae6e193a0ff632e76718155b1fe765d2dcdd"}, "7d2c3372-fce6-4f6f-9a99-7400d89f0a54": {"doc_hash": "552b79a6d015fdced1e936bed5220ea3667bbcc2349bde586432508b6b7e0c5b"}, "6dc64be1-a895-4704-b738-c445de281f6e": {"doc_hash": "d51fb6750828440d62f87f1b40081130498773af9d0236bb51d876f52c1b8e67"}, "a8fe6794-69f0-4994-b153-8d7a34a040c7": {"doc_hash": "58a8db176c38ed1dedc3eb7171fe217f68a62329c2a95de536c50d0c78bccd67"}, "ac7688e3-d1d6-4554-ae48-014d232c9dcc": {"doc_hash": "76cdad14fcebf3b7517956893ec514e648de09a2edc23bcee1d3ea848dc00893"}, "966f0d32-b237-4abc-91f7-f317a76085b2": {"doc_hash": "b6767a243482aefe218221e28ab035d5ecb4c6385f543e087f4772302ace1bd4"}, "482c64f9-ef36-455a-89be-abcdeb979b28": {"doc_hash": "464228e73168b1164db937199b619d0adfcc42a44a85221440f7b16eba9b41d9"}, "afbae059-e1c9-4d78-9b35-d5a3f83d436b": {"doc_hash": "c7e5c81048c942a47c329bd0b14a47899e0cf59efa2a89f72441ed28431cb026"}, "8c77e843-c379-46e0-ae99-d86b01f3c6cd": {"doc_hash": "c8d41a0e9ec04778a6b8711dba46d56e3ae642b561d2652ccf7fb1ef00408b5a"}, "5ec1b41f-2922-41a3-9fbd-53639a03568a": {"doc_hash": "7194833959e4cd7a916390bd5b1e4e2246d75aa17b4090eb6c45da4289a3bf02"}, "1f1bbd87-b197-40a1-81d0-6af92b57bf84": {"doc_hash": "240fecb4cb8ed7ef2e7e0da3db61e16e7307dc194133772f7c4773c4193c83e4"}, "fa063b65-43e0-4548-b13c-47923cbe0152": {"doc_hash": "494610e1f6f703686d91dff9faaa8ca58c4098c65fa341f80ac44bfd10147824"}, "27e16ed6-62dd-47c8-b280-8754a5fda6eb": {"doc_hash": "29ef45558e25bf269eee2cc0ca4e34a817098248be770a4c9509bd1460e988c1"}, "fb002ce3-f2e2-4a1e-bd91-8e7e1aaa13d5": {"doc_hash": "ae605fc0f02d9244b0add24c08a34ada8b3f071fb2d9dc861fbeada757e02503"}, "b39d7cde-fcf7-4e01-a9cb-ef73d506aaf0": {"doc_hash": "b665bfece1b36579020ace6701c6f135cf79d3aeaceffe6bf3c1e1bf7fc0b4af"}, "560fe9c2-f08b-4190-aa6d-95f988c75537": {"doc_hash": "09bec26a18e82364fef8654ac6d2c58b9c8917b9dbbbcb6983aed5f77e222982"}, "aa791d7e-3d3f-436e-9de6-2f8d50e66660": {"doc_hash": "75ca62b00a96f1ee3d382ca2053937b5da0667ea6d8add443d9766b01f1be631"}, "2380a331-60da-42ad-9edb-722081f8a5a2": {"doc_hash": "43ce5ee55e7e7a8677d49f38093902a586171423be8201bccc3626dd6d5a1d1d"}, "3053e571-eb7e-4056-a956-e72425240a91": {"doc_hash": "4d39f6f603467b0285c55ea7357c98a3cdc7e4cfda801ac365fd930f3691c150"}, "94a4ed1d-63ab-4e7a-8ef6-bcdd6043e007": {"doc_hash": "55692339dadb63ae3e54eca8b26eadc74e58dcfe62d008209453bfe1a605d404"}, "8824293e-6eff-4fce-bfc1-d5b0863ad106": {"doc_hash": "828b093e0799e90defceceb3085dbb9a06ccf66d83e9b3019fde46cb0c84681b"}, "ada50c88-b154-4dc6-9aa8-461af7a3be6f": {"doc_hash": "790e94b764e6b0dfc14fb0e4f69cec145c47452e760abc88d374cd4ee9a37552"}, "792407c9-14a5-4598-bff4-4edb58f63e86": {"doc_hash": "9bea10b9cb9a17d0e873382cdfdeb09498ce0c085c33da0cdc9e12206d993e17"}, "6a906159-49cb-4268-af81-e5ff8c88ee7a": {"doc_hash": "b7e5b77e0f4c07cf1b64f111e8c2bd1520c0ef4f9864ce0e2feca78a3f6637cb"}, "9250bf89-e8e5-45b4-8218-583043e12b34": {"doc_hash": "238ba0911183dfd8f9eeddd2c3f70f7b16b717ae1fa90cff757d126fd5fdaea2"}, "c5baf10d-9665-4bf5-a5d8-2f27d580add7": {"doc_hash": "c5e7905de42094e6907af50909f0602ef6f9775f694d7da84341af525e2f8853"}, "7a491e80-de57-44ea-846e-98b192c24fe9": {"doc_hash": "488789aec0bf746abb5d21889a572b1ae2759ffe6db641df16ffeac890f886e7"}, "ac953e25-4f59-4195-b1f4-4e3245bae1ec": {"doc_hash": "3d818f78fd9ad2890abdb642326d95f9fdf08d20b4c73cd7244d6468ca0ab23a"}, "3917df98-f96d-4352-8eff-7fb82f2243a2": {"doc_hash": "aa93e9c5face1a126c947b2371c9e3bb16111baf97741814403b47ec18c1ff00"}, "771dd9c8-b8c0-4789-bbe6-982a3ebe19f5": {"doc_hash": "746b694516efcb2690a16baf410f2fb2c86b9ca69d2739d10f9ce48a79eb8cbe"}, "0c81ed7e-896b-440c-9383-b8db8d366070": {"doc_hash": "041ff89c8da3de9af37616df222099dd041232be7bccddb2c799830ca2bc146f"}, "0a7fc0c8-617f-4fb6-95dd-5ad9e5e07fe9": {"doc_hash": "4ad10661894e7ae4eb6ca0ebeb9875e014864dfaf4836bbd5cb18da0823a3c98"}, "0147b684-fa8d-4b76-9371-e78ae0bb40fe": {"doc_hash": "3e5806fb27629601766da6790d5b42f56e06932eedb38f6ada161aef558624ed"}, "346ea302-ec2a-479b-92d2-09b7b5d4b968": {"doc_hash": "06f69445cb925b362f3b7604f96a4952a1b1ddcd038233ce70db02925fc7c64e"}, "dd71b54f-dedb-40d7-8637-9a4d11da00f0": {"doc_hash": "829e7b2306f2cbad62de5b7703fc2708f9c6bff783d52c6bbc5554e3bcab48bd"}, "67dd0e73-fd09-47e6-975d-75e78c23823b": {"doc_hash": "67c77925ef47ee92da68a79cdbec1dafc5d52d2ac21ca8645aab373947d7ed75"}, "703cb1d0-bec8-47fb-bc07-be5d39a78105": {"doc_hash": "51e83cfeeddb92092a7026500a50bd2e1e140cdf36e12d71efbae13b4279e446"}, "487bbe43-398d-4e75-b7ed-4fc19c77b6ba": {"doc_hash": "d5a8667583894a2cd9ec63c5181d8d2484940a84c2541324be20927e8814d9b0"}, "b169d5ea-b341-471d-a170-d3adc6138947": {"doc_hash": "90c5672421fdc105f04491e53070321f9239d016e2dedc804b274c77ea8a4d83"}, "196c5339-aff1-4786-a56f-0191e46baa90": {"doc_hash": "118b5cc424d1f10227088c730ba9da5b118b91ad330288c1a7b7f7cfefafd53c"}, "89d5a985-c167-40ee-9b68-f37199cad043": {"doc_hash": "4654fba3201e4f7458a39946b30c56b4f9099bdf9ac05a096ff241f79999d781"}, "2c650dd5-c647-4b17-ba01-44283660667a": {"doc_hash": "880755265c184eff2b7ad9ea9948856d8eda2d96953ec52b41021ef77718f6a8"}, "b1762230-6a4a-46a1-b331-c0d820554cac": {"doc_hash": "82754f6976ade7c69bdf7b009fee1ff36c1e909431298b52e5df46941956d1de"}, "0f42a626-eafe-4e17-93ad-70561fcfb775": {"doc_hash": "264d22b09a99fc16ca2328f89afc9bff5f70d584cc74b174b9f2ae018cdfc744"}, "fac042c0-6e67-4ff1-b900-81cbdb3c71b8": {"doc_hash": "ae62e468b23a9b03e722842bf5866e1589038c8cb5f224991d1a4f4b658d37c7"}, "0ce46509-a971-462e-a578-aaa50b5746ba": {"doc_hash": "062f8183bd422d9462bf2495bbaf67f16983b95fe93dc805d913adb7b708b942"}, "d8b85560-b446-4e15-9b39-6014a3df9b4e": {"doc_hash": "d5ea49cafad07b81d1834117b5b6a82ef87b5717e8bc66f0aadb997450c3a93d"}, "0783dc24-f27f-43fb-ad13-449e109cf0c6": {"doc_hash": "d4c2f2d1d1fcffdd1849ffb76800a85c19df140dffb2cedbeefca125cd06741d"}, "1e2a6622-b82d-4181-9c1c-3a890e669151": {"doc_hash": "7368ea8e8bc905459da3f3a45c50c1214e753a2144f770247ed7c008e3e77b97"}, "0f9725b7-540e-465f-a768-5f4b06210203": {"doc_hash": "e48a2aabfd7e95a11feb30b7cab964d38c2c90b8b751d1f0baba5ab71e338151"}, "8ba59f68-d87a-4eba-a736-f82b9d60a472": {"doc_hash": "09dc92217837420ec88810dfddcf7e1064cf6854b7954094c12626b1a694eb11"}, "3951ca83-bdfb-47d6-8700-0d89916f6517": {"doc_hash": "26544f894d422641f9228473f99e9298b096f284b63fb243702c634e31ad91f1"}, "cf68e250-56e7-4bf5-a2e5-450db965699f": {"doc_hash": "817473d417e6a91fadf8e2a91e8dbb34123b24af2abf0e3501062c1c38039622"}, "c3855e5b-d97e-4ffc-be2d-88ee00bb79dc": {"doc_hash": "c69ac86858535869549613afd384403e6ea1223c113980d286fcb33a8808f47a"}, "9e15f5a1-bf3b-4bc5-8764-d8c363c4c175": {"doc_hash": "eea53dbbaea59e0def4c6e1571f4f11f5d4d01201905a367b406d3c7e97c3e78"}, "19e568b1-e141-41cb-8c28-ef1c0b6f5980": {"doc_hash": "b3168ed197432840582fb58bd16b0f457d683d6242eed5ba8bbbbaacb66667d6"}, "efbf3b52-2a27-4f51-8b8a-1a09cc9fc1d0": {"doc_hash": "5592725123a9d190fe88229553046fa4d7e3f9fbf7ee7f33c764e86e41077e36"}, "73c51e20-e10d-48c1-a8bc-b6e86408c306": {"doc_hash": "80d4e55ba10d2e8b5fe18a0395a560796d099f24294e56b403ed9769c00ab204"}, "4820631e-88ee-41b1-871d-0154ab40dc09": {"doc_hash": "73e7f1accc607a1ed7ad6b24f176edab79e9bb8b1418c9a1677aa9cc2baeaaf0"}, "7dc68786-080d-4550-93c2-afd965f6d5f0": {"doc_hash": "8d7983380b25cf0fcdaffd6b5aec7acd13fdd38674caee56c34b4715a1fe3c8e"}, "fbd55246-7dcb-4857-881b-ae346f25b1e0": {"doc_hash": "6eaaedab0b2e7e51b689a1a2bfb15c1ca5b521bb2b4b566c5345b1d8ca4d2247"}, "abe3e6cd-e8b9-4374-8e20-1321515b6e88": {"doc_hash": "c0cd5d1c74f9d4856645dd4c637e667e8312a72cdd597d37c6592134941892a8"}, "afb4c753-534a-4d63-8594-be657b02adb5": {"doc_hash": "9c0385501f5aa1e6495822af4ef9da423114d16486079771e63a6f7acdce242f"}, "2f91fe93-f913-442f-9663-f7ccf2ca565c": {"doc_hash": "2bbc2282f078c9660011340c5ae3ccbf30d0eecfe314c507a0ffdbf881b09e9d"}, "4b2ffbc1-a237-464a-a289-82d2f049047d": {"doc_hash": "b973b703cd10965936dbb5c31deff06023bbae80b35a3629b26d258921d85d49"}, "b0ddc2a5-e109-4b22-9b64-1209beed3b7f": {"doc_hash": "56d256f77f7db9b4e25da6b8b68bd4a7c797b79503403181eee56a12bfe8d8fd"}, "88f50f2d-7609-4d59-856c-aaacbbe7af69": {"doc_hash": "6cd5ac036ff62713763e54c1ed7453b143def4b42692f2c6f857464ed03ff98f"}, "1caf172e-223b-4ba2-9478-21f0f6f20eb8": {"doc_hash": "c62ee49e166add0886efb94fcc1be938b9e82443136d6dd442e5ada36a237132"}, "84330a73-4237-422f-85d8-be7d92ccb2b6": {"doc_hash": "8b3f94ade0e3a04e8b830cc1ed2064fea7be404848aaa5bdf6c09a85af6ae7bd"}, "aaebc1a1-7f67-4d4c-8131-12642caa7c5b": {"doc_hash": "308c8a1a9d6c7ca735239f4752bc58b2af10a31c0a673dbd06f21a56a7423063"}, "39987376-31b9-434c-8871-d56f37b4190d": {"doc_hash": "12db756ba56c5716684f4a8494dfadc73b91d14259dccbefb17b1af5e15d2d7b"}, "8c1e17ca-e535-4902-9ba5-431075b68b34": {"doc_hash": "415292ec864643fcab523d2ad2a2f56224980a0796122f3b908d3a7d858083ef"}, "82e70833-7663-4cd0-a111-621dd03ab73d": {"doc_hash": "92c9bc3de3df52d0f8b3a7bfaf9ac187a2a3a6f0ff1ff1c1777e8758551b77b8"}, "59c71782-ba7d-49be-acd6-559d8ec35580": {"doc_hash": "ff1bae0c5398d88e0277c476366e8ab5579a0f6cba58a0bb9a306933975dd079"}, "3e676e23-79a2-4c02-bd80-a64b9986b998": {"doc_hash": "2d34d52453bd9e1fc658bc9378fe6e456e3b8f75518404efb05f8da9e5539200"}, "8926d179-566a-42be-aac0-c1be3b4ba7fe": {"doc_hash": "9cc471d004ed7dde7e21e67790a95e7fe272bc8dd159e0f02fb479a0486c7766"}, "b91f36cc-82e7-4d11-8013-444bcad2da2d": {"doc_hash": "cd3a9190b94a9ec77d861b45510d5bb4d0f8672a405e9690f0d17051d88fd3d5"}, "fcc8f752-b1e0-46fd-a76b-e9ed6f6e86a5": {"doc_hash": "6a850e75213438891d1a42acd04cf5faef20c911fd378891189be3998ebe4e60"}, "4691fe6c-00f5-49ca-9a3c-f7de59ae59a2": {"doc_hash": "f4d4f4daafd25118f54934e988cb99e94ac9555212da6fdb3c1d296bd18ccc6b"}, "54d555f4-2386-4def-a0d2-6722436f3d3c": {"doc_hash": "8b3bf26f4503b46438e53141cdac8e8a97e1dbffa9756dd7065c9666a703571c"}, "f2698d9d-dce1-4258-bc3c-c4ea8972c5e4": {"doc_hash": "b87187db494d7ab3a4b05078277b26e6c2923d9c5eb9dbe83f30ee929ed1bdc6"}, "e2f4eb12-b142-462b-b4b1-3632b4b5eead": {"doc_hash": "fb89d3560c7414658a09fbfd666fde5324295ee726f32204a7bc39b0b4d97132"}, "ff57dd9c-9777-4b21-ae66-c05e633f4e2d": {"doc_hash": "1faf0dd91848067a35637e70d092ce6e20aa62f35b545b690c40aa6cf9ac3399"}, "deee7b94-225f-46c8-9277-ce66e9b10048": {"doc_hash": "2c734106d920d5c535068faa05f776dc076da52b48214aca97187a1e2923cc89"}, "50e689f9-80cd-4e74-9aa0-467bd871f9f3": {"doc_hash": "dac2334b2895df7856d6f203d026d8d24eb21ea8cbef3be5212de3dc00e5e9da"}, "c112af4c-973a-468d-b06f-21a01feca3d9": {"doc_hash": "82e8d8b3b60e58df0ffcfb714c188cfb9f742fc9239651938dea876c49de3024"}, "eba8089e-b98a-4e12-9f7c-b855bd08b2b8": {"doc_hash": "f8e9b102bc441e194e1dc3258f301ea75118d6423c6089b56a657a1215ac094e"}, "b33486ec-13c8-4894-9156-f068eb1b9e70": {"doc_hash": "1a18d015a46a5d5d77fba430071f78b04767631a4f8fd5d28001aedead57023c"}, "1387ff26-3256-4984-a4bb-e54730b51400": {"doc_hash": "aee3744e6c0d478a02ff051c31e10a5d11f72587c42848ee7f0d862d425504e2"}, "f49c5bdc-f63f-4d5c-b88f-aa29c46bbae4": {"doc_hash": "7111fd88169a14cbc9221b6c129f704cbb27b74edb9cdc275868e8d984489529"}, "3bf38332-bac3-4143-8690-c927d430e97e": {"doc_hash": "7ca191b8b99e55f692f232fb61b41bd5e4541b649b3bb14656499f3facf7b991"}, "2adb2b7e-082c-4a42-9837-782e620496c1": {"doc_hash": "3a3f1ae1415dc6c1ab883c6f454fa86cf379ece1f3a6d6eb5137d693d1159a16"}, "4a8df4ab-6589-4233-b544-a3ad76250fd4": {"doc_hash": "d8dda4e62e28c67b0fa24bc43e7648322e3194fd7b96ce14a9cddaaa6950298a"}, "0dccf6bc-4f9d-4abc-85e1-abcb9064afba": {"doc_hash": "93fe881c6cb9ba368a329d6908594f0a53d2f2ec9e9402075cdd4331f8cec218"}, "9f96fce6-c765-40c9-b323-f51cae4f7743": {"doc_hash": "1fb550db3c2b29785bc729a8fdee8537ad2a2e13472e15290129bcd77bcdd6a3"}, "362e4485-5064-42a1-97a7-d09af70ca3ca": {"doc_hash": "bcb9d27fa7783f9dfb4ef86694cc15e401ae69b8a67f7002709d6dcfc1485c7a"}, "bc3f1398-5d5c-4bea-b628-3aef68c9fcfc": {"doc_hash": "a2a15f4f222bc31ce0e66b376448e35a0cd5e00e054a461ff6b9375ebecc7cad"}, "c602bdcc-dfcb-49de-b3fe-b7ce20cec22f": {"doc_hash": "590a6b173f408004ceddef1c33528fb0896d843c0aff45f1a9eba1fef7f05264"}, "f5eeb6a5-a798-4c24-94c3-cfbded5c0791": {"doc_hash": "5990ab2702c189fbfa71fdb5263f8690d24b8d6696d8455d12839295ef217378"}, "66c96198-50ac-48ae-a0ba-be4889481830": {"doc_hash": "8f33e2658af4937446f65b0f3199fea3daf90ffca43a8596432d4215c1426350"}, "85072ab3-f0e0-4af4-87f8-562084e0f9c5": {"doc_hash": "626d57f8dbe356f1034890c3be908e0784584ae8c7445627a72f1e612f00f141"}, "c5025efa-8448-4703-9ddc-102bb36f6178": {"doc_hash": "3f3a8fcfd4f1d7966619d628a1a56298f8f45cd1e836037bcbcbdb92edac8099"}, "40378cd1-b687-484c-84a0-236cf6788554": {"doc_hash": "cbd96560f3cffa770145df2df7951d1649628ebb440c3b5373d5cdb1243dbed7"}, "7adfca34-4c7b-4345-9a56-88754c7d0ca9": {"doc_hash": "2a277aa4652541929aa2ca2a831d8f67e52819a6afe835d3b6aee7b4e1a928d8"}, "344ae456-2726-4054-9b54-b4cc3a4ad3b9": {"doc_hash": "f05c50f523d4df4e1116c723cb62f1fcea8ddeda418bcfd0723e7f5b7edf3084"}, "02559d49-d142-4f53-855b-2328ed88c9a2": {"doc_hash": "a495db03770bae2a4ec3a91d923155a603742ac9d2b10f6792f8b2ddf8ec401b"}, "89d7871f-c63f-47da-9922-62a38df00c55": {"doc_hash": "2e0eb02f5e7ed5e166e117163f908ee6f7cdaaf6a52512ed1d424b909e7d49c1"}, "06a59f7c-2bea-4156-8566-535fa6a7f293": {"doc_hash": "8abf2df30a714d389bc9e61dfe54b264a95d5065e31770498233e9a1f4a64cdf"}, "d3530761-99fd-4e7d-b8b2-fc035b40e2fb": {"doc_hash": "dc7a99988e57a4f9ceb2c353dbeb7f6e52cff2f1b9c1b18c248d25683b76427b"}, "1a52e426-c073-474e-8aa9-d094436ce2df": {"doc_hash": "b29e9940737bf66982969aad00b6346ab2574b702970d17e46ac975ab20fe00a"}, "76693ae3-af05-41f0-97dd-8770e5d4f85e": {"doc_hash": "16843c8e6b05e6651563f040555f6b48c27fa952bc3ec474766f7af7bcd5e6af"}, "f75533e8-cab0-410c-aeb2-d7b6eeb594f3": {"doc_hash": "d9a0765b644e446947d71673fc0e33ba9804d4c54945f0d986a74cf4aefd1e39"}, "99807eae-fd47-468b-bcec-a9b53982d61f": {"doc_hash": "94b0eedb8eec90204629fabeac8c429fdbfb89a4ca8e373975351b625d893063"}, "fd6c4749-fff5-4215-9b98-49555d27101b": {"doc_hash": "b95e2804959c00688fea5a4db6711b1174145a0e92b1fc42b005142aa6b86582"}, "2805db4a-ec4c-4019-b67a-01264f0e943f": {"doc_hash": "4b5a8691765d11cf6137c858f9c439998d4fa195c9d8d5ee90e3a41826714741"}, "09bf3e45-6a9c-40e4-ac91-98e2f13dc8fc": {"doc_hash": "e324ede448e4b90d6d78554288634875431e88983c861fac7cb7b85436e3b645"}, "0b61ac98-43f1-4268-b8f0-6049fd2f81f4": {"doc_hash": "276475ce3154b15274b83853f15fb250ac1b9ea75426df87b65d68685cf62244"}, "22e4a004-61fa-40e5-a22d-8b844678bb92": {"doc_hash": "2e3106b0fcb8ab24e25456cc88aef3790ff47af5913ca0cfb42179e8862d9d1a"}, "4fe6dd89-af22-46b2-92b3-0f43c32e8d72": {"doc_hash": "60cb3b50e1755636fd13efcc218d12561a64c6d917377500af2c4eea2a0eeaf7"}, "beea5850-a79b-490f-adf3-0b3ec727f7f3": {"doc_hash": "83669b9b8ecf7dbefd7abf06ba97d561a6a2a667071fcb903203d9e4c64f76cd"}, "85b58cab-b764-4062-86c7-1a69ecad937f": {"doc_hash": "4cec2a67e9d7130285c2cce6f2234b7a2848924bf28a7a6ebe99818890e25d62"}, "85c65e15-db97-4825-9943-6ff092600e95": {"doc_hash": "21814030d1c36fca8427f8c8ed4bdf51a7c3fd199ff4b1159e14d5df1a1df3ec"}, "85501a4e-f55e-473f-ad42-ac780c182345": {"doc_hash": "dffc541904bc7952fc7067cb33d999e9ece6675567d8b72ae760c36f119a4f72"}, "ba1f2197-66c2-43dc-9c6e-908e5823937e": {"doc_hash": "5e1ba2aae4515ff053335ae1f593580edf6f46837d3c4ff6263f4cf5bc52a8ad"}, "ae1eb985-1d17-4d81-b056-26e14dd9b835": {"doc_hash": "9a59047d3ac60bf87008af29b4b55a2fc3cd0913bcdf71d044f03d4e08e1f72e"}, "c755d9aa-fa15-4858-a3fc-c3ad291e52f4": {"doc_hash": "b19e1d502dc52d525fe3ae344d42b856cde56536afe5a612c05e5463a9822d83"}, "01d72717-2dd8-4913-b56b-4d2b373cd93d": {"doc_hash": "081e24cb47285eda102620de23261d9696bd9e29121fad77dd6734698dda11ff"}, "1a97e1f5-4179-4c1f-a77d-19565412f136": {"doc_hash": "45c941ed5edc5a348765d62e9c45b184c6a23b1abd85ed553b10bde6680dccdf"}, "97e3321b-5467-40e1-83b7-f1cdb426f110": {"doc_hash": "06631f919287815c8165985554c6cb2b34f994126a705a0ac19e732e51592f39"}, "0cc9cb5c-e661-4855-9f3e-087f9d4cf9bf": {"doc_hash": "b09e77eb0345aee9b761a2e0f6850aa57152ede6a439b1beabd2281590db6378"}, "8611187c-205b-4199-9abb-2f7a47f9c0fc": {"doc_hash": "2fd0e93343b4e59472d5b28cc4fdd9771d21daf6c0c5c548840c85bf5ef1898b"}, "1cf33e8e-8146-4799-9066-07b2580fecf0": {"doc_hash": "6b64a5b4804c3476de63dc08d59ccaae39e460fcba2d4f62b0cd25da3fc9dc87"}, "d6fe59ae-42fa-4959-88d0-b4529dbcb034": {"doc_hash": "63fc56fd03c92436fd4c4323cb7cbc701018226fae620cea16d2a5a4cc8d2edf"}, "ec8fa6d7-3d2d-4d3c-8a5b-7a67434f89a7": {"doc_hash": "4c1ab5997d6228f273891777af18aeddc639f7e7f47764918a14b723a00a1fc8"}, "dd5bcfda-7b90-467f-a444-a1681d60abf6": {"doc_hash": "2fcd71586643dd95877a3a0a04fa931f568c01e8591395df5d451669edf0ff4a"}, "6158fb84-0234-4ac3-858d-ccc48e864fa9": {"doc_hash": "f34efd744252b758c1750dff4f3959d6f9c2f4eb81ba0eb8d5c16bd6ad688b05"}, "a6e92f78-5c0b-4703-8773-6bc9e8a4af53": {"doc_hash": "579866c0a70121b3831732a69202cf023331cdfe676b68b04a7659843b22b0ee"}, "c5d41baa-aecf-4a26-9a0f-b1708cca7cf2": {"doc_hash": "2bf42aa908b585fcc871bc6e8d2576666d812f7183d788ce3963ed3b0ac49ff1"}, "377ee3fd-0734-428c-bf10-fcfe344cc318": {"doc_hash": "32befae75f372c403e1d71f230c7dd0b79e88a5d83a500737deb8b694f623352"}, "7dd01402-49d4-4670-8d7a-fa3e8de1ab2b": {"doc_hash": "a13784c58614383178a59dfe05f1f3f207cb3f39fb1dd1bbd1dbfad289ada1ca"}, "631fdb47-6928-4a96-9188-a15102b881f0": {"doc_hash": "4df1afb6e3b23a60d0f3c44fddbfd6643c4e1ad437e5d17fdc00bb3b023ae611"}, "874de0a4-220c-4850-9d26-50c51e2d6bfe": {"doc_hash": "a82e6a0d1bf0c6730ab2fd50ee45e8636d78ac17559efa8a749a872a3167a7af"}, "6a0ac1f1-e8b7-4b42-a644-372cb58b1e6d": {"doc_hash": "cbc466b740d59a7109f5af1cad69c17022a22fe04ecd38df0f78189acd4b3109"}, "9db7d00c-b423-483d-87fc-856f69cca687": {"doc_hash": "bc5fe85ac7db5d5ec26f73c8f463834a6ddf706783363a5542c6e879dd01afae"}, "0a18d397-b760-474e-8d9c-565d8f47b29d": {"doc_hash": "fcad4e78fae71ea95a6be2a2b1156d3716024bcd5ad01ce989453fe0d673ae56"}, "e7c39aab-c1ad-40c3-b115-92d214f7c79b": {"doc_hash": "ccd8a251a591a1918f871e5aafd691eed7b222ef3828e537f6df80ecce66813b"}, "b8ee0692-9fe2-4f53-a318-b89a209265a4": {"doc_hash": "11b38a36e70c86564410e437ddfdd62bcf7463b275d7e3fab1dd0c205efadb6c"}, "48470833-6db9-4b9d-a658-934c20da83ca": {"doc_hash": "30c39fe8a90b87b313cb70e20d50ef58a854f98205264ca48d35be45df14d980"}, "cbdeba74-e658-4eb9-9816-d7b631dcf59f": {"doc_hash": "9095a9e3146a781075a048899ff324a0d7f1e20400b2df37a88aaf265383ee69"}, "b39f6e21-038c-485d-8138-2a5056c9bb5c": {"doc_hash": "c116236a06c97411e958034cfc9a735c80b3f83cf383da645803625a8163953d"}, "7239b683-cd52-4863-bcfa-0872b0cb97c2": {"doc_hash": "fe693eea4327f4927a68b8931d73ad3a8e79f1d34027900207f2027d75688e8e"}, "2b87975a-2805-47c4-8b8b-6a2b2f66d9ea": {"doc_hash": "e7d162f37b98a68b4b9b2188684862ceef407d3427c4e68551863a0a128b3f8c"}, "94087728-8f9c-4f1b-9534-46adb1c7899f": {"doc_hash": "c84284269cafa4ac0fa2695147ff5226ad8dc7928929af7657f07c457a7cf498"}, "8f491b07-95ef-49ae-97a2-8529ee5b9c45": {"doc_hash": "00fca52535c9d75bea87dbca9ead9f917eb90fd2cde3adf084768aede1799994"}, "a363c584-9a78-4df5-9b8d-b8d7396776ae": {"doc_hash": "127cbcff1fb84e2e84f834ed4ecda4958009faa661be013b89e9284b8222b310"}, "ad9494fb-5d43-449c-b165-e7bcec04341a": {"doc_hash": "d97fa784287905b73503fba999e79d438c4683102669ab5496ff57517835ae1d"}, "fc3c9be0-1dfc-42d6-9943-65dcbcbc3d2a": {"doc_hash": "6815e8aa6dab09d731b5afe0a298d1b5a2ea609d50efccd544c0065fcfac0992"}, "0ebef488-61ac-4da8-a0b4-f08531c33ebe": {"doc_hash": "d12ec9791e4f45ce700d8a143181ce3294c32ce808acca38ef64091a979df0aa"}, "c2bfeb1d-271c-483d-aa8f-cd7e57104ea3": {"doc_hash": "c7c3ae6cf28b73b08f67743b519e6a08acfceb7c8f855f4f15289a28caa7962c"}, "0b97270d-bc2b-4f79-b55c-77ffde38a845": {"doc_hash": "1244303f1f17fd439cd5a79bfe7261944606f28128b4d38ff8ee9b1d1581e33d"}, "d5f8a023-9cfd-4ab4-982d-f4c3456f1040": {"doc_hash": "53f90a1cf1a2348843b514d332f6e754bc797f0756ec13b3a0a5ba98b0fd6cb4"}, "25b92e63-fec9-434d-b143-34594faa01ca": {"doc_hash": "a03c4ac1e1f7c25b9045e7133e31b170e093c887b4188bf4f13168f40f13f7c5"}, "92a43e63-6501-4107-b0ef-be904b62ca24": {"doc_hash": "a35bb45b0586f63eebd56c58dbf651ed74f381a2d18d70624bfde4ff200c0828"}, "539bb7dd-fc68-45a6-be67-fb33adfd057e": {"doc_hash": "0d2d06d2b4914a1f5dd869afee5793b94fc2d95b39b9ac7cbbaa4fb2a75aeb49"}, "1d2f96aa-baa9-494c-9044-dce399687649": {"doc_hash": "d16342b809f7921122ca58c841181791435dfed8e3c89a5cf547d31ca44816f6"}, "2837b228-0fc3-4393-be77-279fe47129f9": {"doc_hash": "84d83c5c85f885b1aae4b2fa5981e45643b97fdfa2ba81657a98584d706da669"}, "d34eb661-b5b4-43c7-95c1-64dd36586c42": {"doc_hash": "13fc56d3b4acc9db0f4e12ec283b5614a5170fbf85ffbcb4f2d69fa2f447e633"}, "0bd24398-6fb7-4d31-84f8-8fb9ca9dde49": {"doc_hash": "ee44c348b34e07f213d1be642dd7c34994444eca4218d91a60385b1ff2b97a3f"}, "0f1cc6ed-1cf3-487d-9809-fc0cd4ac101c": {"doc_hash": "0c79cb51af24f1ec9b2ded8f9ff32421263cc7b8e5a6b163849de8dae9d4bca9"}, "b5dc7a52-9490-420c-a7fa-d8e88d048038": {"doc_hash": "9495a643c46f9596e6e53d1b636c78ef72885c4eba7f593dcbac954ab5609936"}, "7c04e0a5-695d-4a5d-bedd-df418147b0bd": {"doc_hash": "8d7316e0d5fd9afe2faced3ba53bda9166d3e9b563700d995301c1608cb9e979"}, "e0d3dda5-ec4e-4bc5-83bd-18c9305fc34f": {"doc_hash": "8222eaeee0fa604a8ab8261342845337fafd2a0bf223cf7edb8d60d9469a0d51"}, "17a298fe-fdb5-420a-ba45-d433511bd530": {"doc_hash": "a66fd9dbff65c4f951258f607d58b3699fc9c8e27071814ffaf13c50e634a119"}, "bc7083cb-4587-4b28-915c-822014959b30": {"doc_hash": "650192c70c445b392591a876401700528a5f641530223237fd0f08c4ccdb4509"}, "e18e2f3b-abd0-4348-8846-572392427fb4": {"doc_hash": "95d3b99f43293aaf0f8fd278d0423b152646c971f1a696de0e09b52f8d3205fc"}, "c769956c-ef4b-47c7-bd06-67d529b86e25": {"doc_hash": "3a8d2f44ae00d6e6d175eda76d139daed858c685e7d235c05f7cfa12488506d4"}, "5cbee39e-004c-4d65-9c93-f39a70765d8d": {"doc_hash": "964d1d4ce64269db1cbfd17aa2ac684f027709466570e569f32db1ddc247e1de"}, "1f1bdce1-29f3-4bde-8ac7-2ee1f901fa6e": {"doc_hash": "ab4d2d9e792f9261ef2327a38285f718a875af88b7727c4ca86cad1ec136fd07"}, "c5597bbc-4941-4ba3-a88a-17fe1cde0aa8": {"doc_hash": "be3ec362d8c188af7f27250dba93fdbf9217f76940f1c38c3b75d3ffcb2e1806"}, "30481454-c144-4574-a5ef-d4ff6e5a1c0a": {"doc_hash": "2b4f8bd56310c247791d92c141191aa01f0aaaf21c67ace123226374aafab5ca"}, "e63936d6-06d4-4636-bcc7-743f7fd51119": {"doc_hash": "9fe0a7e493b17fb83b338fb50cb023d024d3d58516b373a02584e37f58e9e15a"}, "8efb8f9b-0b55-4919-a1b8-a40d0c8d23b3": {"doc_hash": "06e5399f814b17d1f751fab9ce2e1c9789bf41d3b83a8177bd82dbcf12e53b2c"}, "419b2da0-b616-4cb3-ac8f-40d9fb96c4e7": {"doc_hash": "784b9bcf63858f470e6675f1173ae6f3ed2800affc3deb09c722d2a7774d3ce2"}, "09901796-e63b-4005-bd6e-8741a91e9b70": {"doc_hash": "d6053f77ac82a2db0bd1cbd22fe78de79c218b6df9be57993a2c2b8c46aed97b"}, "5e126043-0060-4a5e-8194-4e89bfd66a2b": {"doc_hash": "02de4beb85b5a06360a162d424966d70be2e20a6894df2df98779021d560b970"}, "d116cbef-1fa7-433b-9001-26d5d25914ab": {"doc_hash": "e9c37ebeef672f81e03e2033a7f8d8d0f4dc1ecd6646f2792b62cc812a390e68"}, "5f1bf227-8755-471e-8372-73968e9cd9b1": {"doc_hash": "5ff23fcd7352a2b5fef00d06b246e312b99047da02ddca0d7d38183630b8e17f"}, "dd54c94d-2b82-42a6-9455-096e626f3b9e": {"doc_hash": "fb778143f0d1d0c4869b1de41b1796613712717d5511fe534dfae13892b7dea2"}, "8d276309-5935-4593-909e-91ca503bfc97": {"doc_hash": "b070c645e87c9c60876f5ac883198764457f5fb33b0c91a09c2c7a41f519af89"}, "d081d663-72f8-4232-b975-7b682e3942c6": {"doc_hash": "3f2f66539b8d281a76c0e2de929d802bbe823f3c62c68aa06b1ef1462a7528de"}, "6a9146a2-ee8e-4520-90bf-4d67d2d50f8d": {"doc_hash": "395b5d5cb3c7e875c6620029b83a8cf36e861c546d52442c1cee5c65fd6ceea5"}, "ca4d2e75-5391-44eb-8f78-faf365ee34dd": {"doc_hash": "fc8b9760183bfb3248402443cfea3a043fe80b3d2a5c15a2f7d90c3337d74b87"}, "fa175df6-bc97-4dd2-b972-1b5eab594436": {"doc_hash": "fc0e95c50d2cc2f3bbc6b33a6b9e4859ea84eb274b6266d81be72794a1c9d633"}, "518fb9d7-3453-4bf9-89b0-852bf3792419": {"doc_hash": "2db97a564d8b6f1bf6de4d9883fc1a43cf9179c6ec804a6fe8d31c934fd432a9"}, "c06e334d-c1ac-4be3-ba89-40a1af82055c": {"doc_hash": "89778c5f273ce3a2eec36ee2b1220d379ca989fd5c78611304acdc3bbb906fbd"}, "0b3bd12e-4fbb-4cbc-b291-ad45256b0bde": {"doc_hash": "bc8e25a25050790248fa29ceb1e295c6c197ddc1cf88a5bd240f0b003342b5e7"}, "bc747c5b-3912-41d9-bc64-4e5075209227": {"doc_hash": "bf3e1a409b385649a1abd4276d8a4e74d99a3a4001088b7d789fcf792f22f28b"}, "100cb3e3-1eeb-4c0f-b98d-dbea4ce0b5b6": {"doc_hash": "84f231517e6ba4db217bd71608743aae7d743f71815a090f571072f2309f4197"}, "82dac807-fe38-4089-a723-94ef1f5d9c0f": {"doc_hash": "9686a6913f79fcf258bf45872e3cfddcd675e46fd99f8fddc8ea83362f88b60f"}, "70815a2f-51ec-40eb-b3b0-711dea9a5e8f": {"doc_hash": "60ab6aa7985b4e6b95e25652e2b94400145cd3bf6e1b772f1a039d63d4d4be72"}, "545dfed3-3de5-4cad-b95d-ee52bb84e405": {"doc_hash": "25d73e27d7b3782d66133f3f00696452b90d20e13c60dbfd02454468b88f10cf"}, "5124210e-abc6-4c29-b02a-a87efd9959c2": {"doc_hash": "6d6978116d576db0aedccfe89f3c46bc16f5260e6c9bd19014c63e49556108fc"}, "06c4ce9d-2b44-4f01-bc89-04890c8b0480": {"doc_hash": "be1946d6000798b061b98792a9ec0319e5d0fb904a093ad0a915aeccdea8c751"}, "71157f8a-d3ff-4396-9b04-a1cdfbc2120d": {"doc_hash": "c192a5e451ec97579b2d8c1decb3a912e808449d88d3812322d1371904ee1242"}, "a200338d-223d-4532-9290-8bbff8e364ae": {"doc_hash": "080d48c3908266ce22dd442d3df55dd397488c8964ed680909a487be135a89ce"}, "8fe4b6d4-b5f6-4430-8ea9-146cbd77f229": {"doc_hash": "0257f5ff340ec4124f1ec81eeaa7eb0691535942a80ea963a91d4d935c241191"}, "ba25bdb8-ee31-4ed8-82a3-d73c3a7b2ae7": {"doc_hash": "3b505ff3f46f11a560f67c2e7fef5f69a07ef1752df5d92c2bd7ac23b1629e47"}, "85c77d2c-b6be-4b53-84bb-9d7f91ff0f81": {"doc_hash": "fcf6027ca9a5b69dd9696db34a993e40e9973bf7d2bf83104317e2b19bfc94f0"}, "7af3b406-6677-46f2-99c8-8b73682fec66": {"doc_hash": "8ce60352b2ff75034a0314f288375de8ed4a6bf1014d3cb46d85c0ee58d3eca2"}, "19f9beee-9efc-4286-9fec-2003fd479be8": {"doc_hash": "bd7395ef28f74d241bfb009fb75d89398cc1f47e5a0a65b51e5bf4b0aee4acab"}, "5e9e730c-f8db-41a6-95b0-50af6a676a82": {"doc_hash": "0a5782f92a712d97cc2a896d424ed2c3144844c607a69f481dc55de5e92149c8"}, "fa3cff2c-8b8f-4440-924a-3516bf9bddb9": {"doc_hash": "7760203e5e1273658eab777e1838f18aeb6833b0d1d9894bbea169bac67c5417"}, "815762ae-ce4b-433a-bab9-3ae505807bfd": {"doc_hash": "ed6d936fad34ac5cc645cec9a959780d88f4d6624bc4560d3658a42b91334ff5"}, "f1f03e24-b948-4b6e-a278-24d4ccf94e3e": {"doc_hash": "fbb875743a91de5ad882043bfeaaae6e193a0ff632e76718155b1fe765d2dcdd"}, "f954a8a0-930e-4a6a-9e69-e078fa917e48": {"doc_hash": "552b79a6d015fdced1e936bed5220ea3667bbcc2349bde586432508b6b7e0c5b"}, "485ca214-6e60-4fde-a1a9-cfc5315b75ee": {"doc_hash": "d51fb6750828440d62f87f1b40081130498773af9d0236bb51d876f52c1b8e67"}, "3dfbe4c2-42df-4ff3-9b80-83c1fedbafb7": {"doc_hash": "58a8db176c38ed1dedc3eb7171fe217f68a62329c2a95de536c50d0c78bccd67"}, "cca0e4ea-348a-4c8e-a0ee-020020f1576c": {"doc_hash": "76cdad14fcebf3b7517956893ec514e648de09a2edc23bcee1d3ea848dc00893"}, "46aaa8c8-7afe-4574-be88-1b74643aa44e": {"doc_hash": "b6767a243482aefe218221e28ab035d5ecb4c6385f543e087f4772302ace1bd4"}, "e94dc342-1673-411d-8ade-156d6751ef6d": {"doc_hash": "464228e73168b1164db937199b619d0adfcc42a44a85221440f7b16eba9b41d9"}, "229c5343-3c1c-44a9-bceb-38ba58aa6893": {"doc_hash": "c7e5c81048c942a47c329bd0b14a47899e0cf59efa2a89f72441ed28431cb026"}, "7ddb5cf6-3fdc-4ff1-964e-5bafd63a1eea": {"doc_hash": "c8d41a0e9ec04778a6b8711dba46d56e3ae642b561d2652ccf7fb1ef00408b5a"}, "1e74a9e4-ec7a-4d05-9769-810f99a4fbd1": {"doc_hash": "7194833959e4cd7a916390bd5b1e4e2246d75aa17b4090eb6c45da4289a3bf02"}, "031d683f-88dd-4f1b-8970-ebe43f068696": {"doc_hash": "240fecb4cb8ed7ef2e7e0da3db61e16e7307dc194133772f7c4773c4193c83e4"}, "fbb00ba4-250d-4aa2-803a-4fc1f5bd2a8b": {"doc_hash": "494610e1f6f703686d91dff9faaa8ca58c4098c65fa341f80ac44bfd10147824"}, "42901de3-95a0-4b28-8f19-a76882e91289": {"doc_hash": "29ef45558e25bf269eee2cc0ca4e34a817098248be770a4c9509bd1460e988c1"}, "b82131f5-5f01-46da-8145-8f26eb44900d": {"doc_hash": "ae605fc0f02d9244b0add24c08a34ada8b3f071fb2d9dc861fbeada757e02503"}, "68faac79-d19e-4e23-87bf-7428690712a1": {"doc_hash": "b665bfece1b36579020ace6701c6f135cf79d3aeaceffe6bf3c1e1bf7fc0b4af"}, "c22974b9-ef5b-4948-a5c2-95e7f8dfa3d6": {"doc_hash": "09bec26a18e82364fef8654ac6d2c58b9c8917b9dbbbcb6983aed5f77e222982"}, "58733f77-7f4d-466d-a88d-95266231e557": {"doc_hash": "75ca62b00a96f1ee3d382ca2053937b5da0667ea6d8add443d9766b01f1be631"}, "09e1f3ed-5d69-418c-a0a6-762121cbf968": {"doc_hash": "43ce5ee55e7e7a8677d49f38093902a586171423be8201bccc3626dd6d5a1d1d"}, "573512dd-51e5-4a4f-8964-46232af53d3b": {"doc_hash": "4d39f6f603467b0285c55ea7357c98a3cdc7e4cfda801ac365fd930f3691c150"}, "d6847a83-83b2-467e-9fea-76eb388da366": {"doc_hash": "55692339dadb63ae3e54eca8b26eadc74e58dcfe62d008209453bfe1a605d404"}, "255634a7-0a9f-41f6-845f-58ff3c826c93": {"doc_hash": "828b093e0799e90defceceb3085dbb9a06ccf66d83e9b3019fde46cb0c84681b"}, "ca0622ef-032f-47eb-8eee-5c205efa3c03": {"doc_hash": "f1931c5f4fcca886ef432cc46286553415074d7a7cc805186e712f5dd49b2d98"}, "57780c9b-b334-497b-a854-9cd4f1902b53": {"doc_hash": "e507d31f94d0c4cad9976e4b86f00c42e7d19e86f2a62420407be20fb981452d"}, "63459516-479d-4de3-a6e4-16497d74e9a2": {"doc_hash": "9bea10b9cb9a17d0e873382cdfdeb09498ce0c085c33da0cdc9e12206d993e17"}, "bd263c35-deb5-4e8d-8b1a-1e95b7763c3b": {"doc_hash": "38a8018c2fff1a87c8a0bf8b7225d298ef80ec6d3aa35d422685e7272cd4ed21"}, "efe2ea5f-889d-4651-b328-11cb9aa58951": {"doc_hash": "0be172ce2fcf163bc4e4dc6a4f006531702e9e69fb2f362c32058af9ca474d66"}, "69f738d7-1004-467d-9bee-16fc406a925a": {"doc_hash": "0da5b0a7a2233fe0eddfb1ed5e6bd2b622ff7e709fbb0aa140090143867e6656"}, "623a1ac5-08c1-4cd9-93a2-b5574f3f459a": {"doc_hash": "a01fe05d163cdc5e498352a4bef7be8da72470ed6b1d966e666611bcd9107cfc"}, "42e84395-d2f6-43b5-ba85-baf020b56bb3": {"doc_hash": "c5e7905de42094e6907af50909f0602ef6f9775f694d7da84341af525e2f8853"}, "3eabcce0-2eb7-442e-a527-f189cb775b11": {"doc_hash": "2641fc76b58c3090c3229b0e9ac046665fe24823931e07e209ac7808d7700941"}, "a8f37ab5-f4a5-4d5c-892e-636cb229e89f": {"doc_hash": "ecdc504147012d9c1042436891b882e5eeb2aecc4860610f7d42c02aeb59f294"}, "51345c04-40f1-4950-ad46-934ef7cee709": {"doc_hash": "a98a8fc390d8e2c1c1c4a06788c7015ff816f5f9b66d9886ea963bd273ff8b71"}, "7d577519-c78c-4c12-a813-13947b79fe77": {"doc_hash": "0e49ab5acf4dc204fea86b685c9527a2978b2fcefa38dd9acbea8d79b23ee484"}, "27726a85-cc2a-4e54-afe4-0d1009faf7b9": {"doc_hash": "aa93e9c5face1a126c947b2371c9e3bb16111baf97741814403b47ec18c1ff00"}, "65892269-f76d-4883-8164-b2c8ff12d8c1": {"doc_hash": "6d2fed80090d391c456fa80d3ad1cbccbf5cfaca9b3b1ae083dfe0ce63e98a55"}, "c8aee3e3-ae3e-430f-8ec9-11c6a48d38f9": {"doc_hash": "1ee639bb1226f6c05d05f42e85ce525345a2e6527a6f4cbb02a23072d1e8f21f"}, "834f9bf8-e160-4733-b7ec-eb9d1f91cf02": {"doc_hash": "c2236199044a33e7f1536b40bc0a6361feb43fcc967573b975a56405465229ae"}, "f679c6e4-f749-4e4f-ab2c-21eca1ba6a16": {"doc_hash": "5e037a2150d83402f2e2217d407ecf04ffbf271a8aa1c41e6dddd2a5d92ba000"}, "a4341c63-d8a9-4f2c-be10-63349ab38d99": {"doc_hash": "4ad10661894e7ae4eb6ca0ebeb9875e014864dfaf4836bbd5cb18da0823a3c98"}, "76034520-14fb-45da-ae44-8b5026f17c86": {"doc_hash": "3e5806fb27629601766da6790d5b42f56e06932eedb38f6ada161aef558624ed"}, "db0e4b4e-b61e-4a6b-89cc-037aac153fe4": {"doc_hash": "06f69445cb925b362f3b7604f96a4952a1b1ddcd038233ce70db02925fc7c64e"}, "fc667658-355c-4ba0-8cc6-56bff314bd2c": {"doc_hash": "829e7b2306f2cbad62de5b7703fc2708f9c6bff783d52c6bbc5554e3bcab48bd"}, "83da7a1d-779e-40b8-9082-257ef964ed62": {"doc_hash": "67c77925ef47ee92da68a79cdbec1dafc5d52d2ac21ca8645aab373947d7ed75"}, "a3389426-7f66-458d-a58d-6b4652a5d7c2": {"doc_hash": "51e83cfeeddb92092a7026500a50bd2e1e140cdf36e12d71efbae13b4279e446"}, "8ea884c5-e2b9-4db6-97e6-3eed7bc92b0a": {"doc_hash": "6df0601d42d7354abf6aafbe914d9103378f2d966947299a1287dd525617dbc7"}, "b49b9a95-9750-4c44-964c-83e201ef199d": {"doc_hash": "15cb3687740ffcf969720c308ecb97d761226f10c21e35272ccf9e4d25bf4048"}, "1b6e7f4a-489a-4653-b257-513b6bb44806": {"doc_hash": "90c5672421fdc105f04491e53070321f9239d016e2dedc804b274c77ea8a4d83"}, "7c50a96a-da7c-48fc-9b57-cc95ba76fd5a": {"doc_hash": "97c957ecd58f923b36c7841dbcefe7ad22138e7d847360a473815e41cb72ed6b"}, "ae5f2525-38d3-4c51-862a-5d4f19dd55bb": {"doc_hash": "f82a0fab6dd191c90fa56ecab1a34c41b0145155467f594582daf3f4d9a8bded"}, "9cf024c1-ac41-42de-984e-d85b6bcb7c71": {"doc_hash": "e3face88293cb5de9ee597d71a7735def2860b928a122ad24abc8dd7c20d025d"}, "ed8f6a4a-976f-491e-9805-48330110f751": {"doc_hash": "0d589b78e7bf64f1b96674ba225293b4a76155435f9ed63460afdeef304fbca2"}, "f54246c7-b8af-409f-a7ea-00786a08e765": {"doc_hash": "bfeb2e814d34945c9e368e23567a2838c0a753fcfca148b24cc6de28568670e4"}, "69b552b8-4aac-4ab3-abca-891bef25ffbe": {"doc_hash": "71c62b278cc05c033739f569052306219ba647773e4050882aa80633bd092a04"}, "1efd8495-de1a-4be9-85ac-ae4031016a3a": {"doc_hash": "bfd6b3e0b5682932816d18c6b12fb26d554220791267891dd5e4f9d6f5fb3d36"}, "202885b5-583a-446f-8ec5-1823b7484e0e": {"doc_hash": "f1145c19ce560e83fafb51d5643cb42577c14bc3ebd3525076bfe331f070a9fd"}, "250f0ba6-64b3-4f71-aa24-4e7e1d336635": {"doc_hash": "264d22b09a99fc16ca2328f89afc9bff5f70d584cc74b174b9f2ae018cdfc744"}, "ac716cc2-563c-4e6f-8334-618a11e31496": {"doc_hash": "ae62e468b23a9b03e722842bf5866e1589038c8cb5f224991d1a4f4b658d37c7"}, "1a23136c-de80-4161-83b2-cc01b46fe134": {"doc_hash": "062f8183bd422d9462bf2495bbaf67f16983b95fe93dc805d913adb7b708b942"}, "c24da791-eb26-45d9-97e9-ead30635d5e2": {"doc_hash": "89b5ac9dbd3fea9227b95af0fb876b4571df7f236753d2a304e96254051b3197"}, "fef9f38e-a86a-4ec8-8d4d-d7e40ab5ddcb": {"doc_hash": "96ab41c665ffbb51cff672479f0aab11b7c32ea29fc2c6e4addf8e073090fe8b"}, "a7052f31-7c78-40e7-8040-d6469190f36c": {"doc_hash": "5c940944f6633f4795cd980e0a73b4c9a3798f1d94cb31d0946b88b52478991c"}, "b5e53e9f-4472-4237-a7d7-4c069c230131": {"doc_hash": "4601932ee4a5d8170c12bff63a09307b74ee0fedec2cc5eaf9f00300fe838d77"}, "b5597225-47a4-44c9-82a7-34836c8c464b": {"doc_hash": "bdc9f63a08a66426f7425de5848e8578ba5cd78e25372a768b90b22702f4f5ab"}, "ace301cd-32ac-4e28-b182-19e6c427bec8": {"doc_hash": "b232e9792b7d1af45a7b09362ca6be19dab13eb9986b5eb84bdf859403d8ad7e"}, "f210f2a0-87df-43e2-be5a-1a1b879c0e1c": {"doc_hash": "c152de1cf4062250689852dafc5b46e1bf6517ada4a515f7a5bbb498401f60ae"}, "75b7a919-cb53-48e3-998c-bd38a6682eed": {"doc_hash": "0991e89f8b73929f7df75e05db97e220b74e763278e40261a3808279ab3507f0"}, "152cedda-0414-4aff-bdac-a3d164adcd21": {"doc_hash": "b9cebe6a21f538f79fe06b8146e683fb2eb91fef59e5f4db20765e07ce5fb1db"}, "1434173b-9c9e-458e-9add-ff3d9e02970f": {"doc_hash": "dfa3a0f3ead8abb5d21d5cb5ab65c27ef535b2bfeeb1028032d16ddaaddc95c7"}, "8ec9f2ff-6b2d-4b04-b1ec-7db9510c7c09": {"doc_hash": "84ce2f1eeaa67bf1d43d09cca1d55bcf6ad458986b57dd583229cd23fe684d96"}, "b32bc6f1-a3d4-43b9-81b3-6760b22b6aa2": {"doc_hash": "396d02ea4d483da2d29965fad25f26d58e219212ee395969324c4fcc71bf3b63"}, "22bf9175-42d1-4b4f-b4fe-144ec2535aa8": {"doc_hash": "817473d417e6a91fadf8e2a91e8dbb34123b24af2abf0e3501062c1c38039622"}, "975e0ace-7b55-4ee4-b683-42d26d5c370f": {"doc_hash": "06cacf0a72bab411f5a2399b421443ded3d0df685f279990860fcb43a3a03943"}, "354cd449-3190-4c88-a326-92bb5867c51f": {"doc_hash": "8ba646e1837165597ea255c8c57f20eeebd727d4bcea806a63af4ae55ef117ef"}, "1188d14b-64fe-4d60-a59d-1b4d66cdec8d": {"doc_hash": "dc52bdcc419b2445b7dffdfd17b0c7eaa6e1d7fad6b2f94bf7660c5092f046b1"}, "b946eb91-e836-44c7-a653-d45867483643": {"doc_hash": "5f241a3b0c7430f4ed85ffd687f4b5ad5f43bdd0c99b9b2428d8d7dbcb05100a"}, "8dc65f67-4f59-4cb1-8b6c-a2265cbd6b89": {"doc_hash": "dd1e406f96ccf257ded3a6c9d1b911d0ce7958342c743f4bcff4db93752be6fb"}, "ab08ece0-e381-4c4c-a70b-1e00b0b85b67": {"doc_hash": "f3c73fb8262cf3dd58f24d5de477c7b1279a823197fbd922ea7535fb32bddc94"}, "d57af40c-0ec6-42f6-9423-4e435ffc5df5": {"doc_hash": "5592725123a9d190fe88229553046fa4d7e3f9fbf7ee7f33c764e86e41077e36"}, "fc828adb-d45f-4185-b8f8-a9994da12a03": {"doc_hash": "80d4e55ba10d2e8b5fe18a0395a560796d099f24294e56b403ed9769c00ab204"}, "1f212c68-5704-4aa8-a508-215f9f26f82c": {"doc_hash": "73e7f1accc607a1ed7ad6b24f176edab79e9bb8b1418c9a1677aa9cc2baeaaf0"}, "7f2a3325-054d-490b-ab22-a1744d05f9ac": {"doc_hash": "1e2fc94d8febbbdccb2fbf153e355dcd8e81215697da7df28ca65370b32c5167"}, "319d334a-49c1-44af-a261-0dfcc14a73ec": {"doc_hash": "8b792b32776f31ad2773334a8c9e5048816ee417da9321d32bfb5b53d9174823"}, "30544676-c464-4660-9005-207b35b14897": {"doc_hash": "6971240c1337a8a0bc7fd6bfb605ebe0eef1d787e4cf30a3e18229d64cdd599d"}, "9ff27a2f-436d-4d0b-918c-f1ed0afa0e36": {"doc_hash": "c19b4f320c00d1de97a19d8cf20315162bdc184f012ce925b575c08fd4571ebd"}, "1869d25b-0f1d-4032-afdc-2ea79f07b888": {"doc_hash": "c91b600d2537d70db7b37ba8ad88f21afaabe60f95c912735b35c1c4614cad1f"}, "fb761f9a-8f88-400d-b587-a089566c1ebd": {"doc_hash": "795035c174e6956ffd17552349f4f343db9d25d0002e350539051c04d9e7f9d8"}, "8b223a07-ab21-4824-9b4d-a46d4ae1595a": {"doc_hash": "0eeaafaa4fa20815000dc588cfb0185cb2ca86043d274fd11854a5d528baa05e"}, "1737229d-4735-46d3-804b-37f1de91cf5d": {"doc_hash": "7c10f55ee007067a29b30c3fe522796b04f7b7ecc53ef3c04ca7ccb44a5254e5"}, "cde61f60-cf53-4451-85e2-3af2ca562b8d": {"doc_hash": "2bbc2282f078c9660011340c5ae3ccbf30d0eecfe314c507a0ffdbf881b09e9d"}, "5d43e204-8959-43a8-a0e4-fd11ed1e5e60": {"doc_hash": "3a67a218b3589d346a93510c19190e577413a170d671b4e06d40ea882078626a"}, "b688a8c2-bfb1-495a-b0d8-8e815c1ef6ca": {"doc_hash": "8d3184f46700537b33e27c4d24fce28e6319b44732cce4ad007272851e1ea73e"}, "fe8b4cac-4662-408f-a9b3-c060ad35adb1": {"doc_hash": "28a372b9d32dc6607560690515f1c34190866b6363b52ff4303230dd76726381"}, "70cd8847-364b-4f78-9a87-7d9441d18d1c": {"doc_hash": "12f6103a86558505e020b40981ddb5dd35f0d27c04260b66a25c9c17075db61d"}, "32b73124-84e4-42ff-bb0e-ccfb9166a75e": {"doc_hash": "6cd5ac036ff62713763e54c1ed7453b143def4b42692f2c6f857464ed03ff98f"}, "1d451b08-b570-43b4-9d88-1d8873b1bb3e": {"doc_hash": "01792c2564de11dfb21a4ba8ba44328f0587722e7d57da39f75d3fa2b46c09ea"}, "c421994e-6e99-43bb-8766-130c97381b4c": {"doc_hash": "be0bb59a37e843ee4cdd040e5a3451dbc0394d652e87f29c39c597c1686f87d4"}, "e041d512-134b-446a-8858-5e8afcc75218": {"doc_hash": "8b3f94ade0e3a04e8b830cc1ed2064fea7be404848aaa5bdf6c09a85af6ae7bd"}, "8cb64f55-802a-484e-954d-90e91ddb323c": {"doc_hash": "a5d1a50276faae6ac75e19798a9f12c39a5124a7e817ed5450aad635e701caf8"}, "c7109f6e-a9d2-4856-9a02-84a1ec22a411": {"doc_hash": "efa9469f82a7cc2d5bd522cbfe3e6e90ce3b3e0047e203cdef14cb85bd8a2c0f"}, "6ca90be7-5f8c-4866-965b-04ddbf784e02": {"doc_hash": "189b319a5120b5d1265c4d0581b2b6563c71d47b970ada0ecae9174539942a63"}, "dedcb646-c837-4f94-921d-1d99de6f1ce1": {"doc_hash": "9b9661fc8c5c10135e12390322e94037868a458792a7c920a50019112c7a18b1"}, "893923dc-7efb-44bc-90a8-6d6cc924f495": {"doc_hash": "415292ec864643fcab523d2ad2a2f56224980a0796122f3b908d3a7d858083ef"}, "be48b0d8-352a-4692-9368-1e9688775e24": {"doc_hash": "92c9bc3de3df52d0f8b3a7bfaf9ac187a2a3a6f0ff1ff1c1777e8758551b77b8"}, "1197ccc6-74fe-4f56-8e33-e48ed113a075": {"doc_hash": "ff1bae0c5398d88e0277c476366e8ab5579a0f6cba58a0bb9a306933975dd079"}, "d68551b8-8ddf-4843-8509-4760e2fc1be6": {"doc_hash": "2cd97fdc5014b96d073a201b43f9210511ca246ab1eb37e6fdd592f3c59e64c6"}, "be72173a-d3cd-4525-930c-65a1f625134f": {"doc_hash": "218c959d06219deff4bb597335a345adfea53767a9096319dcceb86c546696e7"}, "391ff019-167f-4e86-b874-c8a614614ef0": {"doc_hash": "e73afc896dd426234f7becc5b65cfdb138f4ae9e058faaffc65a574395a9d55b"}, "dfbd5717-1683-4e0b-900f-eb8c6e8eaa70": {"doc_hash": "a584e3b4a541162f39a040c1b04fb7d8ea2664af584c92c484f7635304341aea"}, "a8e8350b-cc07-44d6-9b61-1dc8aa16f627": {"doc_hash": "1cbb47606560c99d81ca4cd4157c31348eb9f49f4c8d0fec0f6d8fc910a04b94"}, "3101fe02-be67-4bbc-9913-94a137f27c43": {"doc_hash": "676b9e6ed402fbbe81fd0c73849e22daeae4b011924962eda139b8e66b56162b"}, "9b5178e4-f550-4214-ada8-13c4ead040b5": {"doc_hash": "6a850e75213438891d1a42acd04cf5faef20c911fd378891189be3998ebe4e60"}, "aeef7204-8348-42a8-845e-415e22c9026e": {"doc_hash": "55f87f9483874978d7b0a58961d9751cbb79631e1ccfafcb4cfc67a7e0fb5553"}, "145d2fc2-c740-43f2-ab77-467b6b1f6b64": {"doc_hash": "6f1e609ca550b8d67809b7c04705904a967c3d83ef8cf85f54bd4b54e485de7c"}, "cd422e25-4af2-44f8-a165-d44646e017e1": {"doc_hash": "8b3bf26f4503b46438e53141cdac8e8a97e1dbffa9756dd7065c9666a703571c"}, "215a51bf-f2c5-469d-bda4-dab59475af31": {"doc_hash": "3e37846718118496a9169fef7c7db909d6c3ae827e0c83b3e5a6767e7a7a699d"}, "00d8991c-a5f9-4eef-9285-0de59dde082b": {"doc_hash": "df62929e9955f89a784b84d7dd484a2d6924f06e99bcd6db9c3971810d56d277"}, "43d4f1f2-cdaa-41ab-a43e-7f68ce75b040": {"doc_hash": "fb89d3560c7414658a09fbfd666fde5324295ee726f32204a7bc39b0b4d97132"}, "07b397e1-872c-4aa1-bfc5-3d3c7d27d2da": {"doc_hash": "eef922d6dd4667162494bb52bef69d3fa196217a92af628df9da881d58775555"}, "d9939e53-0d11-4bb3-b918-ab2c55e4312e": {"doc_hash": "991926f39a1a52f81be2f79d05337c56e7f36047f64d7ece510a09c9d19bfa0e"}, "17b960f6-4438-4ae8-8061-5eb6830bdbe5": {"doc_hash": "fe029eedc09b9d79d8aa772293c2bca2ee1dc85f4f3fafad548898e7a4f0617b"}, "3a74c4df-2d58-4361-8910-1b66eabf36ef": {"doc_hash": "665cb0c13f4f4f8291a54849ac0679ef7c4df351532145c6d339e03ea524db9f"}, "d889749e-24de-4313-a2fc-bb6ad1c4c152": {"doc_hash": "dac2334b2895df7856d6f203d026d8d24eb21ea8cbef3be5212de3dc00e5e9da"}, "5dcabdd3-b2d4-482a-9377-fdfe51dd81c9": {"doc_hash": "82e8d8b3b60e58df0ffcfb714c188cfb9f742fc9239651938dea876c49de3024"}, "65d6f49a-474b-4728-bbf2-ce6ce4cce653": {"doc_hash": "f8e9b102bc441e194e1dc3258f301ea75118d6423c6089b56a657a1215ac094e"}, "d4ec40f1-0214-4ebd-8c5f-5aad2f836916": {"doc_hash": "1a18d015a46a5d5d77fba430071f78b04767631a4f8fd5d28001aedead57023c"}}, "docstore/data": {"1387ff26-3256-4984-a4bb-e54730b51400": {"__data__": {"text": "Image Classification Methods Based on Texture Analysis and\nCharacterization\nby\nSteve Tsham Mpinda ATAKY\nTHESIS PRESENTED TO \u00c9COLE DE TECHNOLOGIE SUP\u00c9RIEURE\nIN PARTIAL FULFILLMENT FOR THE DEGREE OF\nDOCTOR OF PHILOSOPHY\nPh.D.\nMONTREAL, OCTOBER 12, 2022\n\u00c9COLE DE TECHNOLOGIE SUP\u00c9RIEURE\nUNIVERSIT\u00c9 DU QU\u00c9BEC\nSteve Tsham Mpinda Ataky, 2022", "doc_id": "1387ff26-3256-4984-a4bb-e54730b51400", "embedding": null, "doc_hash": "aee3744e6c0d478a02ff051c31e10a5d11f72587c42848ee7f0d862d425504e2", "extra_info": {"page_label": "I", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 334}, "relationships": {"1": "c8f20c40-73d8-4c54-9076-5ffa8bb1e6ff"}}, "__type__": "1"}, "f49c5bdc-f63f-4d5c-b88f-aa29c46bbae4": {"__data__": {"text": "This Creative Commons license allows readers to download this work and share it with others as long as the\nauthor is credited. The content of this work cannot be modified in any way or used commercially.", "doc_id": "f49c5bdc-f63f-4d5c-b88f-aa29c46bbae4", "embedding": null, "doc_hash": "7111fd88169a14cbc9221b6c129f704cbb27b74edb9cdc275868e8d984489529", "extra_info": {"page_label": "II", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 203}, "relationships": {"1": "d9433b40-a638-41c6-abd6-04ff384f1bb0"}}, "__type__": "1"}, "3bf38332-bac3-4143-8690-c927d430e97e": {"__data__": {"text": "BOARD OF EXAMINERS\nTHIS THESIS HAS BEEN EVALUATED\nBY THE FOLLOWING BOARD OF EXAMINERS\nM. Alessandro Lameiras Koerich, thesis supervisor\nSoftwareandInformationTechnologyEngineeringDepartment,\u00c9coledetechnologiesup\u00e9rieure\nM. Ismail Ben Ayed, president of the board of examiners\nSoftwareandInformationTechnologyEngineeringDepartment,\u00c9coledetechnologiesup\u00e9rieure\nM. Jose Dolz, member of the jury\nSoftwareandInformationTechnologyEngineeringDepartment,\u00c9coledetechnologiesup\u00e9rieure\nMs. Aura Conci, external independent examiner\nDepartment of Computer Science, Fluminense Federal University\nTHIS THESIS WAS PRESENTED AND DEFENDED\nIN THE PRESENCE OF A BOARD OF EXAMINERS AND THE PUBLIC\nON AUGUST 24, 2022\nAT \u00c9COLE DE TECHNOLOGIE SUP\u00c9RIEURE", "doc_id": "3bf38332-bac3-4143-8690-c927d430e97e", "embedding": null, "doc_hash": "7ca191b8b99e55f692f232fb61b41bd5e4541b649b3bb14656499f3facf7b991", "extra_info": {"page_label": "III", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 729}, "relationships": {"1": "0ad4a960-bb03-4018-94d7-36e99bbc796a"}}, "__type__": "1"}, "2adb2b7e-082c-4a42-9837-782e620496c1": {"__data__": {"text": "ACKNOWLEDGEMENTS\nMay those whose names have not been mentioned receive the expression of all my thoughts,\nrespect, and appreciation.\nPraise ye the LORD: For thy lovingkindness is better than life; my lips shall praise thee.\nTo my advisor/supervisor Dr. Alessandro Lameiras Koerich, for the trust and credibility placed\nupon me since the beginning of this journey. My gratitude for his instructions, adequate\nguidance, and inspiration. Likewise, his patience, the opportunity for growth, understanding\nunderchallengingtimes,andcommitmenttoalwaysbepresentwhenrequested. Iwillperpetually\nhave respect, friendship, and admiration for this great man.\n\"Asamatterofself-preservation,amanneedsgoodfriendsorardentenemies,fortheformer\ninstructhim,andthelattertakehimtotask.\"Diogenes. Asoftheformer,BesidesAtaky\u2019sfamily,\nI am humbled by having Patrick A. Bungama, Daniel-Charles E. Onan, Genick Masongele,\nMbamu\u2019s family, Helv\u00e9cio W. Pereira, L\u00edvio Linhares, and Diego Saqui in my life.\nI have been morally, emotionally or scientifically supported by , but not limited to, Jered Ataky,\nDr. Arist\u00f3fanesC.Silva,Dr. La\u00edseNayra,ReaganMampuya,AliM.Kumakamba,DidierM.\nKazadi,JonathanNyembwa,MagloreTshamaNoella,PlamediLusembo,RosinNgueveu,Dr.\nUlrichMatchiAivodji,Dr. ArthurSawadogo,NdiayeDiop,MouhammadDieye,Jonathande\nMatos, Pr. Norton Lages, Pedro Filho, M\u00e9lanie Maltais, Fernand B. Bi-Tonye, Dr. Thiago\nPaix\u00e3oandThiagoLemosFonseca,SamirSouza,Ra\u00edssaEverton,PauloJos\u00e9,OlavoandD\u00e9bora\nCastro, and Tio Domingos (InMemoriam), to whom I extend my profound gratefulness.\nI could not forget the contributions I received from LIVIA\u2019s members, to whom I am truly\nobliged.\nThisthesiswasfundedbytheRegroupementStrategiqueREPARTI-FondsdeRecherchedu\nQu\u00e9bec-NatureetTechnologie(FRQNT)andbytheNaturalSciencesandEngineeringResearch\nCouncil of Canada (NSERC).", "doc_id": "2adb2b7e-082c-4a42-9837-782e620496c1", "embedding": null, "doc_hash": "3a3f1ae1415dc6c1ab883c6f454fa86cf379ece1f3a6d6eb5137d693d1159a16", "extra_info": {"page_label": "V", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1826}, "relationships": {"1": "7521619a-5927-4eaa-b9f0-6470e648f2da"}}, "__type__": "1"}, "4a8df4ab-6589-4233-b544-a3ad76250fd4": {"__data__": {"text": "M\u00e9thodes de classification d\u2019images bas\u00e9es sur l\u2019analyse et la caract\u00e9risation de la texture\nSteve Tsham Mpinda ATAKY\nR\u00c9SUM\u00c9\nLa texture peut \u00eatre d\u00e9finie comme des changements dans l\u2019intensit\u00e9 de l\u2019image qui forment\ncertains motifs r\u00e9p\u00e9titifs. Ces motifs peuvent \u00eatre caus\u00e9s par les propri\u00e9t\u00e9s physiques \u00e0 la\nsurfaced\u2019unobjetoupardesdiff\u00e9rencesder\u00e9flexion,tellesquelacouleur\u00e0lasurface. Bien\nquelareconnaissancedetexturesoitrelativementsimplepourlaperceptionhumaine,iln\u2019en\nest pas de m\u00eame dans les proc\u00e9dures automatiques, o\u00f9 cette t\u00e2che n\u00e9cessite fr\u00e9quemment\ndes techniques de calcul complexes. L\u2019analyse de texture joue un r\u00f4le important dans la\nvision par ordinateur, et son fondement est l\u2019extraction des propri\u00e9t\u00e9s intrins\u00e8ques d\u2019une\nimage, avec lesquelles sa texture sera caract\u00e9ris\u00e9e. Une telle analyse est remarquable dans\nplusieurs applications telles que la t\u00e9l\u00e9d\u00e9tection, la m\u00e9decine, l\u2019agriculture, l\u2019analyse d\u2019images,\nla microscopie, etc. Comprendre comment les humains font la distinction entre diff\u00e9rentes\ntextures permet le d\u00e9veloppement de techniques capables d\u2019accomplir cette t\u00e2che. Consid\u00e9rant\nque la perception des textures par l\u2019homme ne change pas avec les rotations, les translations ou\nles changements d\u2019\u00e9chelle, toute caract\u00e9risation num\u00e9rique de ces derni\u00e8res devrait avoir les\npropri\u00e9t\u00e9s fondamentales suivantes : invariance aux changements de contraste et invariance aux\ntransformationsmonotones. N\u00e9anmoins,dansl\u2019ensemble,lesapprochesactuellesdel\u2019\u00e9tatde\nl\u2019art pr\u00e9sentent encore des probl\u00e8mes de performances, d\u2019une part pour le manque de caract\u00e8re\ninvariantauxtransformationsg\u00e9om\u00e9triques,tellesquelestransformationsdesimilarit\u00e9,etun\ncomposantpertinentqu\u2019undescripteurdetexturedevrait\u00e9galementremplir,\u00e0savoirl\u2019invariance\nauxchangementsd\u2019intensit\u00e9telsquelestransformationsd\u2019intensit\u00e9monotones;d\u2019autrepart,\nen outre, de telles approches subissent les contrecoups de fluctuations al\u00e9atoires ou de bruit,\ncar les propri\u00e9t\u00e9s intrins\u00e8ques de l\u2019image en question ne sont pas conserv\u00e9es. Compte tenu des\nprobl\u00e8messusmentionn\u00e9setparcequelatextureformeunsyst\u00e8medemod\u00e8lesnond\u00e9terministe,\nla mesure th\u00e9orique de l\u2019information de la diversit\u00e9 \u00e9cologique, une branche de la biologie, peut\naider \u00e0 sa caract\u00e9risation au maximum possible. Pour accomplir cette t\u00e2che, les concepts de\ndiversit\u00e9, de richesse, d\u2019uniformit\u00e9 et de distinction taxonomique des esp\u00e8ces ont \u00e9t\u00e9 adapt\u00e9s et\nappliqu\u00e9s, et utilis\u00e9s comme descripteurs de texture dans cette th\u00e8se. Les r\u00e9sultats obtenus sur\ndes jeux de donn\u00e9es naturelles et histopathologiques ont montr\u00e9 les avantages des m\u00e9thodes\npropos\u00e9es, qui sont comp\u00e9titifs avec les descripteurs de l\u2019\u00e9tat de l\u2019art.\nMots-cl\u00e9s: Reconnaissance de Formes, Descripteur de Caract\u00e9ristiques, Mesures de Diver-\nsit\u00e9 \u00c9cologique, Indices de Biodiversit\u00e9 et", "doc_id": "4a8df4ab-6589-4233-b544-a3ad76250fd4", "embedding": null, "doc_hash": "d8dda4e62e28c67b0fa24bc43e7648322e3194fd7b96ce14a9cddaaa6950298a", "extra_info": {"page_label": "VII", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2785}, "relationships": {"1": "d64eb0eb-9bde-4fd7-b7b9-8fce3a336727", "3": "0dccf6bc-4f9d-4abc-85e1-abcb9064afba"}}, "__type__": "1"}, "0dccf6bc-4f9d-4abc-85e1-abcb9064afba": {"__data__": {"text": "au maximum possible. Pour accomplir cette t\u00e2che, les concepts de\ndiversit\u00e9, de richesse, d\u2019uniformit\u00e9 et de distinction taxonomique des esp\u00e8ces ont \u00e9t\u00e9 adapt\u00e9s et\nappliqu\u00e9s, et utilis\u00e9s comme descripteurs de texture dans cette th\u00e8se. Les r\u00e9sultats obtenus sur\ndes jeux de donn\u00e9es naturelles et histopathologiques ont montr\u00e9 les avantages des m\u00e9thodes\npropos\u00e9es, qui sont comp\u00e9titifs avec les descripteurs de l\u2019\u00e9tat de l\u2019art.\nMots-cl\u00e9s: Reconnaissance de Formes, Descripteur de Caract\u00e9ristiques, Mesures de Diver-\nsit\u00e9 \u00c9cologique, Indices de Biodiversit\u00e9 et Taxonomiques, Analyse de Texture, Th\u00e9orie de\nl\u2019information, Classification d\u2019images.", "doc_id": "0dccf6bc-4f9d-4abc-85e1-abcb9064afba", "embedding": null, "doc_hash": "93fe881c6cb9ba368a329d6908594f0a53d2f2ec9e9402075cdd4331f8cec218", "extra_info": {"page_label": "VII", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 2229, "end": 2870}, "relationships": {"1": "d64eb0eb-9bde-4fd7-b7b9-8fce3a336727", "2": "4a8df4ab-6589-4233-b544-a3ad76250fd4"}}, "__type__": "1"}, "9f96fce6-c765-40c9-b323-f51cae4f7743": {"__data__": {"text": "Image Classification Methods Based on Texture Analysis and Characterization\nSteve Tsham Mpinda ATAKY\nABSTRACT\nTexture can be defined as changes in image intensity that form specific repetitive patterns. Such\npatternscanbecausedbythephysicalpropertiesonthesurfaceofanobjectorbydifferences\ninareflection,suchascoloronthesurface. Althoughtexturerecognitionisrelativelysimple\nfor human perception, it is not likewise in automatic procedures, where this task frequently\nnecessitates complex computational techniques. Texture analysis plays an essential role in\ncomputer vision, and its foundation is the extraction of intrinsic properties from an image,\nwith which its texture will be characterized afterward. Such an analysis is noteworthy in\nseveral remote sensing, medicine, agriculture, image analysis, microscopy applications, etc.\nUnderstandinghowhumansdiscriminatebetweendifferenttexturesallowsdevelopingtechniques\ntoperformthistask. Consideringthattheperceptionoftexturesbyhumansdoesnotchangewith\nrotations,translations,orchangesinscale,anynumericalcharacterizationofthelattershould,\nlikewise, have the following fundamental properties: invariance to changes in contrast and\nmonotonic transformations. Nonetheless, by and large, current state-of-the-art approaches still\nshow performance issues, namely the lack of invariance character to geometric transformations -\nsuchassimilaritytransformations-andarelevantcomponentthatatexturedescriptorshould\nalso fulfill, to wit, invariance to intensity changes such as monotonic intensity transformations.\nAs afurther matter, suchapproaches sufferthe aftereffects ofrandom fluctuations or noise, for\nintrinsicpropertiesoftheimagearenotpreserved. Giventheissuesmentionedaboveandbecause\ntexture forms a non-deterministic system of patterns, the information-theoretical measure of\necological diversity, a branch of biology, can aid in its characterization to the maximum extent.\nAccordingly,conceptsofspeciesdiversity,richness,evenness,andtaxonomicdistinctiveness\nwere adapted and employed to build robust texture descriptors in this thesis, which are generic,\nindependent of macro-level variations in terms of contrast, invariant to in-plane rotations of\nthe image, explainable and interpretable based on biology concepts, and lend themselves to\nfast computation. The resultsachievedon naturaland histopathologicdatasets have shownthe\nadvantages of the proposed methods, which are competitive with state-of-the-art descriptors.\nKeywords: Pattern Recognition, Feature Descriptor, Ecological Diversity Measurements,\nBiodiversityandTaxonomicIndices,TextureAnalysis,InformationTheory,ImageClassification.", "doc_id": "9f96fce6-c765-40c9-b323-f51cae4f7743", "embedding": null, "doc_hash": "1fb550db3c2b29785bc729a8fdee8537ad2a2e13472e15290129bcd77bcdd6a3", "extra_info": {"page_label": "IX", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2643}, "relationships": {"1": "481ca465-436e-414f-96d2-2bdf47cfcc96"}}, "__type__": "1"}, "362e4485-5064-42a1-97a7-d09af70ca3ca": {"__data__": {"text": "TABLE OF CONTENTS\nPage\nINTRODUCTION .................................................................................1\n0.1 Problem Statement and Motivation ...................................................... 4\n0.2 Objectives ................................................................................ 7\n0.3 Research Hypothesis ..................................................................... 8\n0.4 Contributions ............................................................................. 9\n0.5 Thesis Organization ...................................................................... 9\nCHAPTER 1 THEORETICALFOUNDATIONSANDLITERATUREREVIEW\n.................................................................................13\n1.1 Texture ...................................................................................13\n1.2 Texture Analysis .........................................................................14\n1.2.1 Feature Extraction ............................................................15\n1.2.1.1 Statistical Approaches ............................................16\n1.2.1.2 Structural Approaches ............................................ 17\n1.2.1.3 Model-based Approaches .........................................18\n1.2.1.4 Transform-based Approaches .....................................19\n1.2.2 Texture Characterization and Classification .................................20\n1.3 Literature Review on Texture Analysis and Characterization ......................... 21\n1.4 Multi-resolution .........................................................................24\n1.4.1 Gaussian-Laplacian Pyramid (GLP) .........................................25\n1.4.2 Wavelet Analysis .............................................................. 27\n1.4.2.1 Wavelets ...........................................................29\n1.4.2.2 Discrete Wavelet ..................................................30\n1.5 Ecological Diversity Indices ............................................................ 31\n1.5.1 Biodiversity and its Measurements ...........................................33\n1.5.2 Taxonomic Indices ............................................................39\n1.6 Measurements based on Shannon Entropy and Multi-information ...................43\n1.6.1 Shannon Entropy ..............................................................43\n1.6.2 Multi-information .............................................................44\n1.7 Feature Selection ........................................................................44\n1.7.1 Linear and Non-linear Techniques ...........................................46\n1.7.2 Filter, Wrapper, and Embedded Strategies ...................................46\n1.7.3 Multi-objective Optimization Algorithms ...................................48\n1.8 Final Considerations ....................................................................49\nCHAPTER 2 TEXTURE DESCRIPTORS BASED ON ECOLOGICAL\nDIVERSITY MEASURES .................................................. 51\n2.1A Novel Bio-Inspired Texture Descriptor based on Biodiversity and\nTaxonomic Measures .................................................................... 51\n2.1.1 Images as Ecosystems ........................................................52", "doc_id": "362e4485-5064-42a1-97a7-d09af70ca3ca", "embedding": null, "doc_hash": "bcb9d27fa7783f9dfb4ef86694cc15e401ae69b8a67f7002709d6dcfc1485c7a", "extra_info": {"page_label": "XI", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 3277}, "relationships": {"1": "5752ae1a-bb91-4058-a827-536d44f0bdc1"}}, "__type__": "1"}, "bc3f1398-5d5c-4bea-b628-3aef68c9fcfc": {"__data__": {"text": "XII\n2.1.2 Biodiversity and its Measurements ...........................................54\n2.1.2.1 Diversity Measures ................................................55\n2.1.2.2 Taxonomic Indices ................................................ 57\n2.1.3 Properties of BiT Descriptors ................................................64\n2.1.4 BiT and other Texture Descriptors ...........................................66\n2.1.5 Case Study .................................................................... 67\n2.1.5.1 Channel Splitting ..................................................68\n2.1.5.2 Preprocessing ......................................................69\n2.1.5.3 Feature Extraction and Concatenation ...........................70\n2.1.5.4 Normalization .....................................................70\n2.1.5.5 Training/Classification ............................................70\n2.1.6 Experimental Protocol ........................................................ 71\n2.1.6.1 Texture Datasets ................................................... 71\n2.1.6.2 Histopathological Image (HI) Datasets ..........................73\n2.1.6.3 Description of Experiments ......................................74\n2.1.7 Experimental Results and Discussion ........................................76\n2.1.7.1 Experiments with Texture Datasets ..............................76\n2.1.7.2 Invariance of the BiT Descriptor .................................79\n2.1.7.3 Invariance to Intensity Changes ..................................82\n2.1.7.4 Experiments with HI datasets ....................................83\n2.1.8 Final Considerations ..........................................................86\n2.2E-BiT: Extended bio-inspired texture descriptor for texture analysis and\ncharacterization .......................................................................... 87\n2.2.1 Methodology ..................................................................88\n2.2.2 Extended Bio-Inspired Texture (E-BiT) Descriptor .........................89\n2.2.2.1 Diversity Indices ..................................................90\n2.2.2.2 Evenness Indices .................................................. 91\n2.2.3 Experimental Results .........................................................93\n2.2.4 Results on Texture and HI Datasets ..........................................93\n2.2.5 Invariance of the E-BiT Descriptor ..........................................96\n2.2.6 Final Considerations ..........................................................98\nCHAPTER 3 MULTI-SCALE AND MULTI-RESOLUTION TEXTURE\nANALYSIS ...................................................................99\n3.1Multi-resolution Texture Analysis of Histopathologic Images Using\nEcological Diversity Measures ........................................................100\n3.1.1 Ecological Modeling of Wavelet Subbands .................................101\n3.1.2 Experiments and Results ....................................................105\n3.1.2.1 Experiments on CRC ............................................105\n3.1.2.2 Experiments on BreakHis .......................................108\n3.1.3 Discussion ....................................................................111\n3.1.4 Final Considerations .........................................................111\n3.2 Multi-scale Analysis for Improving Texture Classification ...........................113", "doc_id": "bc3f1398-5d5c-4bea-b628-3aef68c9fcfc", "embedding": null, "doc_hash": "a2a15f4f222bc31ce0e66b376448e35a0cd5e00e054a461ff6b9375ebecc7cad", "extra_info": {"page_label": "XII", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 3418}, "relationships": {"1": "90ccd82e-8e53-436c-9048-d2d1007d56a6"}}, "__type__": "1"}, "c602bdcc-dfcb-49de-b3fe-b7ce20cec22f": {"__data__": {"text": "XIII\n3.2.1 Proposed Approach ..........................................................113\n3.2.2 Experimental Results and Discussion .......................................115\n3.2.2.1 Experiments with Texture Datasets .............................116\n3.2.2.2 Experiments with HI Datasets ...................................119\n3.2.3 Final Considerations .........................................................121\nCONCLUSION AND RECOMMENDATIONS ..............................................123\n4.1 Future Works ...........................................................................126\n4.2 Publications .............................................................................127\nLIST OF REFERENCES .......................................................................129", "doc_id": "c602bdcc-dfcb-49de-b3fe-b7ce20cec22f", "embedding": null, "doc_hash": "590a6b173f408004ceddef1c33528fb0896d843c0aff45f1a9eba1fef7f05264", "extra_info": {"page_label": "XIII", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 783}, "relationships": {"1": "6def78aa-5912-43d7-8f2b-4895d1b99bbe"}}, "__type__": "1"}, "f5eeb6a5-a798-4c24-94c3-cfbded5c0791": {"__data__": {"text": "LIST OF TABLES\nPage\nTable1.1Summary of some texture descriptors and datasets used in\nclassification tasks................................................................24\nTable2.1Averageaccuracy(%)onthetestsetofSalzburg,Outex,andKTH-\nTIPS datasets. The overall best result for each dataset is in boldface.\nThe best result for each texture descriptor is marked with\u2217...................79\nTable2.2Non-normalized feature values computed from different\nimage transformations applied to a texture image (Figure 2.9(a)).............80\nTable 2.3 Rescaled feature values computed from Table 2.2.............................. 81\nTable2.4Non-normalized feature values computed from different\nimage transformations applied to a histopathologic image\n(Figure 2.9(g)).................................................................... 81\nTable2.5Average accuracy (%) on the three texture datasets\nwith the BiT descriptor applying gamma transformation on\nthe images of the test set.........................................................83\nTable2.6Average accuracy (%) of monolithic classifiers and\nensemble methods with the BiT descriptor on the CRC dataset...............84\nTable 2.7 Specificity, sensitivity, and kappa for BiT+SuperL on the CRC dataset.......84\nTable2.8Averageaccuracy(%)ofshallowanddeepapproachesontheCRC\ndataset ............................................................................84\nTable2.9Average accuracy (%) of classification algorithms with the BiT\ndescriptor on the BreakHis dataset..............................................85\nTable2.10Average specificity, sensitivity, and Kappa (as percentages) for\nBiT+SVM on the BreakHis dataset .............................................85\nTable2.11Averageaccuracy(%)ofshallowanddeepapproachesontheBreakHis\ndataset. Alltheseworksusedthesamedatapartitionfortrainingand\ntest ................................................................................85\nTable2.12Average accuracy (%) on the test set of KTH-TIPS, Outex, and\nSalzburg datasets. The best result for each texture descriptor is in\nboldface ..........................................................................94", "doc_id": "f5eeb6a5-a798-4c24-94c3-cfbded5c0791", "embedding": null, "doc_hash": "5990ab2702c189fbfa71fdb5263f8690d24b8d6696d8455d12839295ef217378", "extra_info": {"page_label": "XV", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2150}, "relationships": {"1": "91fd8ee9-c807-46e9-88bc-7f28a267fe06"}}, "__type__": "1"}, "66c96198-50ac-48ae-a0ba-be4889481830": {"__data__": {"text": "XVI\nTable2.13Averageaccuracy(%)ofensemblemethodsandmonolithicclassifiers\nwith the BiT and E-BiT descriptors on the CRC dataset.......................95\nTable2.14Average accuracy (%) of state-of-the-art of deep and shallow\napproaches on the CRC dataset .................................................96\nTable2.15Non-normalized feature values computed from different image\ntransformations applied to a texture image ..................................... 97\nTable2.16Non-normalized feature values computed from different image\ntransformations applied to an HI................................................ 97\nTable3.1Accuracy (%) and AUC of monolithic classifiers and ensemble\nmethods with the BiTW descriptor on the CRC dataset for train-test\nsplit and 10-fold CV ............................................................105\nTable3.2Averageaccuracy(%)ofshallowanddeepapproachesontheCRC\ndataset for 5-fold CV, 10-fold CV, and AUC ..................................107\nTable3.3Accuracy (%) and AUC of monolithic classifiers and ensemble\nmethods with the BiTW descriptor on the BreakHis dataset at image\nlevel with train-test split ........................................................110\nTable3.4Averageaccuracy(%)ofmonolithicclassifiersandensemblemethods\nwith the BiTW descriptor on the BreakHis dataset at image level\nwith 10-fold CV.................................................................110\nTable3.5Averageaccuracy(%)ontheBreakHisdatasetofshallowanddeep\napproaches. For training and testing, all of these works used the\nsame data partitions.............................................................110\nTable3.6Averageaccuracy(%)onthetestsetofOutex,ALOTandKTH-TIPS\ndatasets. The best accuracy for each dataset is shown in boldface.\nThe best result for each texture descriptor is marked with\u2217..................117\nTable3.7Average accuracy (%) of the proposed method with related works on\nOutex dataset. The best result is marked with\u2217...............................117\nTable3.8Accuracy (%) of shallow and deep approaches on the ALOT dataset.\nThe best result is marked with\u2217................................................118\nTable3.9Average accuracy (%) of the proposed method with related works on\nKTH-TIPS dataset.The best result is marked with\u2217...........................119\nTable3.10Accuracy (%)of monolithicclassifiers andensemble methods with\nTiO and each descriptor employed individually on the CRC dataset.........120", "doc_id": "66c96198-50ac-48ae-a0ba-be4889481830", "embedding": null, "doc_hash": "8f33e2658af4937446f65b0f3199fea3daf90ffca43a8596432d4215c1426350", "extra_info": {"page_label": "XVI", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2445}, "relationships": {"1": "be9793ff-f0ab-408a-bcd0-7cac7bb272b6"}}, "__type__": "1"}, "85072ab3-f0e0-4af4-87f8-562084e0f9c5": {"__data__": {"text": "XVII\nTable3.11Averageaccuracy(%)ofshallowanddeepapproachesontheCRC\ndataset. The best results are marked with\u2217....................................120\nTable3.12Accuracy (%)of monolithicclassifiers andensemble methods with\nTiOdescriptoronbalanced8-classesimage-levelBreakHisdataset.\nThe best result for each magnification is marked with\u2217......................121\nTable 3.13 Accuracy (%) of shallow and deep approaches on the BreakHis dataset. ....121\nTable 4.1 Published and submitted articles related to this research proposal ...........127\nTable 4.2 Published articles not directly related to this research proposal ..............128", "doc_id": "85072ab3-f0e0-4af4-87f8-562084e0f9c5", "embedding": null, "doc_hash": "626d57f8dbe356f1034890c3be908e0784584ae8c7445627a72f1e612f00f141", "extra_info": {"page_label": "XVII", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 633}, "relationships": {"1": "7f17c82f-8843-47a6-96ae-1ec7e1f5b9e9"}}, "__type__": "1"}, "c5025efa-8448-4703-9ddc-102bb36f6178": {"__data__": {"text": "LIST OF FIGURES\nPage\nFigure1.1An example of Gaussian and Laplacian Pyramids from the same\ninput image. (b) First three levels of Gaussian pyramid; (c) First\nthreelevelsofLaplacianpyramidAdaptedfromAtaky,deMatos,\nde Souza Britto Jr., Oliveira & Koerich (2020) ............................... 27\nFigure 1.2 Multi-resolution representation of an image...................................28\nFigure 1.3 Wavelet decomposition for two-dimensional images.......................... 31\nFigure 1.4 Visualization of species richness...............................................34\nFigure 1.5 Taxonomic tree..................................................................42\nFigure2.1A gray-level image as an abstract model of an ecosystem of three\nspecies(threegraylevels): white(6individuals),gray(5individuals)\nand black (5 individuals).......................................................53\nFigure2.2Genericexampleofafour-speciestaxonomictreeforfourspecies\n(A, B, C, and D) and its respective distance matrix. This matrix\nshows howcumulative branchlengthcorrespondingto taxonomic\ndistances is calculated Adapted from Ricotta (2004) .........................62\nFigure2.3Construction of a phylogenetic tree for computing the taxonomic\nindexes. In each iteration (step), the image is divided based on\nspecies(graylevels). Theaveragespeciesvalueisusedasathreshold\nat each step......................................................................63\nFigure2.4Example of (a) rooted tree; (b) a dendrogram; (c) and the respective\ndistancematrixofgraylevelscomputedfromtheimageinFigure2.3.\nNote that (a) and (b) are equivalent. The dendrogram allows\ncomputing the phylogenetic indexes to infer the phylogenetic\nrelationship between existing gray levels in the original image.\nTherefrom, the taxonomic indexes are likewise computed ...................64\nFigure2.5An overview of the proposed scheme to evaluate the BiT descriptor\nand compare it with other texture extractors .................................. 67\nFigure2.6Samples from the texture datasets: (a) Salzburg, (b) Outex_TC_-\n00010_c, and (c) KTH-TIPS...................................................72", "doc_id": "c5025efa-8448-4703-9ddc-102bb36f6178", "embedding": null, "doc_hash": "3f3a8fcfd4f1d7966619d628a1a56298f8f45cd1e836037bcbcbdb92edac8099", "extra_info": {"page_label": "XIX", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2148}, "relationships": {"1": "9a315e8c-e491-453a-bb9b-d37530b9d5e0"}}, "__type__": "1"}, "40378cd1-b687-484c-84a0-236cf6788554": {"__data__": {"text": "XX\nFigure2.7Samples of the CRC dataset: (a) tumor, (b) stroma, (c) complex, (d)\nlympho, (e) debris, (f) mucosa, (g) adipose, (h) empty.......................73\nFigure2.8Example of HIs: (a) Adenosis, (b) Fibroadenoma, (c) Phyllodes, (d)\nTabular adenomaa, (e) Ductal carcinoma, (f) Lobular carcinoma,\n(g) Mucinous carcinoma, (h) Papillary carcinoma, where (a) to (d)\nare benign and (e) to (f) are malignant tumors................................75\nFigure2.9Example of texture images: (a) original image, (b) rotation 90\u25e6, (c)\nrotation 180\u25e6, (d) horizontal reflection, (e) vertical reflection, (f)\nrescaled 50%. Example of histopathologic images: (g) original\nimage,(h)rotation90\u25e6,(i)rotation180\u25e6,(j)horizontalreflection,\n(k) vertical reflection, (l) rescaled 50%........................................80\nFigure 3.1 General overview of the proposed scheme....................................102\nFigure 3.2 An overview of the proposed scheme .........................................114", "doc_id": "40378cd1-b687-484c-84a0-236cf6788554", "embedding": null, "doc_hash": "cbd96560f3cffa770145df2df7951d1649628ebb440c3b5373d5cdb1243dbed7", "extra_info": {"page_label": "XX", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 983}, "relationships": {"1": "96c77bb5-37ab-41ee-b781-e1c918802101"}}, "__type__": "1"}, "7adfca34-4c7b-4345-9a56-88754c7d0ca9": {"__data__": {"text": "LIST OF ABREVIATIONS\nBiT Bio-Inspired Texture Descriptor\nEBiT Extended Bio-Inspired Texture Descriptor\nHIs Histopathological Images\nGLCM Gray-Level Co-occurrence Matrix\nLBP Local Binary Patterns\nROI Region of Interest\nCNN Convolutional Neural Network\nT-CNN Texture Convolutional Neural Network\nBIF Basic Image Feature\nGLP Gaussian-Laplacian Pyramid\nGP Gaussian Pyramid\nLP Laplacian Pyramid\nSIFT Short Time Fourier Transform\nCWT Continuous Wavelet Transform\nDW Discrete Wavelet\nDWT Discrete Wavelet Transform\nIDWT Inverse Discrete Wavelet Transform\nPRFB Perfect Reconstruction Filter Bank\nLL Approximation", "doc_id": "7adfca34-4c7b-4345-9a56-88754c7d0ca9", "embedding": null, "doc_hash": "2a277aa4652541929aa2ca2a831d8f67e52819a6afe835d3b6aee7b4e1a928d8", "extra_info": {"page_label": "XXI", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 604}, "relationships": {"1": "1a6e4334-76cb-4d88-bfd1-a8a4b447ce3c"}}, "__type__": "1"}, "344ae456-2726-4054-9b54-b4cc3a4ad3b9": {"__data__": {"text": "XXII\nLH Horizontal Detail\nHL Vertical Detail\nHH Diagonal Detail\nDMg Margalef\u2019s Diversity Index\nDMn Menhinick\u2019s Diversity Index\ndBP Berger-Parker Dominance\ndF Fisher\u2019s Alpha Diversity Metric\ndKT Kempton-Taylor Index of Alpha Diversity\nwM McIntosh\u2019s Evenness Measure\ndSW Shannon-Wiener Diversity Index\ndHB Brillouin Index\ndDw Strong\u2019s Dominance Index\ndC Simpson\u2019s Index\ndENS Enspie Index\ndMcInt McIntosh Dominance Diversity Index\neCR Chao1 Richness Estimator\neGC Gini Coefficient\neHE Heip\u2019s Evenness\neJ\u2019 Pielous Evenness\neSE Simpsons Evenness", "doc_id": "344ae456-2726-4054-9b54-b4cc3a4ad3b9", "embedding": null, "doc_hash": "f05c50f523d4df4e1116c723cb62f1fcea8ddeda418bcfd0723e7f5b7edf3084", "extra_info": {"page_label": "XXII", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 540}, "relationships": {"1": "c7f8fe3c-0ec6-466e-b03e-cd6e0f4ad23a"}}, "__type__": "1"}, "02559d49-d142-4f53-855b-2328ed88c9a2": {"__data__": {"text": "XXIII\nSPD Sum of Phylogenetic Distances\ndNN Average Distance from Nearest Neighbor\neIQ Intensive Quadratic Entropy\neEQ Extensive Quadratic Entropy\ndTT Total Taxonomic Distinctness\nPCA Principal Component Analysis\nRGB Red Green Blue\nSVM Support Vector Machine\nXGBCB eXtreme Gradient Boosting\nHistoB Histogram-Based Gradient Boosting Ensembles\nLightB Light Gradient Boosting Machine\nSuperL Super Learner\n\ud835\udc58-NN \ud835\udc58-Nearest Neighbors\nCatBoost Gradient Boosting on Decision Trees\nLDA Linear Discriminant Analysis\nRF Random Forest\nGB Gradient Boosting\nExtraT Extra trees\nHOG Histogram of Oriented Gradients\nCAD Computer-aided Detection", "doc_id": "02559d49-d142-4f53-855b-2328ed88c9a2", "embedding": null, "doc_hash": "a495db03770bae2a4ec3a91d923155a603742ac9d2b10f6792f8b2ddf8ec401b", "extra_info": {"page_label": "XXIII", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 626}, "relationships": {"1": "0c66c84e-aff3-4593-b5a7-9c9b662996fd"}}, "__type__": "1"}, "89d7871f-c63f-47da-9922-62a38df00c55": {"__data__": {"text": "XXIV\nCADx Computer-assisted Diagnostic\nML Machine Learning\nBiTW BiodiversityMeasures, InformationTheoryandTaxonomicIndexesExtracted\nFrom Wavelet Subband\nCV Cross-Validation\nACC Accuracy\nAUC Area Under ROC Curve\nTio Three-in-One (TiO)", "doc_id": "89d7871f-c63f-47da-9922-62a38df00c55", "embedding": null, "doc_hash": "2e0eb02f5e7ed5e166e117163f908ee6f7cdaaf6a52512ed1d424b909e7d49c1", "extra_info": {"page_label": "XXIV", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 233}, "relationships": {"1": "d8fe86fd-982c-46b5-929f-6467620ada51"}}, "__type__": "1"}, "06a59f7c-2bea-4156-8566-535fa6a7f293": {"__data__": {"text": "LIST OF SYMBOLS AND UNITS OF MEASUREMENTS\n\u0394 Taxonomic Diversity\n\u0394\u2217Taxonomic Distinctiveness\n\u0394+Average Taxonomic Distinctiveness", "doc_id": "06a59f7c-2bea-4156-8566-535fa6a7f293", "embedding": null, "doc_hash": "8abf2df30a714d389bc9e61dfe54b264a95d5065e31770498233e9a1f4a64cdf", "extra_info": {"page_label": "XXV", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 127}, "relationships": {"1": "45ab85ea-948a-4c12-96c3-b9da323918b4"}}, "__type__": "1"}, "d3530761-99fd-4e7d-b8b2-fc035b40e2fb": {"__data__": {"text": "INTRODUCTION\nClassifying an image\u2019s pattern is one of the most challenging processes in digital image\nprocessing. Becausetheinformationextractedfromexistingpatternscanaiddecision-making\nin various areas, the proper adjustment and the improved techniques for their classification are\nfundamentalsothatanimagecanbecomeavaluableauxiliarytoolfordecision-making. The\ntexture is helpful information that can be associated with interpreting patterns related to various\nareas of object recognition. The texture of an object is a descriptor of its shape, size, shade, and\ntonality, allowing the visual impression of the roughness or smoothness of a given surface.\nLikewise, the texture is a way to interpret visual information using a natural characteristic of\nhumaneyes,foritcarriesinformationaboutthespatialdistributionofanobject\u2019stonalvariations\northetonalrepetitionofsomegroupsofobjectsthatarenotindividuallyidentifiable-luminosity\n-,andstructuralarrangementofthesurfaceconcerningneighboringregions(Petrou&Sevilla,\n2006). The term texture is frequently used to describe the sensation of touching an object. This\nexperience gave rise to terms like rough, smooth, and soft for classification purposes. There is a\ntexture present inthe imagesknownas visual texture, for whichthere is stillno agreement on its\ndefinition(Gonzalez&Woods,2009). Itisreferredtoastherepetitionofsimpleorcomplex\npatterns on a surface. These patterns can be identical duplicates that appear repeatedly or have\nminor or non-deterministic changes. There is also a link between the visual texture and the\ntexture of the physical objects captured by these images. As a result, analyzing this type of\ntexture is highly beneficial to object recognition. Accordingly, there is a need for computational\ntechniques that allow the classification of such patterns in an image, which not only improve\ntexture characterization - to the maximum extent - but also have a low computational cost.\nThetextureanalysisseekstodeterminetheneighborhoodrelationshipofthetextureelements\nand their position to the others (connectivity), the number of features per spatial unit (density),\nandtheregularity(homogeneity)therefrom(Traina,2001). Textureapproachesdevelopedin", "doc_id": "d3530761-99fd-4e7d-b8b2-fc035b40e2fb", "embedding": null, "doc_hash": "dc7a99988e57a4f9ceb2c353dbeb7f6e52cff2f1b9c1b18c248d25683b76427b", "extra_info": {"page_label": "1", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2211}, "relationships": {"1": "b46d0766-9d98-4522-9f67-3ac63412d1af"}}, "__type__": "1"}, "1a52e426-c073-474e-8aa9-d094436ce2df": {"__data__": {"text": "2\nthe literature to characterize an image can be divided into statistical and geometric methods,\naccordingtoTuceryan&Jain(1993). Theformerseekstodeterminehowandtowhatextent\nsome image properties related to texture may be distributed and then derives numerical texture\nmeasures. Thelatterinvestigatesthevarioustypesofperiodicityinanimageandcharacterizesa\ntexture using the relative spectral energy at different periodicities.\nTexture characterization is not trivial because this process presents considerable challenges,\none of which is related to the conditions in which an image was captured. Accordingly,\nlightinggeometryorintensitychangescansignificantlyimpactatexturalimage\u2019sappearance.\nMoreover, in both the microtexture and macrotexture, different types of texture may restrain the\ncharacterizationprocessandthedevelopmentofmethodsrobustenoughtorepresenttextural\ninformationfrom/inanimage,mainlywhenbotharepresent. Indeed,eachtexturementioned\nabovecontainsintrinsicpropertiesthatmayrequireaspecificstatisticalmethodtoberepresented\nto the utmost extent. In computer vision, this process involves image processing techniques\nused to characterize texture properties from an image. These techniques allow the extraction of\ndescriptors from an image or a region related to characteristics that refer to intrinsic properties\nsuch as roughness, regularity, smoothness, and so forth. Thus, choosing which texture analysis\nmethodtoemployforextractingfeaturesbecomeschallengingforthesuccessoftheclassification\nphase.\nA variety of classical and novel approaches apropos of texture information extraction from\nimages have been developed, namely gray-level co-occurrence matrix (GLCM) (Haralick,\nShanmugam & Dinstein, 1973), Haralick descriptors (Haralick, 1979), local binary patterns\n(LBP)(Pietik\u00e4inen,Hadid,Zhao&Ahonen,2011),wavelettransform(Arivazhagan&Ganesan,\n2003),Markovrandomfields(Cross&Jain,1983),Gabortexturediscriminator(I&Sagi,1989),\nlocal phase quantization (LPQ) (Ojansivu & Heikkil\u00e4, 2008), local tera pattern (LTP) (Saxena,\nTeckchandani, Pandey, Dutta, Travieso, Alonso-Hern\u00e1ndez et al., 2015), binarized statistical", "doc_id": "1a52e426-c073-474e-8aa9-d094436ce2df", "embedding": null, "doc_hash": "b29e9940737bf66982969aad00b6346ab2574b702970d17e46ac975ab20fe00a", "extra_info": {"page_label": "2", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2127}, "relationships": {"1": "623634bf-00d5-49b9-b3f6-661e1222180c"}}, "__type__": "1"}, "76693ae3-af05-41f0-97dd-8770e5d4f85e": {"__data__": {"text": "3\nimagefeatures(BSIF)(Kannala&Rahtu,2012),andfractalmodels(Kaplan,1999),amongst\nmany others that can be found in the literature.\nTexture descriptors, like in natural images, are becoming increasingly popular in medical image\nanalysis, particularly in histopathologic images (HIs), due to the variability of texture that such\nimagesexhibit. Asaresult, researchershaveinvestigatedawiderangeoftexturaldescriptorsfor\nclassifying HIs, which are expected to be insensitive to translation, scale, rotation, and intensity\nchanges. One of the most significant challenges in extracting features from such images is\ncharacterizingmorphologicalfeaturesfromstructuresobservedinHIsandexploringhigher-level\nrepresentations capable of capturing relevant information for medical diagnosis purposes. The\ncharacteristics listed above are related to recognizing tissue changes (such as cell density or\nabnormalcellquantity)orcellularchanges(suchasmalformednuclei)causedbymitoticphases.\nFurthermore, morphological characteristics are linked to how pathologists investigate HIs,\nlooking for specific reasons to classify them. In contrast, high-level features are generalizations\nof all structures in HIs, not just cell structures. As a result, most researchers exploit frequency-\ndomain representations or texture descriptors (de Matos, Ataky, de Souza Britto, Soares de\nOliveira & Lameiras Koerich, 2021a). Several approaches were developed to detect breast\ncancer through HIs\u2014nevertheless, accurate classification of HIs remains a challenge.\nMost often, such approaches concentrate on specific information in the image. Accordingly,\nmost select a finite set of texture features based on contextual information in the form of a\nregionofinterestextractedfromthelocalimage. Nonetheless,relyingsolelyonlocaltexture\ninformation may harm their subsequent classification because the texture is defined not only by\nlocal information but also by its global appearance, representing the repetition and relationship\nbetween local patterns (Liu & Fieguth, 2012). Furthermore, the presence of noise, which\ndistortstheobserveddata,isanotherfactorthatcanpenalizetheclassificationoftexturalimages.\nTypically, noise is inherent in the acquisition of real-world images.", "doc_id": "76693ae3-af05-41f0-97dd-8770e5d4f85e", "embedding": null, "doc_hash": "16843c8e6b05e6651563f040555f6b48c27fa952bc3ec474766f7af7bcd5e6af", "extra_info": {"page_label": "3", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2231}, "relationships": {"1": "c781fbf9-721a-472a-82e3-0a9fe31925a2"}}, "__type__": "1"}, "f75533e8-cab0-410c-aeb2-d7b6eeb594f3": {"__data__": {"text": "4\nIntothebargain,whenitcomestoclassifyingimageswithnoisytextures,traditionalclassification\nmethods and some current ones still have performance issues in most cases.\nDespiteextensiveresearchintotextureanalysis,thereisstillaneedtoinvestigateincreasingly\npreciseandefficienttechniquesthatmeettherequirementsofadiverserangeofapplications,that\nis,a context-freeorgenerictechnique,allowing forutmosttexturecharacterization. Therefore,\nthe main objective of this thesis is to develop approaches that, through the exploration of\ntextureanalysis,canproducediscriminantcharacteristicstoovercomethelimitationsfoundin\nexisting methods of texture characterization for both natural images and images that contain\nother structures in addition to texture.\n0.1 Problem Statement and Motivation\nIn recent years, the concept of information has become increasingly present and relevant at\nall levels of modern society. Because the volume of generated data has never been greater,\nbeing able to decode the symbols present in this vast ocean of information is an essential\nstepinlearning,understanding,andanalyzingtherulesthatgovernthemostdiversecomplex\nphenomena that are part of nature. Some of the burdensome challenges in dealing with this\nscenario are the mining, identification, processing, and classification of patterns and symbols in\nthe data produced by a diverse range of observable phenomena.\nAlongthesamelines,objectrecognitionisoneofthemostcriticaltasksinapplicationsinvolving\na computer vision system. The objective is to obtain a description that contains enough\ninformation to distinguish between different objects of interest. Typically, the recognition\nprocess relies on the objects\u2019 gray levels or colors, shape, and texture characteristics. Some\nexamples of applications involving computer systems are listed below:", "doc_id": "f75533e8-cab0-410c-aeb2-d7b6eeb594f3", "embedding": null, "doc_hash": "d9a0765b644e446947d71673fc0e33ba9804d4c54945f0d986a74cf4aefd1e39", "extra_info": {"page_label": "4", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1815}, "relationships": {"1": "3efa10be-030b-4c8c-a36a-9dd6e5702c5e"}}, "__type__": "1"}, "99807eae-fd47-468b-bcec-a9b53982d61f": {"__data__": {"text": "5\nRemoteSensing : Aerialphotographsmustbeevaluatedandcatalogedwithfidelityandefficiency\nto obtain cartographic maps and geographic studies, such as soil analysis and mapping of forest\nand urban areas, as quickly as possible.\nQualitycontrol : Imageprocessinghasawiderangeofapplicationsinthefieldofqualitycontrol.\nAlmost any industrial process that requires optical or visual monitoring can be automated. For\nexample, the inspection of circuit boards for defects and the separation of parts on an assembly\nline are two typical applications.\nMedicine : Images captured by magnetic resonance imaging (MRI), computed tomography\n(CT), andultrasound canhelp with medicaldiagnoses. Theyhelp locate thedamaged areabut\ndo not work at the cellular level; for that, a microscope level is required. In microscopic images,\nfor instance, the analysis and interpretation help search for cells that have been damaged by\ncancer and other congenital abnormalities, as well as counting blood cells.\nMicroscopy : The analysis of images captured by optical or electron microscopes in fields\nranging from biology to metallurgy to identify and classify cells or particles.\nIn the bargain, when it comes to texture characteristics of objects, it represents valuable\ninformationthatcanbeassociatedwithinterpretingpatternsrelatedtotheareasdescribedabove\nand numerous others. Notwithstanding, texture analysis, in turn, is critical for such applications\nnecessitating an examination of an object\u2019s surface properties, an understanding of how humans\ndistinguish between different textures, and modeling techniques capable of performing this task.\nUnfortunately, even though the texture is an essential aspect of surface appearance, it is difficult\nfor most approaches to manipulate its appearance while considering the effects of illumination,\nviewpoint, and image surface shape.\nAlong the same lines, texture and color are the main aspects of any natural image. Both\ncomponentshaveproventobesignificantinvariouscomputervisionapplications. Oneofthe", "doc_id": "99807eae-fd47-468b-bcec-a9b53982d61f", "embedding": null, "doc_hash": "94b0eedb8eec90204629fabeac8c429fdbfb89a4ca8e373975351b625d893063", "extra_info": {"page_label": "5", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2019}, "relationships": {"1": "97199ac2-09ca-473b-b562-72033d7c8b42"}}, "__type__": "1"}, "fd6c4749-fff5-4215-9b98-49555d27101b": {"__data__": {"text": "6\nassumptions apropos of color-texture integration is that both aspects are mutually dependent\nattributesofanimage. Therefore,theirextractionshouldbeaccomplishedeitherfromcorrelated\npairsofcolorchannelsorindividualcolorchannels. Inthematterofcolor,thechallengeisto\nconvey aspects of surface color appearance, such as the amount and the spatial relationships for\neach color. Even if most of the existing texture descriptors have proven to be discriminative for\ntexture classification, some do not exploit the color information that may exist in images, which\ncould bring - to some extent- relevant information. Human color perception appears so complex\nandnonlinearthatitcannotbefullydescribedbyanysinglecomputationalmodel,letalonea\nsingle linear model.\nOn the other hand, the demand for visual inspection automation in various tasks has grown\nsignificantly. Human inspection performance is frequently variable, making it unsuitable for\nprocesses requiring accuracy and speed of identification. In many cases, the same type of\ntexture must be analyzed repeatedly to detect anomalies, necessitating the observer\u2019s undivided\nattention. Severalstudiesshowthathumansdemonstratetheinabilitytoperformmonotonous\nand repetitive tasks. Furthermore, there are inappropriate environments where human presence\ncan be hazardous. These factors illustrate the need for, as well as the advantages of, using\nautomatedsystems. Amongthemisanincreaseinproductivity,animprovementinthequality\noftheproductsorservicesprovided,theabsenceofpersonalrisks,ahighrateofinspection,and\na reduction in costs (Tobias, Seara, Soares & Bermudez, 1995).\nThe texture attribute is an essential source of information for identifying objects or regions\nof interest in an image, contributing to increased classification accuracy. On the other hand,\ntexture-based segmentation and classification techniques necessitate the development of a set of\nmeasuresthataccuratelyrepresentit. Thus,thisthesispresentsdevelopedmethodsthatallow\ntexture characterization and classification tasks to meet this need. To that end, it was necessary\nto address:", "doc_id": "fd6c4749-fff5-4215-9b98-49555d27101b", "embedding": null, "doc_hash": "b95e2804959c00688fea5a4db6711b1174145a0e92b1fc42b005142aa6b86582", "extra_info": {"page_label": "6", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2098}, "relationships": {"1": "709f7dd2-1d45-4fb1-aebd-6ed0d8b31fa6"}}, "__type__": "1"}, "2805db4a-ec4c-4019-b67a-01264f0e943f": {"__data__": {"text": "7\n1.Thedevelopmentoftechniquesfortextureanalysisandcharacterizationinnaturalimages\nand those containing other structures in addition to texture;\n2.The adaptation and development of strategies that enable analysis with as much relevant\ninformation as possible;\n3.The image representation scheme that allows the biological concepts from the branch of the\nstudyofspeciesdiversity,namelyecologicaldiversityindicesbetweenspecies,richness,\nabundance,andevennessofspecies,tobeadaptedfortheextractionoffeaturesthatmeasure\nand characterize texture;\n4.Theexploitationofmulti-scaleandmulti-resolutionanalysistosupplycharacteristicsthat\ndescribe texture from an image to a great extent under distinct differentiations for bettering\nthe classification performance.\n0.2 Objectives\nConsidering the points raised in the preceding section, this thesis seeks new tools and novel\napproaches for the characterization of textures, intending to extract relevant information and\nthen recognize patterns thereof. The overarching objective of this thesis was to present the\ndevelopmentofapproachesforextractingfeaturesfromtextureimages. Suchapproachesare\ngeneric, provide a high accuracy rate, are independent of macro-level variations in terms of\ncontrast,areinvarianttoin-planerotationsoftheimage,lendthemselvestofastcomputation,and\ncan be explained and interpreted. Results similar to or better than those provided by traditional\nor state-of-the-artmethods availablein theliterature areconsidered tohavehigh accuracylevels.\nTheapproachesproposedinthisthesistoachievetheaforementionedgeneralobjectivearebased\nondevelopingnewtextureanalysisdescriptorsfoundedonbiologicaldiversitymeasurements\n(Clarke&Warwick,1998a;DaSilva&Batalha,2006;Magurran,2004b;Vandamme,Pot,Gillis,\nDe Vos, Kersters & Swings, 1996).", "doc_id": "2805db4a-ec4c-4019-b67a-01264f0e943f", "embedding": null, "doc_hash": "4b5a8691765d11cf6137c858f9c439998d4fa195c9d8d5ee90e3a41826714741", "extra_info": {"page_label": "7", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1780}, "relationships": {"1": "9eeb896d-fdd9-4ad3-9852-232897abf74d"}}, "__type__": "1"}, "09bf3e45-6a9c-40e4-ac91-98e2f13dc8fc": {"__data__": {"text": "8\nMore specifically, the research objectives of this thesis are as follows:\n\u2022Toinvestigate,adapt,andapplybiologicaldiversitymeasurementsfortexturecharacterization\nof textural images and images containing not solely texture;\n\u2022To propose new texture descriptors based on biological diversity measurements;\n\u2022To establish a parallelism between restoration ecology and multi-scale, multiresolution, and\nintegrative methods for leveraging temporal/spatial trends of the texture patterns;\n\u2022To compare the performance of the proposed descriptor against classical methods and\napproaches based on deep learning.\n0.3 Research Hypothesis\nOur point of view is based on the principle that data distribution of textures forms a non-\ndeterministic complex system; that is, its behavior cannot (or not always can) be predicted. We\nstatedthattexturalpatternsbehavesimilarlytoecologicalpatterns,inwhichlargepopulationsof\nunitscanself-organizeintoaggregationsthatgeneratepatternsfromprocessesthatarenonlinear\nand non-deterministic.\nTherefrom, this thesis investigated the following hypotheses:\n- The use of information-theoretical measures of ecological diversity indices in conjunction with\nmeasures of biodiversity can provide a robust tool for quantifying such a complex system of\ndiverse patterns;\n-Thecombinationofspeciesrichness,abundance,evenness,andtaxonomicindicescanintegrate\nproperties of statistical and structural approaches to texture analysis and take advantage of\necological patterns\u2019 invariance characteristics to permutation, rotation, and scale;", "doc_id": "09bf3e45-6a9c-40e4-ac91-98e2f13dc8fc", "embedding": null, "doc_hash": "e324ede448e4b90d6d78554288634875431e88983c861fac7cb7b85436e3b645", "extra_info": {"page_label": "8", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1544}, "relationships": {"1": "57cf3050-a58b-4e9d-8e81-eb20214c0a14"}}, "__type__": "1"}, "0b61ac98-43f1-4268-b8f0-6049fd2f81f4": {"__data__": {"text": "9\n- The exploitation of integrative methods, multi-scale, multiresolution analysis can supply as\nmany intrinsic properties as possible that reflect the local and global descriptors and summarize\nvalues that describe texture from color and gray-scale images to a great extent under distinct\ndifferentiations.\n0.4 Contributions\nThemajorcontributionsofthisthesisarerelatedtothecharacterizationoftexturepatternsbased\non ecological diversity indices. In general, the following three contributions are defined:\n1. Adaptation of Biological concepts, specially:\na. Ecologicalconceptsfromthebranchofthestudyofspeciesdiversity: (i)speciesrichness,\nabundance, and evenness; (ii) evolutionary relationships between species, topology, and\nshortest path; and\nb. Restoration ecology and referent.\n2.Development of descriptors: generic, independent of macro-level variations in terms of\ncontrast,invarianttoin-planerotationsoftheimage,lendthemselvestofastcomputation,\nexplainable and interpretable based on biology concepts.\n3.Modeling of texture image as an ecosystem of organisms for applying Biological concepts;\nand\n4.Establishmentofaparallelismbetweenrestorationecologyandmulti-scaleandmultiresolu-\ntion analysis.\n0.5 Thesis Organization\nThis thesis is organized in six chapters as follows:\nChapter1 presentsthetheoreticalfoundationusedinthedevelopmentofthisthesis,whichis\nnecessarytounderstandthetechniquesemployedintheproposedmethodsforthecharacterization", "doc_id": "0b61ac98-43f1-4268-b8f0-6049fd2f81f4", "embedding": null, "doc_hash": "276475ce3154b15274b83853f15fb250ac1b9ea75426df87b65d68685cf62244", "extra_info": {"page_label": "9", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1446}, "relationships": {"1": "a1a1f3f1-4c0c-4be1-bb75-b055e2ea6d73"}}, "__type__": "1"}, "22e4a004-61fa-40e5-a22d-8b844678bb92": {"__data__": {"text": "10\nand classification of texture images. Likewise, the literature review regarding texture analysis is\npresented. Inanutshell, weexplore theconceptoftexture anditsanalysis, featuresextraction,\nmultiresolution analysis of images, phylogenetic diversity indexes, information theory, and\nfeature selection.\nChapter 2 presents and discusses novel approaches to quantifying patterns for texture char-\nacterizationusingecologicaldiversitymeasures,namelyspeciesdiversity,richness,evenness,\nand taxonomic indices. The proposed methods consider an image as a species ecosystem,\nwhere it becomes possible to extract and compute ecological diversity measures to describe the\ntexture. Section2.1introducesanovelbio-inspiredtexture(BiT)descriptorbasedonbiodiversity\nmeasurements(speciesrichnessandevenness)andtaxonomicdistinctiveness. Section2.2put\nforth an extension of the BiT descriptor that integrates a few sets of diversity and evenness\nmeasures widely used in ecology to resemble the completeness of alpha diversity to build a\nrobust representation for texture characterization and classification.\nRelated publications :\n1.A novel bio-inspired texture descriptor based on biodiversity and taxonomic measures.\nPattern Recognition (Journal). Volume 123, March 2022, 108382.\nStatus: Published.\n2.E-BiT:Extendedbio-inspiredtexturedescriptorfortextureanalysisandcharacterization.\nImage and Vision Computing (Journal).\nStatus: Submitted.\nChapter3 employsthemulti-scaleandmultiresolutionanalysisfortextureanalysisofnatural\nand histopathologic images. We establish a parallelism between restoration ecology and\nmulti-scaleandmultiresolution. Intheformer,asite(soil,hydrology,orclimate)maychange\nover time - yet such changes in primary resources have to be taken into account to strongly\ndefine/characterize a community, for such differentiations reveal the temporal/spatial trends of", "doc_id": "22e4a004-61fa-40e5-a22d-8b844678bb92", "embedding": null, "doc_hash": "2e3106b0fcb8ab24e25456cc88aef3790ff47af5913ca0cfb42179e8862d9d1a", "extra_info": {"page_label": "10", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1869}, "relationships": {"1": "4a60e18d-c5e9-41e0-aea1-8cde3e4fa6c6"}}, "__type__": "1"}, "4fe6dd89-af22-46b2-92b3-0f43c32e8d72": {"__data__": {"text": "11\nthe biodiversity conservation capacity. In the latter, analyses such as wavelet decomposition\nand pyramids are employed to supply a characteristic value that can reflect the background\ncondition and summarize values that describe texture from an image to a great extent under\ndistinct differentiations.\nRelated publications :\n1.Multiresolution Texture Analysis of Histopathologic Images Using Ecological Diversity\nMeasures.\nExpert Systems With Applications (Journal).\nStatus: Minor Review.\n2. Multiscale Analysis for Improving Texture Classification.\nApplied Science (Journal).\nStatus: Submitted.\nConclusion presents final considerations, the limitations discovered in this thesis, and discusses\nfuture works.", "doc_id": "4fe6dd89-af22-46b2-92b3-0f43c32e8d72", "embedding": null, "doc_hash": "60cb3b50e1755636fd13efcc218d12561a64c6d917377500af2c4eea2a0eeaf7", "extra_info": {"page_label": "11", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 712}, "relationships": {"1": "ef1b751e-a053-4497-b621-160efe83a575"}}, "__type__": "1"}, "beea5850-a79b-490f-adf3-0b3ec727f7f3": {"__data__": {"text": "CHAPTER 1\nTHEORETICAL FOUNDATIONS AND LITERATURE REVIEW\nThischapterpresentsthetheoreticalfoundationusedindevelopingthisthesis,whichisnecessary\ntounderstandthetechniquesusedintheproposedmethodsfortheclassificationoftextureimages.\nLikewise, the literature review regarding texture analysis is also presented. The following\nsections explore the concept of texture and its analysis, features extraction, multi-resolution\nanalysis of images, phylogenetic diversity indexes, information theory, and feature selection.\n1.1 Texture\nThe definition of texture has different flavors in the literature on computer vision. A com-\nmon one considers texture as changes in the image intensity that form specific repetitive\npatterns (Tuceryan & Jain, 1993). These patterns may result from the physical properties of the\nobject\u2019ssurface(roughness)thatprovidedifferenttypesoflightreflection. Asmoothsurface\nreflectsthelightatadefinedangle(specularreflection),whilearoughsurfacereflectsitinall\ndirections(diffusereflection). Althoughtexturerecognitioniseasyforhumanperception,itisnot\nthe case with automatic procedures, where this task sometimes requires complex computational\ntechniques. Incomputervision,textureanalysisisofanotablerole,whosebasisisextracting\nrelevant information from an image to characterize its texture. This process involves a set of\nalgorithms and techniques. Since humans\u2019 perception of texture is not affected by rotation,\ntranslation, and scale changes, any numerical image texture characterization should be invariant\nto those aspects and any monotonic transformation in pixel intensity.\nMicrotexture : Primitivesormicro-patternsthatformthepanoramaofagivensurfacedefine\nmicrotexture. These irregular micropatterns make it challenging to develop a structural model\nthat adequately describes them because information about the shape is difficult to obtain. As a\nresult,itiscommontodescribeitusingastochasticapproach. Thatis,employingadescriptor\nthat can statistically summarise the relationship between the patterns in the material that a\nsurface is made of.", "doc_id": "beea5850-a79b-490f-adf3-0b3ec727f7f3", "embedding": null, "doc_hash": "83669b9b8ecf7dbefd7abf06ba97d561a6a2a667071fcb903203d9e4c64f76cd", "extra_info": {"page_label": "13", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2063}, "relationships": {"1": "e804f0a0-5f5c-45bd-bd3f-f49efc2fbaa9"}}, "__type__": "1"}, "85b58cab-b764-4062-86c7-1a69ecad937f": {"__data__": {"text": "14\nMacrotexture : Thecontrastbetweenshadowsandwell-litareasandtheshapeofpatternsin\nmacrotexturetexturesproduceprimitiveswithlargerdimensionswhencomparedtomicrotexture\ndimensions. Furthermore,such patternsand theirshape arequite repetitivein thematerial that\nmakes up the surface under consideration.\n1.2 Texture Analysis\nTheanalysisoftextureinanimageiscritical. Itspurposeistoinvestigateanobject\u2019ssurface\nproperties,understandhowhumansdiscriminatebetweendifferenttextures,andmodelalgorithms\ncapable of performing this task. The following question may arise before analyzing an image\u2019s\ntexture: Is there any texture in the image?\nKaru,Jain&Bolle(1996)addressedthisquestionintheirworkbydeterminingwhetherornota\ngiven image contains texture for analysis. However, most texture definitions consider it to be a\nmeasurementoftheroughnessofanimage. Imageswithnotexturecanbeclassifiedasnoisy\norcontainingdistinctobjectstoolargetocharacterizethetexture. Thus,foranimagetohave\ntexture, it must fall somewhere between these two extremes.\nThetextureisfrequentlyconfoundedandusedasasynonymforthepattern. Thetermpattern\nisusedhereintodescribeacertainspatialregularityinanareaofinterest. Ontheotherhand,\ntexture is a measurement of spatial variability within an area of interest, whether random or not.\nBecauseatechniqueisnotspatialinthemeasurementscale,manytexturemeasurementsmay\nfailtodistinguishpatternsfromothertextures. Moreover,althoughnumerouspatternrecognition\ntechniques can be applied in various domains, an optimal and specific individual approach for a\ngiven application has yet to be discovered.\nBroadly speaking, one of the important aims of texture analysis is to compare textures and\ndetermine whether they are the same or different. Thereby, Materka, Strzelecki et al. (1998)\npresented four elements as part of this set: feature extraction, texture classification, texture\nsegmentation, and texture reconstruction of shapes. The first two elements of this set are the\nfocus of this thesis.", "doc_id": "85b58cab-b764-4062-86c7-1a69ecad937f", "embedding": null, "doc_hash": "4cec2a67e9d7130285c2cce6f2234b7a2848924bf28a7a6ebe99818890e25d62", "extra_info": {"page_label": "14", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1991}, "relationships": {"1": "f0240adb-10f9-4204-8efc-1acc5d9fd00c"}}, "__type__": "1"}, "85c65e15-db97-4825-9943-6ff092600e95": {"__data__": {"text": "15\n1.2.1 Feature Extraction\nExtracting features provides information for further steps, such as classification and analysis.\nVariousinformationorcharacteristicscanbeobtainedinthisprocess,suchashistogram,size,\narea,perimeter,texture,contours,etc. Severalimageclassificationsystemsusecolor,texture,\nand shape to represent an image. Although color is a reliable attribute, situations in which color\ninformationdoesnotdiscriminateimageswellrequireusingtextureorshapeattributes. Besides,\nclassifiersbasedonasingleimageattributemaynotachieveadequateaccuracy,soitisnecessary\nto use multiple image attributes.\nTextureanalysisistheprocessofdeterminingthetexturecontentofaregionorregionsofan\nimage. A feature vector is a result of characterizing the texture of an image\u2019s region of interest\n(ROI). It contains all numerical measurements that can perform various tasks like classification,\nsegmentation, and image retrieval by content. Furthermore, the length of the feature vector will\ndetermineitsdimension( \ud835\udc5b-dimensionalvector). Suchanewrepresentation,nevertheless,should\nmeet the following three considerations to wit reduce the dimensionality of the data, emphasize\naspectsoftheimagetofacilitatehumanperception,andbeinvarianttothetransformationsof\nthe image (Loew, 2000).\nSeveral methods for image classification using texture features have been proposed in the\nliterature. Regardless,nostandardmethodorformalapproachcanbeappliedtoawiderange\nofimages. Inaddition,differenttypesofdescriptorsareclassifiedaccordingtoeachapproach\nadoptedfortheirelaboration. Haralick etal.(1973)definedtextureastheimage\u2019suniformity,\ndensity, roughness, regularity, and intensity, among other things. They define texture as a\ntwo-dimensional concept, with one dimension containing the fundamental properties of tonality\nandtheothercorrespondingtotheirspatialrelationships. Theyindicatedthattheconceptsof\ntonality and texture are not independent, as tonality is dominant in some images while texture is\ndominant in others.\nMaterkaetal.(1998)andBharati,Liu&MacGregor(2004)distinguishfourmainapproaches\nusedinimageclassificationfortexturedescription: (i)statisticalmethods,(ii)structuralmethods,", "doc_id": "85c65e15-db97-4825-9943-6ff092600e95", "embedding": null, "doc_hash": "21814030d1c36fca8427f8c8ed4bdf51a7c3fd199ff4b1159e14d5df1a1df3ec", "extra_info": {"page_label": "15", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2165}, "relationships": {"1": "8b4bddcf-f51a-472c-b91a-d9bdf481c0eb"}}, "__type__": "1"}, "85501a4e-f55e-473f-ad42-ac780c182345": {"__data__": {"text": "16\n(iii) model-based methods, and (iv)transform-based methods. Whereas, Gonzalez &Woods\n(2009) and Dougherty (2009) categorize them as follows: (i) statistical approach, (ii) structural\napproach,and(iii)spectralapproach. Ontheotherhand,Rao(2012)andTuceryan&Jain(1993)\nportray classification for texture description in only two groups: (i) statistical or stochastic\napproach and (ii) structural approach. In addition to the approaches to texture descriptors\nmentioned above, some approaches have come to describe the texture over time and through\nextensive research in this area. These methods rely on auto-regressive models, Gaussian-\nMarkovian random fields, wavelets, fractals, and other techniques. These models provide more\npowerful tools for analyzing invariant textures.\nThethreemainapproachestodescribingtexturesinimageclassificationarestatistical,structural,\nand spectral. A set of local measurements extracted from the pattern defines the texture in\nstatistical approaches. Common statistical measures include entropy, correlation, contrast, and\nvariance. On the other hand, structural approaches are based on the idea that textures are\nmadeupofprimitivesarrangedinanapproximatelyregularandrepetitivemanneraccording\ntowell-definedrules. Forexample,considerthetexturedescriptionbasedonregularlyspaced\nparallellines. Thespectralapproaches,inturn,arebasedonFourierspectrumpropertiesand\nare primarilyused to detect globalperiodicity in an imageby identifying high-energypeaks in\nthe spectrum.\n1.2.1.1 Statistical Approaches\nA texture can be described statistically in a suitable way for statistical pattern recognition. As a\nresult, eachtextureisrepresentedbyafeaturevectorrepresentingapointinamulti-dimensional\nfeaturespace. Thegoalistofindaprobabilisticdecisionrulethatassociatesthetexturewitha\nspecificclass(Sonka,Hlavac&Boyle,2014). Statisticalapproachesdonotattempttounderstand\nthetexture\u2019shierarchicalstructureexplicitly. Instead,theyrepresenttextureindirectlybydefining\nthe distributions and relationships between an image\u2019s grey levels using non-deterministic\nproperties. In other words, they attempt to determine how a texture-related image property may\nbe distributed and then derive numerical texture measures from the computed distributions.", "doc_id": "85501a4e-f55e-473f-ad42-ac780c182345", "embedding": null, "doc_hash": "dffc541904bc7952fc7067cb33d999e9ece6675567d8b72ae760c36f119a4f72", "extra_info": {"page_label": "16", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2258}, "relationships": {"1": "de65fe55-6bbf-485c-83dc-5eff71fcbb86"}}, "__type__": "1"}, "ba1f2197-66c2-43dc-9c6e-908e5823937e": {"__data__": {"text": "17\nSeveralattemptstocharacterizetextureshavebeenmade. However,mostofthemhaverelied\non extracting the first- and second-order properties of grayscale and color levels. The first\norderisconcernedwithpropertiesderiveddirectlyfromindividualpixels,i.e.,withoutcross-\ncomparisons. In contrast, second-order properties involve comparing two pixels at the same\ntime. In other words, it entails determining how one pixel at a reference location statistically\nrelates to another pixel at a location distant from the reference location.\nThe human visual system\u2019s recognition of textures was investigated using statistical properties\n(first and second-order statistics) (Julesz, 1975). Later research by Bergen & Julesz (1983) and\nJulesz (1981) gave rise to this statistical model. The co-occurrence matrix (GLCM) is the most\nwidelyusedtexturedescriptorbasedonsecond-orderstatistics(Haralick,1979). Oncecomputed,\nthis matrix contains all information about the spatial dependence of pixels in an image. The\nrelationships between shades of grey, according to Haralick et al.(1973), are characterized by a\nfunctionofdistancesandanglesandrepresentalltextureinformationwhencontainedinthese\nstructures.\n1.2.1.2 Structural Approaches\nThestructuralapproach,exploredbyHaralick(1979)andLevine(1985)referstotextureanalysis\nby decomposing the image into primitives known as texels (texture elements). In fact, when\nthe texture primitive is large enough to be individually segmented and described, structural\napproaches are considered appropriate. The texture primitive is the fundamental geometric\nstructure that gives rise to the texture. For example, it could be the pixel itself in a very fine\ntexture of digital images. The texture in this method is defined by sub-patterns called primitives\nthat repeatedly appear within a pattern according to well-defined rules (Nadler & Smith, 1993).\nIfareasonablesetoftextureprimitivescanbeextractedfromanimage,atexturecanbedescribed\nusing statistics on the properties of these primitives. The mean or standard deviation of grey\nlevels, area, perimeter, orientation, and so on are some examples. A more straightforward\napproach is to extract blocks with the highest degree of homogeneity and describe the image", "doc_id": "ba1f2197-66c2-43dc-9c6e-908e5823937e", "embedding": null, "doc_hash": "5e1ba2aae4515ff053335ae1f593580edf6f46837d3c4ff6263f4cf5bc52a8ad", "extra_info": {"page_label": "17", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2228}, "relationships": {"1": "59772286-a0ca-4507-8149-801ebc39c883"}}, "__type__": "1"}, "ae1eb985-1d17-4d81-b056-26e14dd9b835": {"__data__": {"text": "18\nin terms of block size statistics. This description can be hierarchical, which means that the\nprimitivescanbemadeupofsub-primitives. Inthiscase,thetextureisdescribedusingstochastic\ngrammars, in which a probability density function determines the rules to be applied.\nWhen a texture is described structurally, the basic idea is that a simple texture primitive can\nbeusedtoformcomplextexturepatternsbyfollowingrulesthatlimitthenumberofpossible\narrangements(Gonzalez&Woods,2009). Furthermore,thestructuralapproachhasthemain\nadvantage of providing a good symbolic description of an image, making it more suitable\nfor analysis tasks than texture synthesis (Materka et al., 1998). However, because structural\ntechniques are limited to well-defined macro-textures, they do not perform well in analyzing\nnatural textures.\n1.2.1.3 Model-based Approaches\nAtexture ismodeledas aprobabilisticmathematical modeloras alinearcombinationof aset\nof basis functions in the context of model-based methods. As a result, they are referred to as\nstochastic and generative models, respectively. In this context, texture analysis begins with\nestimating the coefficients of thesemodels, which are then used to characterize texture images.\nThecentralissueisalwayshowtoestimatethemodelcoefficientsandselectthebestmodelfora\ngiven texture (Zhang & Tan, 2002).\nGaussian Markovian and fractal random fields are classic examples of these paradigms. The\nGaussian Markov random field model can encapsulate spatial dependencies between a pixel\nand its neighbors due to its local conditional probability distribution. That is, the probability\ndistribution establishes that the value of each pixel is directly dependent on its neighbors (Zhao,\nZhang,Li&Huang,2007). Fractalsarebasedonsystematicconstructionrulesatdifferentscales.\nTheyhavedemonstratedgoodperformanceinmodelsandrepresentnaturalsurfacesbecause\npatternsinnaturehavesimilarqualitiestoeachother(withsomestatisticalvariations)atdifferent\nlevels of scale (Dougherty, 2009; Jain & Farrokhnia, 1990; Mandelbrot, 1967; Tuceryan & Jain,\n1993).", "doc_id": "ae1eb985-1d17-4d81-b056-26e14dd9b835", "embedding": null, "doc_hash": "9a59047d3ac60bf87008af29b4b55a2fc3cd0913bcdf71d044f03d4e08e1f72e", "extra_info": {"page_label": "18", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2064}, "relationships": {"1": "19592e41-129a-4c72-a254-4ce51dad7d74"}}, "__type__": "1"}, "c755d9aa-fa15-4858-a3fc-c3ad291e52f4": {"__data__": {"text": "19\n1.2.1.4 Transform-based Approaches\nThe transform-based descriptors reflect an image in space whose coordinate system has an\ninterpretationthatiscloselyrelatedtothefeatures(forexample,frequencies)ofthetexturebeing\nanalyzed (Materka et al., 1998).\nThetextureanalysisinthisapproachisdonebasedonthefrequenciesthatmakeuptheimage. The\nFourier transform, Gabor filters, and wavelet transform stand out among these methods. Fourier\ndescriptors use the signal\u2019s power or energy spectrum to obtain texture information. According\nto Gonzalez & Woods (2009), this spectrum plays a critical role in texture characterization. He\ncan describe the directionality ofan image\u2019s periodicpatterns. It is worth noting that methods\nbased on Fourier transforms do not perform well in practice due to a lack of spatial location\ninformation, that is, there is a lack of information indicating exactly when a given frequency\nappears.\nBecause the texture is highly scale-dependent, its sensitivity can be reduced by describing\nit in multiple resolutions. To achieve the best texture discrimination, choose an appropriate\nscale. Gabor and wavelet transform are suitable for multi-scalar texture characterization (Sonka\netal.,2014). Bothapproachesrepresentanimageinaspacewhosecoordinatesystemhasan\ninterpretation closely related to texture characteristics such as frequency or size.\nGaborfilters improvespatial localization, buttheir practicalutility islimited becausethere are\nno simple resolution filters that can locate a spatial structure in natural textures. Compared\ntotheGabortransform,thewavelettransformhassomeadvantages: (i)byvaryingthespatial\nresolution, textures can be represented on a more appropriate scale; (ii) the wavelet function has\nawiderangeofoptions,makingthisapproachmoresuitablefortextureanalysisinaspecific\napplication. As a result, the wavelet transform is appropriate for texture segmentation (Materka\net al., 1998).\nThere are also hybrid methods that combine more than one approach, resulting in a texture\ndescriptorpartiallyrelatedtooneoranothertechnique. Amulti-leveltexturedescriptionisan", "doc_id": "c755d9aa-fa15-4858-a3fc-c3ad291e52f4", "embedding": null, "doc_hash": "b19e1d502dc52d525fe3ae344d42b856cde56536afe5a612c05e5463a9822d83", "extra_info": {"page_label": "19", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2094}, "relationships": {"1": "9d66dcf9-af61-4b08-8ab9-7d8eb344bcda"}}, "__type__": "1"}, "01d72717-2dd8-4913-b56b-4d2b373cd93d": {"__data__": {"text": "20\nexample that is based on the definition of primitives and the spatial description of relationships\nbetween primitives. The method, which consists of several steps, considers grayscale and\nstructural intensities. Texture primitives must first be extracted, described, and classified. A\nclassifier learns to classify texture primitives due to this processing stage. In a second learning\nstage, known textures are presented to the recognition system. Texture primitives are extracted\nfrom the image, and the first-level classifier recognizes their classes. For each texture in the\ntraining set, spatial relationships between primitive classes areevaluated usingthe recognized\ntexture primitives. A feature vector is used to fit a second-level classifier to describe spatial\nrelationshipsbetweentextureprimitives. Thesecond-level learning processbeginswhenthe\nsecond-level classifier is chosen, and unknown textures can be presented to the recognition\nsystem. The first-level classifier classifies the primitives, the properties of spatial primitives are\ncalculated, and the texture is assigned to one of the texture classes by the second-level classifier\n(Sonkaet al., 2014).\n1.2.2 Texture Characterization and Classification\nAny numerical characterization of image textures must have certain properties to be effective in\npractical applications. It must be invariant to variations in visual contrast caused by shifting or\nuneven illumination of a scene to the greatest extent possible, providing that the texture remains\nnearlythesameaccordingtohumanperception. Attheveryleast,thenumericalcharacterization\nmustbeinvarianttothegrayscale\u2019smonotonictransformation. Thisissignificantbecausethe\nlighting circumstances under which the training data for a machine-learning algorithm was\ngatheredareunlikelytobethesameasthoseunderwhichthetestdatawasacquired. Furthermore,\nitmustbeinvarianttoin-planerotationsoftheimagetothegreatestextentpossible. Because\nthe texture orientation used to train a machine-learning algorithm is unlikely to be identical\nto the orientations of the same texture in the test images. Finally, it must be capable of quick\ncomputation.\nA texture classification task\u2019s main goal is to determine which class (two or more classes\nspecifiedinadvance)atexturesamplebelongstobasedonasimilaritycriterion. Twoprocedures", "doc_id": "01d72717-2dd8-4913-b56b-4d2b373cd93d", "embedding": null, "doc_hash": "081e24cb47285eda102620de23261d9696bd9e29121fad77dd6734698dda11ff", "extra_info": {"page_label": "20", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2328}, "relationships": {"1": "b5e2a31e-bfad-4dbd-bb50-ff28d533dffb"}}, "__type__": "1"}, "1a97e1f5-4179-4c1f-a77d-19565412f136": {"__data__": {"text": "21\nare involved in this task: feature extraction and pattern categorization. The usage of supervised\nmachinelearningmethodsisdirectlyassociatedwithpatternclassification. Thatis,itisfirstand\nforemost important to prepare a set of samples for training. The values of these samples are\nthenmappedtothelabelsoftheirrespectiveclasses,allowingtheinferenceofnewunknown\nsamples, known as test samples. These test samples can be obtained in two ways: through\ncross-validation or by taking samples from outside the training process. Cross-validation,\naccording to Barrow & Crone (2016), is a statistical approach that determines how well the\nresults of an estimate can be generalized to an independent database.\n1.3 Literature Review on Texture Analysis and Characterization\nThis section provides an overview of the existing descriptors and approaches employed in\ntexture analysis, focusing on feature extraction from textural images. Some existing texture\ndescriptorsconsideredstate-of-the-artintextureanalysisofnaturalandhistopathologicalimages\nare presented.\nSeveralcomprehensiveliteraturereviewsaproposoftexturerepresentationastextureanalysis\nare presented in Simon & Uma (2018b) and Liu, Chen, Fieguth, Zhao, Chellappa & Pietik\u00e4inen\n(2019). Whenceaconsiderablenumberofmethodshavebeendevelopedovertime,exploring\neach,therefore,adifferentapproachtoextractingthetextureinformationofanimage. Infact,there\nisavarietyofclassicalandnovelapproachesdevelopedforsuchapurpose,andsomeofthemare\nGray-LevelCo-occurrenceMatrix(GLCM)(Haralick etal.,1973),Haralickdescriptors(Haralick,\n1979),MarkovRandomFields(Cross&Jain,1983),GaborTextureDiscriminator(I&Sagi,\n1989),WaveletTransform(Arivazhagan&Ganesan,2003),FractalModels(Kaplan,1999),Local\nPhaseQuantization(LPQ)(Ojansivu&Heikkil\u00e4,2008),LocalBinaryPatterns(LBP)(Pietik\u00e4inen\net al., 2011), Binarized Statistical ImageFeatures (BSIF) (Kannala & Rahtu, 2012), and Local\nTera Pattern (LTP) (Saxena et al., 2015). Some recent works can be found in Simon & Uma\n(2018a), Wang, Li, Li, Gupta & Choi (2020), Zhang, Wang, Huang & Zhang (2018), and\nNsimba & Levada (2019).", "doc_id": "1a97e1f5-4179-4c1f-a77d-19565412f136", "embedding": null, "doc_hash": "45c941ed5edc5a348765d62e9c45b184c6a23b1abd85ed553b10bde6680dccdf", "extra_info": {"page_label": "21", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2093}, "relationships": {"1": "75687435-3250-4ad6-99d5-c216a86ba06e"}}, "__type__": "1"}, "97e3321b-5467-40e1-83b7-f1cdb426f110": {"__data__": {"text": "22\nFurthermore, researchers have recently been focused on convolutional neural networks (CNNs)\ndue to their effectiveness in object detection and recognition tasks. However, the shape\ninformationextractedbyCNNsisofminorimportanceintextureanalysis(Andrearczyk&Whelan,\n2016). Andrearczyk & Whelan (2016) developed a simple texture CNN (T-CNN) architecture\nfor analyzing texture images that pools an energy measure at the last convolution layer and\ndiscards the overall shape information analyzed by classic CNNs. Despite the promising\nresults, the trade-off between accuracy and complexity is not so favorable. Other T-CNN\narchitectures have also achieved moderate performance on texture classification (de Matos,\nde Souza Britto Jr., de Oliveira & Koerich, 2019; Fujieda, Takayama & Hachisuka, 2017;\nVriesman, Britto Junior, Zimmer & Koerich, 2019). Another disadvantage of CNNs is the lack\nofexplainabilityandinterpretability. Onthatmatter,Gilpin,Bau,Yuan,Bajwa,Specter&Kagal\n(2018)arguedthatinterpretabilityandexplainabilityaretwodistinctconceptsasexplainable\nmodels are interpretable a priori, but the reverse is not always true. Thus, interpretability alone\nis insufficient. Therefore, there is a need for explainable models capable of summarizing the\nreasons for deep learning behavior, gaining the trust about the causes of their decisions.\nBesidesnaturalimages,texturedescriptorsarebecomingquitepopularinbiologicalimaging\nanalysis,particularlyinHistopathologicImages(HI)analysisduetothedifferenttypesoftexture\nfound in HIs. By analyzing an HI, it is clear that different areas of interest in the image, such as\nhigh/low concentration of nuclei and stroma present quite different patterns of textures. For this\nreason,severalresearchershavebeeninvestigatingalargespectrumoftexturaldescriptorsfor\nHI classification. The descriptors based on the Grey-Level Co-occurrence Matrix (GLCM) had\nbeen used by several authors to represent texture in HI. Kuse, Sharma & Gupta (2010) used\nGLCMasfeatureswithapre-segmentationprocessbasedonunsupervisedmean-shiftclustering.\nSuch a method reduces color variety to segment the image using thresholds. Afterward, nuclei\nare identified and have the overlapping removed by contour and area restrictions.\nAdditionally, Caicedo, Gonz\u00e1lez & Romero (2011) combined seven feature extraction methods,\nincluding GLCM, and created a kernel-based representation of the data on each feature type.\nKernelsareusedinsideanSVMtofindsimilaritiesbetweendataandtoimplementacontent", "doc_id": "97e3321b-5467-40e1-83b7-f1cdb426f110", "embedding": null, "doc_hash": "06631f919287815c8165985554c6cb2b34f994126a705a0ac19e732e51592f39", "extra_info": {"page_label": "22", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2499}, "relationships": {"1": "35951e22-800f-4f2f-a64d-edfea511951a"}}, "__type__": "1"}, "0cc9cb5c-e661-4855-9f3e-087f9d4cf9bf": {"__data__": {"text": "23\nretrieval mechanism. Fern\u00e1ndez-Carrobles, Bueno, D\u00e9niz, Salido, Garc\u00eda-Rojo & Gonz\u00e1ndez-\nL\u00f3pez (2015) presented a feature extraction method based on the frequency and spacial textons.\nThe use of textons implies that images are represented by a reduced vocabulary of textures.\nFeatures used for the classification are histograms of textons and GLCM features extracted\nfromtextonmaps. Theyalsoevaluatedtheimpactofdifferentcolormapsontheseprocedures.\nDespite the fact that GLCM requires a gray-level image, the conversion of the hematoxylin and\neosin(H&E)colorimagetogray-levelisaffectedbythevariabilityofthestainingcolor,soin\nthe end, GLCM is also affected. Leo, Lee, Shih, Elliott, Feldman & Madabhushi (2016) used a\nRandomForesttoanalyzewhetherGLCMfeaturesaresusceptibleornottoimagevariations.\nThe work also highlighted the importance of color normalization.\nThe work presented by Reis, Gazinska, Hipwell, Mertzanidou, Naidoo, Williams, Pin-\nder & Hawkes (2017) focused on stroma maturity to evaluate breast cancer. The features\nfor the stroma are Basic Image Features (BIF), obtained by convolving images with a bank\nof derivatives-of-Gaussian filters, and LBP with multiple scales for the neighborhood. Das,\nMitra, Chakraborty, Chatterjee, Maiti & Bose (2017) proposed the so-called geometric- and\ntexture-awarefeatures,whicharebasedonHumomentsandfractaldimensional,respectively.\nSuch a set of features was applied to detect geometrical and textural changes in nuclei to\ndiscriminate between mitotic and non-mitotic cells. Cruz-Roa, Caicedo & Gonz\u00e1lez (2011)\nproposedapatchingmethodonHIslidestocreatesmallregionsandextractSIFT,luminance\nlevel, and discrete cosine transform features to create a bag-of-words.\nTextureanalysisaimsatgroupingthetexturepatternsbelongingtothesameclass. Inadditionto\nwhatispresentedabove,varioustexturedescriptorapproachesforfeatureextractionarefoundin\ntheliterature,andtheyareproventobepromising. Table1.1presentsasummaryofsomeofthe\ntexture descriptors and datasets used in classification tasks.\nInfact,thelistofworkspresentedintheTable1.1isnotexhaustive,moreworkscanbefound\nin Ghalati, Nunes, Ferreira, Serranho & Bernardes (2021), Singh, Sunkaria & Kaur (2022),\nSimon & Uma (2018b), and Tuceryan & Jain (1993).", "doc_id": "0cc9cb5c-e661-4855-9f3e-087f9d4cf9bf", "embedding": null, "doc_hash": "b09e77eb0345aee9b761a2e0f6850aa57152ede6a439b1beabd2281590db6378", "extra_info": {"page_label": "23", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2245}, "relationships": {"1": "000a0c47-9c20-447f-8695-3cebd0bef4cd"}}, "__type__": "1"}, "8611187c-205b-4199-9abb-2f7a47f9c0fc": {"__data__": {"text": "24\nTable 1.1 Summary of some texture descriptors and datasets used in classification tasks.\nAuthor Techniques Datasets\nNsimba & Levada (2020b) Infomation theory and GMRF KTH-TIPS2b, Salzburg\nWang, Zhao, Cai, Li & Yan (2016) LBP and Zernike moments features Outex, CURet\nBashier, Hoe, Hui, Azli & Han (2016) Grand structure and histogram-based UIUC, XU\nHao, Wang, Li & Zhang (2016) Gaussian components and image features KTH-TIPS2, FMD, UIUC\nJunior & Backes (2016) Extreme Learning Machine Brodatz, Outex, Vistex\nQiu, Thompson & Calderbank (2015) Based on binary Heisenberg-Weyl group Fabric texture\nAyed, Larousi & Masmoudi (2014) Local and global information Outex\nMehta & Egiazarian (2014) Granularity at multiscale. KTH-TIPS, UMD, Curet\nQuan, Xu & Sun (2014) Fractal based KTH-TIPS, UMD, UIUC\nZhang, Zhao & Liang (2013) Gaussian derivatives filters CUReT, KTH-TIPS2\nBackes, Casanova & Bruno (2013) Texture as pixel Network Outex, VisTex, Brodatz\nWang, Bichot, Zhu & Li (2013) LBP and neighboring gray-scale props Outex\nZhang, Zhou & Li (2012) Gabor filter and LBP CURet\nGuo, Zhang & Zhang (2010) Completed LBP CUReT, Outex\nXu, Yang, Ling & Ji (2010) Wavelet and fractal UIUC, UMD\nThedescriptorspreviouslymentionedhaveproventobediscriminativeintermsoftexturepattern\nclassification. Consideringthatmostareemployedbuttogray-scaleimages,theirapplication\non natural images as well as microscopic images may be constrained as color information is\nnot exploited. In order to prevail over the presented limitation, an extension of LBP as well\nas other approaches have been proposed to incorporate the local patterns with color features.\nLikewise,intheworkofQi, Qiao,Li&Guo(2013),itisproposedanapproachthatencodes\ncross-channel texture correlation regarding color texture classification. The research conducted\ninNsimba&Levada(2020a)presentedanovelapproachtocomputeinformationtheorymeasures\nfor color texture classification task, an approach based on the capacity of information theory\nmeasurestocapturemeaningfultexturalinformationofaninputcolorimage. Inourmethods,\nwewilldealwiththeselimitationsinordertoimprovethemetricsthatevaluateperformance,\nsuch as accuracy, recall, and Kappa, by considering and exploiting color information.\n1.4 Multi-resolution\nWhenlookingatanimage,weusuallyseeregionsofsimilartextures,colors,orlevelsofgray\nthat combine to form objects. If the objects are small or have low contrast, it may be necessary\nto examine them in high resolution; if they are large or have high contrast, a coarser view is", "doc_id": "8611187c-205b-4199-9abb-2f7a47f9c0fc", "embedding": null, "doc_hash": "2fd0e93343b4e59472d5b28cc4fdd9771d21daf6c0c5c548840c85bf5ef1898b", "extra_info": {"page_label": "24", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2520}, "relationships": {"1": "0abecd52-7d22-4744-a935-922194c4634f"}}, "__type__": "1"}, "1cf33e8e-8146-4799-9066-07b2580fecf0": {"__data__": {"text": "25\nsufficient. If both types of objects appear in an image, it can be helpful to analyze them in\nmultipleresolutions(Gonzalez&Woods,2009). Changingtheresolutioncanalsoleadtothe\ncreation,deletion,ormergingofimagefeatures. Thisservesasamotivationforanimportant\nparadigm in computer vision and image processing: multiresolution processing. In addition,\nthere is evidence that the human visual system processes visual information in a multiresolution\nmanner(Blakemore&Campbell,1969),sensorscanprovidedatainvariousresolutions,and\nmultiresolution algorithms for image processing offer advantages from a computational point of\nview and are generally robust.\n1.4.1 Gaussian-Laplacian Pyramid (GLP)\nWhen analyzing an image, it can sometimes be useful to break it down into separate parts so\nthat there is no loss of information. The pyramid theory provides ways to decompose images at\nmultiple levels of resolution (Goutsias & He\u0133mans, 1998).\nConsider a collectionof representations of animage in different spatial resolutions,stacked on\ntopofeachother,withthehighestresolutionimageatthebottomofthestackandsubsequent\nimages appearing over it in descending order of resolution. This generates a pyramid-like\nstructure, as can be seen in Figure 1.1(a). The traditional procedure for obtaining a lower\nresolution image is to perform low-pass filtering followed by sampling (Jolion & Rosenfeld,\n2012).\nInsignalprocessingandcomputervision,pyramidrepresentationisthemaintypeofmulti-scale\nrepresentation for computing image features in different scales. The pyramid is obtained by\nrepeatedsmoothingandsubsamplingofanimageorasignal. Thisconceptisfrequentlyused\nbecause it expresses computational efficiency approximation compared to other representations\nsuchasscale-spacerepresentationandmulti-resolutionanalysis(Burt,1981;Crowley&Riff,\n2003; Lowe, 2004). For generating the pyramid representation, different smoothing kernels\nhave been brought forward and the binomial one strikingly shows up as useful and theoretically\nwell-founded (Crowley, 1981; Lindeberg, 2013).", "doc_id": "1cf33e8e-8146-4799-9066-07b2580fecf0", "embedding": null, "doc_hash": "6b64a5b4804c3476de63dc08d59ccaae39e460fcba2d4f62b0cd25da3fc9dc87", "extra_info": {"page_label": "25", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2052}, "relationships": {"1": "42b3c985-24ac-4739-a052-badb887b4120"}}, "__type__": "1"}, "d6fe59ae-42fa-4959-88d0-b4529dbcb034": {"__data__": {"text": "26\nAccordingly,forabi-dimensionalimage,thenormalizedbinomialfiltermaybeapplied(1/4,1/2,\n1/4) in most cases twice or even more along all spatial dimensions, afterward, the subsampling\noftheimagebyafactoroftwo,whichleadtoefficientandcompactmulti-levelrepresentation.\nThere are two main types of pyramids, namely, low-pass and band-pass (Adelson, Anderson,\nBergen,Burt&Ogden,1984;Burt&Adelson,1983). Todevelopfilter-basedrepresentationsby\ndecomposing images into information on multiple scales as well as to extract features/structures\nofinterestfromanimage,Gaussianpyramid(GP),LaplacianPyramid(LP),andWaveletpyramid\nare examples of the most frequently used pyramids.\nThe GP illustrated in Figure 1.1 consists of low-pass filtered, reduced density, where subsequent\nimages of the preceding level of the pyramid are weighted down using Gaussian average or\nGaussian blur and scaled-down. The base level is defined as the original image. Formally\nspeaking, assuming that \ud835\udc3c(\ud835\udc65,\ud835\udc66)is a two-dimensional image, the GP is recursively defined in\n(1.1).\n\ud835\udc3a0(\ud835\udc65,\ud835\udc66)=\uf8f1\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4 \uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f4\uf8f3\ud835\udc3c(\ud835\udc65,\ud835\udc66), for level,\ud835\udc59=0\n2\u00cd\n\ud835\udc5a=\u221222\u00cd\n\ud835\udc5b=\u22122\ud835\udc64(\ud835\udc5a,\ud835\udc5b)\ud835\udc3a\ud835\udc59\u22121(2\ud835\udc65+\ud835\udc5a,2\ud835\udc66+\ud835\udc5b),otherwise.(1.1)\nwhere\ud835\udc64(\ud835\udc5a,\ud835\udc5b)is a weighting function (identical at all levels) termed the generating kernel\nwhich adheres to the following properties: separable, symmetric and each node at level \ud835\udc5b\ncontributes the same total weight to nodes at level \ud835\udc59+1. The pyramid name arose from the\nfactthattheweightingfunctionnearlyapproximatesaGaussianfunction. Thispyramidholds\nlocalaveragesondifferentscales,whichhasbeenleveragedfortargetlocalizationandtexture\nanalysis(Anderson,Burt&VanDerWal,1985;Burt,1983;Larkin&Burt,1983). Moreover,\nassumingtheGP[\ud835\udc3c0,\ud835\udc3c1,...,\ud835\udc3c\ud835\udc58],theLPisobtainedbycomputing \ud835\udc4f\ud835\udc58=\ud835\udc3c\ud835\udc58\u2212\ud835\udc38\ud835\udc3c\ud835\udc58+1,where\ud835\udc38\ud835\udc3c\ud835\udc58+1\nrepresentsanup-sampled,smoothedversionof \ud835\udc3c\ud835\udc58+1ofthesamedimension. Intheliterature,LP\nis used for image compression, enhancements, analysis and graphics (Adelson et al., 1984).", "doc_id": "d6fe59ae-42fa-4959-88d0-b4529dbcb034", "embedding": null, "doc_hash": "63fc56fd03c92436fd4c4323cb7cbc701018226fae620cea16d2a5a4cc8d2edf", "extra_info": {"page_label": "26", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1903}, "relationships": {"1": "82a8b0a9-13fc-4b32-9f08-4eb9edada6d0"}}, "__type__": "1"}, "ec8fa6d7-3d2d-4d3c-8a5b-7a67434f89a7": {"__data__": {"text": "27\nFigure 1.1 An example of Gaussian and Laplacian Pyramids from the same input image.\n(b) First three levels of Gaussian pyramid; (c) First three levels of Laplacian pyramid\nAdapted from Ataky et al.(2020)\n1.4.2 Wavelet Analysis\nThe multi-resolution analysis is a signal processing strategy where a set of filters is used,\nspecializedinextractingthesignalinformation,suchasthefrequenciespresentinitandtheir\nlocation depending on the duration of the signal, in different resolutions (Castleman, 1996).\nThe brief description of the multi-resolution analysis allows presenting the two functions\nresponsibleforthegenerationoftheentirewaveletsystem: thescalefunctionandtheprimary\nwavelet (or mother wavelet). The term mother comes from the fact that functions with different\nsizes are used in the transformation process and all of them originate from the main wavelet, the\nmother wavelet.\nThescalefunctions \u03a6\ud835\udc57,\ud835\udc58andwavelets \u03a8\ud835\udc56,\ud835\udc57,aresaidtobeorthogonalbecausetheyrespectthe\nfollowing condition:", "doc_id": "ec8fa6d7-3d2d-4d3c-8a5b-7a67434f89a7", "embedding": null, "doc_hash": "4c1ab5997d6228f273891777af18aeddc639f7e7f47764918a14b723a00a1fc8", "extra_info": {"page_label": "27", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 987}, "relationships": {"1": "6a5518b7-e42f-4b9f-82f7-c67057d174c8"}}, "__type__": "1"}, "dd5bcfda-7b90-467f-a444-a1681d60abf6": {"__data__": {"text": "28\n\u222b+\u221e\n\u2212\u221e\u03a6\ud835\udc57,\ud835\udc58(\ud835\udc65)\u03a8\ud835\udc57,\ud835\udc58(\ud835\udc65)\ud835\udc51\ud835\udc65=0 (1.2)\nwhere,\ud835\udc57\u2208\ud835\udc4dcorresponds to the parameter that represents the scale to which the function is\nrepresented, and \ud835\udc58\u2208\ud835\udc4dcorresponds to the translation of \ud835\udc58/2\ud835\udc57concerning the scale function\nand the primary wavelet, given by \ud835\udc57=0and\ud835\udc58=0. Both the scale function and the wavelet are\ndefined in the set of reals ( R), through scaling and translations of the presented functions.\nThe translation parameter corresponds to the time information in the transform domain and the\nscaling parameter corresponds to the signal compression and expansion process (Mallat, 1999).\nFigure 1.2 Multi-resolution representation of an image\nFigure 1.2 shows an initial image and the degree of refinement applied to it through the wavelet\ntransform. On a smaller scale, the useful information obtained from the original image is found\ninthesixsquaresadjacenttotheimage. Theinformationcontainedinthesesquaresiscalled\ndetail or resolution, which is the information needed to move from one degree of refinement,", "doc_id": "dd5bcfda-7b90-467f-a444-a1681d60abf6", "embedding": null, "doc_hash": "2fcd71586643dd95877a3a0a04fa931f568c01e8591395df5d451669edf0ff4a", "extra_info": {"page_label": "28", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1004}, "relationships": {"1": "32c7d192-78e1-4c81-a348-f8baeb6e15a3"}}, "__type__": "1"}, "6158fb84-0234-4ac3-858d-ccc48e864fa9": {"__data__": {"text": "29\nor degree of \"sharpness\", to another. Adding the information related to the squares makes it\npossibletorecomposetheimage. Thiswayofdecomposingandrecomposingimagescanbe\nimplemented quickly and effectively, employing wavelet transforms.\n1.4.2.1 Wavelets\nTraditional methods of signal analysis, based on the Fourier transform, can determine all\nfrequencies present in the signal, but their relationship with the temporal domain does not exist.\nTo overcome this problem, the Gabor transform (or STFT - Short Time Fourier Transform)\nemerged; themainidea ofthistransform istointroduce anewparameter oflocal frequencyas\nif the \u201clocal transform\u201d observed the signal through a short window within which the signal\nremains approximately stationary (Oliveira, 2007).\nThe Wavelet transform was developed as an alternative to the Gabor transform to solve the\nproblem of resolution. Wavelets are mathematical functions that separate signals into different\ncomponentsandextracteachcomponentwitharesolutionappropriatetoitsscale. Theyhave\nanadvantageovertheFouriertransformbecausetheyanalyzethesignalatdifferentscalesand\nmovearoundanalyzingeachpointofthesignal. TheContinuousWaveletTransform(CWT)can\nbe expressed in the form:\n\ud835\udc36\ud835\udc4a\ud835\udc47(\ud835\udf0f,\ud835\udc4e)=\u222b+\u221e\n\u2212\u221e\ud835\udc53(\ud835\udc61)1\u221a\ud835\udc4e\u03a8\u2217\u0012\ud835\udc61\u22121\n\ud835\udc60\u0013\n\ud835\udc51\ud835\udc61 (1.3)\nwhere\ud835\udf0fand\ud835\udc4eare the translation and scale parameters, respectively.", "doc_id": "6158fb84-0234-4ac3-858d-ccc48e864fa9", "embedding": null, "doc_hash": "f34efd744252b758c1750dff4f3959d6f9c2f4eb81ba0eb8d5c16bd6ad688b05", "extra_info": {"page_label": "29", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1318}, "relationships": {"1": "0c1c2679-3661-40c5-929b-c491e9d2fdab"}}, "__type__": "1"}, "a6e92f78-5c0b-4703-8773-6bc9e8a4af53": {"__data__": {"text": "30\n1.4.2.2 Discrete Wavelet\nTheCWTiscalculatedbymakingcontinuoustranslationsandscalingofafunctionoverasignal.\nIn practice, this transformation is not feasible, as it requires infinite translations and scaling,\ndemanding a lot of time, computational effort, and redundancy. Discrete wavelets (DWs) were\nintroduced to overcome this obstacle. DWs are not translated or scaled continuously, but at\ndiscrete intervals, which is achieved by modifying the continuous wavelet:\n\u03a8\ud835\udc60,\ud835\udf0f(\ud835\udc61)=1\u221a\ufe01\n|\ud835\udc60|\u03a8\u0010\ud835\udc61\u2212\ud835\udf0f\n\ud835\udc4e\u0011\n(1.4)\n\u03a8\ud835\udc57,\ud835\udc58(\ud835\udc61)=1\u221a\ufe02\f\f\f\ud835\udc60\ud835\udc57\n0\f\f\f\u03a8 \n\ud835\udc61\u2212\ud835\udc58\ud835\udf0f0\ud835\udc60\ud835\udc57\n0\n\ud835\udc60\ud835\udc57\n0!\n(1.5)\nwhere\ud835\udc57and\ud835\udc58are integers; \ud835\udc600>1 is a fixed expansion parameter; \ud835\udf0f0is the translation factor,\nwhich depends on the expansion factor.\nGenerally,\ud835\udc600=2ischosentohaveafrequencysamplingcalleddyadicsamplingand \ud835\udf0f0=1is\nchosen for temporal sampling, also dyadic. This results in (Oliveira, 2007):\n\u03a8\ud835\udc57,\ud835\udc58(\ud835\udc61)=\u221a\n2\ud835\udc57\u03a8(2\ud835\udc57\u2212\ud835\udc58) (1.6)\nWhen discrete wavelets are used to analyze a signal, the result is a series of wavelet coefficients,\nalsocalledawaveletdecompositionseries(Oliveira,2007). Sinceawaveletcanbeseenasalow-\npassfilter,theseriesofscaledwaveletscanbeseenasabankofband-passfilterswitha \ud835\udc44factor\n(filter bank fidelity factor). To computationally implement wavelet transform, we need a notion\nofDiscreteWaveletTransform(DWT).DWTisusedtodecomposeasignalintotwoothersignals\nthroughlow-passfilters \ud835\udc59(scalingsignals)andhigh-passfilters \u210e(wavelet signals). Therefore,\nDWTcanbeimplementedasaperfectreconstructionfilterbank(PRFB)whichiscompletely\ncharacterized by a pairwise Quadrature Mirror Filters (QMF) \ud835\udc59and\u210e(Nsimba & Levada, 2019).", "doc_id": "a6e92f78-5c0b-4703-8773-6bc9e8a4af53", "embedding": null, "doc_hash": "579866c0a70121b3831732a69202cf023331cdfe676b68b04a7659843b22b0ee", "extra_info": {"page_label": "30", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1555}, "relationships": {"1": "e7969a41-ec69-444b-9627-fa154a3ee02f"}}, "__type__": "1"}, "c5d41baa-aecf-4a26-9a0f-b1708cca7cf2": {"__data__": {"text": "31\nFigure 1.3 Wavelet decomposition for two-dimensional images\nFor a complete DWT specification, two other filters are required \ud835\udc59and\u210e, known as synthesis\nfilters, and are used to reconstruct the original signal from wavelet coefficients. This process is\nknown as the Inverse Discrete Wavelet Transform (IDWT). Figure 1.3 shows the decomposition\nof a two-dimensional image.\nFurthermore, any wavelet decomposition of a bi-dimensional image involves four sub-bands,\ntowit,LL(Approximation),LH(HorizontalDetail),HL(VerticalDetail),andHH(Diagonal\nDetail). Thesub-bandimageLLisbutusedforDWTcomputationinthenextscale. Additionally,\nthere are many types of the wavelet transform, such as Haar, Daubechies, Symlets, etc. The\nchoice of which to be used depends on how it fits best in a given situation.\n1.5 Ecological Diversity Indices\nAs stated in Magurran (2004a), and Magurran (2013), diversity is a term often used in ecology,\nand the purpose of its indices is to describe the variety of species present in a community or\nregion. The concept of community is presented as a set of species that occur in a certain place\nand time.", "doc_id": "c5d41baa-aecf-4a26-9a0f-b1708cca7cf2", "embedding": null, "doc_hash": "2bf42aa908b585fcc871bc6e8d2576666d812f7183d788ce3963ed3b0ac49ff1", "extra_info": {"page_label": "31", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1121}, "relationships": {"1": "8d19ee5e-a7ee-4fde-a7c8-ca51a2e4a0ff"}}, "__type__": "1"}, "377ee3fd-0734-428c-bf10-fcfe344cc318": {"__data__": {"text": "32\nMeasurementssuchasvarianceandstandarddeviation,whicharecalculatedinstatisticalstudies,\nshowvaluesthatmeasurequantitativevariability,whilediversityindicesdescribequalitative\nvariability.\nDiversity is measured through two variants, namely, species richness (which represents the\nnumber of species contained in a given region) and relative abundance (which refers to the\nnumber of individuals of a given species in a region) (Pianka, 2011; Rousseau, Van Hecke,\nNIjssen & Bogaert, 1999a).\nPhylogenyisabranchofbiologyresponsibleforstudyingtheevolutionaryrelationshipsbetween\nspecies,forverifyingtherelationshipsbetweenthem,inordertodeterminepossiblecommon\nancestors. A phylogenetic tree, or simply phylogeny, is a tree where leaves represent organisms\nand internal nodes represent supposed ancestors. The edges of the tree denote evolutionary\nrelationships.\nIngeneral,diversitycannotbemeasuredonlywiththeuseofdatasuchasabundanceandspecies\nrichness; thus, the phylogenetic parameter is increasingly being inserted in this calculation\n(Clarke & Warwick, 1998a).\nPhylogenetic diversity isa measureof communitydiversitythat incorporates the phylogenetic\nrelationships of species (Magurran, 2013). The combination of species abundance with\nphylogenetic proximity to generate a diversity index is denoted taxonomic diversity. Taxonomy\nis the science that deals with classification (creating new taxa), identification (allocation of\nlineage within species) and nomenclature (Vandamme et al., 1996).\nOne way to represent the phylogenetic tree is through the dendrogram, which is a diagram\nthatrepresentstheancestralrelationshipsbetweenorganisms. Thistypeoftreedescribesthe\nevolutionary sequence of some primates.\nThephylogenetictreecombinedwithphylogeneticdiversityindicesisusedinbiologytocompare\nbehaviorpatternsbetweenspeciesindifferentareas. Thephylogeneticdiversityindiceswere\nchosen due to their potential in characterizing a given region/image.", "doc_id": "377ee3fd-0734-428c-bf10-fcfe344cc318", "embedding": null, "doc_hash": "32befae75f372c403e1d71f230c7dd0b79e88a5d83a500737deb8b694f623352", "extra_info": {"page_label": "32", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1940}, "relationships": {"1": "eb5dec9a-e8e4-4c0b-a61d-0c6b3e770ad2"}}, "__type__": "1"}, "7dd01402-49d4-4670-8d7a-fa3e8de1ab2b": {"__data__": {"text": "33\nTherichnessofdetailsobtainedwitheachgroupofindicesisessentialforthecompositionof\nthe descriptors being proposed in this research.\nItisimportanttomentionthattheseindicesarecomplementary,thatis,agroupofindicesisable\nto measure some property that another group cannot achieve. For example, the phylogenetic\ndiversityindicesbasedonspeciesrichness(biodiversitymeasurements),andthegroupofindices\nbased on the distance between pairs of species (taxonomic indices). The first is able to measure\npropertiesdirectlyrelatedtothespecies,suchasitsrelativeabundance,thatis,thenumberof\nindividuals of a species. The second, on the other hand, is capable of measuring the kinship\nrelationships that certain species have, such as the number of common ancestors that exist\nbetween certain species.\n1.5.1 Biodiversity and its Measurements\nBiodiversity is defined as a variety within and among life forms on an ecosystem or a site;\nand is measured as a combination of two components, to wit, richness, and evenness across\nspecies (Rousseau et al., 1999a). The former component isalso referred to as species richness,\nstanding for the number of groups of functionally related individuals, and the latter denotes the\nproportions of species or functional groups present in an ecosystem or community. Besides\nthese components, another type of indices is taxonomic indices, which consider the taxonomic\nrelationships between different organisms in an ecosystem. Moreover, taxonomic diversity\nreflects the average taxonomic distance between any two organisms, randomly chosen from\na sample. Such a distance can be understood as the length of the path connecting these two\norganisms along the branches of a phylogenetic tree (Sohier, 2019).\nThe diversity can be employed to represent variation in several forms, to wit, genetic, life form,\nand functional group. It is worth mentioning that diverse communities are often a sign of\nfragmentedsiteswheremuchofspeciesrichnessiscontributedbydisturbancespecies(Rousseau\net al., 1999a; Solow & Polasky, 1994). Different objective measures have been brought into\nexistenceasameanstoempiricallymeasurebiodiversity. Thefundamentalideaofadiversity", "doc_id": "7dd01402-49d4-4670-8d7a-fa3e8de1ab2b", "embedding": null, "doc_hash": "a13784c58614383178a59dfe05f1f3f207cb3f39fb1dd1bbd1dbfad289ada1ca", "extra_info": {"page_label": "33", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2162}, "relationships": {"1": "989ea1a4-df2e-4156-b7d1-eced94ff2dbe"}}, "__type__": "1"}, "631fdb47-6928-4a96-9188-a15102b881f0": {"__data__": {"text": "34\nindex is to quantify biological variability, which, in turn, can be used to compare biological\nentities, composed of direct components, in whether space or time (Sohier, 2019). Biodiversity\ncan be expressed or monitored at different scales/spaces: (i) alpha diversity, which is the\ndiversity within a particular ecosystem, that is, the richness and evenness of individuals within a\ncommunity; (ii) beta diversity, which is the diversity between ecosystems, involving comparing\nthenumberoftaxathatareuniquetoeachoftheecosystems. Inotherwords,itexpressesthe\ndiversitybetweenhabitats;and(iii)gammadiversity,whichmeasurestheoveralldiversityfor\ndifferent ecosystems within a region, that is, the diversity of habitats within a region. More\ndetails concerning these three types of indices can be found in Jost (2007). Figure 1.4 illustrates\nan example of Alpha, Beta, and Gamma diversities in different sites.\nFigure 1.4 Schematic visualization of the species\nrichness. Alpha Diversity of Site A = 7 species,\nSite B = 5 species, Site C = 7 species.\nBeta Diversity is observed between Site A and C\nwith 10 species that differ between them and\nonly 2 species in common. Gamma diversity is 3\nhabitat with 12 species total diversity", "doc_id": "631fdb47-6928-4a96-9188-a15102b881f0", "embedding": null, "doc_hash": "4df1afb6e3b23a60d0f3c44fddbfd6643c4e1ad437e5d17fdc00bb3b023ae611", "extra_info": {"page_label": "34", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1225}, "relationships": {"1": "30dadaee-7bdd-4353-962c-151ec23701a9"}}, "__type__": "1"}, "874de0a4-220c-4850-9d26-50c51e2d6bfe": {"__data__": {"text": "35\nSomealphadiversitymeasures,includingmeasuresofrichness,dominance,andevenness(SDR-\nIV, 2020) are described as follows:\nMargalef\u2019s diversity index ( DMg)(Clifford, Stephenson et al., 1975; Magurran, 2004a) and\nMenhinick\u2019sdiversityindex( DMn)(Whittaker,1972)areboththeratiobetweenthenumberof\nspecies recorded ( \ud835\udc46) and the total number of individuals in the sample ( \ud835\udc41):\nDMg=\ud835\udc46\u22121\nln\ud835\udc41(1.7)\nDMn=\ud835\udc46\n\ud835\udc41(1.8)\nBerger-Parker dominance (May, Cody & Diamond, 1975) is the ratio between the number of\nindividualsinthemostabundantspecies \ud835\udc41\ud835\udc5a\ud835\udc4e\ud835\udc65andthetotalnumberofindividualsinthesample\n(\ud835\udc41):\ndBP=\ud835\udc41\ud835\udc5a\ud835\udc4e\ud835\udc65\n\ud835\udc41(1.9)\nFisher\u2019s alpha diversity metric (Fisher, Corbet & Williams, 1943a; Magurran, 1988; SDR-IV,\n2020) is:\ndF=\ud835\udefcln\u0012\n1+\ud835\udc41\n\ud835\udefc\u0013\n(1.10)\nwhere\ud835\udc39denotesthenumberofoperationaltaxonomicunit(groupsofcloselyrelatedspecies)\nand\ud835\udc41is the total number of individuals in the sample, and the index is the alpha parameter, and\n\ud835\udefcis approximately equal to the number of species represented by a single individual.", "doc_id": "874de0a4-220c-4850-9d26-50c51e2d6bfe", "embedding": null, "doc_hash": "a82e6a0d1bf0c6730ab2fd50ee45e8636d78ac17559efa8a749a872a3167a7af", "extra_info": {"page_label": "35", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 973}, "relationships": {"1": "03d1bdff-3cb9-4a15-90c5-409b67234e83"}}, "__type__": "1"}, "6a0ac1f1-e8b7-4b42-a644-372cb58b1e6d": {"__data__": {"text": "36\nKempton-Taylor index of alpha diversity ( dKT)(Kempton & Taylor, 1976) measures the\ninterquartileslopeofthecumulativeabundancecurve,where \ud835\udc5b\ud835\udc5fisthetotalnumberofspecies\nwithabundance \ud835\udc45;\ud835\udc46isthetotalnumberofspeciesinthesample; \ud835\udc451and\ud835\udc452arethe25%and\n75% quartiles of the cumulative species curve; \ud835\udc5b\ud835\udc451is the number of individuals in the class\nwhere\ud835\udc451falls;\ud835\udc5b\ud835\udc452is the number of individuals in the class where \ud835\udc452falls:\ndKT=1\n2\ud835\udc5b\ud835\udc451+\u00cd\ud835\udc452\u22121\n\ud835\udc451+1\ud835\udc5b\ud835\udc5f+1\n2\ud835\udc5b\ud835\udc452\nlog(\ud835\udc452\n\ud835\udc451)(1.11)\nMcIntosh\u2019s evenness measure ( eM)(Heip & Engels, 1974) is the ration between the number of\nindividuals in the \ud835\udc56\ud835\udc61\u210especies and the total number of individuals ( \ud835\udc41) plus the number of species\nin the sample ( \ud835\udc46):\neM=\u221a\ufe04\u00cd\ud835\udc5b2\n\ud835\udc56\n(\ud835\udc41\u2212\ud835\udc46+1)2+\ud835\udc46\u22121(1.12)\nwhere\ud835\udc5b\ud835\udc56denotesthenumberofindividualsinthe \ud835\udc56\ud835\udc61\u210especies,\ud835\udc41isthetotalnumberofindividuals,\nand\ud835\udc46is the number of species in the sample.\nShannon-Wiener diversity index (dSW) (SDR-IV, 2020) is defined as the proportion of\nindividuals of species \ud835\udc56in terms of species abundance ( \ud835\udc46):\ndSW=\u2212\ud835\udc46\u2211\ufe01\n\ud835\udc56=1(\ud835\udc5d\ud835\udc56ln\ud835\udc5d\ud835\udc56) (1.13)\nwhere\ud835\udc5d\ud835\udc56denotes the proportion of individuals in the \ud835\udc56-th species.\nTheBrillouin index(\ud835\udc51HB)is defined as:\n\ud835\udc51HB=ln\ud835\udc41!\u2212\ud835\udc46\u2211\ufe01\n\ud835\udc56=1ln\ud835\udc5b\ud835\udc56!\n\ud835\udc41(1.14)", "doc_id": "6a0ac1f1-e8b7-4b42-a644-372cb58b1e6d", "embedding": null, "doc_hash": "cbc466b740d59a7109f5af1cad69c17022a22fe04ecd38df0f78189acd4b3109", "extra_info": {"page_label": "36", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1130}, "relationships": {"1": "88428a16-47ba-4653-9b97-5ab1e11d6a4a"}}, "__type__": "1"}, "9db7d00c-b423-483d-87fc-856f69cca687": {"__data__": {"text": "37\nwhere\ud835\udc41is defined as the number of individuals, \ud835\udc46is the number of species, and \ud835\udc5b\ud835\udc56is defined as\nthe number of individuals in the \ud835\udc56-th species.\nTheStrong\u2019s dominance index (\ud835\udc51\ud835\udc37\ud835\udc64)is defined as:\n\ud835\udc51Dw=max\n\ud835\udc56[(\ud835\udc4f\ud835\udc56\n\ud835\udc41)\u2212\ud835\udc56\n\ud835\udc46] (1.15)\nwhere\ud835\udc4f\ud835\udc56is the sequential cumulative totaling of the \ud835\udc56-th distinct species values ranked from\nlargest to smallest.\nThe expression in brackets is computed for all species, and \ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc56denotes the maximum value in\nbrackets for any species.\nTheSimpson\u2019s index(\ud835\udc51C)and theEnspie index(\ud835\udc51ENS)are defined as:\n\ud835\udc51C=1\u2212\ud835\udc46\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d2\n\ud835\udc56 (1.16)\n\ud835\udc51ENS=1\n\ud835\udc46\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d2\n\ud835\udc56(1.17)\nwhere\ud835\udc5d\ud835\udc56is the proportion of the community represented by species \ud835\udc56.\nTheMcIntosh dominance diversity index (\ud835\udc51McInt)(McIntosh, 1967) is defined as:\n\ud835\udc51McInt=\ud835\udc41\u2212\ud835\udc48\n\ud835\udc41\u2212\u221a\n\ud835\udc41(1.18)\nwhere\ud835\udc41representsthetotalnumberofindividualsinthesample, \ud835\udc48=\u221a\ufe01\u00cd\ud835\udc5b\ud835\udc562,and\ud835\udc5b\ud835\udc56represents\nthe number of individuals in the \ud835\udc56-th species.", "doc_id": "9db7d00c-b423-483d-87fc-856f69cca687", "embedding": null, "doc_hash": "bc5fe85ac7db5d5ec26f73c8f463834a6ddf706783363a5542c6e879dd01afae", "extra_info": {"page_label": "37", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 862}, "relationships": {"1": "c527156b-747d-4333-891b-4b8e17ab815a"}}, "__type__": "1"}, "0a18d397-b760-474e-8d9c-565d8f47b29d": {"__data__": {"text": "38\nTheChao1 richness estimator (\ud835\udc52CR)(Chao, 1984; Eren, Chao, Hwang & Colwell, 2012) uses\nonly the number of singletons (\ud835\udc391)and doubletons(\ud835\udc392)and the observed richness (\ud835\udc46\ud835\udc5c\ud835\udc4f\ud835\udc60)to\nwrite the following estimator for the class richness:\n\ud835\udc52CR=\ud835\udc46\ud835\udc5c\ud835\udc4f\ud835\udc60+\ud835\udc392\n1\n2\ud835\udc392(1.19)\nwhere\ud835\udc391and\ud835\udc392are the count of singletons and doubletons species in the sample, respectively.\nAccordingtoChao,Shen&Hwang(2006),inthepresenceofmanyclassabundancedistributions,\nthis estimator, originally derived as an estimate of minimum possible richness (number of\nindividualspertainingtothatspecificspecies),ismuchsharpifthereferencesamplesizeislarge\nenough. This corroborates the reason for its use as a valid estimator for large number of species.\nTheGini coefficient(eGC)(Gini, 1912) is defined as:\neGC=2\n\ud835\udc5a\ud835\udc462 \ud835\udc5b\u2211\ufe01\n\ud835\udc56=1(\ud835\udc46+1\u2212\ud835\udc56)\ud835\udc65\ud835\udc56!\n\u22121\n\ud835\udc46(1.20)\nwhere\ud835\udc65\ud835\udc56is the number of individuals of the \ud835\udc56-th species ranked from least to most abundant,\n\ud835\udc56\u2208[1,\ud835\udc46]and\ud835\udc5ais the mean abundance of a species \u2013 the mean of the \ud835\udc65\ud835\udc56values. The Gini\ncoefficient measures income inequality, but can also be used to measure any form of uneven\ndistribution. It ranges between 0 and 1, where 0 denotes a perfect inequality and 1 denotes a\nperfect equality, where each species has the same number of individuals.\nTheHeip\u2019s evenness(eHE)is defined as:\neHE=\ud835\udc52\ud835\udc3b\u22121\n\ud835\udc46\u22121(1.21)\nwhere\ud835\udc3bis the Shannon-Wiener entropy of counts using logarithm base \ud835\udc52.\nThePielous evenness(eJ\u2019)is defined as:\neJ\u2019=\ud835\udc3b\nln\ud835\udc46(1.22)", "doc_id": "0a18d397-b760-474e-8d9c-565d8f47b29d", "embedding": null, "doc_hash": "fcad4e78fae71ea95a6be2a2b1156d3716024bcd5ad01ce989453fe0d673ae56", "extra_info": {"page_label": "38", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1408}, "relationships": {"1": "92863689-b0d5-4155-9c18-09683a23cc31"}}, "__type__": "1"}, "e7c39aab-c1ad-40c3-b115-92d214f7c79b": {"__data__": {"text": "39\nSimpsons evenness e SEis defined as:\neSE=1\n\ud835\udc37\n\ud835\udc46\ud835\udc5c\ud835\udc4f\ud835\udc60(1.23)\nwhere\ud835\udc37is dominance and \ud835\udc46\ud835\udc5c\ud835\udc4f\ud835\udc60is the number of observed species.\n1.5.2 Taxonomic Indices\nThequantificationofecosystemdiversityisgenerallyrequiredforpracticesofenvironmental\nplanning. Thetraditionalecologicaldiversityindicespresentedinprevioussectionarebased\non the abundances of species present in the community. Nevertheless, such indices may be\ninsensitivetotaxonomicorsimilardifferences. Withequalspeciesabundancestheymeasurebut\nthespeciesrichness(speciesnumber)(Izs\u00e1k&Papp,2000). Assemblageswiththesamespecies\nrichnessmayeithercomprisespeciesthatarecloselyrelatedtooneanothertaxonomicallyor\nthey may be more distantly related (Rogers, Clarke & Reynolds, 1999).\nTaxonomicindicesconsiderthetaxonomicrelationbetweendifferentindividualsinanecosystem.\nThe diversity thereof reflects the average taxonomic distance between any two individuals,\nrandomlychosenfromasample. Thedistancecanrepresentthelengthofthepathconnecting\nthese two individuals along the branches of a phylogenetic tree (Ricotta, 2002; Rogers et al.,\n1999).\nGibson,Barnes&Atkinson(2001)proposedthedistinctivenessindexdescribingtheaverage\ntaxonomic distance between two randomly chosen individuals through the phylogeny of all\nthe species in a dataset. This distinctiveness possesses different forms (Sohier, 2019), to wit,\ntaxonomic diversity, and taxonomic distinctness, which are defined as follows:", "doc_id": "e7c39aab-c1ad-40c3-b115-92d214f7c79b", "embedding": null, "doc_hash": "ccd8a251a591a1918f871e5aafd691eed7b222ef3828e537f6df80ecce66813b", "extra_info": {"page_label": "39", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1422}, "relationships": {"1": "2c70cd47-6c99-4dae-9d4f-adc9d0fa0031"}}, "__type__": "1"}, "b8ee0692-9fe2-4f53-a318-b89a209265a4": {"__data__": {"text": "40\nTaxonomic diversity : this index includes aspects of taxonomic relatedness and evenness.\n\u0394=\u00cd\u00cd\n\ud835\udc56<\ud835\udc57\ud835\udc64\ud835\udc56\ud835\udc57\ud835\udc65\ud835\udc56\ud835\udc65\ud835\udc57\n\ud835\udc41(\ud835\udc41\u22121)/2(1.24)\nTaxonomic distinctiveness : the measure of pure taxonomic relatedness.\n\u0394\u2217=\u00cd\u00cd\n\ud835\udc56<\ud835\udc57\ud835\udc64\ud835\udc56\ud835\udc57\ud835\udc65\ud835\udc56\ud835\udc65\ud835\udc57\u00cd\u00cd\n\ud835\udc56<\ud835\udc57\ud835\udc65\ud835\udc56\ud835\udc65\ud835\udc57(1.25)\nwhere\ud835\udc65\ud835\udc56=\ud835\udc41\ud835\udc5d\ud835\udc56,\ud835\udc41and\ud835\udc64\ud835\udc56\ud835\udc57representtheabundanceofthe \ud835\udc56-thspeciesinthesample,thenumber\nofindividualsinthesample,andthe\u2019distinctnessweight\u2019giventothepathlengthlinkingspecies\n\ud835\udc56and\ud835\udc57in the hierarchical classification, respectively.\nAverage taxonomic distinctiveness : in case only presence or absence data is considered, both\n\u0394and\u0394\u2217converge to the same statistic \u0394+, which can be seen as the average taxonomic path\nlength between any two randomly chosen species (Clarke & Warwick, 1998b),\n\u0394+=\u00cd\u00cd\n\ud835\udc56<\ud835\udc57\ud835\udc64\ud835\udc56\ud835\udc57\n\ud835\udc46(\ud835\udc46\u22121)/2(1.26)\nwhere\ud835\udc46is the number of species.\nThe studies that verify the relationship of distances between pairs are based on a distance matrix\nbetween all species of a community. The distances can be based on morphological or functional\ndifferences(Izs\u00e1ki&Papp,1995),onthelengthofthebranchesofthephylogeneticrelationships\nbased on molecular data (Pavoine, Ollier & Dufour, 2005; Solow, Polasky & Broadus, 1993) or,\nif the lengths of the branches are not known, on the number of nodes that separate each pair of\nspecies (Faith, 1992).\nThe values within the distance matrix can be interpreted as the distinction between each pair of\nspecies or of each species in particular for all others (Izs\u00e1ki & Papp, 1995; Rao, 1982).", "doc_id": "b8ee0692-9fe2-4f53-a318-b89a209265a4", "embedding": null, "doc_hash": "11b38a36e70c86564410e437ddfdd62bcf7463b275d7e3fab1dd0c205efadb6c", "extra_info": {"page_label": "40", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1440}, "relationships": {"1": "c8d9a29b-fd87-4f92-be81-11c3020474ba"}}, "__type__": "1"}, "48470833-6db9-4b9d-a658-934c20da83ca": {"__data__": {"text": "41\nThese indices make one up in the distances between pairs of species. Sum of Phylogenetic\nDistances;intensivequadraticentropyandextensivequadraticentropy(Izs\u00e1ki&Papp,1995);\naveragedistinctness(Clarke&Warwick,1998a);totaltaxonomicdistinctness(Clarke,Gorley,\nSomerfield & Warwick, 2014); and average distance (Faith, 1994).\nSum of Phylogenetic Distances : it represents the sum of phylogenetic distances between pairs\nof species.\nsPD=\u0012\ud835\udc60(\ud835\udc60\u22121)\n2\u0013\u00cd\u00cd\n\ud835\udc5a<\ud835\udc5b2\ud835\udc5a\ud835\udc5b\ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc5b\n\u00cd\u00cd\n\ud835\udc5a<\ud835\udc5b\ud835\udc4e\ud835\udc5a\ud835\udc4e\ud835\udc5b(1.27)\nAverage Distance from Nearest Neighbor (Vellend, Cornwell, Magnuson-Ford & Mooers,\n2011): it represents the average distance to the nearest taxon.\ndNN=\ud835\udc5a\u2211\ufe01\n\ud835\udc60\ud835\udc5a\ud835\udc56\ud835\udc5b(\ud835\udc51\ud835\udc5a\ud835\udc5b\ud835\udc4e\ud835\udc5a) (1.28)\nwhere\ud835\udc51\ud835\udc5a\ud835\udc5b(\ud835\udc5a,\ud835\udc5b=1,...,\ud835\udc60)is the distance from species \ud835\udc5ato species\ud835\udc5b;\ud835\udc4eis the species\nabundance and \ud835\udc60is the number of species.\nIntensive Quadratic Entropy : it represents the number of species and their taxonomic\nrelationships.\neIQ=\u00cd\ud835\udc51\ud835\udc56\ud835\udc57\n\ud835\udc602(1.29)\nExtensive Quadratic Entropy : it represents the sum of the differences between species.\neEQ=\u2211\ufe01\n\ud835\udc51\ud835\udc56\ud835\udc57 (1.30)\nTotal Taxonomic Distinctness : it represents the average phylogenetic distinctiveness added\nacross all species.", "doc_id": "48470833-6db9-4b9d-a658-934c20da83ca", "embedding": null, "doc_hash": "30c39fe8a90b87b313cb70e20d50ef58a854f98205264ca48d35be45df14d980", "extra_info": {"page_label": "41", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1105}, "relationships": {"1": "48fc9d56-5d40-428c-879a-ca3040e8d45e"}}, "__type__": "1"}, "cbdeba74-e658-4eb9-9816-d7b631dcf59f": {"__data__": {"text": "42\ndTT=\u2211\ufe01\n\ud835\udc56\u00cd\n\ud835\udc56\u2260\ud835\udc57\ud835\udc51\ud835\udc56\ud835\udc57\n\ud835\udc60\u22121(1.31)\nwhere\ud835\udc51\ud835\udc56\ud835\udc57(\ud835\udc56,\ud835\udc57=1,...,\ud835\udc60)is the distance from species \ud835\udc56to species\ud835\udc57and\ud835\udc60is the number of\nspecies.\nAs a further factor of consideration, to apply the taxonomic indexes of a set of species (the\njoint dissimilarity of species or set of pairwise distances between the species in the set), the\nspeciesdistanceiscomputedbymeansofthetopologytaxonomictree. Thetopologicaldistance,\nwhich is the number of the edge between two species in the Linnaean taxonomic tree, is the\ncumulativebranchlengthofthefullphylogenetictree. Anexampleofataxonomictreealong\nwith its species distance matrix is shown in Figure 1.5.\nFigure 1.5 Generic example of taxonomic tree and its respective distance matrix.\nThis matrix shows how cumulative branch length, which corresponds to taxonomic\ndistances, is calculated\nAdapted from Ricotta (2004)", "doc_id": "cbdeba74-e658-4eb9-9816-d7b631dcf59f", "embedding": null, "doc_hash": "9095a9e3146a781075a048899ff324a0d7f1e20400b2df37a88aaf265383ee69", "extra_info": {"page_label": "42", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 837}, "relationships": {"1": "288207e2-6381-45d1-9758-29a4dac1b1e3"}}, "__type__": "1"}, "b39f6e21-038c-485d-8138-2a5056c9bb5c": {"__data__": {"text": "43\n1.6 Measurements based on Shannon Entropy and Multi-information\n1.6.1 Shannon Entropy\nTheconceptofentropyisusedinthermodynamics,statisticalmechanics,andinformationtheory.\nEntropy is considered a measure of uncertainty and of the information necessary for, in any\nprocess, to be able to limit, reduce, or eliminate the uncertainty.\nItturnsoutthattheconceptofinformationandthatofentropyarebasicallyrelatedtoeachother.\nInthefieldofinformationtheory,Shannonentropyisrelatedtoarandomvariableandisusedto\nmeasure the uncertainty of an information source (Shannon, 1948).\nSupposethatanevent(randomvariable)hasaninitialdegreeofindeterminacyequalto \ud835\udc58(i.e.\nthereare\ud835\udc58possiblestates)andsupposeallstatesareequiprobable. Thentheprobabilitythat\none of these combinations occurs will be \ud835\udc5d=1\n\ud835\udc58. Then we can represent the expression \ud835\udc50\ud835\udc56as:\n\ud835\udc50\ud835\udc56=log2(\ud835\udc58)=log2\"\n1\n1\n\ud835\udc58#\n=log2(1\n\ud835\udc5d)=\ud835\udc59\ud835\udc5c\ud835\udc542(1)\u2212log2(\ud835\udc5d)=\u2212log2(\ud835\udc5d)(1.32)\nIfnoweachofthe \ud835\udc58stateshasaprobability \ud835\udc5d\ud835\udc56,thentheentropywillbegivenbytheweighted\nsum of the amount of information:\n\ud835\udc3b=\u2212\ud835\udc5d1log2(\ud835\udc5d1)\u2212\u2212\ud835\udc5d2log2(\ud835\udc5d2)\u2212\u00b7\u00b7\u00b7\u2212\ud835\udc5d\ud835\udc58log2(\ud835\udc5d\ud835\udc58)=\u2212\ud835\udc58\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d\ud835\udc56log2(\ud835\udc5d\ud835\udc56)(1.33)\nTherefore,theentropyofamessage \ud835\udc4b,denotedby \ud835\udc3b(\ud835\udc4b),istheweightedaveragevalueofthe\namountofinformationofthevariousstatesofthemessage;inotherwords,itrepresentsameasure\nof the mean uncertainty about a random variable and therefore the amount of information.\n\ud835\udc3b(\ud835\udc4b)=\u2212\ud835\udc58\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d(\ud835\udc65\ud835\udc56)log2\ud835\udc5d(\ud835\udc65\ud835\udc56)=\ud835\udc58\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d(\ud835\udc65\ud835\udc56)log2(1\n\ud835\udc5d(\ud835\udc65\ud835\udc56)) (1.34)", "doc_id": "b39f6e21-038c-485d-8138-2a5056c9bb5c", "embedding": null, "doc_hash": "c116236a06c97411e958034cfc9a735c80b3f83cf383da645803625a8163953d", "extra_info": {"page_label": "43", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1381}, "relationships": {"1": "9497395d-38eb-400c-a703-93a7eafa77cd"}}, "__type__": "1"}, "7239b683-cd52-4863-bcfa-0872b0cb97c2": {"__data__": {"text": "44\n1.6.2 Multi-information\nIninformationtheory,multi-information(Studen `y&Vejnarov\u00e1,1998)(a.k.atotalcorrelation\n(Watanabe, 1960)), is among the various generalizations of the mutual information, and it\nquantifies the dependency among a group of random variables.\nGivendiscreterandomvariables \ud835\udc4b1,\u00b7\u00b7\u00b7,\ud835\udc4b\ud835\udc5b,themulti-information \ud835\udc47(\ud835\udc4b1,\u00b7\u00b7\u00b7,\ud835\udc4b\ud835\udc5b)isdefinedas:\n\ud835\udc47(\ud835\udc4b1,\u00b7\u00b7\u00b7,\ud835\udc4b\ud835\udc5b)= \ud835\udc5b\u2211\ufe01\n\ud835\udc56=1\ud835\udc3b(\ud835\udc4b\ud835\udc56)!\n\u2212\ud835\udc3b(\ud835\udc4b1,\u00b7\u00b7\u00b7,\ud835\udc4b\ud835\udc5b) (1.35)\nwhere\ud835\udc3b(\ud835\udc65)denotes the entropy and \ud835\udc3b(\ud835\udc65\ud835\udc56,\u00b7\u00b7\u00b7,\ud835\udc65\ud835\udc5b)denotes the joints entropy.\nBoth Shannon entropy and total multi-information are found in the literature to be used for\nclustering and feature selection algorithms (Watanabe, 1960). In this thesis, both measurements\nareusedforfeatureextraction,whereanimageisconsideredanarraycontainingdiscreterandom\nvariable realizations.\n1.7 Feature Selection\nFeatureselectionistheprocessofselectingasubsetofrelevantfeaturesforuseinmodelbuilding\ninmachinelearning. Itisdesiredthatthesubsetoffeaturespromotesbetterperformancethan\nthe original set. This is necessary for simplifying models to make them easier for users to\ninterpret,avoidingthecurseofdimensionality,andreducingdatacorrelationanddatavolume.\nThefundamentalassumptionwhileusingafeatureselectiontechniqueisthatthedatacomprises\nvariousredundantorirrelevantinformationandcanberemovedwithoutincurringmuchloss\nof information. A feature selection algorithm can be seen as a coupling of search techniques\nto propose new feature subsets and an evaluation that measures scores provided by different\nsubsets of features.", "doc_id": "7239b683-cd52-4863-bcfa-0872b0cb97c2", "embedding": null, "doc_hash": "fe693eea4327f4927a68b8931d73ad3a8e79f1d34027900207f2027d75688e8e", "extra_info": {"page_label": "44", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1500}, "relationships": {"1": "c1247868-be08-4b3a-9416-9cc03afc3434"}}, "__type__": "1"}, "2b87975a-2805-47c4-8b8b-6a2b2f66d9ea": {"__data__": {"text": "45\nAutomaticfeatureselectionmethodsarehelpfulwhenalargesetoffeaturesisavailableanda\nsuitable subset must be chosen. In addition to being a type of dimensionality reduction, data\nfusion from multiple data models is an important application. Given a set of features, automatic\nfeature selection attempts to select a subset of size \ud835\udc5a, where (\ud835\udc5a < \ud835\udc41), which maximizes a\ncriterion function \ud835\udc53(\ud835\udc65).\nTo illustrate, let \ud835\udc53(\ud835\udc65)=1\u2212\ud835\udc38, where\ud835\udc38is the rate or probability of error of a classifier. The\ngreaterthecriterionfunction,thelessredundancybetweenthecharacteristicsandtheeasierit\nistodiscriminatepatternsofdifferentclasses. Thefeatureselectionalgorithmwillbeableto\nreduce the dimensionality in this manner, resulting in the smallest possible drop in the power of\nclassdiscriminationbyaclassifierinthefeaturespace. Furthermore,applyingagoodfeature\nselection algorithm reduces the number of training samples required to obtain good results with\na classifier, thereby reducing the dimensionality problem.\nIn addition to selecting the criterion function, an appropriate dimensionality of the reduced\nfeaturespacemust alsobedetermined. Asimplesolutionto thisproblemistoperform feature\nselectionfordifferentvaluesof \ud835\udc5a. AccordingtoJain,Duin&Mao(2000),theauthorsargue\nthatinpracticalproblemswhere |\ud835\udc47|isthesizeofthesettraining,thedimensionalityproblem\ncan be avoided by using fewer than |\ud835\udc47|/10 features.\nDespitetheimportanceoffeatureselection,therearenoclearrulesormethodsfordoingsoineach\napplication,especiallywhenthenumberoffeaturesprovidedis vast. Asaresult, manyfeature\nselectionmethodshavebeendevelopedovertime(Kumar&Minz,2014;Remeseiro&Bolon-\nCanedo, 2019; Venkatesh & Anuradha, 2019).\nTogetthebestperformanceoutofaclassifier,onemustfirstdeterminetheidealdimensionalityfor\nagivenpatternrecognitionproblem. Toaccomplishthis, asimpletrial-and-errordimensionality\nstrategycanbeused,employingadimensionalityreductionmethod(includingfeatureextraction\nand selection) until themaximum performancepoint ofa classifieris reached. Inthis strategy,\ndimensionalityreductiontestsareruntogeneratefeaturesubspacesofvarioussizesuntilthe\ndimensionality that minimizes the classification error is found.", "doc_id": "2b87975a-2805-47c4-8b8b-6a2b2f66d9ea", "embedding": null, "doc_hash": "e7d162f37b98a68b4b9b2188684862ceef407d3427c4e68551863a0a128b3f8c", "extra_info": {"page_label": "45", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2169}, "relationships": {"1": "631862ad-f050-4a61-b21e-7170ea6f5774"}}, "__type__": "1"}, "94087728-8f9c-4f1b-9534-46adb1c7899f": {"__data__": {"text": "46\nThefollowingsectionspresentafewcategoriesoffeatureselectionandfeaturetransformation\ntechniques.\n1.7.1 Linear and Non-linear Techniques\nOne of the commonly used techniques for feature transformation and dimensionality reduction\nis principal componentanalysis(PCA) (Dunteman, 1989), a family of techniques for handling\nhigh-dimensional data that exploits the dependencies between variables to represent them more\ncompactly without losing relevant information. It is a second-order statistical method and\noptimalbymaximizingthevarianceofthenewcompactrepresentation \ud835\udc4candminimizingthe\nmeansquareerrorbetweentheoriginaldata \ud835\udc4bandthenewcompactrepresentation \ud835\udc4c. Although\nthe dimensionality reduction by the PCA is optimal from the point of view of data compression,\nowingtothefactthatitminimizesthemeansquarederrorbetweentheoriginalrepresentation\nand the new representation, it is not optimal for discriminating data in classes.\nBesides being a linear method, PCA assumes that data are found in a Euclidean subspace of\n\ud835\udc45\ud835\udc5b. In many cases, however, linear methods cannot learn the geometric structure of the data.\nTherefore, the hypothesis that data are found in Euclidean space is not valid. It is, therefore,\nnecessarytofinda moresuitablemetricthantheEuclidean distance(metriclearning). Thus,\nmanifold learning can be applied to overcome this limitation. A manifold is a subspace with\ncurvature,andEuclideandistancefailstocapturethegeometricpropertiesofsuchsets. Someof\nthe manifold learning techniques are Laplacian eigenmaps, ISOMAP, locally linear embedding\n(LLE),andmultidimensionalscaling(MDS)(Cox&Cox,2008). Manifoldlearningisapopular\napproach for nonlinear dimensionality reduction, and it uses geodesic distance to understand the\ndata, amongst other advantages.\n1.7.2 Filter, Wrapper, and Embedded Strategies\nThere is another subcategory of methods for feature selection known as Filter, Wrapper, and\nEmbedded. The methods based on the Filter strategy establish evaluation metrics and then", "doc_id": "94087728-8f9c-4f1b-9534-46adb1c7899f", "embedding": null, "doc_hash": "c84284269cafa4ac0fa2695147ff5226ad8dc7928929af7657f07c457a7cf498", "extra_info": {"page_label": "46", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1991}, "relationships": {"1": "1075cadc-927f-4d1e-8cc4-26c375841b14"}}, "__type__": "1"}, "8f491b07-95ef-49ae-97a2-8529ee5b9c45": {"__data__": {"text": "47\neliminates a subset of features before the construction of the classification model (Tuv, Borisov,\nRunger & Torkkola, 2009). Thus, the feature selection is carried out first. Afterward, the\nnecessary steps for training the classifiers are followed. This is in line with the principle that\nmethods basedon the Filter strategy do notincorporatea classifier in thesearchprocess and,\ntherefore,donotrequirelabeleddata (classes)(Habermann,2018). Notwithstanding, methods\nbasedontheFilterstrategyarenotlimitedtobeingunsupervised. Itispossibletouselabeled\nsamples to establish metrics for the attributes without using a classifier. Otherwise, they would\nbe characterized as based on the strategy Wrapper.\nWrapper methods have been widely used for hyperspectral images for band selection. Wrapper-\nbased methods use a classifier and directly evaluate the weight of each feature (Tuv et al., 2009).\nIn this strategy, the selection occurs during the training of the classifier. Then, for each band or\nsetofbandsaddedorremovedfromthepossiblecombinations,theclassifiermustbetrained\nagain,generatingamodelthatisevaluatedafterward(Habermann,2018). Adisadvantageof\nthis strategy relative to Filter is its slowness due to repetitive training processes. In addition,\nsets with a large number of samples may be needed to be performed, especially when using\nparametric classifiers.\nTypically, researchers using supervised band selection have to devise methods capable of\nhandlinglittle trainingdata. Thiscanbe challengingforFilter methodsbasedon classification\nandclassseparationmeasures. However,thescarcityoftrainingdatacanworsentheproblem\nfor methodsbasedon theWrapper strategysincethe methodsrely exclusively onclassifiersto\ngenerateresults. Incompensation forthisdisadvantage, duetothe wrappermethodsusingthe\nclassifierincorporatedinthebandselectionprocess,theselectedbandscanhelptopromotea\nclassifiermodel withmuch higheraccuracyperformance comparedto methodsbased onFilter\nstrategy (Molina, Belanche & Nebot, 2002; Shahana & Preeja, 2016). However, bands selected\nbysuchmethodscanoperatewellonlywiththeclassifierincorporatedintothebandselection\nprocess. Therefore, it is recommended to use the selection with the same classifier to be used in\nthe application for which the bands were selected (Kohavi, John et al., 1997).", "doc_id": "8f491b07-95ef-49ae-97a2-8529ee5b9c45", "embedding": null, "doc_hash": "00fca52535c9d75bea87dbca9ead9f917eb90fd2cde3adf084768aede1799994", "extra_info": {"page_label": "47", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2312}, "relationships": {"1": "f795a17a-785a-45a1-b998-99633b1691c2"}}, "__type__": "1"}, "a363c584-9a78-4df5-9b8d-b8d7396776ae": {"__data__": {"text": "48\nAnothercategoryfoundintheliteratureforfeatureselectionisEmbeddedstrategy. Thisstrategy\ntries to combine the qualities of the two previous strategies, using classification algorithms\nthat havetheir ownfeatureselection methods. Methods basedon theEmbedded strategyuse\nall variables to generate a classification model and then analyze this model by inferring the\nimportanceofitsvariables(Tuv etal.,2009). Thebest-knownrepresentativesofthisstrategy\nare based on decision trees or artificial neural networks (Mitchell, 1982).\n1.7.3 Multi-objective Optimization Algorithms\nBesides the previous strategies, there are feature selection methods based on multiobjective\noptimization algorithms. Xu, Shi & Pan (2017) proposed an incorporated rank-based mul-\ntiobjective band selection (IRMOBS), a method based on the Filter strategy, unsupervised\nand with the objectives based on entropy, variance, and the number of bands. Saqui, Saito,\nDe Lima, Cura & Ataky (2019) proposed an incorporated Decision-maker-based multiobjective\nband selection (IDMMoBS), a method based on the Wrapper strategy, and supervised for\nmultiobjective selection of bands of hyperspectral images.\nSome recent methods with a single objective, which present the most current components\nexplored in the literature, are the trivariate mutual information-clonal selection algorithm\n(TMI-CSA) (Feng, Jiao, Zhang & Sun, 2013) and are based on the adequacy of the mutual\ninformation (MI) that considers the correlation between three variables, the class label, and\ntwo bands. It uses CSA as a search engine for optimization based on the Filter strategy and\nsupervisedlearning. TheSemi-supervisedbandselectionapproachbasedonTMIandgraph\nregulation (STMIGR) proposed in (Feng, Jiao, Liu, Sun & Zhang, 2014) is similar to TMI-CSA\nbut uses a semi-supervised learning strategy that allows the propagation of labels. Finally,\nthemaximuminformationandminimumredundancy-clonalselectionalgorithm(MIMRCSA)\nproposed by Feng, Jiao, Liu, Sun & Zhang (2016) uses CSA to optimize a function derived\nfromMIandentropycalledMaximuminformationandminimumredundancy(MIMR).This\nmethod operates unsupervised, based on the Filter strategy, and uses the search for optimization.\nXie, Li, Lei & Ke (2018) proposed the information gain - gray wolf optimizer (IG-GWO),", "doc_id": "a363c584-9a78-4df5-9b8d-b8d7396776ae", "embedding": null, "doc_hash": "127cbcff1fb84e2e84f834ed4ecda4958009faa661be013b89e9284b8222b310", "extra_info": {"page_label": "48", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2298}, "relationships": {"1": "93f2cdda-78c3-4509-af76-3f1f256593fe"}}, "__type__": "1"}, "ad9494fb-5d43-449c-b165-e7bcec04341a": {"__data__": {"text": "49\nwhich operates as a supervised method with a fitness function based on the information gain\nof the bands, but based on the Filter strategy, as it does not incorporate a classifier in the\nprocess of band selection. The Single-layer neural network (SLN) proposed by Habermann,\nFremont&Shiguemori(2019)isthemethodconsideredFilterbecauseitusesSLNtoselectbands\nand other algorithms for classification; and genetic algorithm with Support Vector Machines\n(GA-SVM)(Nagasubramanian,Jones,Sarkar,Singh,Singh&Ganapathysubramanian,2018;\nZhuo,Zheng,Li,Wang,Ai&Qian,2008)isamethodbasedontheWrapperstrategy,supervised\nand uses a fitness function with a weighted average between classification accuracy and the\nnumberofbands. Thiscombinationistraditionalintheliterature,beingexploredindifferent\nways as presented in (Nagasubramanian et al., 2018; Zhuo et al., 2008).\nAn important and common point of the presented strategies is that the majority has only one\nobjective, feature selection, which does not imply the guarantee of effective classification\nperformance. Methods based on multiobjective optimization demonstrated an interesting ability\ntodealwithconflictingobjectives. Asinmostoftherelatedworkspresentedabove,itallows\nsearching for solutions that achieve a good classification ability with fewer bands. In the\nproposedmethod,weexplorethelimitationsandadvantagesofbothsingleandmultiobjective\noptimization algorithms, intending to find a solution that makes a trade-off between the number\nof features and classification accuracy.\n1.8 Final Considerations\nThis chapter presented the theoretical basis used in the development of this thesis. The concepts\npresentedareofparamountimportancefortheportentousunderstandingoftheproposedmethods.\nConcepts about texture images, digital image processing, texture analysis, multi-resolution\nanalysis, phylogenetic diversity indices, and information theory were presented.\nIn the following chapters, the materials and methods applied in constructing the approaches for\nanalysisandcharacterizationoftextureimagesarediscussed,aimingtoincrease/improvethe\naccuracy performance in classification.", "doc_id": "ad9494fb-5d43-449c-b165-e7bcec04341a", "embedding": null, "doc_hash": "d97fa784287905b73503fba999e79d438c4683102669ab5496ff57517835ae1d", "extra_info": {"page_label": "49", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2123}, "relationships": {"1": "8c368563-9da2-4bf7-93c3-0cc604192ed1"}}, "__type__": "1"}, "fc3c9be0-1dfc-42d6-9943-65dcbcbc3d2a": {"__data__": {"text": "CHAPTER 2\nTEXTURE DESCRIPTORS BASED ON ECOLOGICAL DIVERSITY MEASURES\nGiventhattextureconstitutesanon-deterministicsystemofpatterns,wehypothesizethattextural\npatternsbehavesimilarlytoecologicalpatterns. Largepopulationsofunitscanself-organizeinto\naggregations that generate patterns from non-deterministic nonlinear processes in an ecosystem.\nThischapterdiscussesnovelapproachestoquantifyingsuchacomplexsystemofdiversepatterns\nusingecologicaldiversitymeasures,namelyspeciesdiversity,richness,evenness,andtaxonomic\nindices. The proposed methods consider an image as a species ecosystem, in which case it\nbecomes possible to extract and compute ecological diversity measures to describe the texture.\nFurthermore, such approaches take advantage of the invariance characteristics of ecological\npatterns to construct permutation, rotation, and translation invariant descriptors. Thus, the\nfollowingsectionsinvestigatehowleveraginginformation-theoreticalmeasuresofecological\ndiversity indices in conjunction with measures of biodiversity can provide a robust approach for\ntexture characterization and classification.\n2.1A Novel Bio-Inspired Texture Descriptor based on Biodiversity and Taxonomic\nMeasures\nThis section introduces a novel bio-inspired texture (BiT) descriptor based on biodiversity\nmeasurements(speciesrichnessandevenness)andtaxonomicdistinctiveness. Ecologyprimarily\nexploitstheseconceptsbyconsideringpatternsinecosystems. Inthisthesis,texturalimageis\nconsidered an ecosystem, where both the biodiversity measurements and taxonomic indices are\ncomputed and quantified. The proposed approach exploits both sides of ecological diversity\nindices,towit,distance-basedphylogeneticdiversityindicesandspeciesrichness,abundance,\nand evenness - as a generalization.\nThe BiT descriptoris a generic descriptor thatcan characterize texture information onvarious\nimages. Into the bargain, the BiT relies on the values of the indices, which can be explained and\ninterpreted based on the related ecological concepts. Furthermore, the proposed approach also", "doc_id": "fc3c9be0-1dfc-42d6-9943-65dcbcbc3d2a", "embedding": null, "doc_hash": "6815e8aa6dab09d731b5afe0a298d1b5a2ea609d50efccd544c0065fcfac0992", "extra_info": {"page_label": "51", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2050}, "relationships": {"1": "6a8d220d-28b5-4186-bf03-1e6860268fea"}}, "__type__": "1"}, "0ebef488-61ac-4da8-a0b4-f08531c33ebe": {"__data__": {"text": "52\nexploitscolorinformation. Werepresentanddescribebiodiversityastheinteractionofpixels\nwith their neighborhood within each image channel (R, G, or B) and on a single RGB image.\nBesides,taxonomicindicesandspeciesrichnessmeasuresonwhichthenovelBiTdescriptor\nreliesareofanunderlyinguseastheycapturetheall-inclusivebehavioroftextureimagepatterns.\nIn ecology, they capture the intrinsic properties of the whole ecosystem, although the latter\nforms a non-deterministic complex system. The complexity, in this case, surges when causality\nbreaks down. The aim is that this approach performs well regardless of this texture nature since\nbiodiversity indices measurements cope with such complexity from the ecosystem perspective.\nThemaincontributionisanovelbio-inspireddescriptorthatleveragesspeciesdiversity,richness,\nand taxonomic distinctiveness to build a texture representation for classification purposes. This\ncontribution of the thesis highlights the following points:\n\u2022Modeling each channel of a color image as an ecosystem;\n\u2022Anovelbio-inspiredtexture(BiT)descriptorcombiningmeasurementsofspeciesdiversity\nand richness and taxonomic distinctiveness;\n\u2022The BiT descriptor is invariant to scale, translation and permutation;\n\u2022The BiT descriptor is easy to compute and has low computational complexity;\n\u2022The BiT descriptor is a generic texture descriptor that performs well on different image\ncategories, such as natural textures and medical images.\nIn the following sections, we describe how these ideas were applied to extract efficient features\nfor the texture classification task.\n2.1.1 Images as Ecosystems\nInorderfortheecologicalconceptstobeemployedinthisapproach,weassumethatanimageis\nan abstract model of an ecosystem where:\n\u2022Gray levels of pixels in an image correspond to the species in an ecosystem;\n\u2022Pixels in an image correspond to the individuals in an ecosystem;", "doc_id": "0ebef488-61ac-4da8-a0b4-f08531c33ebe", "embedding": null, "doc_hash": "d12ec9791e4f45ce700d8a143181ce3294c32ce808acca38ef64091a979df0aa", "extra_info": {"page_label": "52", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1873}, "relationships": {"1": "dfe6bee2-b884-43b0-8281-37796e171056"}}, "__type__": "1"}, "c2bfeb1d-271c-483d-aa8f-cd7e57104ea3": {"__data__": {"text": "53\n\u2022The number of different gray levels in an image corresponds to species richness in an\necosystem;\n\u2022The number of pixels per gray level corresponds to species abundance;\n\u2022Thenumberofdistinctgraylevelsinaspecificregionofanimagecorrespondstorelative\nabundance in that region.\nAnother factor is that both the patterns in an ecosystem and texture images form a non-\ndeterministic system.\nFigure 2.1 illustrates an example of an ecosystem with three species, where there are six\nindividuals of white species, five individuals of gray species, and five individuals of black\nspecies.\nFigure 2.1 A gray-level image as an abstract model\nof an ecosystem of three species (three gray levels):\nwhite (6 individuals), gray (5 individuals) and\nblack (5 individuals)", "doc_id": "c2bfeb1d-271c-483d-aa8f-cd7e57104ea3", "embedding": null, "doc_hash": "c7c3ae6cf28b73b08f67743b519e6a08acfceb7c8f855f4f15289a28caa7962c", "extra_info": {"page_label": "53", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 753}, "relationships": {"1": "38f53d92-77a5-410e-8e0c-11545258a526"}}, "__type__": "1"}, "0b97270d-bc2b-4f79-b55c-77ffde38a845": {"__data__": {"text": "54\n2.1.2 Biodiversity and its Measurements\nBiodiversity is defined as the variety within and among life forms on an ecosystem or a site, and\nitismeasuredasacombinationofrichnessandevennessacrossspecies(Rousseau etal.,1999a).\nDiversity can represent variation in several forms, such as genetic, life form, and functional\ngroups. Itisworthyofmentionthatdiversecommunitiesareoftenasignoffragmentedsites\nwhere much species richness is contributed by disturbance species (Rousseau et al., 1999a).\nDifferentobjectivemeasureshavebeenproposedasameanstomeasurebiodiversityempirically.\nThefundamentalideaofadiversityindexistoquantifybiologicalvariability,which,inturn,can\nbe used to compare biological entities composed of direct components in space or time (Sohier,\n2019). Biodiversitycanbeexpressedormonitoredatdifferentscalesandspaces: alphadiversity,\nbetadiversity,andgammadiversity.Jost(2007)presentsmoredetailsonthesethreetypesof\nindices.\nIn texture analysis, the statistical approach defines texture as a set of local measurements\nextractedfromthepattern,favoringimagedescriptionthroughstatisticalrulesthatgovernthe\ndescriptionandtherelationshipbetweenthedifferentgraylevels. Tocharacterizetexture,we\nuse phylogenetic diversity indices, most of which are statistical measures.\nIn ecology, diversity cannot be generally measured solely through data such as abundance and\nspeciesrichness;thephylogeneticparameterisincreasinglybeingincorporatedintothisanalysis\n(Clarke & Warwick, 1998b). Phylogenetic diversity measures a community\u2019s diversity that\nconsiders species relationships (Magurran, 2004b). The combination of species abundance and\nphylogeneticproximityyieldsadiversityindexknownastaxonomicdiversity(DaSilva&Batalha,\n2006).\nThe set of distances between pairs of species accumulated from taxonomic trees is used to\ncalculate taxonomic diversity. In biology, phylogenetic trees and phylogenetic diversity indices\nare used to compare behavior patterns between species from different areas.", "doc_id": "0b97270d-bc2b-4f79-b55c-77ffde38a845", "embedding": null, "doc_hash": "1244303f1f17fd439cd5a79bfe7261944606f28128b4d38ff8ee9b1d1581e33d", "extra_info": {"page_label": "54", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1989}, "relationships": {"1": "b8b088a2-270b-4a4d-9821-857fe16dafe6"}}, "__type__": "1"}, "d5f8a023-9cfd-4ab4-982d-f4c3456f1040": {"__data__": {"text": "55\nIt is important to note that phylogenetic diversity indices based on species richness and the\ndistancebetweenspeciespairscanmeasurespecies-specificpropertiessuchasrelativeabundance\nand parenthood relationships.\nThe following sections present both sides of ecological diversity. It is noteworthy that diversity\nindicesbasedonspeciesrichnesscaptureglobalinformation,whereasthosebasedonparenthood\nrelationships, capture local (spatial) information. In other words, diversity measures are\ncalculated globally. Nevertheless, taxonomic indices capture the spatial arrangement of pixels.\n2.1.2.1 Diversity Measures\nDiversity measurements rely on three assumptions (Magurran, 2004a): (i) all species are equal \u2013\nrichness measurement makes no distinctions among species and considers species exceptionally\nabundant in the same way as those extremely rare. In other words, no species is excluded from\ncomputing the ecosystem richness due to its abundance; (ii) all individuals are equal \u2013 there\nis no distinction between the largest and the most minor individual; however, in practice, the\nleastanimalscanoftenescape,forinstance,bysamplingwithnets. Thisdoesnotnecessarily\napply to taxonomic and functional diversity measures; (iii) species abundance is recorded using\nappropriate and comparable units.\nWe can translate such assumptions to our abstract model as (i) all gray levels are equally taken\nintoaccount regardlessof thenumberof pixels\u2013 richnessmeasurement makesnodistinctions\namong gray levels and treats the gray levels that are exceptionally abundant in the same way as\nthosesignificantlylessrepresented;Inotherwords,allgraylevelswithinanimagearetakeninto\naccount forfurther calculation,regardless ofhow non-representative someof themare; (ii) all\npixelvaluesareequal\u2013thereisnodistinctionbetweenthelargestandthesmallestpixelvalue;\n(iii) gray-level abundance hasto be recorded using appropriate and comparable units such asthe\nintensity.\nSome alpha diversity measures used to build the BiT descriptor, including measures of richness,\ndominance,andevenness(Magurran,2004b;SDR-IV,2020),aredescribedasfollows. They", "doc_id": "d5f8a023-9cfd-4ab4-982d-f4c3456f1040", "embedding": null, "doc_hash": "53f90a1cf1a2348843b514d332f6e754bc797f0756ec13b3a0a5ba98b0fd6cb4", "extra_info": {"page_label": "55", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2113}, "relationships": {"1": "7ac30887-b462-4524-9d44-bc3239a70e22"}}, "__type__": "1"}, "25b92e63-fec9-434d-b143-34594faa01ca": {"__data__": {"text": "56\nrepresentthediversitywithinaparticularecosystem: the richness andevennessof individuals\nwithin a community. All these indices are computed on a gray-level image of dimensions \ud835\udc5aand\n\ud835\udc5bdenotedas I\ud835\udc5a\u00d7\ud835\udc5b. Itisworthnotingthatwewillhenceforthuseimageanalysistermsinsteadof\necosystem ones.\nMargalef\u2019s (dMg) (Clifford et al., 1975; Magurran, 2004a) and Menhinick\u2019s (dMn) (Whittaker,\n1972)diversity index are both the ratio between the number of species ( \ud835\udc46) and the total number\nof individuals in the sample ( \ud835\udc41):\ndMg=\ud835\udc46\u22121\nln\ud835\udc41(2.1)\ndMn=\ud835\udc46\n\ud835\udc41(2.2)\nwhere,\ud835\udc46and\ud835\udc41denote thenumber of differentgray levels and thetotal number ofpixelsin an\nimage, respectively.\nBerger-Parkerdominance (dBP)(Mayetal.,1975)istheratiobetweenthenumberofindividuals\nin the most abundant species ( \ud835\udc41\ud835\udc5a\ud835\udc4e\ud835\udc65) and the total number of individuals in the sample:\ndBP=\ud835\udc41\ud835\udc5a\ud835\udc4e\ud835\udc65\n\ud835\udc41(2.3)\nwhere\ud835\udc41\ud835\udc5a\ud835\udc4e\ud835\udc65denotes the number of pixels belonging to the most frequent gray level in an image.\nFisher\u2019salphadiversitymetric (dF)(Fisher,Corbet&Williams,1943b;SDR-IV,2020)denotes\nthenumber ofoperationaltaxonomic units,thatis, groupsof closelyrelatedindividuals, andit\nis defined as:\ndF=\ud835\udefcln\u0012\n1+\ud835\udc41\n\ud835\udefc\u0013\n(2.4)\nwhere\ud835\udefcis approximately equal to the number of gray levels represented by a single pixel.\nKempton-Taylor index of alpha diversity (dKT) (Kempton & Taylor, 1976) measures the\ninterquartileslopeofthecumulativeabundancecurve. \ud835\udc451and\ud835\udc452arethe25%and75%quartiles", "doc_id": "25b92e63-fec9-434d-b143-34594faa01ca", "embedding": null, "doc_hash": "a03c4ac1e1f7c25b9045e7133e31b170e093c887b4188bf4f13168f40f13f7c5", "extra_info": {"page_label": "56", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1383}, "relationships": {"1": "62bb1acf-72bc-4109-935d-b66b090674ae"}}, "__type__": "1"}, "92a43e63-6501-4107-b0ef-be904b62ca24": {"__data__": {"text": "57\nofthecumulativespeciescurve,respectively, \ud835\udc5b\ud835\udc5fisthenumberofspecieswithabundance \ud835\udc45,\ud835\udc5b\ud835\udc451\nis the number of individuals in the class where \ud835\udc451falls, and\ud835\udc5b\ud835\udc452is the number of individuals in\nthe class where \ud835\udc452falls:\ndKT=1\n2\ud835\udc5b\ud835\udc451+\ud835\udc452\u22121\u2211\ufe01\n\ud835\udc451+1\ud835\udc5b\ud835\udc5f+1\n2\ud835\udc5b\ud835\udc452\nlog\ud835\udc452\n\ud835\udc451(2.5)\nwhere\ud835\udc5b\ud835\udc5fdenotes the number of gray levels with abundance \ud835\udc45;\ud835\udc451and\ud835\udc452are the 25% and 75%\nquartilesofthecumulativegraylevelcurve; \ud835\udc5b\ud835\udc451isthenumberofpixelsintheclasswhere \ud835\udc451\nfalls;\ud835\udc5b\ud835\udc452is the number of pixels in the class where \ud835\udc452falls.\nMcIntosh\u2019s evenness measure (eM) (Heip & Engels, 1974) is the ratio between the number of\nindividuals in the \ud835\udc56-th species and the total number of individuals, and the number of species in\nthe sample:\neM=vuuuuuut\ud835\udc46\u2211\ufe01\n\ud835\udc56=1\ud835\udc5b2\n\ud835\udc56\n(\ud835\udc41\u2212\ud835\udc46+1)2+\ud835\udc46\u22121(2.6)\nwhere\ud835\udc5b\ud835\udc56denotes the number of pixels of the \ud835\udc56-th gray level (the summation is over all gray\nlevels).\nShannon-Wiener diversity index (dSW) (SDR-IV, 2020) is defined as the proportion of\nindividuals of species \ud835\udc56in terms of species abundance ( \ud835\udc46):\ndSW=\u2212\ud835\udc46\u2211\ufe01\n\ud835\udc56=1(\ud835\udc5d\ud835\udc56ln\ud835\udc5d\ud835\udc56) (2.7)\nwhere\ud835\udc5d\ud835\udc56denotes the proportion of pixels in the \ud835\udc56-th gray level.\n2.1.2.2 Taxonomic Indices\nThe ecological diversity indices presented in the previous section rely on the richness and\nabundance of species present in a community. Nevertheless, such indices may be insensitive", "doc_id": "92a43e63-6501-4107-b0ef-be904b62ca24", "embedding": null, "doc_hash": "a35bb45b0586f63eebd56c58dbf651ed74f381a2d18d70624bfde4ff200c0828", "extra_info": {"page_label": "57", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1264}, "relationships": {"1": "3e142f07-f872-42a9-b6c1-5e93ba3abb66"}}, "__type__": "1"}, "539bb7dd-fc68-45a6-be67-fb33adfd057e": {"__data__": {"text": "58\ntotaxonomicdifferencesorsimilarities. Withequalspeciesabundances,theymeasuremerely\nthe species richness. Assemblages with the same species richness may either comprise species\nclosely related taxonomically or more distantly related (Rogers et al., 1999)\nTaxonomicindicesconsiderthetaxonomicrelationbetweendifferentindividualsinanecosystem.\nThe diversity thereof reflects the average taxonomic distance between any two individuals\nrandomlychosenfromasample. Thedistancecanrepresentthelengthofthepathconnecting\nthese two individuals along the phylogenetic tree branches (Rogers et al., 1999). Taxonomic\ndiversity and taxonomic distinctiveness define the relationship between two organisms in an\nexisting phylogeny in a community (Clarke & Warwick, 1998a; Gibson et al., 2001), and\nthreekeyfactorscharacterizethem: (i)thenumberofindividuals;(ii)thenumberofspecies;\n(iii) the structure of species connection, that is, the number of edges. Furthermore, Gibson\net al.(2001) also proposed the distinctiveness index describing the average taxonomic distance\nbetweentworandomlychosenindividualsthroughthephylogenyofallspeciesinasample. This\ndistinctivenessmayberepresentedastaxonomicdiversityandtaxonomicdistinctness(Sohier,\n2019), which is described as follows.\nTaxonomicdiversity (\u0394)(Clarke&Warwick,1998a)includesaspectsoftaxonomicrelatedness\nandevenness. Inotherwords,itconsiderstheabundanceofspecies(numberofdifferentgray\nlevels)andthetaxonomicrelationshipbetweenthem,andwhosevaluerepresentstheaverage\ntaxonomic distance between any two individuals (pixels) chosen at random from a sample.\n\u0394=\ud835\udc46\u2211\ufe01\n\ud835\udc56=0\ud835\udc46\u2211\ufe01\n\ud835\udc56<\ud835\udc57\ud835\udc64\ud835\udc56\ud835\udc57\ud835\udc65\ud835\udc56\ud835\udc65\ud835\udc57\n\ud835\udc41(\ud835\udc41\u22121)\n2(2.8)\nwhere\ud835\udc65\ud835\udc56,\ud835\udc65\ud835\udc57,and\ud835\udc64\ud835\udc56\ud835\udc57representthenumberofpixelsthathavethe \ud835\udc56-thgraylevelintheimage,the\nnumberofpixelsthathavethe \ud835\udc57-thgraylevelintheimage,andthe\u2019distinctnessweight\u2019(distance)\ngiven to the path length linking pixels \ud835\udc56and\ud835\udc57in the hierarchical classification, respectively, and\n\ud835\udc56,\ud835\udc57=0,...,\ud835\udc46.", "doc_id": "539bb7dd-fc68-45a6-be67-fb33adfd057e", "embedding": null, "doc_hash": "0d2d06d2b4914a1f5dd869afee5793b94fc2d95b39b9ac7cbbaa4fb2a75aeb49", "extra_info": {"page_label": "58", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1907}, "relationships": {"1": "6350f339-8203-443f-b87d-1144b77b3f85"}}, "__type__": "1"}, "1d2f96aa-baa9-494c-9044-dce399687649": {"__data__": {"text": "59\nTaxonomicdistinctiveness (\u0394\u2217)isameasureofpuretaxonomicrelatedness. Itrepresentsthe\naveragetaxonomicdistancebetweentwoindividuals(pixels),constrainedtodifferentspecies\n(gray levels).\n\u0394\u2217=\ud835\udc46\u2211\ufe01\n\ud835\udc56=0\ud835\udc46\u2211\ufe01\n\ud835\udc56<\ud835\udc57\ud835\udc64\ud835\udc56\ud835\udc57\ud835\udc65\ud835\udc56\ud835\udc65\ud835\udc57\n\u2211\ufe01\u2211\ufe01\n\ud835\udc56<\ud835\udc57\ud835\udc65\ud835\udc56\ud835\udc65\ud835\udc57(2.9)\nDifferentecologicalstudies,particularlylarge-scaleones,employspeciesrichnesstomeasure\nbiodiversity. Nevertheless, species richness as the sole reflection of biodiversity can present\nlimitations as all species are treated equally without considering phylogenetic relationships.\nTheliteratureshowsthatphylogeneticrelationshipsareessentialfactorsdeterminingspecies\u2019\nextinction. Thus,phylogeneticinformationmaybeabetterindicatorofthepreservationvalue\nthanmerelythespeciesrichness. Studiesverifyingthedistancerelationshipbetweenthespecies\npairsdependonadistancematrixcomputedforallcommunityspecies. Inecology,thisdistance\nmatrixreliesoneitherfunctionalormorphologicaldifferences(Izs\u00e1ki&Papp,1995),onthe\nlength of the branches of the phylogenetic relationships based on molecular data (Pavoine et al.,\n2005). Accordingly,ifthebranches\u2019lengthisunknown,suchdistancesrelyonthenumberof\nnodes that separate each pair of species (Faith, 1992). Therefore, the distance matrix values\ncanbeinterpretedasthedistinctnessbetweeneachpairofspeciesorbetweeneachparticular\nspecies vis-\u00e0-vis all others (Izs\u00e1ki & Papp, 1995).\nSum of Phylogenetic Distances (sPD) represents the sum of phylogenetic distances between\npairs of species.\nsPD=\u0012\ud835\udc46(\ud835\udc46\u22121)\n2\u0013\u2211\ufe01 \u2211\ufe01\n\ud835\udc56<\ud835\udc572\ud835\udc56\ud835\udc57\ud835\udc4e\ud835\udc56\ud835\udc4e\ud835\udc57\n\u2211\ufe01 \u2211\ufe01\n\ud835\udc56<\ud835\udc57\ud835\udc4e\ud835\udc56\ud835\udc4e\ud835\udc57(2.10)\nwhere\ud835\udc56and\ud835\udc57denote two distinct gray levels, and \ud835\udc4eis the number of pixels that have such gray\nlevels.", "doc_id": "1d2f96aa-baa9-494c-9044-dce399687649", "embedding": null, "doc_hash": "d16342b809f7921122ca58c841181791435dfed8e3c89a5cf547d31ca44816f6", "extra_info": {"page_label": "59", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1588}, "relationships": {"1": "7fc2c9d9-2475-4b34-805c-0c5f8443c9e0"}}, "__type__": "1"}, "2837b228-0fc3-4393-be77-279fe47129f9": {"__data__": {"text": "60\nAverage Distance from the Nearest Neighbor (dNN) (Vellend et al., 2011) represents the\naverage distance to the nearest taxon 1.\ndNN=\ud835\udc46\u2211\ufe01\n\ud835\udc56min\u0000\ud835\udc51\ud835\udc56\ud835\udc57,\ud835\udc4e\ud835\udc56\u0001(2.11)\nwhere\ud835\udc51\ud835\udc56\ud835\udc57(\ud835\udc56,\ud835\udc57=1,...,\ud835\udc46)is the distance between the species (gray levels) \ud835\udc56and\ud835\udc57;\ud835\udc4eis the\nabundance of the species, and \ud835\udc46is the total number of species (gray levels).\nExtensive Quadratic Entropy (eEQ) represents the sum of the differences between gray levels.\neEQ=\ud835\udc46\u2211\ufe01\n\ud835\udc56\u2260\ud835\udc57\ud835\udc51\ud835\udc56\ud835\udc57 (2.12)\nIntensive Quadratic Entropy (eIQ) represents the number of species and their taxonomic\nrelationships. It aims at establishing a possible link between the diversity indices and the\nbiodiversitymeasurementindices. Thus,expressingtheaveragetaxonomicdistancebetween\ntwospecieschosenatrandom,therelationshipsbetweentheminfluencetheentropy,unlikeother\ndiversity indices.\neIQ=\ud835\udc46\u2211\ufe01\n\ud835\udc56\u2260\ud835\udc57\ud835\udc51\ud835\udc56\ud835\udc57\n\ud835\udc462(2.13)\nTotal Taxonomic Distinctness (dTT): represents the average phylogenetic distinctiveness added\nacross all species (gray levels).\ndTT=\u2211\ufe01\n\ud835\udc56\ud835\udc46\u2211\ufe01\n\ud835\udc56\u2260\ud835\udc57\ud835\udc51\ud835\udc56\ud835\udc57\n\ud835\udc46\u22121(2.14)\n1Taxon is a group of one or more populations of an organism or organisms seen by taxonomists to form\na unit.", "doc_id": "2837b228-0fc3-4393-be77-279fe47129f9", "embedding": null, "doc_hash": "84d83c5c85f885b1aae4b2fa5981e45643b97fdfa2ba81657a98584d706da669", "extra_info": {"page_label": "60", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1089}, "relationships": {"1": "9beb6642-1959-4e77-aea5-03615c04ac7c"}}, "__type__": "1"}, "d34eb661-b5b4-43c7-95c1-64dd36586c42": {"__data__": {"text": "61\nAccordingly, in image processing, such indices allow for each individual\u2019s (pixel) specific\nlocation (physical point in space) and the spatial distribution of gray levels. The following\nindices are based on the distances between pairs of species.\nIt is worth noting that Equations 2.1 to 2.9 are based on species richness, abundance, and\nevenness, whereas Equations 2.10 to 2.14 are based on the pairwise distance between pairs\nof species. All measurements described in Equations 2.1 to 2.14 can be computed from an\nimage \u2013in thissection, fromeachchannel ofa colorimage\u2013 andtheyresult inscalar values.\nNormalizationisrequiredbecausedynamicrangesofsuchscalarsarerelatedtospeciesrichness,\nabundance, and their relationship within an image or a region of an image, either directly or\ninversely. Therefore,thesescalarsareconcatenatedandnormalizedwithintheinterval [0,1]\nusing min-max mapping to form a \ud835\udc51-dimensional feature vector named the BiT descriptor.\nThetaxonomicindicesrequireataxonomictreetocomputespecies\u2019jointdissimilarity(different\ngray levels) or pairwise distances between species (different gray levels). The topological\ndistance, defined as the number of edges between two species in the Linnaean taxonomic tree, is\nthe entire phylogenetic tree\u2019s cumulative branch length. An example of a taxonomic tree and its\nspecies distance matrix is shown in Figure 2.2.\nBasedontheexamplementionedabove(Figure2.2),wecanderiveaninstanceofthetaxonomic\ntree and its corresponding distance matrix of gray levels (Figure 2.3). We have represented\nthe taxonomic tree as a matrix, where the distance between two gray levels represents the\ndistance between two species. The division of species in the rooted tree shows the phylogenetic\nrelationship between ancestor species. Such a division allows computing indices connecting\ndiversity, richness,andparenthood. Furthermore,a dendrogramcandescribetheevolutionary\nrelationships between species: the parenthood relationship between gray levels, where the\nleaves represent the species and the internal nodes represent the common ancestors of the\nspecies. This relationship allows establishing an evolutionary connection between the gray\nlevels (species) (Vane-Wright, Humphries & Williams, 1991), which, in this work, relies on the\nintrinsic properties of the texture present in an image. Thus, the division of an image or a patch", "doc_id": "d34eb661-b5b4-43c7-95c1-64dd36586c42", "embedding": null, "doc_hash": "13fc56d3b4acc9db0f4e12ec283b5614a5170fbf85ffbcb4f2d69fa2f447e633", "extra_info": {"page_label": "61", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2372}, "relationships": {"1": "2712329b-bd59-4c30-bccf-f48c0b144ad4"}}, "__type__": "1"}, "0bd24398-6fb7-4d31-84f8-8fb9ca9dde49": {"__data__": {"text": "62\nFigure2.2 Genericexampleofafour-speciestaxonomictreeforfourspecies(A,B,C,and\nD) and its respective distance matrix. This matrix shows how cumulative branch length\ncorresponding to taxonomic distances is calculated\nAdapted from Ricotta (2004)\nfor generating a dendrogram should rely on the parenthood, the similarity between pixels.\nFigure 2.3 illustrates the process of division performed in an image or part of it to assemble\naphylogenytree(dendrogram)basedonthesimilaritybetweengraylevelsforcomputingthe\ntaxonomic indexes. In this case, some iterations are needed to divide the original region/image\nuntilasinglegraylevelremainsoneachleaf. Thedivisioniscarriedoutbasedonathreshold\n\u2013 considering all the pixels in the entire image \u2013 which splits recursively an image into two\nparts, each containing pixels of gray levels above (right) and below (left) the threshold until\nthe number of species present in each region is 1. Thus, the threshold can be the average of\ngray levels, where a gray level is a set of pixels with the same intensity value. From the original\nimage, having five gray levels (6, 75, 117, 141, 230), with average(6+75+117+141+230)\n5=113.8, in\nthe first iteration (step 1), gray levels 6 and 75 (left) are below the threshold 113.8, whereas gray\nlevels 117, 141, and 230 (right) are above the threshold.", "doc_id": "0bd24398-6fb7-4d31-84f8-8fb9ca9dde49", "embedding": null, "doc_hash": "ee44c348b34e07f213d1be642dd7c34994444eca4218d91a60385b1ff2b97a3f", "extra_info": {"page_label": "62", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1326}, "relationships": {"1": "5443c456-b1f3-41f0-abe6-a808180d489d"}}, "__type__": "1"}, "0f1cc6ed-1cf3-487d-9809-fc0cd4ac101c": {"__data__": {"text": "63\nFigure 2.3 Construction of a phylogenetic tree for computing the taxonomic indexes.\nIn each iteration (step), the image is divided based on species (gray levels). The average\nspecies value is used as a threshold at each step\nThe second iteration (step 2) splits the left part resulting from step 1, that is, gray levels 6 (left)\nand75(right),intotwoparts. Sincetherearesinglegraylevelsineachregionresultingfrom\nstep 2, these regions become leaves.", "doc_id": "0f1cc6ed-1cf3-487d-9809-fc0cd4ac101c", "embedding": null, "doc_hash": "0c79cb51af24f1ec9b2ded8f9ff32421263cc7b8e5a6b163849de8dae9d4bca9", "extra_info": {"page_label": "63", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 450}, "relationships": {"1": "3d2845e8-cf5e-4aac-8a69-0bf6fee987ca"}}, "__type__": "1"}, "b5dc7a52-9490-420c-a7fa-d8e88d048038": {"__data__": {"text": "64\nThe third iteration (step 3) separates the right part resulting from step 1 into two parts: pixels of\ngray levels 141 and 117, which are below the threshold (162.6) go to the left, while pixels of\ngray-level 230 to the right.\nFinally,thefourthiteration(step4)separatestheleftpartfromstep3intotwoparts: pixelsof\ngraylevels141and117. Figure2.4illustratestherootedtree,thedendrogram,andtherespective\nspecies (gray levels), as well as their characteristics.\n(a)\n(b) (c)\nFigure 2.4 Example of (a) rooted tree; (b) a dendrogram; (c) and the respective distance\nmatrix of gray levels computed from the image in Figure 2.3. Note that (a) and (b) are\nequivalent. The dendrogram allows computing the phylogenetic indexes to infer the\nphylogenetic relationship between existing gray levels in the original image. Therefrom, the\ntaxonomic indexes are likewise computed\n2.1.3 Properties of BiT Descriptors\nFormanyapplications,atexturedescriptorshouldhaveessentialpropertiessuchasinvariance\nto rotation, translation, and scale. Furthermore, the descriptor should be easy to calculate.\nThediversityindicesbasedonspeciesrichnessmeasurepropertiesdirectlyrelatedtospecies,\nsuchastheirrelativeabundanceandevenness. Thesemeasurementsareinvarianttoin-plane", "doc_id": "b5dc7a52-9490-420c-a7fa-d8e88d048038", "embedding": null, "doc_hash": "9495a643c46f9596e6e53d1b636c78ef72885c4eba7f593dcbac954ab5609936", "extra_info": {"page_label": "64", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1238}, "relationships": {"1": "da2688ab-5fcc-4ebd-a74e-3c6d5836bf99"}}, "__type__": "1"}, "7c04e0a5-695d-4a5d-bedd-df418147b0bd": {"__data__": {"text": "65\nrotations and scale (because the true essence of the pattern is invariance). The fundamental idea\nof diversity indices is to quantify biological variability, which, in turn, can be used to compare\nbiological entities composed of direct components, whether space or time (Sohier, 2019).\nBiodiversity can be expressed or monitored at different scales and spaces. It is assumed that all\nspecies are equal, meaning that richness measurement makes no distinctions among species and\ntreats the exceptionally abundant species in the same way as scarce species. All individuals are\nequal, meaningthere isno distinction betweenthe largestand theminor individual (Magurran,\n2004a).\nIn our abstract model, these assumptions may be expressed as pixels of any gray level are equal.\nTherefore, the richness measurement makes no distinctions among gray levels and treats pixels\nthat are exceptionally abundant in the same way as significantly less represented pixels. In\notherwords,pixels ofallgraylevelspresentin animageareconsideredforfurther calculation,\nregardless of how non-representative some are; and all pixel values are equal. There is no\ndistinction between the largest and the smallest pixel value.\nIn ecology, a pattern is subject to how form remains invariant to changes in measurement.\nSomepatternsretainthesameshapeafteruniformlystretchingorshrinkingthemeasurement\nscale. The rotational invariance in the ecological pattern has been stated by Frank & Bascompte\n(2019), being the most general way to understand commonly observed patterns. From there,\nspecies abundance distributions provide a transcendent example in which the maximum entropy\nandneutralmodelscansucceedinsomecasesbecausetheyderivefrominvarianceprinciples.\nLikewise, as presented by Daly, Baetens & De Baets (2018), diversity is invariant to the\nspecies abundance vector\u2019s permutation. Rousseau, Van Hecke, NIjssen & Bogaert (1999b)\nemphasizesthatthereisaone-to-onecorrespondencebetweenabundancevectorsandLorenz\ncurves. Consequently, abundancevectorscanbepartiallyorderedaccordingtotheLorenzorder,\nwhich is permutation-invariant (rotation) and scale-invariant.", "doc_id": "7c04e0a5-695d-4a5d-bedd-df418147b0bd", "embedding": null, "doc_hash": "8d7316e0d5fd9afe2faced3ba53bda9166d3e9b563700d995301c1608cb9e979", "extra_info": {"page_label": "65", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2129}, "relationships": {"1": "7d7b5e52-baa9-48e7-b040-7c9ec7b6e6b2"}}, "__type__": "1"}, "e0d3dda5-ec4e-4bc5-83bd-18c9305fc34f": {"__data__": {"text": "66\nTherefore, the BiT descriptor combines statistical and structural approaches and takes advantage\nofecologicalpatterns\u2019invariancecharacteristicstopermutation,rotation,andscalebycombining\nspecies richness, abundance, evenness, and taxonomic indices.\n2.1.4 BiT and other Texture Descriptors\nThe BiT descriptor shares some characteristics of both GLCM (Haralick et al., 1973) and\nLBP (Pietik\u00e4inen et al., 2011) descriptors. The BiT descriptor also characterizes textures based\non second-order statistical properties, which involves comparing pixels and determining how a\npixel at a specific location relates statistically to pixels at different locations.\nInecology,taxonomicindicesapproximatesecond-orderstatisticsatthespecieslevel. These\nindices are based on group analysis, thus enabling a behavioral exploration of the neighborhood\nof regions displaced from a reference location. For example, given a distance measurement\nbetween pairs of species (pairs of pixels of different gray levels), a classical approach to solving\nthephylogenyissuecanbefindingatreethatpredictstheobservedsetofadjoiningdistances.\nSuch distances are represented in a matrix that indicates the existing phylogenetic distance,\nreducingittoasimpletableofpairwisedistances(Rogers etal.,1999;Vane-Wright etal.,1991).\nFurthermore, the BiT descriptor also shares some characteristics of Gabor filters (Fogel & Sagi,\n1989). Gabor filters explore different periodicities in an image and attempt to characterize a\ntextureatthesedifferentperiodicities. Thisanalysisisconfinedtotheadjacentneighborhoodsof\ntheindividualpixels. Thesewithin-neighborhoodperiodicitypropertiescanbeusedtorecognize\ntexture differences between the different regions. Accordingly, phylogenetic trees combined\nwith diversity indices are used in biology to compare behavioral patterns between species in\ndifferentareasandwithin-neighborhood. Besides,diversityindicesbasedonspeciesrichness\nare of an underlying use when defining an all-inclusive behavior of an ecosystem, forming a\nnon-deterministic complex system.", "doc_id": "e0d3dda5-ec4e-4bc5-83bd-18c9305fc34f", "embedding": null, "doc_hash": "8222eaeee0fa604a8ab8261342845337fafd2a0bf223cf7edb8d60d9469a0d51", "extra_info": {"page_label": "66", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2052}, "relationships": {"1": "df3c3e60-1f52-4301-87c4-523b1def6695"}}, "__type__": "1"}, "17a298fe-fdb5-420a-ba45-d433511bd530": {"__data__": {"text": "67\n2.1.5 Case Study\nThissectionpresentshowtheproposedbio-inspiredtexturedescriptorcanbeintegratedwith\nimage processing and machine learning algorithms for classification tasks. The proposed\nclassification scheme is structured into five stages: image channel splitting, preprocessing,\nfeatureextraction,normalization,andtraining/classification. Figure2.5showsanoverviewof\ntheproposedscheme. Algorithm2.1integratesthefirstthreesteps,anditreceivesanRGBimage\nas input and provides a \ud835\udc51-dimensional feature vector of BiT descriptors. An implementation of\nthis algorithm is available as a Python module 2.\nThe five stages are described as follows.\nFigure 2.5 An overview of the proposed scheme to evaluate the BiT descriptor and\ncompare it with other texture extractors\n2https://github.com/stevetmat/BioInspiredFDesc. The Python class BiT(image, b_feat = True, t_feat =\nTrue,unsharp_filter=True,crimmins_filter=True,normalization=False )generatesa56-dimensional\nfeature vector. The library may be found in https://pypi.org/project/Bitdesc/.", "doc_id": "17a298fe-fdb5-420a-ba45-d433511bd530", "embedding": null, "doc_hash": "a66fd9dbff65c4f951258f607d58b3699fc9c8e27071814ffaf13c50e634a119", "extra_info": {"page_label": "67", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1033}, "relationships": {"1": "e277e0a2-4e3f-45ac-ad33-df01be44018d"}}, "__type__": "1"}, "bc7083cb-4587-4b28-915c-822014959b30": {"__data__": {"text": "68\n2.1.5.1 Channel Splitting\nBesidestheoriginalRBGimage,eachimagechannel(R,G,B)isconsideredaseparateinput.\nNotwithstandingthatthetexturedescriptorspresentedinChapiter1haveshownadiscriminative\nability to classify texture patterns, their performance on natural and microscopic images may be\nbounded on the condition that they are applied only to gray-level images. Thus, they do not\nexploitcolorinformation. M\u00e4enp\u00e4\u00e4&Pietik\u00e4inen(2004)andCernadas,Fern\u00e1ndez-Delgado,\nGonz\u00e1lez-Rufino & Carri\u00f3n (2017) evaluated the impact of color on texture analysis, and\ntheystatedthattheyaredistinctphenomenathatshouldbetreatedindividually. Additionally,\ncomparing texture features extracted from gray-level and color images, it has been put forth\nthat color information improves the accuracy under static illumination conditions. However,\nemployingtextureandcolorinparallelisnotaspowerfulaseithercolororgray-leveltexture\nalone. The channel splitting aims to capture the textural information of color images based\nontheprinciplethatmostecosystemsworkinacause-effectrelationship. Sucharelationship\nimplies that when one resource is added or lost, it affects the entire ecosystem. Some of the\nmost marked temporal/spatial fluctuations in species abundances are linked to this cause-effect\nrelationship(Shimadzu,Dornelas,Henderson&Magurran,2013). Therefore,wecharacterize\nthe biodiversity in an image by local descriptors generated from the interaction between a pixel\nand its neighborhood in each channel (R, G, B) and the RGB image.\nThe conversion from RGB to grayscale was carried out using:\nRGB[A] to Gray: \ud835\udc4c\u21900.299\u00b7\ud835\udc45+0.587\u00b7\ud835\udc3a+0.114\u00b7\ud835\udc35 (2.15)", "doc_id": "bc7083cb-4587-4b28-915c-822014959b30", "embedding": null, "doc_hash": "650192c70c445b392591a876401700528a5f641530223237fd0f08c4ccdb4509", "extra_info": {"page_label": "68", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1620}, "relationships": {"1": "a973dd23-e3f3-4f3e-a292-a407feabc1a3"}}, "__type__": "1"}, "e18e2f3b-abd0-4348-8846-572392427fb4": {"__data__": {"text": "69\n2.1.5.2 Preprocessing\nIt consists of an unsharp masking filter to highlight image characteristics and a Crimmins filter 3\ntoremovespeckles(Crimmins,1985). Theunsharp 4filter(Polesel,Ramponi&Mathews,2000)\nisappliedtoeachimagechannel,andtheCrimminsfilterisappliedtotheRGBimagetoimprove\ntheir quality for the feature extraction step.\nUnsharp masking, a method well-known to photographers, is used to modify the relative\nhigh-passcontentofanimagebydeletingaversionoftheimagethathasbeensoftened(lowpass\nfiltered). The latter can be accomplished optically by developing a blurry image onto a negative\nfilmandthenusingthisfilmasamaskduringaseconddevelopmentstage. Whenprocessing\ndigital picture data, it is preferable to maintain the image\u2019s local mean. Contrary to its name,\nan\"unsharpmask\"isusedtosharpenanimage. Inthepost-processingofthevastmajorityof\ndigital photos, sharpening is essential for highlighting texture and detail. Unsharp masks are the\nmost popular type of sharpening and may be applied by practically all image editing programs.\nAnunsharpmaskcannot provideextradetails,but itcanconsiderablyimprove theappearance\nof existing details by enhancing small-scale acuity. The sharpening techniqueemploys a slightly\nblurred version of the original image, which is removed from the original to create the unsharp\nmask (effectively a high-pass filter) to detect the presence of edges. Using this mask, contrast is\ndeliberatelyraisedalongtheseedges, resultinginasharperfinalimage. Itturnsoutthatablurry\nmaskemploysatrickperformedbythehumanvisualsystem. Atthebordersofsharptransitions,\nthe human eye perceives what is known as \"Mach bands,\" named after their discovery in the\n1860s by physicist Ernst Mach. These boost our ability to distinguish edge details.\nOn the other hand, the Crimmins speckle removal algorithm works by putting an image through\na speckle and removing the filter that uses complimentary hulling to reduce an image\u2019s speckle\nindex. The algorithm uses a non-linear noise reduction technique that compares each pixel\nintensitytoitseightnearestneighbors. Basedontherelativevalues,itaddsordecrementsthe\n3More details about the implementation: https://homepages.inf.ed.ac.uk/rbf/HIPR2/crimmins.htm\n4Parameters: radius=5, amount=2", "doc_id": "e18e2f3b-abd0-4348-8846-572392427fb4", "embedding": null, "doc_hash": "95d3b99f43293aaf0f8fd278d0423b152646c971f1a696de0e09b52f8d3205fc", "extra_info": {"page_label": "69", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2249}, "relationships": {"1": "39f278e4-db33-4ae3-a23c-c13178eda2d3"}}, "__type__": "1"}, "c769956c-ef4b-47c7-bd06-67d529b86e25": {"__data__": {"text": "70\npixelvaluetomakeitmorerepresentativeofitssurroundings. Crimmins\u2019approachfornoisy\npixelchange(anddetection)ismoresophisticatedthanthenon-linearmedianfilter\u2019sranking\nprocedure. Inasearchforintensityspikes,the\"middle\"pixelvalueineachneighboringwindow\nis compared with each group of neighbors (N-S, E-W, NW-SE, NE-SW).\n2.1.5.3 Feature Extraction and Concatenation\nAfter the preprocessing step, the images undergo feature extraction, which looks for informative\nanddiscriminativecharacteristics. Imagesarerepresentedbyseveralmeasurementsorganizedin\nfeaturevectors. Fromeachimage, weextractbiodiversity measurements(Equations2.1 to2.7)\nandtaxonomicindices(Equations2.8to2.14),whichareconcatenatedintoasinglevector. This\nprocess is repeated for all the images of a dataset.\n2.1.5.4 Normalization\nBefore the training step, we first split the feature vectors into training and test sets and perform\nfeaturenormalizationoverthetrainingdata,wherevaluesarenormalizedtotherange [0,1]using\nthemin-maxnormalization. Afterward,weperformnormalizationontestinginstancesusingthe\nminimum and maximum values of the training variables. In the case of \ud835\udc58-fold cross-validation,\nwe used the same procedure by splitting the feature vectors into \ud835\udc58folds and computing the\nmin-maxpairsinthemergedtrainingfolds. Thetrainingdatamin-maxpairsarethenusedto\nnormalizeboththetrainingandthetestfold. Thisprocedureisrepeatedforeachnewtraining/test\nfold during the cross-validation procedure.\n2.1.5.5 Training/Classification\nThefinalstepoftheproposedschemeconsistsofusingashallowapproachwherefeaturevectors\nare split into training and test partitions to train different classification algorithms, as detailed in\nSection2.1.6. Finally,thelearnedmodelsareevaluatedandtheresultsobtainedarepresented\nand discussed in Section 2.1.7.", "doc_id": "c769956c-ef4b-47c7-bd06-67d529b86e25", "embedding": null, "doc_hash": "3a8d2f44ae00d6e6d175eda76d139daed858c685e7d235c05f7cfa12488506d4", "extra_info": {"page_label": "70", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1791}, "relationships": {"1": "fc39364e-5e62-4ebf-9c4c-3b9dcd83c64d"}}, "__type__": "1"}, "5cbee39e-004c-4d65-9c93-f39a70765d8d": {"__data__": {"text": "71\nAlgorithm 2.1 Feature_Extraction_Procedure\nDescription: Compute BiT descriptor\nInput : A RGB image I\ud835\udc5a\u00d7\ud835\udc5b\u00d73\nOutput : A\ud835\udc51-dimensional feature vector x\n1Separate the RGB image Iin channels IR=I[1...\ud835\udc5b, 1...\ud835\udc5a, 1],\nIG=I[1...\ud835\udc5b, 1...\ud835\udc5a, 2],IB=I[1...\ud835\udc5b, 1...\ud835\udc5a, 3];\n2ConvertI,IR,IG, andIBto gray-level images Ig,IRg,IGg, andIBg;\n3Apply unsharp filter to IRg,IGg, andIBg;\n4Apply Crimmins filter to Ig;\n5Compute biodiversity measurements (Equations 2.1-2.7) and taxonomic indices\n(Equations 2.8-2.14) for IRg,IGg,IBg, andIg;\n6Concatenate the computed measures and indices into a single vector x;\n7Return x;\n2.1.6 Experimental Protocol\nThissectionpresentsthedatasetsusedtoassess theperformanceoftheproposedBiTdescriptor,\nwhich includes natural texture images and histopathological images (HIs), and the experimental\nprotocoltoevaluatethepropertiesoftheBiTdescriptoranditsperformanceonclassification\ntasks. We compare the BiT descriptor\u2019s performance with classical texture descriptors such\nas LBP, GLCM, and Haralick. It is worthy of mention that our contribution relies on the\ncombination of biodiversity measurements and taxonomic indices to build a discriminative\ndescriptor capable of efficiently classifying textures.\n2.1.6.1 Texture Datasets\nWe use three texture datasets that have already been employed for evaluating texture descriptors,\nsuch as LBP, GLCM, and Haralick (Simon & Uma, 2018a).\n-TheSalzburg dataset 5contains476colortextureimagesofresolution128 \u00d7128,captured\naround Salzburg in Austria. These images belong to 10 different classes, and 70% of the\nimages are used for training and validating the classification algorithms, while the remaining\n5http://www.wavelab.at/sources/STex/", "doc_id": "5cbee39e-004c-4d65-9c93-f39a70765d8d", "embedding": null, "doc_hash": "964d1d4ce64269db1cbfd17aa2ac684f027709466570e569f32db1ddc247e1de", "extra_info": {"page_label": "71", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1686}, "relationships": {"1": "7c63f636-8a45-4156-ac06-de5d332bce12"}}, "__type__": "1"}, "1f1bdce1-29f3-4bde-8ac7-2ee1f901fa6e": {"__data__": {"text": "72\n30% are used for testing. Figure 2.6(a) shows some samples from the Salzburg texture\ndataset.\n-TheOutex_TC_00010_c dataset 6has a training set consisting of 20 non\u2013rotated color\nimages of each of the 24 classes (480 in total) of illuminant \u201cinca\u201d, color counterpart of\ntheoriginalOutex_TC_00010dataset. Thetestsetconsistsof3,840colorimagesofeight\norientations (5, 10, 15, 30, 45, 60, 75, and 90 degrees). Each image has the resolution of\n128\u00d7128pixels. Figure2.6(b)showssomesamplesfromthetrainingsetoftheOutexdataset.\n-TheKTH-TIPS dataset 7containsacollectionof810colortextureimagesof200 \u00d7200pixels\nof resolution. The images were captured at nine scales, under three different illumination\ndirections and three different poses, with 81 images per class. Seventy percent of images are\nusedfortraining,whiletheremaining30%areusedfortesting. Figure2.6(c)showssome\nsamples from the KTH-TIPS dataset.\n(a)\n(b)\n(c)\nFigure 2.6 Samples from the texture datasets: (a) Salzburg, (b) Outex_TC_00010_c, and\n(c) KTH-TIPS\n6http://lagis-vi.univ-lille1.fr/datasets/outex.html\n7https://www.csc.kth.se/cvap/databases/kth-tips/", "doc_id": "1f1bdce1-29f3-4bde-8ac7-2ee1f901fa6e", "embedding": null, "doc_hash": "ab4d2d9e792f9261ef2327a38285f718a875af88b7727c4ca86cad1ec136fd07", "extra_info": {"page_label": "72", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1110}, "relationships": {"1": "76aeae04-d75c-4690-b7a3-7f9704bfc689"}}, "__type__": "1"}, "c5597bbc-4941-4ba3-a88a-17fe1cde0aa8": {"__data__": {"text": "73\n2.1.6.2 Histopathological Image (HI) Datasets\nHIs are more challenging than pure texture images since HIs usually have other structures, such\nas nuclei (shape) and tissue variations (colors) within the same class.\n-The CRC dataset (Kather, Weis, Bianconi, Melchers, Schad, Gaiser, Marx & Z\u00f6llner, 2016a)\nencompasses colorectal cancer histopathology images of dimension 5,000 \u00d75,000 pixels\ncropped into 150\u00d7150 patches and labeled according to the structure they contain. Eight\ntypes of structures are labeled: tumor (T), stroma (ST), complex stroma (C), immune or\nlymphoidcells(L),debris(D),mucosa(M),adipose(AD),andbackgroundorempty(E).\nEach structure detailed in the CRC dataset has a specific textural characteristic. For example,\nfew shape characteristics are found in cell nuclei formation, which has a rounded shape but\ndifferent coloring due to hematoxylin. The total number of images is 625 per structure type,\nresulting in 5,000 images. Figure 2.7 shows samples of each class from the CRC dataset.\nThe experiments were performed with stratified 5-fold and 10-fold cross-validation.\nFigure 2.7 Samples of the CRC dataset: (a) tumor, (b) stroma, (c) complex,\n(d) lympho, (e) debris, (f) mucosa, (g) adipose, (h) empty", "doc_id": "c5597bbc-4941-4ba3-a88a-17fe1cde0aa8", "embedding": null, "doc_hash": "be3ec362d8c188af7f27250dba93fdbf9217f76940f1c38c3b75d3ffcb2e1806", "extra_info": {"page_label": "73", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1227}, "relationships": {"1": "80dab9ce-a5e9-4a5e-a495-e381a685ba20"}}, "__type__": "1"}, "30481454-c144-4574-a5ef-d4ff6e5a1c0a": {"__data__": {"text": "74\n-TheBreakHis dataset (Spanhol, Oliveira, Petitjean & Heutte, 2016a) comprises 7,909\nmicroscopic images of breast tumor tissue collected from 82 patients using different\nmagnification factors (40 \u00d7, 100\u00d7, 200\u00d7, and 400\u00d7). The breast tissues extracted from\nbiopsy usually have some basic structures, such as glands, ducts, and supporting tissue.\nForexample,therewillbeadifferenceintexturesbetweenanareawithamalignanttumor\nductal carcinoma and a healthy area. There will be a significant presence of nuclei in the\nregion with carcinoma, identified by the purple color of hematoxylin\u2019s reaction with its\nproteins. Thenucleiandmanycellsinareducedregionmaketheapparenttexturenoisier.\nInanareawithoutcarcinoma,theepithelialtissueisthinanddelimitstworegions,lumen\nandstroma,withdifferenttexturalcharacteristicsduetotheexcessofepithelialcells. The\nlumen generally presents itself as a homogeneous and whitish region. Due to its reaction\nto eosin, the stroma shows a pink and homogeneous color, with little noise. At this point,\na texture descriptor can assist in detecting carcinomas by characterizing a given texture.\nNevertheless,theevaluationoftypesofmalignanttumors,thatis,differentiationbetween\ntypesofcarcinomaonadatasetsuchasBreaKHis,wouldneedtodetectshapetodifferentiate\nthepapillaefromadisorderlyclusterofcells. TheBreakHisdatasetcontains2,480benign\nand 5,429 malignant samples (700 \u00d7460 pixels, 3-channel RGB, 8-bit depth in each channel,\nPNGformat). Weusedhold-outswithrepetition,where70%ofsamplesareusedfortraining,\nand30%ofsamplesareusedfortesting. Figure2.8showssamplesfromeachclassofthe\nBreakHis dataset.\n2.1.6.3 Description of Experiments\nWe have carried out three types of experiments to evaluate the proposed BiT descriptor:\n\u2022Experiments on texture images in which the accuracy of classification algorithms trained\nusing the BiT descriptor are computed for a comparative analysis with traditional texture\ndescriptors.\n\u2022Experiments on texture images to evaluate invariance of the BiT descriptor to rotation, scale,\nand intensity.", "doc_id": "30481454-c144-4574-a5ef-d4ff6e5a1c0a", "embedding": null, "doc_hash": "2b4f8bd56310c247791d92c141191aa01f0aaaf21c67ace123226374aafab5ca", "extra_info": {"page_label": "74", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2040}, "relationships": {"1": "ab480b53-62fd-4490-9757-eed5fdaa0273"}}, "__type__": "1"}, "e63936d6-06d4-4636-bcc7-743f7fd51119": {"__data__": {"text": "75\nFigure 2.8 Example of HIs: (a) Adenosis, (b) Fibroadenoma, (c) Phyllodes,\n(d) Tabular adenomaa, (e) Ductal carcinoma, (f) Lobular carcinoma, (g) Mucinous\ncarcinoma, (h) Papillary carcinoma, where (a) to (d) are benign and\n(e) to (f) are malignant tumors\n\u2022ExperimentsonHIsinwhichmeasuresfrequentlyusedinmedicalimagingsuchassensitivity,\nspecificity, and Kappa scores are computed.\nThe BiTdescriptoris evaluatedbytheaccuracy achievedbydifferentclassification algorithms\non three texture datasets. The same classification algorithms are trained with other texture\ndescriptors,andtheirperformanceiscomparedwiththeperformanceachievedwithBiT.For\na fair comparison with other texture descriptors, we use the same approach described in\nSection 2.1.5 for all texture descriptors, including the feature extraction procedure described\nin Algorithm 2.1 as well as the preprocessing and normalization steps. In addition, we have\nused SVM and \ud835\udc58-NN and four ensemble learning algorithms: decision tree-based ensemble\nalgorithm that uses a gradient boosting framework (XGBCB), a histogram-based algorithm for\nbuildinggradientboostingensemblesofdecisiontrees(HistoB),lightgradientboostingdecision\ntrees (LightB), and super learner (SuperL) (van der Laan, Polley & Hubbard, 2007), which\ninvolves the selection of different base classifiers and the evaluation of their performances using\na resampling technique. SuperL applies a stacked generalization through out-of-fold predictions\nduring\ud835\udc58-fold cross-validation. The base classifiers used in SuperL are \ud835\udc58-NN, decision trees,", "doc_id": "e63936d6-06d4-4636-bcc7-743f7fd51119", "embedding": null, "doc_hash": "9fe0a7e493b17fb83b338fb50cb023d024d3d58516b373a02584e37f58e9e15a", "extra_info": {"page_label": "75", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1559}, "relationships": {"1": "702a7036-d5d9-4e7c-aba5-60bfefd6c2fa"}}, "__type__": "1"}, "8efb8f9b-0b55-4919-a1b8-a40d0c8d23b3": {"__data__": {"text": "76\nand ensembles of decision trees such as AdaBoost, bagging, extra trees, and random forest.\nFurthermore, the \ud835\udc58-NNwastuned with \ud835\udc58valuesbetween 1and 21. The SVMwastuned usinga\ngrid search with the hyperparameter \ud835\udc50between 0.1 and 2 and linear, polynomial, Gaussian, and\nsigmoid kernels.\nThe invariance properties of the proposed BiT descriptor are evaluated on different transforma-\ntions applied to texture images. We compute the BiT descriptor for each image and compare\nthemtothosecomputedfromthetransformedimages. Inthiscase,featurevaluesshouldnot\nchange with the transformations. Additionally, we have also evaluated the invariance of the BiT\ndescriptor to monotonic intensity transformations.\nTheBiTdescriptorisalsoevaluatedontwoHIdatasets. Onlytheclassificationalgorithmthat\nachievedthebestperformancewiththeBiTdescriptorinthepreviousexperimentisretained. Its\nperformance is compared with the state-of-the-art of these datasets, which includes approaches\nbased on CNNs. The experiments are performed using stratified \ud835\udc58-fold cross-validation because\nthe related works employed such a strategy.\n2.1.7 Experimental Results and Discussion\nThissectionpresentstheexperimentalsetstoevaluatetheproposedmethod. Wehaveconducted\nexperimentsontexturedatasets(ofnaturalimages)andHIdatasets. Alongthesameline,we\nalsopresentedtheinvariancepropertiesoftheBiTdescriptor. Moreover,weprovidedthedetails\nof the environment where all the experiments were carried out.\n2.1.7.1 Experiments with Texture Datasets\nTable 2.1 shows the accuracy achieved by monolithic classifiers and ensemble methods trained\nwithfourtexturedescriptorsonSalzburg,Outex,andKTH-TIPSdatasets. TheproposedBiT\ndescriptorachievedthebestaccuracyformostoftheclassificationalgorithmsontheSalzburg\ndataset, and the best result was achieved with BiT+SuperL (94.23%), which outperformed\nall other texture descriptors. The difference in accuracy achieved by BiT and the second and", "doc_id": "8efb8f9b-0b55-4919-a1b8-a40d0c8d23b3", "embedding": null, "doc_hash": "06e5399f814b17d1f751fab9ce2e1c9789bf41d3b83a8177bd82dbcf12e53b2c", "extra_info": {"page_label": "76", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1929}, "relationships": {"1": "17b26881-20dd-4097-985e-c24ee1f3c120"}}, "__type__": "1"}, "419b2da0-b616-4cb3-ac8f-40d9fb96c4e7": {"__data__": {"text": "77\nthe third-best texture descriptors (Haralick+SVM and GLCM+ \ud835\udc58-NN) is nearly 6% and 19%,\nrespectively. The BiT descriptor also provided the best accuracy on the Outex dataset, and\nBiT+SVM(99.88%) achieved thebest result. Thedifference inaccuracy achieved by BiT+SVM\nandthesecondandthethird-besttexturedescriptors(Haralick+ \ud835\udc58-NNandGLCM+LightB)is\nnearly 3% and 5%, respectively. On the KTH-TIPS dataset, the BiT descriptor provided the\nbest accuracy for all the classification algorithms. The best result was achieved with BiT+SVM\n(97.87%). The difference in accuracy achieved by BiT and the second and the third-best texture\ndescriptor (Haralick+SVM and GLCM+SuperL) is nearly 3% and 11%. Additionally, the\nMcNemartest 8hasshownadifferentproportionoferrorsonthetestsetforthethreedatasets.\nTherefore, there is a statistically significant difference between the best results of the BiT\ndescriptor and the three other feature descriptors.\nWe havealso evaluated the importanceof the preprocessing stepin the final accuracy. Overall,\nthereisnoclearadvantageofpreprocessingtextureimagesbecause,dependingonthedataset\nand classification algorithm, the preprocessing may improve or harm the accuracy of the feature\nextraction methods. However, it is worth mentioning that the preprocessing played an important\nroleforGLCMandHaralickdescriptorsforspecificclassifiers(mainly \ud835\udc58-NN),wheresignificant\ndifferences (greater than 10%) were observed between the accuracy achieved on the original\ndataset (lower) and the preprocessed one (higher). In general, the proposed method does not\nexperience a significant variation in terms of accuracy. For instance, the accuracy of BiT+SVM\nwithout preprocessing decreases slightly on the Salzburg (93.78%) and KTH-TIPS (97.57%)\ndatasets, and it increases slightly on the Outex dataset (99.99%).\nAdirectcomparisonoftheresultspresentedinTable2.1withotherworksthatemployedthe\nsame datasets may not be reasonable due to differences in the experimental protocols. For\nexample,theresultsreportedontheSalzburgdatasetomitthesubclassesusedintheexperiments\nand which samples made up the test set. Several works have also used the Outex dataset for\ntexture classification. For instance, Mehta & Egiazarian (2016) presented an approach based on\narotation-invariantLBP,whichachievedanaccuracyof96.26%witha \ud835\udc58-NN.Nonetheless,it\n8Significance level of 95%.", "doc_id": "419b2da0-b616-4cb3-ac8f-40d9fb96c4e7", "embedding": null, "doc_hash": "784b9bcf63858f470e6675f1173ae6f3ed2800affc3deb09c722d2a7774d3ce2", "extra_info": {"page_label": "77", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2365}, "relationships": {"1": "95f57c90-709a-405f-95d9-5258fcec2062"}}, "__type__": "1"}, "09901796-e63b-4005-bd6e-8741a91e9b70": {"__data__": {"text": "78\nhasthedownsideofnotconsideringcolorinformationandglobalfeatures. Du,Yan&Ma(2016)\npresented a rotation-invariant, impulse noise resistant, and illumination-invariant approach\nbased on a local spiking pattern, which achieved an accuracy of 86.12% with a neural network.\nNotwithstanding, it is not extended for color textures, and it requires many input parameters.\nThe KTH-TIPS dataset has also been used to evaluate approaches for texture classification.\nHazgui, Ghazouani& Barhoumi(2021)presented anapproach basedon geneticprogramming\nand fusion of HOG and LBP features. Such an approach achieved an accuracy of 91.20% with\na\ud835\udc58-NN. Nevertheless, it does not consider color information and global features. Nguyen,\nVu & Manzanera (2016) presented statistical binary patterns, which are rotational and noise\ninvariant. Such an approach reached an accuracy of 97.73%, which is slightly lower than\nthe accuracy achieved by BiT+SVM. In addition to being resolution sensitive, this method\npresents a high computational complexity. Qi et al.(2013) studied the relative variance of\ntexture patterns between different color channels using LBP and Shannon entropy to encode the\ncross-channeltexturecorrelation. Theyproposedamulti-scalecross-channelLBP(CCLBP),\nwhich is rotation-invariant. The CCLBP computes the LBP descriptors in each channel and\nthreescalesandcomputesco-occurrencestatisticsbeforeconcatenatingtheextractedfeatures.\nSuchanapproachachievedanaccuracyof99.01%forthreescaleswithanSVM,whichis1.14%\nhigher than the accuracy achieved by BiT+SVM. Notwithstanding, this method is not invariant\nto scale.\nInadditiontotheshallowmethods,wehavealsocarriedoutexperimentsonthethreetexture\ndatasets with a tiny T-CNN of 11,900 trainable parameters with and without data augmentation\n(1\u00d7, 2\u00d7, 4\u00d7, and 6\u00d7) (de Matos et al., 2019)(Ataky et al., 2020). The T-CNN achieved the\nbest accuracy of 61.06%, 70.6%, and 70.22% for Salzburg, Outex, and KTH-TIPS datasets,\nrespectively. However, these results are far below the accuracy achieved by BiT+SVM and\nBiT+SuperL reported in Table 2.1.\nFinally,wehavecarriedoutanempiricalevaluationtoassessthecomputationaltimerequiredby\nthe BiT descriptor for feature extraction and compare it with the other three texture descriptors", "doc_id": "09901796-e63b-4005-bd6e-8741a91e9b70", "embedding": null, "doc_hash": "d6053f77ac82a2db0bd1cbd22fe78de79c218b6df9be57993a2c2b8c46aed97b", "extra_info": {"page_label": "78", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2256}, "relationships": {"1": "85d74f35-2f1b-474a-81c1-1d21c6312c8e"}}, "__type__": "1"}, "5e126043-0060-4a5e-8194-4e89bfd66a2b": {"__data__": {"text": "79\nonthethreetexturedatasets. Theaveragetime 9perimage,includingpreprocessing,isasfollows:\n(i) KTH-TIPS dataset: 27.2 msec, 79.8msec, 106.2 msec, and1.39 sec forGLCM, Haralick,\nLBP, and BiT, respectively; (ii) Outex dataset: 24.4 msec, 42.3 msec, 51.1 msec, and 461.8\nmsecforGLCM, Haralick,LBP and,BiT,respectively;(iii) Salzburgdataset: 12.6msec, 18.7\nmsec, 15.8 msec, and 881 msec for GLCM, Haralick, LBP, and BiT, respectively. The entire\nmethodologywasdevelopedusingMicrosoftWindows10operatingsystem,withthePython\nprogramming language running on an Intel Core i7-8850H CPU @ 2.60 GHz, 64-bit operating\nsystem, x64-based processor, and 32 GB of RAM memory.\nTable 2.1 Average accuracy (%) on the test set of Salzburg, Outex, and KTH-TIPS\ndatasets. The overall best result for each dataset is in boldface. The best result for each\ntexture descriptor is marked with\u2217\nTexture Classification Algorithms\nDataset Descriptors XGBCB HistoB LightB SuperL\ud835\udc58-NNSVM\nSalzburgLBP56.13\u00b10.02456.89\u00b10.02957.21\u00b10.021 64.12\u221732.23 62.12\nGLCM 70.74\u00b10.02268.33\u00b10.01871.77\u00b10.016 75.04 75.38\u221763.68\nHaralick 81.75\u00b10.01582.27\u00b10.01784.27\u00b10.017 86.88 82.5487.99\u2217\nBiT88.65\u00b10.01588.20\u00b10.01490.17\u00b10.013 94.23 88.65 92.33\nOutexLBP55.30\u00b10.01157.80\u00b10.01357.35\u00b10.014 83.21\u221748.20 82.41\nGLCM 94.37\u00b10.01294.13\u00b10.00695.52\u00b10.008\u221794.29 94.37 94.06\nHaralick 96.15\u00b10.00396.69\u00b10.00396.53\u00b10.004 95.596.92\u221796.71\nBiT99.34\u00b10.00699.68\u00b10.00598.53\u00b10.006 99.53 99.83 99.88\nKTH-TIPSLBP57.17\u00b10.02159.51\u00b10.03157.18\u00b10.019 64.83\u221758.26 61.78\nGLCM 83.53\u00b10.02883.12\u00b10.01786.00\u00b10.022 86.83\u221774.89 79.83\nHaralick 90.12\u00b10.01988.83\u00b10.01990.94\u00b10.020 93.00 89.7194.89\u2217\nBiT92.18\u00b10.02492.59\u00b10.02294.65\u00b10.024 95.41 95.49 97.87\n\ud835\udc58= 3, 5, and 1 for \ud835\udc58-NN on Salzburg, Outex, KTH-TIPS datasets, respectively.\nLinear kernel and \ud835\udc50= 2.0, 1.3, and 1.7 for SVM on Salzburg, Outex, KTH-TIPS datasets, respectively\n2.1.7.2 Invariance of the BiT Descriptor\nFigure 2.9 illustrates different transformations applied to texture images (first row) and HIs\n(second row). We have computed some BiT descriptors for each transformed image, and the\nnon-normalized feature values are presented in Tables 2.2 and 2.4.\n9Average time in seconds per image for running a Python implementation of Algorithm 1.", "doc_id": "5e126043-0060-4a5e-8194-4e89bfd66a2b", "embedding": null, "doc_hash": "02de4beb85b5a06360a162d424966d70be2e20a6894df2df98779021d560b970", "extra_info": {"page_label": "79", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2211}, "relationships": {"1": "0ca60c14-2df3-46f3-945e-e2edd4ee447f"}}, "__type__": "1"}, "d116cbef-1fa7-433b-9001-26d5d25914ab": {"__data__": {"text": "80\nFigure 2.9 Example of texture images: (a) original image, (b) rotation 90\u25e6, (c) rotation\n180\u25e6, (d) horizontal reflection, (e) vertical reflection, (f) rescaled 50%. Example of\nhistopathologic images: (g) original image, (h) rotation 90\u25e6, (i) rotation 180\u25e6, (j) horizontal\nreflection, (k) vertical reflection, (l) rescaled 50%\nTable 2.2 Non-normalized feature values computed from different\nimage transformations applied to a texture image (Figure 2.9(a))\nTransformations\nBiTOriginal Rotation Reflection Rescaling\nFeatures 90\ud835\udc5c180\ud835\udc5cHorizontal Vertical 50%\ndMg2636.49 2636.49 2636.49 2636.49 2636.49 725.45\neM0.00055 0.00055 0.00055 0.00055 0.00055 0.00109\ndMn20.3073 20.3073 20.3073 20.3073 20.3073 10.1634\ndSW15.0453 15.0453 15.0453 15.0453 15.0453 14.9963\n\u0394101297.7 101297.7 101297.7 101297.7 101297.7 6253.41\n\u0394\u22172.002325 2.002325 2.002325 2.002325 2.002325 2.003482\neIQ2.4900637 2.4900637 2.4900637 2.4900637 2.4900637 2.4901419\ndNN 4.9999 4.9999 4.9999 4.9999 4.9999 4.9999\nBecausethecomputedvaluesforfeaturespresentedinTable2.2(thesameforTable2.4)have\nconsiderable variances in their absolute values (significant characters and position after the dot),\nrelying merely on the number does not allow for fair comparisons between them. Table 2.3\nshowsthe relative error amongthem, along withthe values ofeach variable after theyhave been\nrescaled.", "doc_id": "d116cbef-1fa7-433b-9001-26d5d25914ab", "embedding": null, "doc_hash": "e9c37ebeef672f81e03e2033a7f8d8d0f4dc1ecd6646f2792b62cc812a390e68", "extra_info": {"page_label": "80", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1347}, "relationships": {"1": "4baadb9f-6d9d-4d6d-af7a-7a86a5f52b07"}}, "__type__": "1"}, "5f1bf227-8755-471e-8372-73968e9cd9b1": {"__data__": {"text": "81\nTable 2.3 Rescaled feature values computed from Table 2.2\nAbsolute Values\nFeatures Original Rescaled Error Relative Error\ndMg 2636.4900000 723.4500000 1913.0400000 0.7256011\neM 0.0005500 0.0010900 0.0005400 0.9818182\ndMn 20.3073000 10.1634000 10.1439000 0.4995199\ndSW 15.0453000 14.9963000 0.0490000 0.0032568\n\u0394 101297.7000000 6253.4100000 95044.2900000 0.9382670\n\u0394\u22172.0023250 2.0032820 0.0009570 0.0004779\neIQ 2.4900637 2.4901419 0.0000782 0.0000314\ndNN 4.9999000 4.9999000 0.0000000 0.0000000\nTable 2.4 Non-normalized feature values computed from different\nimage transformations applied to a histopathologic image (Figure 2.9(g))\nTransformations\nBiTOriginal Rotation Reflection Rescaling\nFeatures 90\ud835\udc5c180\ud835\udc5cHorizontal Vertical 50%\ndMg1975.95 1975.95 1975.95 1975.95 1975.95 548.347\neM0.00036 0.00036 0.00036 0.00036 0.00036 0.00072\ndMn13.2022 13.2022 13.2022 13.2022 13.2022 6.64831\ndSW14.8910 14.8910 14.8910 14.8910 14.8910 14.6985\n\u0394214389.7 214389.7 214389.7 214389.7 214389.7 15287.596\n\u0394\u22172.00673 2.00673 2.00673 2.00673 2.00673 2.00710\neIQ2.48115 2.48115 2.48115 2.48115 2.48115 2.48099\ndNN4.9998 4.9998 4.9998 4.9998 4.9998 4.9998\nThevaluesofBiTdescriptorspresentedinTables2.2and2.4showthat: (i)allmeasurements\nemployedareinvarianttorotationandreflectionasshowninFigures2.9(a)-(e)and2.9(g)-(k),\nsince they presented the same values for all texture images or HIs.\nThisanalysisalsocorroboratesthefactthatBiTdescriptorscapturetheall-inclusivebehaviors\nof patterns in an image; (ii) Shannon-Wiener diversity index ( dSW), taxonomic distinctness ( \u0394\u2217),\nintensive quadratic entropy ( eIQ), and the average distance from the nearest neighbor ( dNN)\nare invariant to scale as they provided values of the order of other transformations for each\nof the images. By way of explanation, from Table 2.3, the latter can be expressed as: (ii)\nShannon-Wiener diversity index ( dSW), taxonomic distinctness ( \u0394\u2217), intensive quadratic entropy\n(eIQ), and the average distance from the nearest neighbor ( dNN) is invariant to scale as they", "doc_id": "5f1bf227-8755-471e-8372-73968e9cd9b1", "embedding": null, "doc_hash": "5ff23fcd7352a2b5fef00d06b246e312b99047da02ddca0d7d38183630b8e17f", "extra_info": {"page_label": "81", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2024}, "relationships": {"1": "43afa818-25fd-4890-b215-f5e46b075566"}}, "__type__": "1"}, "dd54c94d-2b82-42a6-9455-096e626f3b9e": {"__data__": {"text": "82\nprovided relative error between the original and the rescaled sample less than 0.5% for each\nimage.\nOn the other hand, the measures based on richness and abundance show some scale dependence.\nBychangingtheimagescale,wesomehowaffecttheproportionofbothfactors,whichaffectsthe\nresultingvalueseitherdirectlyorinversely. Conjointly,taxonomicindicesrelyontheparenthood\nrelationship between species. Therefore, they are not affected by the change in scale, as the\nphylogenetic relationship depends on the intrinsic properties found in the ecosystem (image).\n2.1.7.3 Invariance to Intensity Changes\nWe have also carried out an empirical evaluation to assess the impact of monotonic intensity\ntransformationsontheperformanceoftheBiTdescriptor. Wehaveappliedgammatransformation\nwith values between 0.5 and 3.0 on the test set of Salzburg, Outex, and KTH-TIPS datasets for\nsuch an aim. Table 2.5 shows the results for selected combinations of the BiT descriptor and\nclassifiers 10from Table 2.1.\nThedifferenceinaccuracybetweentheoriginalandgamma-transformedimagesfortheSalzburg\ndataset is above 5%. Notwithstanding, the results are still slightly higher than other texture\ndescriptors, as shown in Table 2.1. On the other hand, the results achieved on the Outex dataset\nvarylessthan1%,whichshowssomerobustnessoftheBiTdescriptortointensitychanges. There\nis a difference of nearly 3% in terms of accuracy between the original and gamma-transformed\nimages for the KTH-TIPS dataset.\nFrom Table 2.5, the McNemar test has shown similar proportions of errors between the original\ntestsetandalltransformedtestsetsoftheKTH-TIPSdataset. Ontheotherhand,fortheSalzburg\ndataset, the McNemar test has shown equal proportions of errors with gamma values of 2.0, 2.5,\nand3.0,butdifferentproportionsoferrorswithgammavaluesof0.5and1.5. Finally,forthe\nOutexdataset,theMcNemartesthasshownsimilarproportionsoferrorswithgammavalues\nof 0.5, 2.5, and 3.0 and different proportions of errors with gamma values of 1.5 and 2.0. In\n10The classification models were trained only on the original images.", "doc_id": "dd54c94d-2b82-42a6-9455-096e626f3b9e", "embedding": null, "doc_hash": "fb778143f0d1d0c4869b1de41b1796613712717d5511fe534dfae13892b7dea2", "extra_info": {"page_label": "82", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2065}, "relationships": {"1": "10307648-056f-4425-8db4-dc67a0dd31dd"}}, "__type__": "1"}, "8d276309-5935-4593-909e-91ca503bfc97": {"__data__": {"text": "83\nsummary,theproposedBiTdescriptorisnotinvarianttointensitychangesforsomedatasets,\neven though it achieved promising results for the KTH-TIPS dataset.\nTable 2.5 Average accuracy (%) on the three texture datasets\nwith the BiT descriptor applying gamma transformation on\nthe images of the test set\nClassification Gamma Correction\nDataset Algorithm Original 0.51.52.02.53.0\nSalzburg SuperL 94.23 92.2793.1991.3791.3390.88\nOutex SVM 99.88 99.4599.6199.4599.7699.69\nKTH-TIPS SVM 97.87 97.6597.2397.6597.3596.41\n2.1.7.4 Experiments with HI datasets\nTable 2.6 shows the accuracy of monolithic classifiers and ensemble methods trained with\nBiT descriptors on the CRC dataset. Among all classification algorithms, SuperL provided\nthe best results. We have also computed other important metrics used in medical images for\nBiT+SuperL.Table2.7showsthatspecificity,sensitivity,andKappaachievedontheCRCdataset\nare94.19%, 94.22%,and 93.53%,respectively. Forbothcases ofTable2.6, theMcNemar test\nhas shown a similar proportion of errors on the test set for the CRC dataset under Super Learner\ncomparedwithalltheclassifiers,excepttheSVM,whichpresentsadifferentproportionoferrors.\nTherefore,thereisnostatisticallysignificantdifferenceinthedisagreementsbetweenthebest\nresultsoftheBiTdescriptoronCRCandallotherclassifiers. However,thereisastatistically\nsignificant difference in the disagreements between SVM and Super Learner.\nTable2.8comparestheresultsachievedbyBiT+SuperLwiththestate-of-the-artfortheCRC\ndataset. The proposed descriptor slightly outperforms the accuracy achieved by nearly all\nother methods. For instance, the difference in accuracy to the second-best method (CNN) is\n0.12%,consideringan8-classclassificationtaskforthosewhoused10-foldcross-validation.\nIn contrast, BiT+SuperL reached the second-best accuracy with a slight difference of 0.29%\ncomparedwith thefirst-bestmethod (CNN).Itis worthyofmention thatthesuccess ofCNNs\nreliesontheabilitytoleveragemassivelabeleddatasetstolearnhigh-qualityrepresentations.\nNotwithstanding,dataavailabilityforafewfieldsmaybescanty,andthereforeCNNsbecome", "doc_id": "8d276309-5935-4593-909e-91ca503bfc97", "embedding": null, "doc_hash": "b070c645e87c9c60876f5ac883198764457f5fb33b0c91a09c2c7a41f519af89", "extra_info": {"page_label": "83", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2091}, "relationships": {"1": "482b3a87-8ad5-46ac-997b-e11a331a5642"}}, "__type__": "1"}, "d081d663-72f8-4232-b975-7b682e3942c6": {"__data__": {"text": "84\nprohibitiveinseveraldomains. TheresultsachievedbytheBiTdescriptorontheCRCdatasetfor\nHIclassificationhaveshownthattheproposeddescriptorworks wellonothertypesofimages,\nwhich have structures other than textures, with no need for data augmentation.\nTable 2.6 Average accuracy (%) of monolithic classifiers and\nensemble methods with the BiT descriptor on the CRC dataset\nTexture Classification Algorithms\nFolds XGBCB HistoB LightB SuperL\ud835\udc58-NNSVM\n590.80\u00b10.00989.60\u00b10.01090.20\u00b10.013 92.31 83.5090.40\n1090.50\u00b10.01090.71\u00b10.00890.23\u00b10.013 92.52 83.7090.98\nTable 2.7 More evaluation\nperformance for BiT+SuperL\non the CRC dataset\nSpecificity Sensitivity Kappa\n94.43 94.47 93.87\nTable 2.8 Average accuracy (%) of shallow and deep approaches on the CRC dataset\nReference Approach 10-fold 5-fold\nRibeiro, Neves, do Nascimento, Roberto, Martins & Tosta (2019) Shallow 97.60\u2217\u2013\nKather, Weis, Bianconi, Melchers, Schad, Gaiser, Marx & Z\u00f6llner (2016b) Shallow 87.40 \u2013\nSarkar & Acton (2017) Shallow 73.60 \u2013\nBiT+SuperL Shallow 92.52 92.31\nWang, Shi, Zhang & Ying (2017) CNN \u201392.60\nPham (2017) CNN \u201384.00\nRaczkowski, Mo\u017cejko, Zambonelli & Szczurek (2019) CNN 92.40 92.20\n\u2217Used 2-classes classification instead.\nTable2.9showstheaccuracyofmonolithicclassifiersandensemblemethodstrainedwiththe\nBiTdescriptorontheBreakHisdataset. TheSVMclassifierachievedthebestaccuracyforall\nmagnifications, followed by the SuperLearner. Table 2.10 shows specificity, sensitivity, and\nKappa achieved by BiT+SVM.\nTable2.11comparestheresultsachievedbyBiT+SVMwiththestate-of-the-artfortheBreakHis\ndataset. The proposed descriptor achieved a considerable accuracy of 97.29% for 40 \u00d7magnifi-\ncation, which slightly outperforms the accuracy of shallow and deep methods. The difference in\naccuracybetween theproposed methodand thesecond-best method(CNN) isabout 0.29%for", "doc_id": "d081d663-72f8-4232-b975-7b682e3942c6", "embedding": null, "doc_hash": "3f2f66539b8d281a76c0e2de929d802bbe823f3c62c68aa06b1ef1462a7528de", "extra_info": {"page_label": "84", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1822}, "relationships": {"1": "f56ad6b6-e701-42c2-bb5d-322d8ffd2e8a"}}, "__type__": "1"}, "6a9146a2-ee8e-4520-90bf-4d67d2d50f8d": {"__data__": {"text": "85\nTable 2.9 Average accuracy (%) of\nclassification algorithms with the BiT\ndescriptor on the BreakHis dataset\nClassification Magnification\nAlgorithms 40\u00d7100\u00d7200\u00d7400\u00d7\nXGBCB 94.0194.0392.0891.10\nHistoB 93.8593.8291.7590.83\nLightB 94.9694.8993.6892.81\nSuperL 96.1895.9594.6393.81\nSVM 97.2996.6295.6295.19\nTable 2.10 More evaluation performance\nfor BiT+SVM on the BreakHis dataset\nMagnification Specificity Sensitivity Kappa\n40\u00d7 95.12 94.82 95.42\n100\u00d7 95.35 94.43 95.21\n200\u00d7 94.05 94.18 93.22\n400\u00d7 95.12 95.24 93.72\n40\u00d7magnification. Notwithstanding,thebestCNNmethodoutperformsBiT+SVMfor100 \u00d7,\n200\u00d7, and 400\u00d7magnification with a difference of 0.88%, 1.58%, and 2.01%, respectively.\nMoreover,Table2.11presentstheresultsachievedbySpanhol etal.(2016a),whichalsoused\nLBP,GLCM,andothertexturedescriptorswithmonolithicclassifiersandensemblemethods.\nForinstance,theresultsachievedbyBiT+SVMoutperformtheirGLCMapproachby22.59%,\n19.82%, 12.22% and 13.49% for 40 \u00d7, 100\u00d7, 200\u00d7and 400\u00d7, respectively.\nTable 2.11 Average accuracy (%) of shallow and deep approaches\non the BreakHis dataset. All these works used the same data partition\nfor training and test\nMagnification\nReference Method 40\u00d7100\u00d7200\u00d7400\u00d7\nSpanholet al.(2016a)\u2217Shallow 75.6073.0072.9071.20\nSpanholet al.(2016a)+Shallow 74.7076.8083.4081.70\nErfankhah, Yazdi, Babaie & Tizhoosh (2019) Shallow 88.3088.3087.1083.40\nBiT+SVM Shallow 97.2996.6295.6295.19\nAlom, Yakopcic, Nasrin, Taha & Asari (2019) CNN 97.0097.5097.2097.20\nHan, Wei, Zheng, Yin, Li & Li (2017) CNN 92.8093.9093.7092.90\nBayramoglu, Kannala & Heikkil\u00e4 (2016) CNN 83.0083.1084.6082.10\nSpanhol, Oliveira, Petitjean & Heutte (2016b) CNN 90.0088.4084.6086.10\n\u2217: LBP;+: GLCM.", "doc_id": "6a9146a2-ee8e-4520-90bf-4d67d2d50f8d", "embedding": null, "doc_hash": "395b5d5cb3c7e875c6620029b83a8cf36e861c546d52442c1cee5c65fd6ceea5", "extra_info": {"page_label": "85", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1677}, "relationships": {"1": "0af5a1fa-7811-4325-ba39-c663c3b426de"}}, "__type__": "1"}, "ca4d2e75-5391-44eb-8f78-faf365ee34dd": {"__data__": {"text": "86\nThough CNNs have overcome shallow methods for several classification tasks, their advantages\nontextureimagesarenotsohigh. Pre-trainedCNNarchitecturesdesignedforobjectclassification\nstill require fine-tuning some convolutional and fully connected layers on a large amount of\ndata to achieve good performance, including tiny architectures such as T-CNN and T-CNN\nInception(Ataky etal.,2020;deMatos etal.,2019),compactarchitecturessuchasEfficientNets\nandMobileNets 11. Besides,CNNsstillhaveexplainabilityandinterpretabilityissues. Incontrast,\ntheamountofdataandthecomputationalefforttocalculatetheBiTdescriptorarerelativelylow.\nFurthermore, the proposed BiT descriptor is generic. As the experiments over different datasets\nhave shown, it does not require retraining or hyperparameter configuration while providing\nstate-of-the-art performance.\n2.1.8 Final Considerations\nThissectionhaspresentedanessentialcontributiontotexturecharacterizationusingbiodiversity\nmeasurementsandtaxonomicdistinctiveness. Wehaveproposedabio-inspiredtexturedescriptor\nnamedBiT,basedonabstractmodelingofanecosystemasagray-levelimagewhereimagepixels\ncorrespond to a community of organisms. We have revisited several biodiversity measurements\nandtaxonomicdistinctivenesstocomputefeaturesbasedonspeciesrichness,speciesabundance,\nandtaxonomicindices. Thecombinationof speciesrichness, species abundance, and taxonomic\nindicestakesadvantageoftheinvariancecharacteristicsofecologicalpatternssuchasreflection,\nrotation, and scale.\nThese bio-inspired features form a robust and invariant texture descriptor that can be used with\nmachinelearningalgorithmstobuildpowerfulclassificationmodels. Furthermore,experimental\nresults on texture and HI datasets have shown that the proposed texture descriptor can train\ndifferent classification algorithms that outperform traditional texture descriptors and achieve\nvery competitive results compared to deep methods. Therefore, the proposed texture descriptor\n11Numberofparameters: T-CNN:11,900;T-CNNInception: 1.2M;MobileNetV2: 3.5M;EfficientNetB0:\n5.3M", "doc_id": "ca4d2e75-5391-44eb-8f78-faf365ee34dd", "embedding": null, "doc_hash": "fc8b9760183bfb3248402443cfea3a043fe80b3d2a5c15a2f7d90c3337d74b87", "extra_info": {"page_label": "86", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2063}, "relationships": {"1": "3331fb8b-ce70-447b-9eac-8c1769a43e36"}}, "__type__": "1"}, "fa175df6-bc97-4dd2-b972-1b5eab594436": {"__data__": {"text": "87\nis promising for mainly dealing with texture analysis and characterization problems. The results\ndemonstrate the promising performance of such a bio-inspired texture descriptor presented.\nAs an extension of the BiT in Section 2.2, we propose integrating a few sets of diversity and\nevenness measures widely used in ecology, aiming to resemble the completeness of alpha\ndiversity as a generalization of biodiversity analysis.\n2.2E-BiT:Extendedbio-inspiredtexturedescriptorfortextureanalysisandcharacteri-\nzation\nIn ecology, diversity is defined as describing the variety and abundance of species in a specific\nunit of study. It is a measure often used to describe the complexity of a community (Magurran,\n2004b). Evenness measures the relative abundance of the different species in the same area and\nisawaytomeasurehowthespeciesareevenlydistributedinacommunity. Inotherwords,it\nrefers to the equitability of the taxa frequencies in a community (Wagner, Grunwald, Zerbe,\nMikulich-Gilbertson,Robertson,Zemanick&Harris,2018). Notwithstandingtheconceptof\ndiversity is rather precise, Wagner et al.(2018) presented a few reasons that may restrain its\napplication, and some of them are: (i) the existence of numerous commonly used diversity\nindices that can yield different results; (ii) partitioning diversity into components, such as\nrichnessandevenness,maybeuseful,butvariesdependingonthediversitymeasure;and(iii)\ntheterminologycurrentlyinusetodescribediversityiscomplexandconfusing. Forinstance,\nShannonandSimpson,bothindexesofdiversityworkdifferently. Theformerequallyweights\nrichnessandevenness,whereasthelatterprovidesmoreweighttoevenness,andsuchdifferences\nin weighting clarify differences often perceived in results from each measure. What if we\nintegrateandcombinemorediversityindexes? Inthissection, westatethatbyincorporating\nmore diversity and evenness indexes, considering the variations in the mathematical properties\nof each of them, it is possible to build a descriptor even more robust than the existing BiT\ndescriptor.\nThe main contribution of this section is an extension of the BiT descriptor that integrates a few\nsets of diversity and evenness measures widely used in ecology to resemble the completeness of", "doc_id": "fa175df6-bc97-4dd2-b972-1b5eab594436", "embedding": null, "doc_hash": "fc0e95c50d2cc2f3bbc6b33a6b9e4859ea84eb274b6266d81be72794a1c9d633", "extra_info": {"page_label": "87", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2226}, "relationships": {"1": "44e55030-0b1c-4d8a-875e-c0324c6ea8a3"}}, "__type__": "1"}, "518fb9d7-3453-4bf9-89b0-852bf3792419": {"__data__": {"text": "88\nalpha diversity to build a robust representation for texture characterization and classification.\nMore specifically, the contributions are:\n\u2022An extended version of the BiT descriptor (henceforth E-BiT) combining species diversity,\nevenness,richness,andtaxonomicindexestoresemblethecompletenessofalphadiversity\nas a generalization of biodiversity analysis.\n\u2022Adescriptorthatcapturestheall-inclusivebehavioroftextureimagepatterns(bothlocaland\nglobal features).\n\u2022The E-BiT descriptor is invariant to scale, translation and permutation; (iv) the E-BiT\ndescriptor is easy to compute and has low computational complexity.\n\u2022TheE-BiTdescriptorisagenerictexturedescriptorthatperformswellondifferentimage\ncategories, such as natural textures and medical images.\n2.2.1 Methodology\nTheapproachproposedinthisworkisinspiredbythepreviousonepresentedinSection2.1,where\nwereliedonthebiodiversitymeasuresandtaxonomicindicestobuildarobustandgenerictexture\ndescriptor. Some important properties of such a descriptor are: (i) the advantage of ecological\npatterns\u2019 invariance characteristics to build a permutation, rotation, and translation invariant\ndescriptor;(ii)itsabilitytocapturetheall-inclusivebehavioroftextureimagepatternsregardless\nof the latter forming a non-deterministic complex system, which allows the characterization of\nthe intrinsic properties of the whole image.\nThe BiT descriptor consists of fourteen ecological diversity indices comprising biodiversity\nmeasures and taxonomic indices. Nonetheless, in ecology, numerous commonly used diversity\nindicescanyielddifferentresults,consequentlybringingmoreinformationrelatedtodiversity\ncharacterization. What if we integrate and combine more diversity indexes? We extend the\nBiTdescriptorbyintegratingmorediversityandevennessindicesasabaseline. Withthis,we\ninvestigate new diversity and evenness indices not used in our previous Section by considering\nthe variations in the mathematical properties of each of them.", "doc_id": "518fb9d7-3453-4bf9-89b0-852bf3792419", "embedding": null, "doc_hash": "2db97a564d8b6f1bf6de4d9883fc1a43cf9179c6ec804a6fe8d31c934fd432a9", "extra_info": {"page_label": "88", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1960}, "relationships": {"1": "4ae38cb6-3b35-4824-ad52-542aa50038d1"}}, "__type__": "1"}, "c06e334d-c1ac-4be3-ba89-40a1af82055c": {"__data__": {"text": "89\nThe combination of fourteen indices used to build the BiT descriptor and ten other indices\ngive rise to the Extended BiT (E-BiT) descriptor, which provides a representation that leads to\nclassification accuracy superior to the existing BiT descriptor.\n2.2.2 Extended Bio-Inspired Texture (E-BiT) Descriptor\nBiodiversityismeasuredasacombinationofrichnessandevennessacrossspecies(Rousseau\net al., 1999a). The former component is also referred to as species richness. It stands for the\nnumberofgroupsoffunctionallyrelatedindividuals,andthelatterdenotestheproportionsof\nspecies or functional groups present in an ecosystem or community. Besides these components,\nanothertypeofindexistaxonomic,whichconsidersthetaxonomicrelationshipsbetweendifferent\norganisms in an ecosystem. Moreover, taxonomic diversity reflects the average taxonomic\ndistancebetweenanytwoorganisms,randomlychosenfromasample. Suchadistancerepresents\nthe length of the path connecting these two organisms along the branches of a phylogenetic\ntree (Sohier, 2019).\nThe multitude of indices proposed in biodiversity is one of the reasons why it is a bit difficult to\nquantify it. Ecological diversity indexes are mathematical measures of species diversity and\nrelyonrichness(numberofspecies)andabundance(numberofindividualsperspecies). The\nmajority of indices used in ecology usually measure proportional abundances. Nonetheless, two\nmain types of indices are dominance indices (e.g., the Simpson index) and information statistic\nindices (e.g., the Shannon-Weiner index).\nMultiplediversityindicesofrichnesscanbemeasured. However,thereisnoclearconsensus\nabout which indices are more appropriate and informative (Morris, Caruso, Buscot, Fischer,\nHancock, Maier, Meiners, M\u00fcller, Obermaier,Prati et al.,2014). Notwithstanding, richnessis\nthe most straightforward metric and most commonly applied to represent diversity. Whereas\nevenness describes the degree to which individuals are divided among species, the individuals\u2019\ndistribution pattern.", "doc_id": "c06e334d-c1ac-4be3-ba89-40a1af82055c", "embedding": null, "doc_hash": "89778c5f273ce3a2eec36ee2b1220d379ca989fd5c78611304acdc3bbb906fbd", "extra_info": {"page_label": "89", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2005}, "relationships": {"1": "cd48b511-5077-49a1-9663-f5ca6926585f"}}, "__type__": "1"}, "0b3bd12e-4fbb-4cbc-b291-ad45256b0bde": {"__data__": {"text": "90\nLower values indicate that one or a few species dominate. Higher values suggest that relatively\ncomparable numbers of individuals belong to each species and, consequently, a more useful\nmeasure of evenness in multiple contexts.\nTherefore,thequestionis,\"whichonetochoosetoquantifythediversity?\"Bothrichnessand\nevenness represent two (among many) of biodiversity\u2019s facets. Accordingly, no single number\ncanincorporatethembothwithoutinformationloss. However,takenjointly,theyprovidearobust\nsuiteofmethodstoexploreandanalyzethestructureofacommunity. Likewise,Morris etal.\n(2014)statedthatinsimpleanalyses,standarddiversityindicesmightappearinterchangeable.\nNonetheless, by considering complex interactions, the choice of the index can significantly\nalter the interpretation of the outcomes. Thus, data mining should be avoided to identify the\nindex yielding the most effective results. However, the author suggested that simultaneously\nconsideringanalysesusingmultiple indicescan providegreater insightinto theinteractions in\nasystem. Inthissection,weintegratetenmorediversityandevennessindicestogaingreater\ninsight into the interactions in a system (a textural image). Such diversity measures (Magurran,\n2004b; SDR-IV, 2020) are described underneath. It is worthy of note that the terminology and\nthe notation used in this section are similar to those of Section 2.1.\n2.2.2.1 Diversity Indices\nTheBrillouin index(\ud835\udc51\ud835\udc3b\ud835\udc35)is defined as:\n\ud835\udc51\ud835\udc3b\ud835\udc35=ln\ud835\udc41!\u2212\ud835\udc46\u2211\ufe01\n\ud835\udc56=1ln\ud835\udc5b\ud835\udc56!\n\ud835\udc41(2.16)\nwhere\ud835\udc41isdefinedasthetotalnumberofpixelsinthesample, \ud835\udc46isthenumberofgraylevels,\nand\ud835\udc5b\ud835\udc56is defined as the number of pixels in the \ud835\udc56-th gray level.\nTheStrong\u2019s dominance index (\ud835\udc51\ud835\udc37\ud835\udc64)is defined as:\n\ud835\udc51\ud835\udc37\ud835\udc64=max\n\ud835\udc56[(\ud835\udc4f\ud835\udc56\n\ud835\udc41)\u2212\ud835\udc56\n\ud835\udc46] (2.17)", "doc_id": "0b3bd12e-4fbb-4cbc-b291-ad45256b0bde", "embedding": null, "doc_hash": "bc8e25a25050790248fa29ceb1e295c6c197ddc1cf88a5bd240f0b003342b5e7", "extra_info": {"page_label": "90", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1680}, "relationships": {"1": "f254afe6-2678-4459-a519-a9563ae7e5e7"}}, "__type__": "1"}, "bc747c5b-3912-41d9-bc64-4e5075209227": {"__data__": {"text": "91\nwhere\ud835\udc4f\ud835\udc56is the sequential cumulative totaling of the \ud835\udc56-th distinct gray levels\u2019 values ranked from\nlargest to smallest. The expression in brackets is computed for all gray levels, and \ud835\udc5a\ud835\udc4e\ud835\udc65\ud835\udc56denotes\nthe maximum value in brackets for any gray level.\nTheSimpson\u2019s index(\ud835\udc51\ud835\udc36)and theEnspie index(\ud835\udc51\ud835\udc38\ud835\udc41\ud835\udc46)are defined as:\n\ud835\udc51\ud835\udc36=1\u2212\ud835\udc46\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d2\n\ud835\udc56 (2.18)\n\ud835\udc51\ud835\udc38\ud835\udc41\ud835\udc46=1\n\ud835\udc46\u2211\ufe01\n\ud835\udc56=1\ud835\udc5d2\n\ud835\udc56(2.19)\nwhere\ud835\udc5d\ud835\udc56is the proportion of the community represented by gray level \ud835\udc56.\nTheMcIntosh dominance diversity index (\ud835\udc51\ud835\udc40\ud835\udc50\ud835\udc3c\ud835\udc5b\ud835\udc61)(McIntosh, 1967) is defined as:\n\ud835\udc51\ud835\udc40\ud835\udc50\ud835\udc3c\ud835\udc5b\ud835\udc61=\ud835\udc41\u2212\ud835\udc48\n\ud835\udc41\u2212\u221a\n\ud835\udc41(2.20)\nwhere\ud835\udc41representsthetotalnumberofpixelsintheimage, \ud835\udc48=\u221a\ufe01\u00cd\ud835\udc5b\ud835\udc562,and\ud835\udc5b\ud835\udc56representsthe\nnumber of pixels in the \ud835\udc56-th species.\n2.2.2.2 Evenness Indices\nTheChao1richness estimator (\ud835\udc52\ud835\udc36\ud835\udc45)(Chao, 1984;Eren etal., 2012)uses only the number of\nsingletons(\ud835\udc391)and doubletons(\ud835\udc392)and the observed richness (\ud835\udc46\ud835\udc5c\ud835\udc4f\ud835\udc60)to write the following\nestimator for the class richness:\n\ud835\udc52\ud835\udc36\ud835\udc45=\ud835\udc46\ud835\udc5c\ud835\udc4f\ud835\udc60+\ud835\udc392\n1\n2\ud835\udc392(2.21)\nwhere\ud835\udc391and\ud835\udc392arethecountofsingletonsanddoubletonsgraylevelsintheimage,respectively.\nAccording to Chao et al.(2006), in the presence of many class abundance distributions, this", "doc_id": "bc747c5b-3912-41d9-bc64-4e5075209227", "embedding": null, "doc_hash": "bf3e1a409b385649a1abd4276d8a4e74d99a3a4001088b7d789fcf792f22f28b", "extra_info": {"page_label": "91", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1077}, "relationships": {"1": "8ff13eb5-8c82-4562-a8f7-5b78c3ce5cd6"}}, "__type__": "1"}, "100cb3e3-1eeb-4c0f-b98d-dbea4ce0b5b6": {"__data__": {"text": "92\nestimator, originally derived as an estimate of minimum possible richness (number of pixels\npertaining to that specific gray level), is much sharp if the reference sample size is large enough.\nThis corroborates the reason for its use as a valid estimator for large number of gray levels.\nTheGini coefficient(\ud835\udc52\ud835\udc3a\ud835\udc36)(Gini, 1912) is defined as:\n\ud835\udc52\ud835\udc3a\ud835\udc36=2\n\ud835\udc5a\ud835\udc462 \ud835\udc5b\u2211\ufe01\n\ud835\udc56=1(\ud835\udc46+1\u2212\ud835\udc56)\ud835\udc65\ud835\udc56!\n\u22121\n\ud835\udc46(2.22)\nwhere\ud835\udc65\ud835\udc56is the number of pixels of the \ud835\udc56-th gray level ranked from least to most abundant,\n\ud835\udc56\u2208[1,\ud835\udc46]and\ud835\udc5ais the mean abundance of a gray level \u2013 the mean of the \ud835\udc65\ud835\udc56values. The Gini\ncoefficient measures income inequality, but can also be used to measure any form of uneven\ndistribution. It ranges between 0 and 1, where 0 denotes a perfect inequality and 1 denotes a\nperfect equality, where each gray level has the same number of pixels.\nTheHeip\u2019s evenness(\ud835\udc52\ud835\udc3b\ud835\udc38)is defined as:\n\ud835\udc52\ud835\udc3b\ud835\udc38=\ud835\udc52\ud835\udc3b\u22121\n\ud835\udc46\u22121(2.23)\nwhere\ud835\udc3bis the Shannon-Wiener entropy of counts using logarithm base \ud835\udc52.\nThePielous evenness(\ud835\udc52\ud835\udc3d\u2032)is defined as:\n\ud835\udc52\ud835\udc3d\u2032=\ud835\udc3b\nln\ud835\udc46(2.24)\nFinally, the Simpsonsevenness \ud835\udc52\ud835\udc46\ud835\udc38is definedas follows, where \ud835\udc37is dominanceand \ud835\udc46\ud835\udc5c\ud835\udc4f\ud835\udc60is the\nnumber of observed gray levels:\n\ud835\udc52\ud835\udc46\ud835\udc38=1\n\ud835\udc37\n\ud835\udc46\ud835\udc5c\ud835\udc4f\ud835\udc60(2.25)", "doc_id": "100cb3e3-1eeb-4c0f-b98d-dbea4ce0b5b6", "embedding": null, "doc_hash": "84f231517e6ba4db217bd71608743aae7d743f71815a090f571072f2309f4197", "extra_info": {"page_label": "92", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1135}, "relationships": {"1": "d93d4899-b249-46e6-babb-d82833e76e13"}}, "__type__": "1"}, "82dac807-fe38-4089-a723-94ef1f5d9c0f": {"__data__": {"text": "93\n2.2.3 Experimental Results\nWe used four texture datasets (Salzburg, Outex, KTH, and CRC) to assess the performance\noftheproposedE-BiTdescriptor,whichincludeshistopathologicalimages(HIs)andnatural\ntextureimages. Thesedatasetshavepreviouslybeenutilizedtoevaluateothertexturedescriptors,\nincludingHaralick,GLCM,andLBP(Simon&Uma,2018a),andwereusedtoevaluatetheBiT\nlikewise. HIs usually have structures such as nuclei (shape) and tissue variations (colors) within\nthe same class, which make them more challenging than pure texture images (de Matos, Ataky,\nde Souza Britto, Soares de Oliveira & Lameiras Koerich, 2021b).\nWe compare the E-BiT descriptor\u2019s performance with the previous BiT texture descriptor,\nwhich already achieved state-of-the-art performance on the datasets described above. Our\nmain contribution lies in integrating ten more diversity and evenness indices to build a more\ndiscriminant descriptor capable of efficiently classifying textures due to its ability to capture the\nall-inclusive behavior of texture patterns regardless of the latter forming a non-deterministic\ncomplex system. Moreover, like the previous BiT descriptor, the E-BiT descriptor is also\npermutation, rotation, and reflection invariant. For feature extraction, we followed the same\nscheme used for the BiT descriptor (Figure 2.5).\n2.2.4 Results on Texture and HI Datasets\nTodemonstratethebenefitsofthenewlyintegratedindices,Table2.12comparestheaverage\naccuracy achieved by the E-BiT descriptor and different classification algorithms with the\naccuracyachievedbyBiT,GLCM,LBP,andHaralickdescriptorswiththesameclassification\nalgorithms on the Salzburg, Outex and KTH-TIPS datasets.\nOn the Salzburg dataset, the proposed E-BiT descriptor achieved the best result with SuperL\n(95.79%). ItoutperformednotonlythebestBiTdescriptor(94.23%),withadifferenceof1.56%,\nbut also all other texture descriptors. The accuracy differences between E-BiT+SuperL and\nHaralick+SVM and GLCM+ \ud835\udc58-NN are nearly 8% and 20%, respectively. The E-BiT descriptor\nalso provided the best accuracy on the Outex dataset. The accuracy differences between the", "doc_id": "82dac807-fe38-4089-a723-94ef1f5d9c0f", "embedding": null, "doc_hash": "9686a6913f79fcf258bf45872e3cfddcd675e46fd99f8fddc8ea83362f88b60f", "extra_info": {"page_label": "93", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2109}, "relationships": {"1": "87368beb-f090-466f-a6ff-95283609823b"}}, "__type__": "1"}, "70815a2f-51ec-40eb-b3b0-711dea9a5e8f": {"__data__": {"text": "94\nE-BiT and the other descriptors range from 0.12% to 16.79% for BiT+SVM and LBP+SuperL,\nrespectively. Finally, the E-BiT descriptor outperformed all other descriptors on the KTH-TIPS\ndataset. TheE-BiT+SVMachievedthebestaccuracyof98.92%,whichis1.05%,4.03%,and\n12.14% higher than the accuracy achieved by BiT+SVM, Haralick+SVM, and GLCM+SuperL,\nrespectively.\nTable 2.12 Average accuracy (%) on the test set of\nKTH-TIPS, Outex, and Salzburg datasets. The best result\nfor each texture descriptor is in boldface\nTexture\nDescriptorClassification Algorithm\nDataset HistoBLightBSuperL\ud835\udc58-NNSVM\nSalzburgLBP56.8957.2164.1232.2362.12\nGLCM 68.3371.7775.0475.3863.68\nHaralick 82.2784.2786.8882.5487.99\nBiT88.2090.1794.2388.6592.33\nProposed E-BiT 89.3291.9695.7989.7694.20\nOutexLBP57.8057.3583.2148.2082.41\nGLCM 94.1395.5294.2994.3794.06\nHaralick 96.6996.53 95.596.9296.71\nBiT99.6898.53 99.5399.8399.88\nProposed E-BiT 100.099.72100.099.69100.0\nKTH-TIPSLBP59.5157.1864.8358.2661.78\nGLCM 83.1286.0086.8374.8979.83\nHaralick 88.8390.94 93.0089.7194.89\nBiT92.5994.65 95.4195.4997.87\nProposed E-BiT 94.7794.5096.4596.5198.92\n\ud835\udc58= 3, 5, and 1 for \ud835\udc58-NN on Salzburg, Outex, and KTH-TIPS datasets,\nrespectively. Linear kernel and \ud835\udc50= 2.0, 1.3, and 1.7 for SVM on Salzburg,\nOutex, and KTH-TIPS datasets, respectively.\nAdirectcomparisonoftheresultspresentedinTable2.12withotherworksthatusedsimilar\ndatasets may not be reasonable due to differences in the experimental protocols.Most of the\nresultsontheSalzburgdatasetomitthesubclassesusedintheexperimentsandthesamplesused\nin the test set. Mehta & Egiazarian (2016) presented a method based on a rotation-invariant\nLBPthatachievedanaccuracyof96.26%witha \ud835\udc58-NNontheOutexdataset. Nonetheless,it\nhasthedisadvantageofnotexploitingcolorinformationandglobalfeatures.Du etal.(2016)\nproposed a rotation-invariant, impulse noise-resistant, and illumination-invariant method based\non a local spiking pattern with an accuracy of 86.1% using a neural network also on the\nOutex dataset. Nonetheless, it does not broaden to color textures and has a large number of", "doc_id": "70815a2f-51ec-40eb-b3b0-711dea9a5e8f", "embedding": null, "doc_hash": "60ab6aa7985b4e6b95e25652e2b94400145cd3bf6e1b772f1a039d63d4d4be72", "extra_info": {"page_label": "94", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2069}, "relationships": {"1": "19498481-ce29-4b5a-8f2a-7bc44854453f"}}, "__type__": "1"}, "545dfed3-3de5-4cad-b95d-ee52bb84e405": {"__data__": {"text": "95\nhyperparameters. Hazgui et al.(2021) defined a method based on genetic programming and\ncombiningHOGandLBPfeatures. Witha \ud835\udc58-NN,suchanapproachachieved91.20%ofaccuracy\non the KTH-TIPS dataset. Nonetheless, color information and global features are not taken into\naccount. Nguyen et al.(2016) proposed rotational and noise invariant statistical binary patterns.\nThis method achieved an accuracy of 97.73% on the KTH-TIPS dataset, which is approximately\n1.19%lowerthanthatachievedbytheE-BiT+SVM.However,thismethodisresolutionsensitive\nand has high computational complexity. Qi et al.(2013) used LBP and Shannon entropy to\nencodecross-channeltexturecorrelationandinvestigatedtherelativevarianceoftexturepatterns\nbetween different color channels. They proposed a multi-scale rotation-invariant cross-channel\nLBP(CCLBP).TheycomputetheLBPdescriptorsineachchannelandforthreescales,aswellas\nco-occurrence statistics. Such an approach achieved 99.01% accuracy on the KTH-TIPS dataset\nwith an SVM, which is nearly equal to the accuracy achieved by the E-BiT+SVM. Nonetheless,\nthis method is not scaling invariant.\nTable 2.13 presents and compares the performance of BiT and E-BiT descriptors. The accuracy\ndiffersin3.69%,3.13%,3.04%,1.90%,1.07%,and0.20%for \ud835\udc58-NN,SVM,LightB,XGBCB,\nSuperL,andHistoBclassifiers,respectively,TheE-BiTdescriptorwinsinallthecases. Another\nremark is that, unlike the BiT, the E-BiT obtained its best accuracy with a monolithic classifier\n(SVM), even though E-BiT+SuperL also outperformed BiT+SuperL.\nTable 2.13 Average accuracy (%) of ensemble methods\nand monolithic classifiers with the BiT and E-BiT\ndescriptors on the CRC dataset\nTexture\nDescriptorClassification Algorithm\nXGBCB HistoBLightBSuperL\ud835\udc58-NNSVM\nBiT90.50 90.7190.2392.5283.7090.98\nProposed E-BiT 91.59 90.9193.27 93.5987.3994.11\nFinally, Table 2.14 compares the best result of Table 2.13 achieved with the E-BiT+SVM to\nthe state-of-the-art for the CRC dataset. The E-BiT outperforms almost all other methods in\nterms of accuracy. For example, considering an 8-class classification task and a 10-fold CV, the\ndifferenceinaccuracybetweenthesecond-bestmethod(shallow)is1.15%and1.71%forthe", "doc_id": "545dfed3-3de5-4cad-b95d-ee52bb84e405", "embedding": null, "doc_hash": "25d73e27d7b3782d66133f3f00696452b90d20e13c60dbfd02454468b88f10cf", "extra_info": {"page_label": "95", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2163}, "relationships": {"1": "3d458915-f7d7-4cf7-9dc0-77bd189462a7"}}, "__type__": "1"}, "5124210e-abc6-4c29-b02a-a87efd9959c2": {"__data__": {"text": "96\nthird-bestmethod(CNN).Inaddition,theE-BiTdescriptorslightlyoutperformedthesecond-best\nmethod (CNN) for 5-fold CV, with a difference of 0.67%. The results highlight the E-BiT\ndescriptor\u2019sadvantagesovershallowanddeepmethods. Furthermore,CNNsrequiremassive\nlabeled datasets, pre-trained models, and data augmentation strategies to learn high-quality\nrepresentations. Nonetheless, this may not always be possible in medical imaging.\nTable 2.14 Average accuracy (%) of state-of-the-art\nof deep and shallow approaches on the CRC dataset\nReference Approach 10-fold CV 5-fold CV\nAtaky & Lameiras Koerich (2022) Shallow 92.96 \u2013\nRibeiroet al.(2019) Shallow 97.60\u2217\u2013\nSarkar & Acton (2017) Shallow 73.60 \u2013\nKatheret al.(2016b) Shallow 96.90\u2217\u2013\nKatheret al.(2016b) Shallow 87.40 \u2013\nE-BiT+SVM Shallow 94.11 93.27\nWanget al.(2017) CNN \u2013 92.60\nPham (2017) CNN \u2013 84.00\nRaczkowski et al.(2019) CNN 92.40 92.20\n\u2217Used 2-classes classification instead (malignant and benign)\n2.2.5 Invariance of the E-BiT Descriptor\nWe have also verified the invariant propertiesof new aggregated diversity indices. We applied\ndifferentgeometrictransformationstoeachimage(Figure2.9)andcomputedallnewlyintegrated\nfeatures. The non-normalized feature values are shown in the Tables 2.15 and 2.16 for a texture\nimage from KTH and CRC datasets, respectively.\nThe values of the E-BiT descriptors presented in Tables 2.15 and 2.16 show that: (i) all\nmeasurements are reflection and rotation invariant, as they have the same values of original\ntextureimagesandHIs. ThisalsosubstantiatesthefactthattheE-BiTdescriptorscapturethe\nall-inclusive behaviors of patterns within an image; (ii) Simpson index ( dc), Gini coefficient\n(eGC), Heip\u2019s evenness ( eHG), Pielous evenness ( ej\u2019), McIntosh dominance diversity ( dMcInt),\nand Simpson evenness ( eSE) are scale-invariant as they provided values of the order of original\nimages. Ontheotherhand,mostdiversitymeasuresbasedonabundanceandrichnessexhibit\nsome scale dependence. By rescaling the original image, we affect the proportion of both", "doc_id": "5124210e-abc6-4c29-b02a-a87efd9959c2", "embedding": null, "doc_hash": "6d6978116d576db0aedccfe89f3c46bc16f5260e6c9bd19014c63e49556108fc", "extra_info": {"page_label": "96", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2037}, "relationships": {"1": "e71fc53e-2cf1-4df3-adc5-f28900b5bb76"}}, "__type__": "1"}, "06c4ce9d-2b44-4f01-bc89-04890c8b0480": {"__data__": {"text": "97\nfactors, which affects the resulting values either inversely or directly. However, normalizing\nsuch measurements by the total number of pixels can mitigate this effect. On the other hand,\nindexes based on evenness are based on the equitability of taxa frequencies in a community. As\na result, they are unaffected by the change in scaling because evenness is determined by the\nintrinsic properties of the ecosystem (image).\nTable 2.15 Non-normalized feature values computed from\ndifferent image transformations applied to a texture image\nE-BiT DescriptorsTransformations\nOriginal Rotation Reflection Rescaling\n90\ud835\udc5c180\ud835\udc5cHorizontal Vertical 50%\ndHB 9.66469.66469.6646 9.66469.6646 8.2780\neDw 0.03640.03640.0364 0.03640.0364 0.0372\ndC 0.99990.99990.9999 0.99990.9999 0.9998\ndENS 16263.116263.116263.1 16263.116263.1 4064.3\neCR 16384.016384.016384.0 16384.016384.0 4096.0\neGC 0.04930.04930.0493 0.04930.0493 0.0503\ndMcInt 0.99990.99990.9999 0.99990.9999 0.9997\neHE 0.99630.99630.9963 0.99630.9963 0.9962\neJ\u2019 0.99960.99960.9996 0.99960.9996 0.9995\neSE 0.99260.99260.9926 0.99260.9926 0.9923\nTable 2.16 Non-normalized feature values computed from\ndifferent image transformations applied to an HI\nE-BiT DescriptorsTransformations\nOriginal Rotation Reflection Rescaling\n90\ud835\udc5c180\ud835\udc5cHorizontal Vertical 50%\ndHB 10.301710.301710.3017 10.301710.3017 8.9275\neDw 0.05090.05090.0509 0.05090.0509 0.0477\ndC 1.00001.00001.0000 1.00001.0000 0.9999\ndENS 30136.530136.530136.5 30136.530136.5 7631.3\neCR 30625.030625.030625.0 30625.030625.0 7744.0\neGC 0.07030.07030.0703 0.07030.0703 0.0663\ndMcInt 1.00011.00011.0001 1.00011.0001 1.0001\neHE 0.99210.99210.9921 0.99210.9921 0.9928\neJ\u2019 0.99920.99920.9992 0.99920.9992 0.9992\neSE 0.98400.98400.9840 0.98400.9840 0.9850", "doc_id": "06c4ce9d-2b44-4f01-bc89-04890c8b0480", "embedding": null, "doc_hash": "be1946d6000798b061b98792a9ec0319e5d0fb904a093ad0a915aeccdea8c751", "extra_info": {"page_label": "97", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1740}, "relationships": {"1": "5d118b46-703a-4c07-af15-3e39c8c323f7"}}, "__type__": "1"}, "71157f8a-d3ff-4396-9b04-a1cdfbc2120d": {"__data__": {"text": "98\n2.2.6 Final Considerations\nThis section proposed an extended version of the bio-inspired texture descriptor (BiT) to\ncharacterizetextureinimages. Thisextension,namedE-BiT,combinesglobalecologicalconcepts\nof species diversity, evenness, richness, and taxonomic indexes to resemble the completeness of\ndiversityasageneralizationofbiodiversityanalysis. Thatallowsthedevelopmentofadescriptor\nthat captures the all-inclusive behavior of texture image patterns, both at local and global levels.\nFurthermore, the E-BiT descriptor is insensitive to scale, translation, or permutation.\nCompared to related methods for texture characterization and its baseline version, the E-BiT\ndescriptoremergesasapromisingtoolfortexturecharacterization,achievingstate-of-the-art\nperformancefortextureclassification. Inaddition,itsgenericnatureisnotable,asitperforms\nwell in both natural and histopathologic images.\nThisresearchcouldbeextendedtoexaminehowtheE-BiTdescriptorbehavesatdifferentspatial\nscales and resolutions. That may allow for the most effective extraction of texture properties\nwhile maintaining or even improving performance.", "doc_id": "71157f8a-d3ff-4396-9b04-a1cdfbc2120d", "embedding": null, "doc_hash": "c192a5e451ec97579b2d8c1decb3a912e808449d88d3812322d1371904ee1242", "extra_info": {"page_label": "98", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1121}, "relationships": {"1": "2c55a98f-65ce-4c0e-b3f3-f3c1b12f8e3a"}}, "__type__": "1"}, "a200338d-223d-4532-9290-8bbff8e364ae": {"__data__": {"text": "CHAPTER 3\nMULTI-SCALE AND MULTI-RESOLUTION TEXTURE ANALYSIS\nInthecontextofvegetationmeasurementsandsummarizingvaluestodescribesitecommunities\nto a great extent, it is, by and large, desirable to compare two communities of species and\ndeterminehowsimilartheymaybe. Suchsimilaritymeasuresmayexaminedifferencesbetween\ntwositeunits,similarsitesunderdifferentmanagementpractices,changesthatmayhaveoccurred\nbecauseofdisturbance(e.g.,thesimilaritybetweenaridandhumidvegetation),andvariation\nbetween different study times on the same site (e.g., determine how similar the communities are\nto whatit wasa decade ago),and comparing asite to adesirable state(described as areferent).\nThe latter entails gathering data from the exact location throughout time to make a credible\ncomparison to its original (reference) condition.\nInrestorationecology,asite\u2019shydrology,soil,climate,andbiologymaychangeovertime,making\nsumming values to strongly define site communities or spatial comparisons of biodiversity\ntherefromineffectiveifsuchchangesinprimaryresourcesarenottakenintoaccount(Dong,Hou,\nXu,He&Liu,2018). Nevertheless,takingintoaccountdifferentiationshouldrevealthetemporal\ntrendsofthebiodiversityconservationcapacity. Forexample,suchaconceptevaluatesecological\nenvironments and river health. Thus, in essence, channel split and color spaces, and multi-scale\nand multi-resolution analysis, such as wavelet decomposition and pyramids, are employed to\nsupplyacharacteristicvaluethatcanreflectthebackgroundconditionandsummarizevalues\nthat describe texture from an image to a great extent under distinct differentiations.\nIn this chapter, we leverage the multi-scale and multi-resolution analysis for texture analysis of\nnatural and histopathologic images in the following sections.", "doc_id": "a200338d-223d-4532-9290-8bbff8e364ae", "embedding": null, "doc_hash": "080d48c3908266ce22dd442d3df55dd397488c8964ed680909a487be135a89ce", "extra_info": {"page_label": "99", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1765}, "relationships": {"1": "5079b5e4-626f-4148-afc5-b5dfe7cc3d35"}}, "__type__": "1"}, "8fe4b6d4-b5f6-4430-8ea9-146cbd77f229": {"__data__": {"text": "100\n3.1Multi-resolution Texture Analysis of Histopathologic Images Using Ecological Diver-\nsity Measures\nHistopathologystudieshowaspecificdiseaseaffectscells(tissue). Usually,abiopsystudyis\ndone using a microscope and dyes. It can also be done during surgery or an autopsy (death\ninvestigation). Histopathologicimages(HIs)aremedicalimagingobtainedviamicroscopyof\ntissuesfrombiopsies,whichallowspecialiststoobservetissuecharacteristicsonacellbasis.\nThis process consists of tissue processing by chemical fixation or frozen section slides (creating\ntheslidewiththestainingprocess). Afterward,theslidesundergostainingwithoneorseveral\npigments to envision the tissue through a microscope, aiming to reveal cellular components;\ncounterstainsareusedtoprovidecontrast;andfinally,thepathologistanalysis. Thestain,byand\nlarge, used in histopathology is a combination of hematoxylin and eosin (H&E). The former is\nemployedtostainnuclei(blue),whilethelatterstainscytoplasmandtheextracellularconnective\ntissuematrix(pink). However,thestainingprocessmaygiverisetoavarianceintheanalysis\nprocessbecauseH&Eispronetoproducedifferentcolorintensitiesbeingconditionedbythe\ntemperature, storage conditions, and brand. Nevertheless, as stated by de Matos et al.(2021a),\nHIs continue to be the gold standard for evaluating several types of tumors for cancer diagnosis.\nComputer-aideddetection(CAD)andcomputer-assisteddiagnostic(CADx)systemsarecon-\ntinuously developed to assist in medical image analysis. Clinicians are heavily reliant upon\nCAD for cancer detection and monitoring. However, given the reliance on CAD and CADx for\ncancerdetection,thereisalwaysanextrafocusandneedfordevelopingsystemsthatimprove\npathologists\u2019 productivity and ameliorate the reliance on outcomes by adding consistency to the\ndiagnosisprocessandreducingobserversubjectivity. Machinelearning(ML)approachesare\nincreasingly used in CAD and HI analysis to diagnose cancer in various tissues or organs, such\nas the breast, prostate, skin, brain, bones, liver, etc. Furthermore, when used in HI analysis, ML\napproachesrevealpotentialbenefits. Asaresult,theyhaveseenmuchuseintaskslikefeature\nextraction, classification, and segmentation. The visual properties of macro vision images used\nin machine learning applications, such as scene reconstruction, and object and face recognition,\ndiffer from those of HIs, which contain complex textures and rich geometric structures.", "doc_id": "8fe4b6d4-b5f6-4430-8ea9-146cbd77f229", "embedding": null, "doc_hash": "0257f5ff340ec4124f1ec81eeaa7eb0691535942a80ea963a91d4d935c241191", "extra_info": {"page_label": "100", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2422}, "relationships": {"1": "dcd4ba0d-38b0-4c99-9b94-d71e5365b9ec"}}, "__type__": "1"}, "ba25bdb8-ee31-4ed8-82a3-d73c3a7b2ae7": {"__data__": {"text": "101\nInto the bargain, computational tools have been proposed to help the specialist interpret the\nbreast HI exam, providing features for detecting and diagnosing tumors and cancerous cells.\nDetecting tumors with a high sensitivity rate while reducing false positives remains challenging.\nTexture descriptors have become popular in HI analysis due to the variability of texture found in\nsuchimagesandtissueappearanceduetoirregularitiesinthestainingprocess. Variabilityin\nstaining protocol, such as fixation, inconsistency in staining condition, and reagents, may exist\nbetween laboratories or within the same laboratory. Moreover, textural feature extraction for\ndiscriminantlyquantifyingHIinformationischallengingbecausethedistributionofintrinsic\nproperties of such images is complex and nonlinear.\nThis section presents a method for characterizing texture across HIs with a reasonable success\nrate. We formulate that it is possible to quantify the intrinsic properties of HIs to the maximum\nextentbycombiningbiodiversity,taxonomicmeasures,anddiscretewavelettransform. Thus,\nthe main highlights are:\n\u2022An information-theoretical measure of ecological diversity for HI texture characterization.\n\u2022The exploitation of independent wavelet subband coefficients\u2019 non-linear interactions across\ntime.\n\u2022The mixture of wavelet features and statistical properties of taxonomic indexes represents an\nunexplored method.\n\u2022SuchamixturecharacterizesHIs,sointrinsicpropertieshaveprovidedpromisingperformance\nfor real-world HI datasets such as the CRC and the BreakHis datasets.\n3.1.1 Ecological Modeling of Wavelet Subbands\nTheproposedmethod,illustratedinFigure3.1,isemployedandintegratedfortextureclassification\nas follows: (1) image channel splitting; (2\u2032) wavelet subband decomposition; (2\u2032\u2032) computation\nof biodiversity measures and information theory from each channel (R, G, and B) to form a\nfeaturesvector;(3)computationoftaxonomicindexesandinformationtheoryfromeachwavelet\nsubbandtoformafeaturesvector;(4)featurevectorsconcatenation;and(5)classificationand\nperformance evaluation.", "doc_id": "ba25bdb8-ee31-4ed8-82a3-d73c3a7b2ae7", "embedding": null, "doc_hash": "3b505ff3f46f11a560f67c2e7fef5f69a07ef1752df5d92c2bd7ac23b1629e47", "extra_info": {"page_label": "101", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2071}, "relationships": {"1": "e3f734f3-fa25-40f5-a368-aedaf89b4c0e"}}, "__type__": "1"}, "85c77d2c-b6be-4b53-84bb-9d7f91ff0f81": {"__data__": {"text": "102\nFigure 3.1 General overview of the proposed scheme\nToelaborate,Algorithm3.1illustratesastepbysteppseudocodeoftheproposedarchitecture.\nIn regard of the discrete wavelet decomposition, numerous wavelets transform, such as Haar,\nDaubechies, andSymletsare available. Nonetheless, the decisiontouse oneofthem maybe\ninfluencedbyhowwellitfitsinagivensituation. Inthiswork,weusedDaubechies. Infuture\nwork, we will verify how different orthogonal wavelets and other families of wavelets will\nperform.\n1.Channel Splitting and Feature Extraction\nWe appliedthe integrative methodto make eachimage channel (R,G, B)a separate input.\nThemotivationisto exploitcolor informationand summarizevaluesthat describetexture\nfromanimagetoagreatextentunderdistinctdifferentiation,asmentionedabove. Therefore,", "doc_id": "85c77d2c-b6be-4b53-84bb-9d7f91ff0f81", "embedding": null, "doc_hash": "fcf6027ca9a5b69dd9696db34a993e40e9973bf7d2bf83104317e2b19bfc94f0", "extra_info": {"page_label": "102", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 787}, "relationships": {"1": "1b7a9f13-0418-45aa-8063-222e4b1d1bb3"}}, "__type__": "1"}, "7af3b406-6677-46f2-99c8-8b73682fec66": {"__data__": {"text": "103\nwe represent and characterize an input image using a set of local descriptors derived from\na pixel\u2019s interaction with its neighbors in a particular channel (R, G, or B) and wavelet\nsubbands thereof.\nAfter the channel splitting stage, each image channel undergoes feature extraction. Intrinsic\npropertiesanddiscriminantcharacteristicswithineachinputchannelareextractedasfollows.\nFirst, for eachchannel(R,B, andG),weperform amulti-resolutionanalysisofatexture\nemploying a wavelet transform, generating four subbands: a, h, v, andd. Since we used\nthree levels, in the following scale, the subband ais used for DWT computation. After,\nwe compute taxonomic measures, Shannon entropy, and total information, resulting in a\n9-dimensionalvectorforeachsubband. ThissequencecanbeseeninFigure3.1(steps2\u2032\nand3). Taxonomicmeasurescomprisetaxonomicdiversity,taxonomicdistinctness,thesum\nofphylogeneticdistances,averagedistancefromthenearestneighbor,extensivequadratic\nentropy,intensivequadraticentropy,andtotaltaxonomicdistinctness(Section2.1). Because\nwehavesplitaninputimageintothreechannelsandchosena3-levelwaveletdecomposition\n(leadingto10subbands),step3willproducea270-dimensionalfeaturevector(9 \u00d73\u00d710).\nIn parallel, we compute biodiversity measures and Shannon entropy, and total information\ndirectly from each original image channel resulting in a 9-dimensional vector for each\nchannel. Biodiversitymeasuresfromstep2\u2032\u2032compriseMargalef\u2019sandMenhinick\u2019sdiversity\nindexes,Berger-Parkerdominance,Fisher\u2019salphadiversitymetric,Kempton-Taylorindexof\nalphadiversity,McIntosh\u2019sevennessmeasure,andShannon-Wienerdiversityindex(Section\n2.1). The reason for not employing DWT in this stage is that low-pass decomposition filters\nmay present negative coefficients in the subband adepending on filter coefficients used\nfor decomposition. Nevertheless, biodiversity measures such as abundance and richness\nare non-negative. Because we have split an input image into three channels, step 2\u2032\u2032will\nproduce a 27-dimensional feature vector (9 \u00d73). Finally, feature vectors resulting from steps\n2\u2032\u2032and3are concatenated to form the final feature vector (step 4 in Figure 3.1). We named\nittheBiTWdescriptorbecauseitresultsfromtheconcatenationofbiodiversitymeasures,\ninformation theory and taxonomic indexes extracted from wavelet subbands.", "doc_id": "7af3b406-6677-46f2-99c8-8b73682fec66", "embedding": null, "doc_hash": "8ce60352b2ff75034a0314f288375de8ed4a6bf1014d3cb46d85c0ee58d3eca2", "extra_info": {"page_label": "103", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2311}, "relationships": {"1": "e370b66c-22d3-4db3-85fe-78bf382b0e1b"}}, "__type__": "1"}, "19f9beee-9efc-4286-9fec-2003fd479be8": {"__data__": {"text": "104\nThe BiTW is a 297-dimensional feature vector, which may leave a whole path to a possible\nfeature selection step.\n2.Normalization\nThe feature vectors are split into training and test sets before the training step. Then,\nnormalizationand scaling occur independently on each featurein the training set, where\nvalues are normalized to the range [0,1]using the min-max normalization. Minimum and\nmaximum are then stored to be used on feature normalization over the testing data. The\nsame procedure is used for the \ud835\udc58-fold cross-validation (CV), where feature vectors are split\ninto\ud835\udc58foldsandcomputingthemin-maxpairsinthemergedtrainingfolds. Themin-max\npairs calculated from the trained data normalize the training and test folds. This procedure\nis repeated during the CV stage for each new training/test fold.\n3.Training and Classification\nAfter feature extraction, the resulting feature vectors are taken through the classification\nprocess utilizing seven classifiers: a histogram-based algorithm for building gradient\nboosting ensembles of decision trees (HistoB), light gradient boosting decision trees\n(LightB), fast, scalable, high-performance gradient boosting decision trees (CatBoost),\nextra trees (ExtraT), random forest (RF), gradient boosting decision trees (GB), and linear\ndiscriminant analysis (LDA). A performance analysis is carried out using accuracy and the\narea under the curve (AUC).\nAlgorithm 3.1 FeatureExtractionProcedure\nResult:final feature descriptor\n10. Loada RGB image file ;\n21. Channel Splitting R, G, B ;\n32. For each channel ;\n42.1 Extract Biodiversity measures (equations 1- 7) and Shannon Entropy, append to V1 ;\n53. For each channel ;\n63.1 Generate three wavelet levels decomposition ;\n73.2 For each subband of each decomposition level (from step 3.1) ;\n83.2.1 Compute taxonomic indices and Shannon entropy, append to V2 ;\n94. Concatenate V1 and V2 into a single vector (297-dimensions);\n105. Repeat steps 1 to 5 for all images of the dataset", "doc_id": "19f9beee-9efc-4286-9fec-2003fd479be8", "embedding": null, "doc_hash": "bd7395ef28f74d241bfb009fb75d89398cc1f47e5a0a65b51e5bf4b0aee4acab", "extra_info": {"page_label": "104", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1974}, "relationships": {"1": "a64a8da2-44d1-413a-aa4e-a748f1d101b4"}}, "__type__": "1"}, "5e9e730c-f8db-41a6-95b0-50af6a676a82": {"__data__": {"text": "105\n3.1.2 Experiments and Results\nTwo medical datasets were used in the experiments, CRC(Katheret al., 2016a)(Figure 2.7)\nandBreakHis (Spanhol etal.,2016a))(Figure2.8)toevaluatetheperformanceoftheBiTW\ndescriptor, as well as the experimental protocol used to assess the properties of the BiTW\ndescriptor and its performance on classification tasks using various classification and ensemble\nmethods. WecontrasttheperformanceoftheBiTWdescriptorwiththatofshallowanddeep\nstate-of-the-art approaches.\n3.1.2.1 Experiments on CRC\nTheaccuracy ofbothmonolithicclassifiers andensemblemethodstrained withfeaturevectors\nfrom BiTW on the CRC dataset is presented in Table 3.1. GB produced the best results for\nboth train-test split and \ud835\udc58-fold CV in the group of all classification algorithms. Similarly, we\ncomputed the area under the ROC curve (AUC), another essential metric commonly used in\nmedicalimagesthatcomparesthetrue-positiveratetothefalse-positiverateatvariousthreshold\nlevels. The BiTW descriptor with GB achieved an AUC of 0.99. AUCs of 0.7 to 0.8 are\nconsidered acceptable, 0.8 to 0.9 are regarded as excellent, and greater than 0.9 is deemed\nexceptional.\nTable 3.1 Accuracy (%) and AUC of monolithic classifiers and ensemble\nmethods with the BiTW descriptor on the CRC dataset for train-test split\nand 10-fold CV\nExperimental Protocol\n(Metric)Classification Algorithms\nHistoB LightB LDACatBExtraT RFGB\n70/30 (Acc) 92.42 92.20 89.2792.20 92.42 92.4293.28\n70/30 (AUC) 0.991 0.992 0.9880.993 0.993 0.9910.991\n10-fold (Acc) 91.12 91.81 89.4591.33 91.53 90.5993.73\n10-fold (SD) \u00b10.05\u00b10.01\u00b10.08\u00b10.02\u00b10.03\u00b10.02\u00b10.02\n10-fold (AUC) 0.990 0.992 0.9890.993 0.993 0.9910.994\nAcc: Accuracy; SD: Standard Deviation.\nTable3.2comparestheresultsachievedbyBiTW+GBwiththestate-of-the-artfortheCRC\ndataset. The BiTW slightly outperforms the accuracy achieved by almost all other methods. For", "doc_id": "5e9e730c-f8db-41a6-95b0-50af6a676a82", "embedding": null, "doc_hash": "0a5782f92a712d97cc2a896d424ed2c3144844c607a69f481dc55de5e92149c8", "extra_info": {"page_label": "105", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1872}, "relationships": {"1": "5fc3dcf5-fa78-4ee2-94a2-b2d8c6631404"}}, "__type__": "1"}, "fa3cff2c-8b8f-4440-924a-3516bf9bddb9": {"__data__": {"text": "106\ninstance, the difference in accuracy to the second-best method (shallow) is 0.77%, and with the\nthird-bestmethod(CNN)is1.33%,consideringan8-classclassificationtaskand10-foldCV.For\n5-foldCV,BiTWslightlyoutperformedthesecond-bestmethod(CNN)withadifferenceof1.0%.\nRegarding the works that lay on shallow methods, Kather et al.(2016b) considered six distinct\nsetsofdescriptorstodescribethetextureofhistologicalimages: lower-orderandhigher-order\nhistogram features, Local binary patterns (LBP), Gray-level co-occurrence matrix (GLCM),\nGabor filters, Perception-like features, and Combined feature sets. Before computing the texture\nfeatures,allimageswereconvertedtogreyscale. Classifierssuchas1-nearestneighbor,linear\nSVM, radial-basis function SVM, and decision trees were used for evaluation purposes. The\nBiT (Ataky & Lameiras Koerich, 2022) and DWT used to build the proposed method share\ncharacteristicswithLBP,GLCM,andGabor. Intheirstudy,Sarkar&Acton(2017)presenta\nnovel method of saliency-based sparse coding and vocabulary learning for computing image\nsimilarity between two images. The system extracts prominent image features by utilizing\na salient object recognition technique. The developed dictionary learning technique takes\nadvantageofsaliencytocreatesparsecodesandasetofbasisfunctionsforpicturerepresentation\nso that the more salient image regions significantly impact dictionary learning. As in this work,\nthe descriptor used in the proposed method allows extracting local and global information from\nthe image to the maximum extent, as wavelet transform generates a signal representation in both\nthe time and frequency domains, enabling quick access to the signal\u2019s localized information.\nItisnoteworthytohighlightthatCNNsgenerallyrequiremassivelabeleddatasetsand,whennot\npossible, may need pre-trained models and data augmentation to learn high-quality representa-\ntions. Inthemedicalfield,however,thisisnotalwayspossible. Theshallowapproachesusing\ntheBiTWdescriptor,unlikethelatter,didnotrequireanydataaugmentationontheCRCdataset\nand have proven to be promising relative to CNNs as well as other shallow methods, despite HIs\nhaving other structures than textures.\nElaborating, in the context of histopathological images, the future of feature extraction methods\nare moving away from morphological information and toward high-level representations, owing\nto the challenge presented by the availability and capability of capturing images with high", "doc_id": "fa3cff2c-8b8f-4440-924a-3516bf9bddb9", "embedding": null, "doc_hash": "7760203e5e1273658eab777e1838f18aeb6833b0d1d9894bbea169bac67c5417", "extra_info": {"page_label": "106", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2464}, "relationships": {"1": "4ffe6612-a354-42f5-82a7-33c152650211"}}, "__type__": "1"}, "815762ae-ce4b-433a-bab9-3ae505807bfd": {"__data__": {"text": "107\nresolutions,suchastheWSI.Amongthehigh-levelcharacteristics,deeplearningmethodsas\nextractors are gaining popularity. They extensively use parallelism methods, providing good\nperformance for their application in large images and allowing knowledge transfer. Another\nupper hand of such methods is that they can be trained and adapted to specific characteristics of\ntheproblemtobesolved,resultinginrepresentationlearning. Notwithstandingdeeplearning\nmethods(deeplearning-basedfeatureextractors),suchasconvolutionalneuralnetworkshave\nrecently gained popularity because they are end-to-end with good performance for image\nclassification(forcapturingmoreshapefeatures),itisalsoputforththatusingCNNsdirectly\n(from scratch) on texture datasets results in only moderate accuracy in texture classification\n(Hafemann, Oliveira & Cavalin, 2014). Improving the performance of CNNs requires millions\nof parameters and a large amount of data (which is not always possible in the medical domain),\nbringing high computational costs. Such an improvement, that is, a non-direct use of CNNs, are\nfound in the works of Wang et al.(2017), Pham (2017), and Raczkowski et al.(2019).\nTable 3.2 Average accuracy (%) of shallow and deep approaches on\nthe CRC dataset for 5-fold CV, 10-fold CV, and AUC\nReference ApproachAccuracy (%)AUC10-fold 5-fold\nRibeiroet al.(2019) Shallow 97.60\u2217\u20130.994\nSarkar & Acton (2017) Shallow 73.60 \u2013 \u2013\nKatheret al.(2016a) Shallow 96.90\u2217\u2013 \u2013\nKatheret al.(2016b) Shallow 87.40 \u2013 \u2013\nNaiyar, Asim & Shahid (2015) Shallow \u2013 \u20130.960\nRathore, Iftikhar, Hussain & Jalil (2013) Shallow \u2013 \u20130.970\nKalkan, Nap, Duin & Loog (2012) Shallow \u2013 \u20130.950\nMasood & Rajpoot (2009) Shallow \u2013 \u20130.900\nAtaky & Lameiras Koerich (2022) Shallow 92.96 \u2013 \u2013\nBiTW+GB Shallow 93.73 93.60\u00b10.20.994\nWanget al.(2017) CNN \u2013 92.60 \u2013\nPham (2017) CNN \u2013 84.00 \u2013\nRaczkowski et al.(2019) CNN 92.40 92.20 \u2013\n\u2217Used 2-classes classification instead (malignant and benign).\nRaczkowski et al.(2019) created and trained a CNN model whose architecture, ARA-CNN,\nwas inspired by various cutting-edge systems, such as Microsoft ResNet and DarkNet 19. They\nutilizedtherenownedbatchnormalisationapproachfornormalizationandtoavoidoverfitting.\nInARA-CNN,dropoutisalsousedtoreduceoverfitting. Pham(2017)advocatedtexturescaling", "doc_id": "815762ae-ce4b-433a-bab9-3ae505807bfd", "embedding": null, "doc_hash": "ed6d936fad34ac5cc645cec9a959780d88f4d6624bc4560d3658a42b91334ff5", "extra_info": {"page_label": "107", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2269}, "relationships": {"1": "ac050d62-11cb-4213-b4a9-6238c2d16493"}}, "__type__": "1"}, "f1f03e24-b948-4b6e-a278-24d4ccf94e3e": {"__data__": {"text": "108\ninCRChistologyasawaytoreducethecomputationalburdenofnetworktraining. Onlytwo\nhiddenlayerswerebuiltfordeeplearning;accordingtotheauthor,amoresignificantnumber\nof hidden layers would be expected to demonstrate the superior performance of deep neural\nnetworks regarding classification accuracy and machine-learning time. Wang et al.(2017)\nintroduced a novel BCNN-based method for the classification of histopathological pictures,\nwhichfirstdecomposestheimagesintohematoxylinandeosinstaincomponentsandthenapplies\nBCNN to thedecomposed images to fuse andimprovethe feature representation performance.\nThe bilinear CNN (BCNN) is a new CNN model for classification at the granular level. At each\nspatial point, the convolutional-layer outputs of two CNNs are multiplied with the outer product\nto form the BCNN.\n3.1.2.2 Experiments on BreakHis\nTable 3.3 and 3.4 present the accuracy of both the monolithic classifiers and ensemble methods\ntrained with BiTW feature vectors on the BreakHis dataset with train-test split and \ud835\udc58-fold\ncross-validation,respectively. Byemployingthetrain-testsplit,theLightBachievedthebest\naccuracy of 99.26% and 98.62% for 40 \u00d7and 200\u00d7magnifications, respectively. The ExtraT\nachieved 98.50% and HistoB 98.38% accuracy for 100 \u00d7and 400\u00d7magnifications, respectively.\nFurthermore, the AUC is nearly 0.98 or above, regardless of the classifier or ensemble method.\nConsideringthe \ud835\udc58-foldCV, ExtraTyieldedthe best accuracyof98.75% and98.63%for 40 \u00d7\nand 100\u00d7magnifications, respectively. The LightB, in turn, achieved an accuracy of 98.72% for\n200\u00d7magnification. Finally, HistoB yielded an accuracy of 98.38% for 400 \u00d7magnification.\nFurthermore, we carried out experiments with \ud835\udc58-fold cross-validation to guarantee that each\nsample from the dataset does have a chance of being selected in the training and test sets, which\nis a best practice when working with limited data. Table 3.4 presents the average accuracy with\ntheBiTW descriptoronthe BreakHisdataset attheimage levelwith a10-foldCV.Theresults\nfor both types of dataset splitting are very similar for nearly all the classifiers and ensemble\nmethods.", "doc_id": "f1f03e24-b948-4b6e-a278-24d4ccf94e3e", "embedding": null, "doc_hash": "fbb875743a91de5ad882043bfeaaae6e193a0ff632e76718155b1fe765d2dcdd", "extra_info": {"page_label": "108", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2123}, "relationships": {"1": "37ff28ce-9a20-4934-8256-8fefbdba82bb"}}, "__type__": "1"}, "f954a8a0-930e-4a6a-9e69-e078fa917e48": {"__data__": {"text": "109\nTable3.5contraststheresultsachievedbytheproposedapproachwiththestate-of-the-artforthe\nBreakHis dataset. Though different classifiers outperformed others for different magnifications,\nforthesakeoffairness,wechooseaclassifiertopresentforcomparisonwithrelatedworkbased\nontheaverageperformanceofthefourmagnifications. Computingtheaverageweobtain98.58%,\n98.54%,93.21%,97.95%,98.50%,97.65%and97.53%,forHistoB,LightB,LDA,CatB,ExtraT,\nRFandGB.Thus,HistoBischosenforcomparisonpurposesbecauseitpresentedthehighest\naverage accuracy. The BiTW descriptor with HistoB achieved a substantial accuracy of 98.97%,\n98.43%, 98.55% and 98.38% for 40 \u00d7, 100\u00d7, 200\u00d7, and 400\u00d7magnifications, respectively. It is\nimportant to note that, regardless of magnification, the proposed method surpasses the accuracy\nofdeepandshallowmethods. Thedifferencesinaccuracybetweentheproposedmethodand\nthe second- and third-best methods are 1.47% (Shallow) and 1.97% (CNN), 0.93% (CNN) and\n1.63% (Shallow), 1.35% (CNN) and 2.75% (Shallow), 1.18% and 3.18% (Shallow) for 40 \u00d7,\n100\u00d7, 200\u00d7, and 400\u00d7magnifications, respectively.\nAnalyzing theCNNresultsof relatedresearchleadsusto believe thatamoresignificant number\nof hidden layers, fine-tuning of hyperparameters, and a large amount of training data would\nenableCNNsmethodstoachieveevenmoreaccurateclassificationoverthemethodproposed\nin this section. Notwithstanding, CNNs continue to have challenges with explainability and\ninterpretability. In comparison, the proposed method requires a relatively small quantity of\ndata and processing effort to compute. Moreover, it is generic (since it worked well on various\nimagetypes,suchasnaturalimages)anddoesnotrequireretrainingorhyperparametersetup\nwhile achieving state-of-the-art performance, as demonstrated by experiments on HIs datasets.\nMoreover,mostofthedescriptorsusedtoextractfeaturesintherelatedworksthatlayonshallow\nmethods, which were shown to be outperformed by the BiT (Ataky & Lameiras Koerich, 2022)\ndescriptor proposed in this thesis.", "doc_id": "f954a8a0-930e-4a6a-9e69-e078fa917e48", "embedding": null, "doc_hash": "552b79a6d015fdced1e936bed5220ea3667bbcc2349bde586432508b6b7e0c5b", "extra_info": {"page_label": "109", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2009}, "relationships": {"1": "7d2c3372-fce6-4f6f-9a99-7400d89f0a54"}}, "__type__": "1"}, "485ca214-6e60-4fde-a1a9-cfc5315b75ee": {"__data__": {"text": "110\nTable 3.3 Accuracy (%) and AUC of monolithic classifiers and ensemble\nmethods with the BiTW descriptor on the BreakHis dataset at image level\nwith train-test split\nImage\nMagnificationClassification Algorithm\nMetric HistoB LightB LDACatBExtraT RFGB\n40\u00d7Acc98.97 99.26 99.2698.25 98.97 98.2598.18\nAUC 0.992 0.995 0.9930.981 0.985 0.9880.987\n100\u00d7Acc98.43 98.30 92.4197.19 98.50 97.1996.64\nAUC 0.991 0.990 0.9820.987 0.992 0.9870.980\n200\u00d7Acc98.55 98.62 90.8898.62 98.55 98.0097.58\nAUC 0.989 0.993 0.9630.994 0.992 0.9890.988\n400\u00d7Acc98.38 97.98 90.2997.74 97.98 97.1997.74\nAUC 0.993 0.990 0.9830.987 0.989 0.9820.986\nTable 3.4 Average accuracy (%) of monolithic classifiers and\nensemble methods with the BiTW descriptor on the BreakHis dataset\nat image level with 10-fold CV\nImage\nMagnificationClassification Algorithm\nHistoB LightB LDACatBExtraT RFGB\n40\u00d7 98.62 98.61 98.6198.06 98.75 98.0498.12\n100\u00d7 98.48 98.45 91.6097.74 98.63 97.8797.76\n200\u00d7 98.54 98.72 91.5597.98 98.65 97.9898.53\n400\u00d7 98.76 98.74 91.0098.08 98.33 97.5897.77\nTable 3.5 Average accuracy (%) on the BreakHis dataset of shallow\nand deep approaches. For training and testing, all of these works used\nthe same data partitions\nImage Magnification\nReference Method 40\u00d7100\u00d7200\u00d7400\u00d7\nAlomet al.(2019) CNN 97.00 97.5097.2097.20\nHanet al.(2017) CNN 92.8093.9093.7092.90\nBayramoglu et al.(2016) CNN 83.0083.1084.6082.10\nSpanholet al.(2016b) CNN 90.0088.4084.6086.10\nGandomkar, Brennan & Mello-Thoms (2018) CNN 94.1093.2094.7093.50\nBardou, Zhang & Ahmad (2018) CNN 88.2384.6483.31 8.98\nNawaz, Ahmed, Tahir & Khan (2018) CNN \u201395.00 \u2013\u2013\nSpanholet al.(2016a)\u2217Shallow 75.6073.0072.9071.20\nSpanholet al.(2016a)+Shallow 74.7076.8083.4081.70\nErfankhah et al.(2019)\u2217Shallow 88.3088.3087.1083.40\nAtaky & Lameiras Koerich (2022)\u2020Shallow 97.5096.8095.8095.20\nBiTW + HistoB Shallow 98.9798.4398.5598.38\n\u2217LBP descriptor;+GLCM descriptor;\u2020BiT descriptor.", "doc_id": "485ca214-6e60-4fde-a1a9-cfc5315b75ee", "embedding": null, "doc_hash": "d51fb6750828440d62f87f1b40081130498773af9d0236bb51d876f52c1b8e67", "extra_info": {"page_label": "110", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1895}, "relationships": {"1": "6dc64be1-a895-4704-b738-c445de281f6e"}}, "__type__": "1"}, "3dfbe4c2-42df-4ff3-9b80-83c1fedbafb7": {"__data__": {"text": "111\n3.1.3 Discussion\nThe proposed approach was assessed with two HI datasets, both with eight classes. The\nexperiment protocol employed a train-test split (70/30) and a \ud835\udc58-fold CV. For either experimental\nprotocol, the results led to the following findings:\n\u2022Exploitinginformation-theoreticalmeasuresofecologicaldiversityindicesinconjunction\nwithnon-linearinteractionsofsingleandindependentwaveletsubbandcoefficientsthroughout\ntime yielded promising results.\n\u2022Although HIs contain other structures than texture, it was possible to characterize texture\nand achieve a reasonable discriminating capability by employing biodiversity measures and\ntaxonomic indexes together with multi-resolution analysis through DWT.\n\u2022Such a mixture allowed the characterization of HIs to such an extent that intrinsic properties\nhaveprovidedapromisingperformanceforthereal-worlddatasetsclassification,reaching\n93.73%accuracyand0.994AUCfortheCRCdataset. RegardingtheresultsontheBreakHis\ndataset, the accuracy were 99.26%, 98.50%, 98.62%, and 98.76% for 40 \u00d7, 100\u00d7, 200\u00d7and\n400\u00d7magnification, respectively. The AUC of all the magnifications was above 0.98.\n\u2022By and large, results for HIS are better than for the CRC dataset.\nOverall, the proposed approach outperformed state-of-the-art shallow and deep works on CRC\nand BreakHis datasets, regardless of the non-textural information that HIs may contain.\n3.1.4 Final Considerations\nThecurrentresearchleveragedtheinformation-theoreticalmeasureofecologicaldiversityindices\ntogether with a discrete wavelet transform to characterize texture across HIs. We explored\nthe interactions of individual wavelet subband coefficients over time and modeled each as an\necosystemfrom which measuresofbiodiversity andstatisticalproperties oftaxonomicindexes\nare extracted to represent HI texture effectively. We stated that by combining measurements\nofbiodiversityfromeachHIchannelandtaxonomicindexesextractedfromdifferentwavelet\nsubbands,itshouldbepossibletoquantifytheintrinsicpropertiesofsuchimagestothemaximum", "doc_id": "3dfbe4c2-42df-4ff3-9b80-83c1fedbafb7", "embedding": null, "doc_hash": "58a8db176c38ed1dedc3eb7171fe217f68a62329c2a95de536c50d0c78bccd67", "extra_info": {"page_label": "111", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2023}, "relationships": {"1": "a8fe6794-69f0-4994-b153-8d7a34a040c7"}}, "__type__": "1"}, "cca0e4ea-348a-4c8e-a0ee-020020f1576c": {"__data__": {"text": "112\nextent. Themixtureofwaveletfeaturesandstatisticalpropertiesofecologydiversityindexes\nrepresentanovelmethodandapromisingtoolforthequantificationoftheintrinsicproperties\noftextureacrossHIs. Wherefore,theexperimentalresultshaveshownanincreaseintermsof\ntexture discrimination over both HI datasets. Moreover, the proposed method outperformed\nseveral shallow and deep state-of-the-art methods.\nWithal, it is noteworthy that the proposed method presents the following limitations: (i)\nSpecifyingtheexpecteddynamicrangesofthebiodiversityandtaxonomicindicesisnotpossible.\nThe ranges of the biodiversity and taxonomic indices are necessarily related to the species\nrichness, abundance, and their relationship within an image and a wavelet subband of an image,\neitherdirectlyorinversely. Thedynamicrangeis,therefore,notknownbeforehand. Thereby,\nfeaturenormalizationmaybenecessary;(ii)Imagesareusuallycorruptedwithnoiseintroducing\nrandomvariationstograylevelssothathomogeneousregionspresentagray-leveldispersion\ndependingonnoisepower,decreasingtheperformance. Sofar,theproposedmethoddoesnot\nprovide, to some extent, a tolerance parameter to cope with such noise-produced variations that\nhelps to decide if a species (gray-level) or individual (pixel) should be considered or not. Thus,\nwe suggest considering the preprocessing before the feature extraction phase.\nIn future work, we intend to further improve the classification accuracy by exploring various\ncolorspacesandfractalfeaturesfordealingwithmulti-resolutionaspectsofthetexturesthatwill\nbring ondiscriminative information forcharacterizing HI categories. Furthermore, because an\nincreasing number of DWT-level decompositions can result in high-dimensional feature vectors,\nwe want to look into appropriate feature selection approaches or dimensionality reduction\ntechniquestofindfeaturesubspacesthatnotonlyreducetexturefeaturesdimensionalitybutalso\nimprove the proposed method\u2019s class discrimination capability. Furthermore, we will also focus\non finding a tolerance parameter to minimize performance issues when we apply our method in\nthe presence of noise.\nThe following section presents how texture classification can be improved by leveraging the\nmulti-scale / multi-resolution analysis and combining different descriptors.", "doc_id": "cca0e4ea-348a-4c8e-a0ee-020020f1576c", "embedding": null, "doc_hash": "76cdad14fcebf3b7517956893ec514e648de09a2edc23bcee1d3ea848dc00893", "extra_info": {"page_label": "112", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2279}, "relationships": {"1": "ac7688e3-d1d6-4554-ae48-014d232c9dcc"}}, "__type__": "1"}, "46aaa8c8-7afe-4574-be88-1b74643aa44e": {"__data__": {"text": "113\n3.2 Multi-scale Analysis for Improving Texture Classification\nInformation from an image occurs over multiple and distinct spatial scales. Image pyramid\nmulti-resolution representations are a proper data structure for image analysis and manipulation\noveraspectrumofspatialscales. Likewise,eventhoughthedescriptorspresentedinChapter\n2 have shown a significant discriminative ability, combining them with other descriptors\nmay be a promising strategy to provide a representation based on several intrinsic textural\nproperties. With this in mind, we evaluate the combination of texture descriptors such as\ntheBiT(Ataky&LameirasKoerich,2022),information-theoreticmeasures(Shannon,1948),\nGLCM(Haralick etal.,1973),andHaralickfeatures(Haralick,1979)toimprovetheperformance\nof texture classification. To this end, individually, the feature vector representing an image\nis formed by concatenating features provided by different descriptors. The rationale is to\ncompensate for the possible loss when using a single technique to give the textural description.\nThis process is done over a spectrum of spatial scales representation using Gaussian-Laplacian\n(GLP), a proper data structure for image analysis and manipulation.\nThe highlights of this section are threefold, as follows:\n\u2022The combination of BiT descriptor, information theory, Haralick, and GLCM features for\ntexture characterization.\n\u2022Abetterdiscriminatingabilitywhileusingcolorandgray-scalefeaturesondifferentcategories\nof images.\n\u2022Amethodfortextureclassificationthatrepresentsthestate-of-the-artonchallengingdatasets.\n3.2.1 Proposed Approach\nThis section describes how the proposed method integrates multi-resolution analysis and\nmultipletexturedescriptorsfortextureclassification. Tothisend,weputforwardanarchitecture\nstructured in five main stages as follows. Figure 3.2 shows an overview of the proposed scheme.\nAlgorithm 3.2 shows the steps of the first three stages.", "doc_id": "46aaa8c8-7afe-4574-be88-1b74643aa44e", "embedding": null, "doc_hash": "b6767a243482aefe218221e28ab035d5ecb4c6385f543e087f4772302ace1bd4", "extra_info": {"page_label": "113", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1927}, "relationships": {"1": "966f0d32-b237-4abc-91f7-f317a76085b2"}}, "__type__": "1"}, "e94dc342-1673-411d-8ade-156d6751ef6d": {"__data__": {"text": "114\nFigure 3.2 An overview of the proposed scheme\nMulti-resolution representation: in this stage, for an input image, we generate three others\ncorresponding to the levels of the Gaussian pyramid (L0: original image, L1: first level of\nthepyramid,L2: secondlevelofthepyramid). Thepurposeistorepresentaninputimagein\ndifferent resolutions to capture intrinsic details.\nChannelSplitting : inthisphase,eachimagechannel(R,G,B)isconsideredasaseparateinput.\nThe key reason behind the splitting channels is to exploit color information. Thus, we represent\nandcharacterizeaninputimageinagivenresolutionbyasetoflocaldescriptorsgeneratedfrom\nthe interaction of a pixel with its neighborhood inside a given channel (R, G, or B).\nFeature Extraction : after the channel splitting step, the images undergo feature extraction,\nwhichlooksforintrinsicpropertiesanddiscriminativecharacteristicswithin. Foreachlevelof\nGP of an image, we extract: BiT (Ataky & Lameiras Koerich, 2022) (14-dimensional), Shannon\nentropy and multi-information, aka total information (3-dimensional), Haralick (Haralick et al.,\n1973) (13-dimensional), and GLCM (Haralick et al., 1973) (6-dimensional) from each channel.\nImages are then represented by the concatenation of different measurements organized as\nfeature vectors (Algorithm 2.1). For simplicity, we name the resulting descriptor Three-in-One\n(TiO). It is worth mentioning that images were converted in gray-scale for GLCM and Haralick\nmeasurementtobeextractedbutremainedcolorforextractingthebio-inspiredindices. After\nfeature extraction and before concatenation, the feature vectors have 126, 117, 54, and 18\ndimensions for BiT, Haralick, GLCM, and Shannon entropy and multi-information, respectively.\nThereby, after concatenation, we have a 315-dimensional feature vector.", "doc_id": "e94dc342-1673-411d-8ade-156d6751ef6d", "embedding": null, "doc_hash": "464228e73168b1164db937199b619d0adfcc42a44a85221440f7b16eba9b41d9", "extra_info": {"page_label": "114", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1791}, "relationships": {"1": "482c64f9-ef36-455a-89be-abcdeb979b28"}}, "__type__": "1"}, "229c5343-3c1c-44a9-bceb-38ba58aa6893": {"__data__": {"text": "115\nNormalization : because test points simulate real-world data, we split the data into train and test\nsets and perform min-max normalization on the training data. Subsequently, we used the same\nmin-max values to normalize the test set.\nTraining/Classification : we have a normalized featurevector comprising theconcatenation of\nfeatures extracted from each resolution and color channel from the previous stage. This texture\nrepresentation is used to train one monolithic and three ensemble-based models. The linear\ndiscriminant analysis (LDA) is used for the monolithic classification model.\nIn contrast, the ensemble models are created using the histogram-based algorithm for building\ngradient boosting ensembles of decision trees (HistoB), the light gradient boosting decision\ntrees (LightB), and the CatBoost 1, which is an efficient implementation of the gradient boosting\nalgorithm.\nAlgorithm 3.2 FeatureExtractionProcedure\nResult:feature descriptor\n11. Reada RGB image file ;\n22. Generate 3 multi-resolution levels with Gaussian pyramids L0, L1, L2 ;\n33. For each level (L0, L1, L2) of Gaussian pyramids ;\n43.1. Separate the image in channels R, G, B;\n53.2. Convert R, G, and B to grayscale images (for GLCM and Haralick only);\n63.3. Compute Bio-inspired indices, Shannon entropy and multi-information, Haralick, and\nGLCM of R, G, B ;\n73.4. Concatenate these values into a single vector (315-dimensional);\n84. Repeat steps 1 to 4 for all images of the dataset\n3.2.2 Experimental Results and Discussion\nThe used experimental protocol considers five datasets, three of which are texture image\ncollections, and two are composed of medical images. In addition to the KTH-TIPS, Outex,\nCRC,andBreakHisdatasetspresentedinSection2.1,wealsousedtheAmsterdamLibraryof\nTextures (ALOT) (Napoletano, 2017), which is a color image collection of 250 (classes) rough\ntextures.\n1https://catboost.ai/", "doc_id": "229c5343-3c1c-44a9-bceb-38ba58aa6893", "embedding": null, "doc_hash": "c7e5c81048c942a47c329bd0b14a47899e0cf59efa2a89f72441ed28431cb026", "extra_info": {"page_label": "115", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1889}, "relationships": {"1": "afbae059-e1c9-4d78-9b35-d5a3f83d436b"}}, "__type__": "1"}, "7ddb5cf6-3fdc-4ff1-964e-5bafd63a1eea": {"__data__": {"text": "116\nThe authors systematically varied the viewing angle, illumination angle, and illumination color\nfor each material so that they could capture the sensory variation in object recordings.\nWe split each dataset into training (70%) and testing (30%) sets to evaluate all the classifiers\non the same experimental condition. In the experiments, the full feature vector generated by\nconcatenatingalldescriptorsisusedfortrainingamonolithicclassifierusingtheLDAalgorithm\nand ensembles using the HistoB, LightB, and CatBoost algorithms.\n3.2.2.1 Experiments with Texture Datasets\nTable 3.6 presents the results of the proposed method (TiO), BiT, GLCM, and Haralick over\nOutex, KTH-TIPS, and ALOT datasets. For each dataset, we present the results obtained by\ncombiningallthedescriptors(TiO)andtheresultsobtainedwitheachdescriptorindividually.\nThe primary purpose is not only to verify the effectiveness of TiO but also the complementary\nof the descriptors in the study. The proposed method achieved the best average accuracy of\n100% on the Outex dataset with LDA and CatBoost classifiers. On the ALOT dataset, the\nproposed method achieved an average accuracy of 98.48% with the LDA classifier. Again,\nTiOoutperformedallindividualdescriptors. Finally,ontheKTH-TIPSdataset,theproposed\nmethod achieved the best average accuracy of 100% with the LDA classifier and outperformed\nall individual descriptors.\nDifferentworkshaveusedtheOutexdatasetfortextureclassification. Forinstance,Mehta&Egiazar-\nian (2016) introduced an approach based on a rotation-invariant LBP, achieving an accuracy of\n96.26%witha \ud835\udc58-NNclassifier. Du etal.(2016)presentedarotation-invariant,impulsenoise\nresistant,andillumination-invariantapproachbasedonalocalspikingpattern. Thisapproach\nachieved an accuracy of 86.12% with a neural network but is not extended for color textures,\nand it requires several input parameters. In Section 2.1, we introduced a bio-inspired texture\ndescriptorbasedonbiodiversityandtaxonomicmeasures(Ataky&LameirasKoerich,2022).\nSuchatexturedescriptorachievedanaccuracyof99.88%withanSVM.Table3.7comparesthe\nbest results of the proposed method with a few works that also used the Outex dataset.", "doc_id": "7ddb5cf6-3fdc-4ff1-964e-5bafd63a1eea", "embedding": null, "doc_hash": "c8d41a0e9ec04778a6b8711dba46d56e3ae642b561d2652ccf7fb1ef00408b5a", "extra_info": {"page_label": "116", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2178}, "relationships": {"1": "8c77e843-c379-46e0-ae99-d86b01f3c6cd"}}, "__type__": "1"}, "1e74a9e4-ec7a-4d05-9769-810f99a4fbd1": {"__data__": {"text": "117\nTable 3.6 Average accuracy (%) on the test set of Outex,\nALOT and KTH-TIPS datasets. The best accuracy for each\ndataset is shown in boldface. The best result for each\ntexture descriptor is marked with\u2217\nTexture Classification Algorithms\nDataset Descriptors HistoB1LightB2LDACatBoost3\nOutexTiO100.0 100.0 100.0 100.0\nBiT99.92 99.69 100.0\u221799.84\nGLCM 98.84 97.99 95.91 99.30\u2217\nHaralick 99.69 99.53 99.38 99.84\u2217\nALOTTiO41.50 43.07 98.48 93.47\nBiT10.71 11.52 68.14 74.90\u2217\nGLCM 11.28 14.52 66.61\u221764.23\nHaralick 18.52 20.47 86.57\u221783.23\nKTH-TIPSTiO98.53 97.20 100.0 98.91\nBiT96.29 96.70 99.58\u221797.53\nGLCM 89.71 90.12 87.65 92.01\u2217\nHaralick 95.88 96.29 98.35\u221796.11\n1max_bins=10, max_iter=1500.2,3n_estimators=1500.\nTable 3.7 Average accuracy (%) of the proposed\nmethod with related works on Outex dataset.\nThe best result is marked with\u2217\nReference Approach Accuracy\nAtaky & Lameiras Koerich (2022)GLCM 95.52\nHaralick 96.92\nBiT 99.88\nMehta & Egiazarian (2016) Shallow 96.23\nDuet al.(2016) Shallow 86.12\nTiO+LDA or TiO+CatBoost Shallow 100.0\u2217\nTable 3.8 presents a few works that also used the ALOT dataset. There was an improvement in\ntheaccuracyofnearly1%and0.1%comparedwithshallowanddeepmethods. Notwithstanding,\nthe differenceis notsignificantly high;it isworth mentioningthat thesuccess ofCNNs places\nreliance on the ability to leverage massive labeled datasets to learn high-quality representations.\nNonetheless, data availability for a few domains may be restricted, and therefore CNNs become\nrestrained from several fields. Moreover, some works evaluated small-scale CNN architectures,\nsuch as T-CNN and T-CNN Inception, with 11,900 and 1.5M parameters. Despite the reduced\nnumber of parameters and lower computational cost for training, both still required a large\namount of training data to perform satisfactorily.", "doc_id": "1e74a9e4-ec7a-4d05-9769-810f99a4fbd1", "embedding": null, "doc_hash": "7194833959e4cd7a916390bd5b1e4e2246d75aa17b4090eb6c45da4289a3bf02", "extra_info": {"page_label": "117", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1812}, "relationships": {"1": "5ec1b41f-2922-41a3-9fbd-53639a03568a"}}, "__type__": "1"}, "031d683f-88dd-4f1b-8970-ebe43f068696": {"__data__": {"text": "118\nEven some small architectures of comparable performance, such as MobileNets, EfficientNets,\nandsparsearchitecturesresultingfrompruning,stillhavemanytrainingparameters. Forinstance,\nthenumberofparametersofaMobileNetrangebetween3.5Mand4.2M,whileEfficientNets\nrangebetween5.3Mand66.6M.GoogleNet,ResNet,andVGGgenerallyneedextensivetraining,\nand the number of hyperparameters and the computational cost is high.\nTable 3.8 Accuracy (%) of shallow and deep approaches\non the ALOT dataset. The best result is marked with\u2217\nReference Approach Accuracy\nArmi, Abbasi & Zarepour-Ahmadabadi (2021) Shallow 97.56\nDubey, Singh & Singh (2016) Shallow 63.04\nHe, Zhang, Ren & Sun (2016)ResNet50 75.68\nResNet101 75.60\nNapoletano (2017)ResNet101 98.13\nResNet50 98.35\nVGG VeryDeep19 94.93\nVGG M128 85.56\nGoogleNet 92.65\nVGG M1024 92.58\nVGG M2048 93.30\nAlpaslan & Hanbay (2020) Shallow 97.20\nTiO+LDA Shallow 98.48\u2217\nLikewise, the KTH-TIPS dataset has been used to evaluate texture characterization and clas-\nsificationapproaches.Hazgui etal.(2021)introducedanapproachthatintegratesthegenetic\nprogramming and the fusion of HOG and LBP features, which achieved an accuracy of 91.20%\nwith a\ud835\udc58-NN classifier. Such an approach does not use color information and global features.\nNguyenetal.(2016)putforthrotationalandnoiseinvariantstatisticalbinarypatterns,which\nreached an accuracy of 97.73%, which is lower than the accuracy achieved by the proposed\nmethod of about 2.3%. This approach is resolution sensitive and presents a high computational\ncomplexity.Qi etal.(2013)proposedarotation-invariantmultiscalecross-channelLBP(CCLBP)\nthatencodesthecross-channeltexturecorrelation. TheCCLBPcomputestheLBPdescriptors\nin each channel and three scales and computes co-occurrence statistics before concatenating the\nextractedfeatures. Suchanapproachachievedanaccuracyof99.01%forthreescaleswithan\nSVM. Nevertheless, this method is not invariant to scale. Table 3.9 shows that the proposed\napproach outperforms other works that also used the KTH-TIPS.", "doc_id": "031d683f-88dd-4f1b-8970-ebe43f068696", "embedding": null, "doc_hash": "240fecb4cb8ed7ef2e7e0da3db61e16e7307dc194133772f7c4773c4193c83e4", "extra_info": {"page_label": "118", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2016}, "relationships": {"1": "1f1bbd87-b197-40a1-81d0-6af92b57bf84"}}, "__type__": "1"}, "fbb00ba4-250d-4aa2-803a-4fc1f5bd2a8b": {"__data__": {"text": "119\nTable 3.9 Average accuracy (%) of the proposed\nmethod with related works on KTH-TIPS dataset.\nThe best result is marked with\u2217\nReference Approach Accuracy\nAtaky & Lameiras Koerich (2022)GLCM 86.83\nHaralick 94.89\nBiT 97.87\nHazguiet al.(2021) Shallow 91.20\nNguyenet al.(2016) Shallow 97.73\nQiet al.(2013) Shallow 99.01\nTiO+LDA Shallow 100.0\u2217\n3.2.2.2 Experiments with HI Datasets\nTable 3.10 presents the accuracy achieved by monolithic classifiers and ensemble methods, both\ntrained with the proposed method on the CRC dataset with TiO and BiT, GLCM, and Haralick,\nindividually. The proposed approach provided its best accuracy of 94.71%, with HistoB and\nLightB with all the features. Into the bargain, the accuracy difference between TiO and the first\nbest-related work is nearly 2.00%, which corroborates the discriminating ability of the proposed\nmethod. Additionally,comparedtoeachdescriptorthatTiOismadeupof,TiOoutperformed\neach of them when employed individually.\nTable3.11comparestheresultsoftheproposedapproachwithsomestate-of-the-artworksto\nassessitseffectiveness. TheresultsachievedbyTiOontheCRCdatasethaveshownthatthe\nproposed approach works well on images with other structures apart from textures and with no\nneed for data augmentation. Besides, such CNNs need to be trained with a large amount of data\nwhich may be prohibitive in fields such as medical imaging.\nTable 3.12 shows the accuracy achieved by monolithic classifiers and ensemble methods trained\nwithallthefeaturesoftheproposedapproach. FortheBreakHisdataset,theHistoBclassifier\nachieved the best accuracy for 40 \u00d7, 100\u00d7, and 400\u00d7magnifications, and LightB for 200 \u00d7.\nTable 3.13 shows and compares the results achieved by the proposed approach using all the\nfeatures with the state-of-the-art for the BreakHis dataset. One can note that the proposed\napproachachievedaconsiderableaccuracyof98.64%withallthefeaturesfor40 \u00d7magnification,", "doc_id": "fbb00ba4-250d-4aa2-803a-4fc1f5bd2a8b", "embedding": null, "doc_hash": "494610e1f6f703686d91dff9faaa8ca58c4098c65fa341f80ac44bfd10147824", "extra_info": {"page_label": "119", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1908}, "relationships": {"1": "fa063b65-43e0-4548-b13c-47923cbe0152"}}, "__type__": "1"}, "42901de3-95a0-4b28-8f19-a76882e91289": {"__data__": {"text": "120\nwhichslightlyoutperformstheaccuracyofbothshallowanddeepmethods. Thedifferencein\naccuracybetweentheproposedapproachandthesecond-bestmethod(CNN)isnearly1%for\n40\u00d7magnification. Likewise,theproposedmethodachievedaconsiderableaccuracyof97.85%,\n98.76%and98.22%for100 \u00d7,200\u00d7,and400\u00d7,respectively,whichslightlyoutperformedthe\nsecond-best method with difference of 0.9% for 100 \u00d7, 1.05% for 200\u00d7, and 1.0% for 400\u00d7.\nWe also carried out the experiments individually with BiT, GLCM, and Haralick. For all the\nmagnifications,TiOoutperformedeachdescriptorwiththemaximumaccuracydifferenceof\n1.25%,0.48%,1.01%,1.5%for40 \u00d7,100\u00d7,200\u00d7,and400\u00d7,respectively. Thus,thecombination\nof the descriptors mentioned above increased nearly 1% in accuracy.\nTable 3.10 Accuracy (%) of monolithic\nclassifiers and ensemble methods with TiO\nand each descriptor employed individually\non the CRC dataset\nTexture Classification Algorithms\nDescriptors HistoB LightB LDACatBoost\nTiO94.71 94.71 94.37 93.80\nBiT93.22 92.61 86.67 92.92\nGLCM 85.98 86.97 81.79 87.20\nHaralick 91.62 91.31 92.38 91.39\nTable 3.11 Average accuracy (%) of shallow and deep\napproaches on the CRC dataset. The best results\nare marked with\u2217\nReference Approach 10-fold 5-fold\nKatheret al.(2016b) Shallow 87.40 \u2013\nSarkar & Acton (2017) Shallow 73.60 \u2013\nAtaky & Lameiras Koerich (2022) Shallow 92.96 \u2013\nTiO+HistoB Shallow 94.71\u221792.77\u2217\nWanget al.(2017) CNN \u2013 92.60\nPham (2017) CNN \u2013 84.00\nRaczkowski et al.(2019) CNN 92.40 92.20", "doc_id": "42901de3-95a0-4b28-8f19-a76882e91289", "embedding": null, "doc_hash": "29ef45558e25bf269eee2cc0ca4e34a817098248be770a4c9509bd1460e988c1", "extra_info": {"page_label": "120", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1457}, "relationships": {"1": "27e16ed6-62dd-47c8-b280-8754a5fda6eb"}}, "__type__": "1"}, "b82131f5-5f01-46da-8145-8f26eb44900d": {"__data__": {"text": "121\nTable 3.12 Accuracy (%) of monolithic\nclassifiers and ensemble methods with TiO\ndescriptor on balanced 8-classes image-level\nBreakHis dataset. The best result for each\nmagnification is marked with\u2217\nClassification Algorithms\nMagnification HistoB LightB LDACatBoost\n40\u00d7 98.64\u221798.12 97.83 98.04\n100\u00d7 97.85\u221797.50 96.81 96.67\n200\u00d7 97.62 98.76\u221794.63 97.28\n400\u00d7 98.22\u221798.06 94.92 96.98\nTable 3.13 Accuracy (%) of shallow and deep approaches on the\nBreakHis dataset. All these works used the same data partitions for\ntraining and test. The best results are indicated with\u2217\nMagnification\nReference Method 40\u00d7100\u00d7200\u00d7400\u00d7\nSpanholet al.(2016a) (LBP) Shallow 75.60 73.00 72.90 71.20\nSpanholet al.(2016a) (GLCM) Shallow 74.70 76.80 83.40 81.70\nErfankhah et al.(2019) Shallow 88.30 88.30 87.10 83.40\nAtaky & Lameiras Koerich (2022) Shallow 97.50 96.80 95.80 95.20\nAlomet al.(2019) CNN 97.00 97.50 97.20 97.20\nHanet al.(2017) CNN 92.80 93.90 93.70 92.90\nBayramoglu et al.(2016) CNN 83.00 83.10 84.60 82.10\nSpanholet al.(2016b) CNN 90.00 88.40 84.60 86.10\nTiO+HistoB Shallow 98.64\u221797.85\u221798.76\u221798.22\u2217\n3.2.3 Final Considerations\nThis section provided an essential study regarding image analysis and manipulation over a\nspectrumofspatialscalesandthecomplementarityoffeaturedescriptorsfortextureclassification.\nWestatedthatindividuallyemployingeachdescriptormayoverlookrelevanttexturalinformation,\nreducing the classification performance. Moreover, we exploited the pyramids\u2019 multi-resolution\nrepresentationasaproperdatastructureforanalyzingandcapturingintrinsicdetailsfromtexture\nover a spectrum of spatial scales. To produce a feature vector from an image, we combined\nseveral descriptors that have proven to be discriminating for the classification, namely, the BiT,\ninformation-theoretic measures, GLCM, and Haralick descriptors to extract gray-level and color\nfeaturesindifferentresolutions. Suchacombinationaimedtobringfeaturesthatcharacterize", "doc_id": "b82131f5-5f01-46da-8145-8f26eb44900d", "embedding": null, "doc_hash": "ae605fc0f02d9244b0add24c08a34ada8b3f071fb2d9dc861fbeada757e02503", "extra_info": {"page_label": "121", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1933}, "relationships": {"1": "fb002ce3-f2e2-4a1e-bd91-8e7e1aaa13d5"}}, "__type__": "1"}, "68faac79-d19e-4e23-87bf-7428690712a1": {"__data__": {"text": "122\nthe texture to the maximum extent and with some advantages such as rotation, permutation,\nscale-invariant,reducednoisesensitivity,andgenericandhighgeneralizationability,asithas\nprovided effective performance for the real-world datasets.\nThe proposed approach outperformed state-of-the-art shallow and deep methods. Moreover,\nthe descriptors employed herein have proven complementary as their combination resulted in a\nbetterperformancethanusingeachindividually. Regardless,somefeaturesmayberedundant\nafter the concatenation into a single feature vector, given the different resolutions, channels,\nand descriptors. This may cause a downfall in the classification performance. Likewise, such a\nconcatenationmayalsoleadtotheHughesphenomenon. Thisalsoexplainswhywehavenot\nincludedotherdescriptorssuchasLBP,HOG,etc. However, wewillconsider includingother\ndescriptors in future studies.\nTo circumvent the possible feature redundancy and cope with the increase in dimensionality,\ninfutureworks,weintendtoinvestigatetheimpactofincorporatingadecisionmarkermulti-\nobjective feature selection.", "doc_id": "68faac79-d19e-4e23-87bf-7428690712a1", "embedding": null, "doc_hash": "b665bfece1b36579020ace6701c6f135cf79d3aeaceffe6bf3c1e1bf7fc0b4af", "extra_info": {"page_label": "122", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1086}, "relationships": {"1": "b39d7cde-fcf7-4e01-a9cb-ef73d506aaf0"}}, "__type__": "1"}, "c22974b9-ef5b-4948-a5c2-95e7f8dfa3d6": {"__data__": {"text": "CONCLUSION AND RECOMMENDATIONS\nTextureanalysisinimagesisfundamentalincomputervision. Severalapplicationsinremote\nsensing, medicine, agriculture, image analysis, microscopy, etc., require the study of the surface\npropertiesofanobject,theunderstandingofhowhumansdiscriminatebetweendifferenttextures\nfor,afterward,modelingtechniquesthatcanperformthistask,byquantifyingasuitablesimilarity\nmeasure between different objects in a dataset.\nIn addition to natural images, texture analysis is a task of high complexity and significant\nrelevancefordetectinganddiagnosingtumorsandcancerouscellssince,inhistopathological\nimages, for example, the cells often have very similar textures, even though they belong to\ndifferent classes, which can cause errors in classification. Because detecting tumors with a\nhigh sensitivity rate and reducing the false positives is still challenging, texture descriptors\nhave been quite popular in medical image analysis, particularly in histopathologic images (HI),\ndue to the variability of the texture found in such images and the tissue appearance caused\nby irregularity ascribable to the staining process. Such variability may exist depending on\ndifferences in staining protocol such as fixation, inconsistency in the staining condition, and\nreagents, either between laboratories or in the same laboratory. Moreover, such images contain\nnot solely texture, for most of them present shape, making them challenging to characterize\nwith only texture. Into the bargain, texture feature extraction for quantifying HI information\ninadiscriminantwayischallenging,giventhatthedistributionofintrinsicpropertiesofsuch\nimages forms a non-deterministic complex system.\nIn summary, this thesis presented methods for classifying natural and medical images, such\nas histopathological images, through image processing and pattern recognition techniques,\nleveraging textureproperties. In thiscontext, thetheoretical foundationofthe subjectsrelated\ntothearea ofstudywas presented,which arenecessaryforunderstanding theworkdeveloped", "doc_id": "c22974b9-ef5b-4948-a5c2-95e7f8dfa3d6", "embedding": null, "doc_hash": "09bec26a18e82364fef8654ac6d2c58b9c8917b9dbbbcb6983aed5f77e222982", "extra_info": {"page_label": "123", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2038}, "relationships": {"1": "560fe9c2-f08b-4190-aa6d-95f988c75537"}}, "__type__": "1"}, "58733f77-7f4d-466d-a88d-95266231e557": {"__data__": {"text": "124\nand the techniques addressed in the methods. Also, some related works are presented in the\ncharacterization and classification of texture images and those that do not have only texture.\nExperiments with natural image datasets (Salzburg, Outex, KTH-TIPS, and ALOT) and\nhistopathological image datasets (CRC and BreakHis) were used to evaluate the proposed\napproaches. At this point, the adaptation and application of biological concepts, such as\nbiodiversitymeasuresandtaxonomyindices,tothecomputingareaenabledthecreationofa\nnew descriptor for texture image characterization and classification. As a result, this is the main\ncontribution of the present doctoral research.\nThepromisingperformanceintheclassificationtaskofsuchimagesthroughecologicalmodeling\nand mathematical representation of an image demonstrated that the proposed approach is valid.\nItproducesstatisticallysignificantresultsandiscompetitivewithstate-of-the-artworksinthe\nfield.\nOverall, the contributions of this thesis can be summarized as follows:\nWe developed methods for image classification leveraging texture analysis, in particular:\n1.We adapted and developed strategies that enable analysis with as much relevant information\nas possible;\n2.Weleveragedecologicalconceptsfortexturecharacterizationforbothnaturalandhistopatho-\nlogic images by using:\n- Biodiversity indices based on species richness and abundance;\n- Diversity indices based on species evenness;\n- Diversity indices based on evolutionary relationships between pairs of species;\n- Diversity indices based on phylogenetic distance; and\n- Ecological patterns\u2019 invariance characteristics to permutation, rotation, and scale.", "doc_id": "58733f77-7f4d-466d-a88d-95266231e557", "embedding": null, "doc_hash": "75ca62b00a96f1ee3d382ca2053937b5da0667ea6d8add443d9766b01f1be631", "extra_info": {"page_label": "124", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1660}, "relationships": {"1": "aa791d7e-3d3f-436e-9de6-2f8d50e66660"}}, "__type__": "1"}, "09e1f3ed-5d69-418c-a0a6-762121cbf968": {"__data__": {"text": "125\n3.We proposed an image representation scheme that allows the extraction of mathematical\nproperties therefrom through ecological concepts;\n4.Wedevelopedseveraldescriptorsthataregeneric,independentofmacro-levelvariations\nin terms of contrast, invariant to in-plane rotations of the image, lend themselves to fast\ncomputation, explainable and interpretable based on biology concepts;\nIn general, the methods outlined in this thesis could form a reliable instrument for application in\nreal-world classification and diagnosis scenarios. It is also essential to look into their sturdiness\nwhen they are put to the evaluation in databases with enormous amounts of data and cases that\nrequire complex processing.\nMoreover,itisnoteworthythatthemethodsproposedinthisthesishavelimitationsinthatthe\ndynamic ranges of the biodiversity and taxonomic indices are not specified beforehand. Feature\nnormalization may be required as the biodiversity, and taxonomic indices range depend on the\nspecies richness, abundance, and relationship within an image. In addition, images are typically\ncorruptedbynoise,whichintroducesrandomvariationstogreylevels,causinghomogeneous\nregions to display a gray-level dispersion proportional to the noise power, thereby reducing\nperformance. Although the proposed descriptor performed well in the presence of noise, it\ndoes not provide a tolerance parameter to deal with such noise-induced variations that aid in\ndetermining whether a species (gray-level) or individual (pixel) should be considered or not,\nsuggesting that preprocessing be performed prior to the feature extraction phase.\nInadditiontothescientificcontributions,wehavealsodevelopedseveralopen-sourcepython\npackagesthatimplementallthemethodsproposedinthisthesis,whichmaybeusedbyeveryone\nconsidering incorporating the proposed descriptors into their applications (Ataky & L. Koerich,\n2022).", "doc_id": "09e1f3ed-5d69-418c-a0a6-762121cbf968", "embedding": null, "doc_hash": "43ce5ee55e7e7a8677d49f38093902a586171423be8201bccc3626dd6d5a1d1d", "extra_info": {"page_label": "125", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1874}, "relationships": {"1": "2380a331-60da-42ad-9edb-722081f8a5a2"}}, "__type__": "1"}, "573512dd-51e5-4a4f-8964-46232af53d3b": {"__data__": {"text": "126\n4.1 Future Works\nAspresentedinthisthesis,theinterestincomputationalresearchthatassistsinthecharacterization\noftextureinvariousareasofcomputationalvisionisextremelyrelevant,givenalargeamountof\nexisting research. Therefore, for future works, some suggestions were listed:\n\u2022In real-world applications, images are usually corrupted with noise introducing random\nvariations to gray levels so that homogeneous regions present a gray-level dispersion\ndependingonnoisepower. Accordingly,onewillstudyatoleranceparametertocopewith\nsuchnoise-producedvariationsthathelptodecidewhetheraspeciesoraregionshouldbe\ntaken into consideration or not before computing ecological diversity indices.\n\u2022Alternative levels of Gaussian pyramids could be used to improve the performance of the\nsuggested descriptor.\n\u2022The exploitationof fractalfeatures for dealingwith multi-resolutionaspects ofthe textures\nthat could bring on discriminative information for characterizing texture images.\n\u2022The exploitation of the curvelet transforms (an extension of the wavelet concept) for a multi-\nscale directional transform that allows an almostoptimal nonadaptive sparse representation\nof objects with edges, in which case it could be possible to employ ecological diversity\nmeasures to characterize images containing the most edges.\n\u2022Because 1-D transform processing of intrinsic geometrical structures, such as curve smooth-\nness, is limited in one direction, more powerful representations in higher dimensions are\nnecessary. Thus,thecontourlettransformstandsasaninterestingtwo-dimensionaltransform\nmethod for image representations. Multiresolution, localization, directionality, critical\nsampling, and anisotropy are all features of the contourlet transform. As such, we will study\nthe contourlet transforms to effectively capture the contours of original images, for example,\ncells contours, which are the significant features in both natural and histopathologic images,\nusing only a few coefficients.", "doc_id": "573512dd-51e5-4a4f-8964-46232af53d3b", "embedding": null, "doc_hash": "4d39f6f603467b0285c55ea7357c98a3cdc7e4cfda801ac365fd930f3691c150", "extra_info": {"page_label": "126", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1971}, "relationships": {"1": "3053e571-eb7e-4056-a956-e72425240a91"}}, "__type__": "1"}, "d6847a83-83b2-467e-9fea-76eb388da366": {"__data__": {"text": "127\n\u2022Investigationofhowtoincorporateadecision-makertoselectrelevantfeaturesandscales\nandresolutionsfromwaveletdecompositionsandcurveletsthatprovidethemostrelevant\nintrinsic properties for texture characterization.\n\u2022Consideringanimageasanecosystem,therewillbemanydifferentpatchesofgray-levelx\nandgray-levely. Alphadiversityisthespeciesdiversitywithineachgray-levelxorgray-level\ny patch of the image. Beta diversity is represented by the species diversity between any two\npatches and their communities. Gamma diversity of the images is the species diversity along\nwith the entire range of the dataset or class to which the image belongs. Thus, we aim to\nleverage such concepts to develop an ecological representation-based descriptor-classifier.\n4.2 Publications\nThe current doctoral project resulted in the publication/submission of several scholarly articles\nin related conferences and journals. The primarily published works, as well as those submitted\nfor publication, are listed in Table 4.1.\nTable 4.1 Published and submitted articles related to this research proposal\nPlace Paper Status\nJournalAtaky, STM., Lameiras Koerich, A.\nA novel bio-inspired texture descriptor based on biodiversity\nand taxonomic measures. Pattern Recognition.\nVolume 123, March 2022, 108382Published\nJournalAtaky, STM., Lameiras Koerich, A.\nE-BiT: Extended bio-inspired texture descriptor for texture analysis\nand characterization.\nImage and Vision Computing.Submitted\nJournalAtaky, STM., Lameiras Koerich, A.\nMultiresolution Texture Analysis of Histopathologic Images\nUsing Ecological Diversity Measures.\nExpert Systems With Applications.Minor review\nJournalAtaky, STM., Saqui,D., Lameiras Koerich, A.\nImproving Texture Classification by Multi-objective Feature Selection.\nExpert Systems With Applications.Under review\nConferenceAtaky, STM.,Lameiras Koerich, A.\nMultiscale Analysis for Improving Texture Classification.\nApplied Science (Journal)Submitted", "doc_id": "d6847a83-83b2-467e-9fea-76eb388da366", "embedding": null, "doc_hash": "55692339dadb63ae3e54eca8b26eadc74e58dcfe62d008209453bfe1a605d404", "extra_info": {"page_label": "127", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 1935}, "relationships": {"1": "94a4ed1d-63ab-4e7a-8ef6-bcdd6043e007"}}, "__type__": "1"}, "255634a7-0a9f-41f6-845f-58ff3c826c93": {"__data__": {"text": "128\nTable 4.2 Published articles not directly related to this research proposal\nPlace Paper Status\nConferenceSTM Ataky, J de Matos, AS Britto, LES Oliveira, AL Koerich\nData Augmentation for Histopathological Images Based on\nGaussian-Laplacian Pyramid Blending.\nIEEE International Joint Conference on Neural Networks, June 2020Published\nJournalJ de Matos, STM Ataky, A de Souza Britto, LE Soares de Oliveira,\nAL Koerich\nMachine Learning Methods for Histopathological Image Analysis:\nA Review.\nElectronics, 2021Published\nTable 4.2 lists the scientific articles published throughout the doctoral path, but not directly\nrelated to the objectives of the proposal herein.", "doc_id": "255634a7-0a9f-41f6-845f-58ff3c826c93", "embedding": null, "doc_hash": "828b093e0799e90defceceb3085dbb9a06ccf66d83e9b3019fde46cb0c84681b", "extra_info": {"page_label": "128", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 665}, "relationships": {"1": "8824293e-6eff-4fce-bfc1-d5b0863ad106"}}, "__type__": "1"}, "ca0622ef-032f-47eb-8eee-5c205efa3c03": {"__data__": {"text": "REFERENCES\nAdelson, E. H., Anderson, C. H., Bergen, J. R., Burt, P. J. & Ogden, J. M. (1984). Pyramid\nmethods in image processing. RCA engineer , 29(6), 33\u201341.\nAlom, M. Z., Yakopcic, C., Nasrin, M. S., Taha, T. M. & Asari, V. K. (2019). Breast\ncancer classification from histopathological images with inception recurrent residual\nconvolutional neural network. Journal of digital imaging , 32(4), 605\u2013617.\nAlpaslan, N. & Hanbay, K. (2020). Multi-resolution intrinsic texture geometry-based local\nbinary pattern for texture classification. IEEE Access , 8, 54415\u201354430.\nAnderson, C. H., Burt, P. J. & Van Der Wal, G. S. (1985). Change detection and tracking using\npyramid transform techniques. Intelligent Robots and Computer Vision IV , 579, 72\u201378.\nAndrearczyk, V. & Whelan, P. F. (2016). Using filter banks in Convolutional Neu-\nral Networks for texture classification. Pattern Recognition Letters , 84, 63-69.\ndoi: 10.1016/j.patrec.2016.08.016.\nArivazhagan, S. & Ganesan, L. (2003). Texture classification using wavelet transform. Pattern\nrecognition letters , 24(9-10), 1513\u20131521.\nArmi,L.,Abbasi,E.&Zarepour-Ahmadabadi,J. (2021). Textureimagesclassificationusing\nimprovedlocalquinarypatternandmixtureofELM-basedexperts. NeuralCompApp ,\n1\u201324.\nAtaky, S. T. M. & Lameiras Koerich, A. (2022). A novel bio-inspired texture de-\nscriptor based on biodiversity and taxonomic measures. Patt Recogn , 123, 108382.\ndoi: https://doi.org/10.1016/j.patcog.2021.108382.\nAtaky, S. T. M., de Matos, J., de Souza Britto Jr., A., Oliveira, L. E. S. & Koerich, A. L. (2020).\nData Augmentation for Histopathological Images Based on Gaussian-Laplacian Pyramid\nBlending. Intl Joint Conf on Neural Networks, (\u0132CNN), Glasgow, UK , pp. 1\u20138.\nAtaky, S. & L. Koerich, A. (2022). Bio-Inspired texture descriptors. GitHub.\nAyed,N. G.B., Larousi,M. G.&Masmoudi, A.D. (2014). Multi-scaleGray Leveland Local\nDifference for texture classification. 2014 World Congress on Computer Applications and\nInformation Systems (WCCAIS) , pp. 1\u20135.\nBackes, A. R., Casanova, D. & Bruno, O. M. (2013). Texture analysis and classification: A\ncomplex network-based approach. Information Sciences , 219, 168\u2013180.\nBardou, D., Zhang, K. & Ahmad, S. M. (2018). Classification of breast cancer based on\nhistology images using convolutional neural networks. Ieee Access , 6, 24680\u201324693.\nBarrow,D.K.&Crone,S.F. (2016). Cross-validationaggregationforcombiningautoregressive\nneural network forecasts. International Journal of Forecasting , 32(4), 1120\u20131137.\nBashier, H. K., Hoe, L. S., Hui, L. T., Azli, M. F. & Han, P. Y. (2016). Texture classification via\nextended local graph structure. Optik, 127(2), 638\u2013643.\nBayramoglu,N.,Kannala,J.&Heikkil\u00e4,J. (2016). Deeplearningformagnificationindependent\nbreast cancer histopathology image classification. 23rd Intl. Conf. on pattern recognition\n(ICPR),", "doc_id": "ca0622ef-032f-47eb-8eee-5c205efa3c03", "embedding": null, "doc_hash": "f1931c5f4fcca886ef432cc46286553415074d7a7cc805186e712f5dd49b2d98", "extra_info": {"page_label": "129", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2840}, "relationships": {"1": "ada50c88-b154-4dc6-9aa8-461af7a3be6f", "3": "57780c9b-b334-497b-a854-9cd4f1902b53"}}, "__type__": "1"}, "57780c9b-b334-497b-a854-9cd4f1902b53": {"__data__": {"text": "images using convolutional neural networks. Ieee Access , 6, 24680\u201324693.\nBarrow,D.K.&Crone,S.F. (2016). Cross-validationaggregationforcombiningautoregressive\nneural network forecasts. International Journal of Forecasting , 32(4), 1120\u20131137.\nBashier, H. K., Hoe, L. S., Hui, L. T., Azli, M. F. & Han, P. Y. (2016). Texture classification via\nextended local graph structure. Optik, 127(2), 638\u2013643.\nBayramoglu,N.,Kannala,J.&Heikkil\u00e4,J. (2016). Deeplearningformagnificationindependent\nbreast cancer histopathology image classification. 23rd Intl. Conf. on pattern recognition\n(ICPR), pp. 2440\u20132445.\nBergen, J. R. & Julesz, B. (1983). Rapid discrimination of visual patterns. IEEE Transactions\non Systems, Man, and Cybernetics , (5), 857\u2013863.\nBharati, M. H., Liu, J. J. & MacGregor, J. F. (2004). Image texture analysis: methods and\ncomparisons. Chemometrics and intelligent laboratory systems , 72(1), 57\u201371.", "doc_id": "57780c9b-b334-497b-a854-9cd4f1902b53", "embedding": null, "doc_hash": "e507d31f94d0c4cad9976e4b86f00c42e7d19e86f2a62420407be20fb981452d", "extra_info": {"page_label": "129", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 2259, "end": 3165}, "relationships": {"1": "ada50c88-b154-4dc6-9aa8-461af7a3be6f", "2": "ca0622ef-032f-47eb-8eee-5c205efa3c03"}}, "__type__": "1"}, "63459516-479d-4de3-a6e4-16497d74e9a2": {"__data__": {"text": "130\nBlakemore, C. & Campbell, F. W. (1969). On the existence of neurones in the human visual\nsystemselectivelysensitivetotheorientationandsizeofretinalimages. TheJournalof\nphysiology , 203(1), 237\u2013260.\nBurt, P. & Adelson, E. (1983). The Laplacian pyramid as a compact image code. IEEE\nTransactions on communications , 31(4), 532\u2013540.\nBurt, P. J. (1981). Fast filter transform for image processing. Computer graphics and image\nprocessing , 16(1), 20\u201351.\nBurt, P. J. (1983). Fast algorithms for estimating local image properties. Computer Vision,\nGraphics, and Image Processing , 21(3), 368\u2013382.\nCaicedo, J. C., Gonz\u00e1lez, F. A. & Romero, E. (2011). Content-based histopathology image\nretrieval using a kernel-based semantic annotation framework. Journal of Biomedical\nInformatics , 44(4), 519\u2013528. doi: https://doi.org/10.1016/j.jbi.2011.01.011.\nCastleman, K. R. (1996). Digital image processing . Pearson.\nCernadas, E., Fern\u00e1ndez-Delgado, M., Gonz\u00e1lez-Rufino, E. & Carri\u00f3n, P. (2017). Influence\nofnormalizationandcolorspacetocolortextureclassification. PatternRecognition ,61,\n120\u2013138.\nChao, A. (1984). Nonparametric estimation of the number of classes in a population. Scandina-\nvian Journal of statistics , 265\u2013270.\nChao, A., Shen, T.-J. & Hwang, W.-H. (2006). Application of Laplace\u2019s boundary-mode\napproximationstoestimatespeciesandsharedspeciesrichness. Australian&NewZealand\nJournal of Statistics , 48(2), 117\u2013128.\nClarke, K. R. & Warwick, R. M. (1998a). A taxonomic distinctness index and its statistical\nproperties. Journal of applied ecology , 35(4), 523\u2013531.\nClarke,K.R.,Gorley,R.,Somerfield,P.J.&Warwick,R.(2014). Changeinmarinecommunities:\nan approach to statistical analysis and interpretation . Primer-E Ltd.\nClarke, K. & Warwick, R. (1998b). A taxonomic distinctness index and its statistical properties.\nJournal of applied ecology , 35(4), 523\u2013531.\nClifford, H. T., Stephenson, W. et al. (1975). An introduction to numerical classification .\nAcademic Press New York.\nCox, M. A. & Cox, T. F. (2008). Multidimensional scaling. In Handbook of data visualization\n(pp. 315\u2013347). Springer.\nCrimmins, T. R. (1985). Geometric filter for speckle reduction. Applied optics , 24(10),\n1438\u20131443.\nCross, G. R. & Jain, A. K. (1983). Markov random field texture models. IEEE Transactions on\nPattern Analysis and Machine Intelligence , (1), 25\u201339.\nCrowley, J. L. (1981). A Representation for Visual Information.\nCrowley, J. L.& Riff, O. (2003). Fast computation of scale normalised gaussian receptive fields.\nInternational Conference on Scale-Space Theories in Computer Vision , pp. 584\u2013598.\nCruz-Roa, A., Caicedo, J. C. & Gonz\u00e1lez, F. A. (2011). Visual pattern mining in histology\nimagecollectionsusingbagoffeatures. ArtificialIntelligenceinMedicine ,52(2),91\u2013106.\ndoi: https://doi.org/10.1016/j.artmed.2011.04.010.\nDaSilva,I.A.&Batalha,M.A. (2006). Taxonomicdistinctnessanddiversityofahyperseasonal\nsavanna in central Brazil. Diversity and Distributions , 12(6), 725\u2013730.", "doc_id": "63459516-479d-4de3-a6e4-16497d74e9a2", "embedding": null, "doc_hash": "9bea10b9cb9a17d0e873382cdfdeb09498ce0c085c33da0cdc9e12206d993e17", "extra_info": {"page_label": "130", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2972}, "relationships": {"1": "792407c9-14a5-4598-bff4-4edb58f63e86"}}, "__type__": "1"}, "bd263c35-deb5-4e8d-8b1a-1e95b7763c3b": {"__data__": {"text": "131\nDaly, A. J., Baetens, J. M. & De Baets, B. (2018). Ecological diversity: measuring the\nunmeasurable. Mathematics , 6(7), 119.\nDas, D. K., Mitra, P., Chakraborty, C., Chatterjee, S., Maiti, A. K. & Bose, S. (2017).\nComputationalapproachformitoticcelldetectionanditsapplicationinoralsquamous\ncell carcinoma. Multidimensional Systems and SignalProcessing , 28(3, SI),1031\u20131050.\ndoi: 10.1007/s11045-017-0488-6.\ndeMatos,J.,deSouzaBrittoJr.,A.,deOliveira,L.E.S.&Koerich,A.L. (2019). TextureCNN\nforHistopathologicalImageClassification. 32ndIEEEInt\u2019lSymponComputer-Based\nMedical Systems , pp. 580\u2013583. doi: 10.1109/CBMS.2019.00120.\ndeMatos,J.,Ataky,S.T.M.,deSouzaBritto,A.,SoaresdeOliveira,L.E.&LameirasKoerich,\nA. (2021a). Machinelearningmethodsforhistopathologicalimageanalysis: Areview.\nElectronics , 10(5), 562.\ndeMatos,J.,Ataky,S.T.M.,deSouzaBritto,A.,SoaresdeOliveira,L.E.&LameirasKoerich,\nA. (2021b). MachineLearningMethodsforHistopathologicalImageAnalysis: AReview.\nElectronics , 10(5). doi: 10.3390/electronics10050562.\nDong,K.,Hou,G.,Xu,D.,He,H.&Liu,Z. (2018). AMethodtoComparetheBiodiversityCon-\nservation Effectiveness between Regions based on a Reference Condition. Sustainability ,\n10(10), 3694.\nDougherty,G. (2009). Digitalimageprocessingformedicalapplications . CambridgeUniversity\nPress.\nDu, S., Yan, Y. & Ma, Y. (2016). Local spiking pattern and its application to rotation-and\nillumination-invariant texture classification. Optik, 127(16), 6583\u20136589.\nDubey, S.R., Singh,S. K.& Singh, R.K. (2016). Multichannel decoded localbinary patterns\nfor content-based image retrieval. IEEE Trans Image Process , 25(9), 4018\u20134032.\nDunteman, G. H. (1989). Principal components analysis . Sage.\nEren, M. I., Chao, A., Hwang, W.-H. & Colwell, R. K. (2012). Estimating the richness of a\npopulation when the maximum number of classes is fixed: a nonparametric solution to an\narchaeological problem. PLoS One , 7(5), e34179.\nErfankhah, H., Yazdi, M., Babaie, M. & Tizhoosh, H. R. (2019). Heterogeneity-aware local\nbinary patterns for retrieval of histopathology images. IEEE Access , 7, 18354\u201318367.\nFaith,D.P. (1992). Conservationevaluationandphylogeneticdiversity. Biologicalconservation ,\n61(1), 1\u201310.\nFaith, D. P. (1994). Phylogenetic pattern and the quantification of organismal biodiversity.\nPhilosophical Transactions of the Royal Society of London. Series B: Biological Sciences ,\n345(1311), 45\u201358.\nFeng, J., Jiao, L., Zhang, X. & Sun, T. (2013). Hyperspectral band selection based on trivariate\nmutual information and clonal selection. IEEE Transactions on Geoscience and Remote\nSensing, 52(7), 4092\u20134105.\nFeng, J., Jiao, L., Liu, F., Sun, T. & Zhang, X. (2014). Mutual-information-based semi-\nsupervised hyperspectral band selection", "doc_id": "bd263c35-deb5-4e8d-8b1a-1e95b7763c3b", "embedding": null, "doc_hash": "38a8018c2fff1a87c8a0bf8b7225d298ef80ec6d3aa35d422685e7272cd4ed21", "extra_info": {"page_label": "131", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2739}, "relationships": {"1": "6a906159-49cb-4268-af81-e5ff8c88ee7a", "3": "efe2ea5f-889d-4651-b328-11cb9aa58951"}}, "__type__": "1"}, "efe2ea5f-889d-4651-b328-11cb9aa58951": {"__data__": {"text": "Biologicalconservation ,\n61(1), 1\u201310.\nFaith, D. P. (1994). Phylogenetic pattern and the quantification of organismal biodiversity.\nPhilosophical Transactions of the Royal Society of London. Series B: Biological Sciences ,\n345(1311), 45\u201358.\nFeng, J., Jiao, L., Zhang, X. & Sun, T. (2013). Hyperspectral band selection based on trivariate\nmutual information and clonal selection. IEEE Transactions on Geoscience and Remote\nSensing, 52(7), 4092\u20134105.\nFeng, J., Jiao, L., Liu, F., Sun, T. & Zhang, X. (2014). Mutual-information-based semi-\nsupervised hyperspectral band selection with high discrimination, high information,\nand low redundancy. IEEE Transactions on Geoscience and Remote Sensing , 53(5),\n2956\u20132969.", "doc_id": "efe2ea5f-889d-4651-b328-11cb9aa58951", "embedding": null, "doc_hash": "0be172ce2fcf163bc4e4dc6a4f006531702e9e69fb2f362c32058af9ca474d66", "extra_info": {"page_label": "131", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 2164, "end": 2874}, "relationships": {"1": "6a906159-49cb-4268-af81-e5ff8c88ee7a", "2": "bd263c35-deb5-4e8d-8b1a-1e95b7763c3b"}}, "__type__": "1"}, "69f738d7-1004-467d-9bee-16fc406a925a": {"__data__": {"text": "132\nFeng, J., Jiao, L., Liu, F., Sun, T. & Zhang, X. (2016). Unsupervised feature selection based\nonmaximuminformationandminimumredundancyforhyperspectralimages. Pattern\nRecognition , 51, 295\u2013309.\nFern\u00e1ndez-Carrobles, M. M., Bueno, G., D\u00e9niz, O.,Salido, J., Garc\u00eda-Rojo, M. & Gonz\u00e1ndez-\nL\u00f3pez, L. (2015). Frequential versus spatial colour textons for breast\n{TMA} classification. Computerized Medical Imaging and Graphics , 42, 25-37.\ndoi: https://doi.org/10.1016/j.compmedimag.2014.11.009.\nFisher, R. A., Corbet, A. S. & Williams, C. B. (1943a). The relation between the number of\nspecies and the number of individuals in a random sample of an animal population. The\nJournal of Animal Ecology , 42\u201358.\nFisher, R. A., Corbet, A. S. & Williams, C. B. (1943b). The relation between the number of\nspecies and the number of individuals in a random sample of an animal population. The\nJournal of Animal Ecology , 42\u201358.\nFogel, I. & Sagi, D. (1989). Gabor Filters as Texture Discriminator. Biological Cybernetics , 61,\n103\u2013113.\nFrank, S. A. & Bascompte, J. (2019). Invariance in ecological pattern. F1000Research , 8.\nFujieda, S., Takayama, K. & Hachisuka, T. (2017). Wavelet convolutional neural networks for\ntexture classification. arXiv preprint arXiv:1707.07394 .\nGandomkar, Z., Brennan, P. C. & Mello-Thoms, C. (2018). MuDeRN: Multi-category\nclassification of breast histopathological image using deep residual networks. Artif Intell\nMed, 88, 14\u201324.\nGhalati, M.K., Nunes, A., Ferreira,H., Serranho, P.& Bernardes, R. (2021). Texture analysis\nand its applications in biomedical imaging: A survey. IEEE Reviews in Biomedical\nEngineering .\nGibson, R., Barnes, M. & Atkinson, R. (2001). Practical measures of marine biodiversity based\non relatedness of species. Oceanography and Marine Biology , 39, 207\u2013231.\nGilpin, L. H., Bau, D., Yuan, B. Z., Bajwa, A., Specter, M. & Kagal, L. (2018). Explaining\nexplanations: An overview of interpretability of machine learning. 2018 IEEE 5th\nInternational Conference on data science and advanced analytics (DSAA) , pp. 80\u201389.\nGini, C. (1912). Variabilit\u00e0 emutabilit\u00e0. Reprinted inMemorie di metodologica statistica (Ed.\nPizetti E.\nGonzalez,R.C.&Woods,R.C. (2009). Processamentodigitaldeimagens. PearsonEducaci\u00f3n.\nGoutsias, J. & He\u0133mans, H. (1998). Multiresolution signal decomposition schemes. Part\n1: Linear and morphological pyramids. CWI (Centre for Mathematics and Computer\nScience) Amsterdam, The Netherlands, Tech. Rep .\nGuo, Z., Zhang, L. & Zhang, D. (2010). A completed modeling of local binary pattern operator\nfor texture classification. IEEE transactions on image processing , 19(6), 1657\u20131663.\nHabermann,M. (2018). Bandselectioninhyperspectralimagesusingartificialneuralnetworks .\n(Ph.D. thesis, Compi\u00e8gne).\nHabermann, M., Fremont, V. & Shiguemori, E. H. (2019). Supervised band selection in\nhyperspectral images using single-layer neural networks. International journal of", "doc_id": "69f738d7-1004-467d-9bee-16fc406a925a", "embedding": null, "doc_hash": "0da5b0a7a2233fe0eddfb1ed5e6bd2b622ff7e709fbb0aa140090143867e6656", "extra_info": {"page_label": "132", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2919}, "relationships": {"1": "9250bf89-e8e5-45b4-8218-583043e12b34", "3": "623a1ac5-08c1-4cd9-93a2-b5574f3f459a"}}, "__type__": "1"}, "623a1ac5-08c1-4cd9-93a2-b5574f3f459a": {"__data__": {"text": "(1998). Multiresolution signal decomposition schemes. Part\n1: Linear and morphological pyramids. CWI (Centre for Mathematics and Computer\nScience) Amsterdam, The Netherlands, Tech. Rep .\nGuo, Z., Zhang, L. & Zhang, D. (2010). A completed modeling of local binary pattern operator\nfor texture classification. IEEE transactions on image processing , 19(6), 1657\u20131663.\nHabermann,M. (2018). Bandselectioninhyperspectralimagesusingartificialneuralnetworks .\n(Ph.D. thesis, Compi\u00e8gne).\nHabermann, M., Fremont, V. & Shiguemori, E. H. (2019). Supervised band selection in\nhyperspectral images using single-layer neural networks. International journal of remote\nsensing, 40(10), 3900\u20133926.", "doc_id": "623a1ac5-08c1-4cd9-93a2-b5574f3f459a", "embedding": null, "doc_hash": "a01fe05d163cdc5e498352a4bef7be8da72470ed6b1d966e666611bcd9107cfc", "extra_info": {"page_label": "132", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 2274, "end": 2954}, "relationships": {"1": "9250bf89-e8e5-45b4-8218-583043e12b34", "2": "69f738d7-1004-467d-9bee-16fc406a925a"}}, "__type__": "1"}, "42e84395-d2f6-43b5-ba85-baf020b56bb3": {"__data__": {"text": "133\nHafemann, L. G., Oliveira, L. S. & Cavalin, P. (2014). Forest species recognition using\ndeep convolutional neural networks. 2014 22nd International Conference on Pattern\nRecognition , pp. 1103\u20131107.\nHan, Z., Wei, B., Zheng, Y., Yin, Y., Li, K. & Li, S. (2017). Breast cancer multi-classification\nfrom histopathological images with structured deep learning model. Scientific reports ,\n7(1), 1\u201310.\nHao,H.,Wang,Q.,Li,P.&Zhang,L. (2016). Evaluationofgrounddistancesandfeaturesin\nEMD-based GMM matching for texture classification. Pattern Recognition , 57, 152\u2013163.\nHaralick, R. M. (1979). Statistical and structural approaches to texture. Proceedings of the\nIEEE, 67(5), 786\u2013804.\nHaralick, R. M., Shanmugam, K. & Dinstein, I. H. (1973). Textural features for image\nclassification. IEEE Transactions on systems, man, and cybernetics , (6), 610\u2013621.\nHazgui, M., Ghazouani, H. & Barhoumi, W. (2021). Genetic programming-based fusion of\nHOGandLBPfeaturesforfullyautomatedtextureclassification. TheVisualComputer ,\n37, 1\u201320. doi: 10.1007/s00371-020-02028-8.\nHe, K., Zhang, X., Ren, S. & Sun, J. (2016). Deep residual learning for image recognition.\nIEEE Conf Comp Vis Patt Recognit , pp. 770\u2013778.\nHeip, C. & Engels, P. (1974). Comparing species diversity and evenness indices. Journal of the\nMarine Biological Association of the United Kingdom , 54(3), 559\u2013563.\nI, I. F. & Sagi, D. (1989). Biological Cybernetics O Springer-Verlag 1989 Gabor Filters as\nTexture Discriminator.\nIzs\u00e1k, J. & Papp, L. (2000). A link between ecological diversity indices and measures of\nbiodiversity. Ecological Modelling , 130(1-3), 151\u2013156.\nIzs\u00e1ki,J.&Papp,L. (1995). Applicationofthequadraticentropyindicesfordiversitystudiesof\ndrosophilid assemblages. Environmental and Ecological Statistics , 2(3), 213\u2013224.\nJain,A.K.&Farrokhnia,F. (1990). UnsupervisedtexturesegmentationusingGaborfilters. 1990\nIEEE international conference on systems, man, and cybernetics conference proceedings ,\npp. 14\u201319.\nJain,A.K.,Duin,R.P.W.&Mao,J. (2000). Statisticalpatternrecognition: Areview. IEEE\nTransactions on pattern analysis and machine intelligence , 22(1), 4\u201337.\nJolion, J.-M. & Rosenfeld, A. (2012). A pyramid framework for early vision: multiresolutional\ncomputer vision . Springer Science & Business Media.\nJost,L. (2007). Partitioningdiversityintoindependentalphaandbetacomponents. Ecology,\n88(10), 2427\u20132439.\nJulesz, B. (1975). Experiments in the visual perception of texture. Scientific American , 232(4),\n34\u201343.\nJulesz,B. (1981). Textons,theelementsoftextureperception,andtheirinteractions. Nature,\n290(5802), 91\u201397.\nJunior, J. J. d. M. S. & Backes, A. R. (2016). ELM based signature for texture classification.\nPattern Recognition , 51, 395\u2013401.\nKalkan, H., Nap, M., Duin, R. P. & Loog, M. (2012). Automated classification of local patches\nin colon histopathology. 21st Int\u2019l Conf Patt Recogn (ICPR2012) , pp. 61\u201364.", "doc_id": "42e84395-d2f6-43b5-ba85-baf020b56bb3", "embedding": null, "doc_hash": "c5e7905de42094e6907af50909f0602ef6f9775f694d7da84341af525e2f8853", "extra_info": {"page_label": "133", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2887}, "relationships": {"1": "c5baf10d-9665-4bf5-a5d8-2f27d580add7"}}, "__type__": "1"}, "3eabcce0-2eb7-442e-a527-f189cb775b11": {"__data__": {"text": "134\nKannala,J.&Rahtu,E. (2012). Bsif: Binarizedstatisticalimagefeatures. 21stIntl.Conf.on\npattern recognition (ICPR2012) , pp. 1363\u20131366.\nKaplan, L. M. (1999). Extended fractal analysis for texture classification and segmentation.\nIEEE Transactions on Image Processing , 8(11), 1572\u20131585.\nKaru, K., Jain, A. K. & Bolle, R. M. (1996). Is there any texture in the image? Pattern\nRecognition , 29(9), 1437\u20131446.\nKather, J. N., Weis, C.-A., Bianconi, F., Melchers, S. M., Schad, L. R., Gaiser, T., Marx,\nA.&Z\u00f6llner,F.G. (2016a). Multi-classtextureanalysisincolorectalcancerhistology.\nScientific Reports , 6(1), 27988. doi: 10.1038/srep27988.\nKather, J. N., Weis, C.-A., Bianconi, F., Melchers, S. M., Schad, L. R., Gaiser, T., Marx,\nA.&Z\u00f6llner,F.G. (2016b). Multi-classtextureanalysisincolorectalcancerhistology.\nScientific reports , 6, 27988.\nKempton,R.&Taylor,L. (1976). Modelsandstatisticsforspeciesdiversity. Nature,262(5571),\n818\u2013820.\nKohavi,R.,John,G.H.etal. (1997). Wrappersforfeaturesubsetselection. Artificialintelligence ,\n97(1-2), 273\u2013324.\nKumar, V. & Minz, S. (2014). Feature selection: a literature review. SmartCR, 4(3), 211\u2013229.\nKuse,M.,Sharma,T.&Gupta,S. (2010). Aclassificationschemeforlymphocytesegmentation\nin H&E stained histology images. Lecture Notes in Computer Science , 6388 LNCS,\n235\u2013243. doi: 10.1007/978-3-642-17711-8_24.\nLarkin, L. I. & Burt, P. J. (1983). Multi-resolution texture energy measures. Proceedings in\nIEEE conference on computer vision and pattern recognition .\nLeo, P., Lee, G., Shih, N. N. C., Elliott, R., Feldman, M. D. & Madabhushi, A. (2016).\nEvaluating stability of histomorphometric features across scanner and staining variations:\nprostate cancer diagnosis from whole slide images. Journal of Medical Imaging , 3(4).\ndoi: 10.1117/1.JMI.3.4.047502.\nLevine, M. D. (1985). Vision in man and machine . McGraw-Hill College.\nLindeberg, T. (2013). Scale-space theory in computer vision . Springer Science & Business\nMedia.\nLiu,L.&Fieguth,P. (2012). Textureclassificationfromrandomfeatures. IEEEtransactionson\npattern analysis and machine intelligence , 34(3), 574\u2013586.\nLiu, L., Chen, J., Fieguth, P., Zhao, G., Chellappa, R. & Pietik\u00e4inen, M. (2019). From BoW\ntoCNN:Twodecadesoftexturerepresentationfortextureclassification. International\nJournal of Computer Vision , 127(1), 74\u2013109.\nLoew, M. H. (2000). Feature Extraction, chapter 5. SPIE, Belligham, WA, m. sonka and j.\nmichael fitzpatrick edition .\nLowe,D.G. (2004). Distinctiveimagefeaturesfromscale-invariantkeypoints. International\njournal of computer vision , 60(2), 91\u2013110.\nM\u00e4enp\u00e4\u00e4, T. & Pietik\u00e4inen, M. (2004). Classification with color and texture: jointly or\nseparately? Pattern Recognition , 37(8), 1629\u20131640.\nMagurran, A. (2004a). Measuring Biological", "doc_id": "3eabcce0-2eb7-442e-a527-f189cb775b11", "embedding": null, "doc_hash": "2641fc76b58c3090c3229b0e9ac046665fe24823931e07e209ac7808d7700941", "extra_info": {"page_label": "134", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2754}, "relationships": {"1": "7a491e80-de57-44ea-846e-98b192c24fe9", "3": "a8f37ab5-f4a5-4d5c-892e-636cb229e89f"}}, "__type__": "1"}, "a8f37ab5-f4a5-4d5c-892e-636cb229e89f": {"__data__": {"text": "R. & Pietik\u00e4inen, M. (2019). From BoW\ntoCNN:Twodecadesoftexturerepresentationfortextureclassification. International\nJournal of Computer Vision , 127(1), 74\u2013109.\nLoew, M. H. (2000). Feature Extraction, chapter 5. SPIE, Belligham, WA, m. sonka and j.\nmichael fitzpatrick edition .\nLowe,D.G. (2004). Distinctiveimagefeaturesfromscale-invariantkeypoints. International\njournal of computer vision , 60(2), 91\u2013110.\nM\u00e4enp\u00e4\u00e4, T. & Pietik\u00e4inen, M. (2004). Classification with color and texture: jointly or\nseparately? Pattern Recognition , 37(8), 1629\u20131640.\nMagurran, A. (2004a). Measuring Biological Diversity Blackwell Publishing. Malden, MA .\nMagurran, A. E. (1988). A variety of diversities. In Ecological Diversity and Its Measurement\n(pp. 81\u201399). Dordrecht: Springer Netherlands. doi: 10.1007/978-94-015-7358-0_5.", "doc_id": "a8f37ab5-f4a5-4d5c-892e-636cb229e89f", "embedding": null, "doc_hash": "ecdc504147012d9c1042436891b882e5eeb2aecc4860610f7d42c02aeb59f294", "extra_info": {"page_label": "134", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 2162, "end": 2973}, "relationships": {"1": "7a491e80-de57-44ea-846e-98b192c24fe9", "2": "3eabcce0-2eb7-442e-a527-f189cb775b11"}}, "__type__": "1"}, "51345c04-40f1-4950-ad46-934ef7cee709": {"__data__": {"text": "135\nMagurran, A. E. (2004b). Measuring biological diversity . John Wiley & Sons.\nMagurran, A. E. (2013). Measuring biological diversity . John Wiley & Sons.\nMallat, S. (1999). A wavelet tour of signal processing . Elsevier.\nMandelbrot,B. (1967). HowlongisthecoastofBritain? Statisticalself-similarityandfractional\ndimension. science, 156(3775), 636\u2013638.\nMasood,K.&Rajpoot,N. (2009). Texturebasedclassificationofhyperspectralcolonbiopsy\nsamples using CLBP. IEEE Int\u2019l Symp Biom Imag: From Nano to Macro , pp. 1011-1014.\ndoi: 10.1109/ISBI.2009.5193226.\nMaterka,A.,Strzelecki,M.etal. (1998). Textureanalysismethods\u2013areview. Technicaluniversity\nof lodz, institute of electronics, COST B11 report, Brussels , 10(1.97), 4968.\nMay, R., Cody, M. & Diamond, J. (1975). Ecology of Species and Communities.\nMcIntosh,R.P. (1967). Anindexofdiversityandtherelationofcertainconceptstodiversity.\nEcology, 48(3), 392\u2013404.\nMehta,R.&Egiazarian,K. (2014). Textureclassificationusingdensemicro-blockdifference\n(DMD).Asian Conference on Computer Vision , pp. 643\u2013658.\nMehta,R.&Egiazarian,K. (2016). Dominantrotatedlocalbinarypatterns(DRLBP)fortexture\nclassification. Pattern Recognition Letters , 71, 16\u201322.\nMitchell, T. M. (1982). Generalization as search. Artificial intelligence , 18(2), 203\u2013226.\nMolina,L.C.,Belanche,L.&Nebot,\u00c0. (2002). Featureselectionalgorithms: Asurveyand\nexperimental evaluation. 2002 IEEE International Conference on Data Mining, 2002.\nProceedings. , pp. 306\u2013313.\nMorris,E.K.,Caruso,T.,Buscot,F.,Fischer,M.,Hancock,C.,Maier,T.S.,Meiners,T.,M\u00fcller,\nC., Obermaier,E., Prati,D. etal. (2014). Choosing andusing diversity indices: insights\nfor ecological applications from the German Biodiversity Exploratories. Ecology and\nevolution, 4(18), 3514\u20133524.\nNadler, M. & Smith, E. P. (1993). Pattern recognition engineering . Wiley-interscience.\nNagasubramanian, K., Jones, S., Sarkar, S., Singh, A. K., Singh, A. & Ganapathysubramanian,\nB. (2018). Hyperspectral band selection using genetic algorithm and support vector\nmachines for early identification of charcoal rot disease in soybean stems. Plant methods ,\n14(1), 86.\nNaiyar, M.,Asim,Y.& Shahid,A. (2015). Automated coloncancer detectionusingstructural\nandmorphologicalfeatures. 201513thInt\u2019lConfFrontiersofInformationTechnology\n(FIT), pp. 240\u2013245.\nNapoletano, P. (2017). Hand-crafted vs learned descriptors for color texture classification. Intl\nWorkshop Comp Color Imaging , pp. 259\u2013271.\nNawaz,W.,Ahmed,S.,Tahir,A.&Khan,H.A. (2018). Classificationofbreastcancerhistology\nimages using alexnet. Int\u2019l Conf image analysis and recognition , pp. 869\u2013876.\nNguyen, T. P., Vu, N.-S. & Manzanera, A. (2016). Statistical binary patterns for rotational\ninvariant texture classification. Neurocomputing , 173, 1565\u20131577.\nNsimba, C. B. & Levada,", "doc_id": "51345c04-40f1-4950-ad46-934ef7cee709", "embedding": null, "doc_hash": "a98a8fc390d8e2c1c1c4a06788c7015ff816f5f9b66d9886ea963bd273ff8b71", "extra_info": {"page_label": "135", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2784}, "relationships": {"1": "ac953e25-4f59-4195-b1f4-4e3245bae1ec", "3": "7d577519-c78c-4c12-a813-13947b79fe77"}}, "__type__": "1"}, "7d577519-c78c-4c12-a813-13947b79fe77": {"__data__": {"text": "201513thInt\u2019lConfFrontiersofInformationTechnology\n(FIT), pp. 240\u2013245.\nNapoletano, P. (2017). Hand-crafted vs learned descriptors for color texture classification. Intl\nWorkshop Comp Color Imaging , pp. 259\u2013271.\nNawaz,W.,Ahmed,S.,Tahir,A.&Khan,H.A. (2018). Classificationofbreastcancerhistology\nimages using alexnet. Int\u2019l Conf image analysis and recognition , pp. 869\u2013876.\nNguyen, T. P., Vu, N.-S. & Manzanera, A. (2016). Statistical binary patterns for rotational\ninvariant texture classification. Neurocomputing , 173, 1565\u20131577.\nNsimba, C. B. & Levada, A. (2019). An information-theoretic wavelet-based texture descriptor\nusing Gaussian Markov random field models. Multimedia Tools and Applications .\ndoi: 10.1007/s11042-019-07916-3.", "doc_id": "7d577519-c78c-4c12-a813-13947b79fe77", "embedding": null, "doc_hash": "0e49ab5acf4dc204fea86b685c9527a2978b2fcefa38dd9acbea8d79b23ee484", "extra_info": {"page_label": "135", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 2229, "end": 2965}, "relationships": {"1": "ac953e25-4f59-4195-b1f4-4e3245bae1ec", "2": "51345c04-40f1-4950-ad46-934ef7cee709"}}, "__type__": "1"}, "27726a85-cc2a-4e54-afe4-0d1009faf7b9": {"__data__": {"text": "136\nNsimba,C. B.&Levada, A.L. (2020a). ExploringInformation TheoryandGaussian Markov\nRandom Fields for Color Texture Classification. International Conference on Image\nAnalysis and Recognition , pp. 130\u2013143.\nNsimba, C. B. & Levada, A. L. (2020b). Exploring Information Theory and Gaussian Markov\nRandom Fields for Color Texture Classification. International Conference on Image\nAnalysis and Recognition , pp. 130\u2013143.\nOjansivu, V. & Heikkil\u00e4, J. (2008). Blur insensitive texture classification using local phase\nquantization. Intl. Conf. on image and signal processing , pp. 236\u2013243.\nOliveira, H. (2007). An\u00e1lise de fourier e wavelets: sinais estacion\u00e1rios e n\u00e3o estacion\u00e1rios.\nEditora Universit\u00e1ria da UFPE .\nPavoine, S., Ollier, S. & Dufour, A.-B. (2005). Is the originality of a species measurable?\nEcology Letters , 8(6), 579\u2013586.\nPetrou, M. M. & Sevilla, P. G. (2006). Image processing: dealing with texture . Wiley.\nPham, T. D. (2017). Scaling of texture in training autoencoders for classification of histological\nimages of colorectal cancer. International Symposium on Neural Networks , pp. 524\u2013532.\nPianka, E. R. (2011). Evolutionary ecology . Eric R. Pianka.\nPietik\u00e4inen, M., Hadid, A., Zhao, G. & Ahonen, T. (2011). Computer vision using local binary\npatterns. Springer Science & Business Media.\nPolesel,A.,Ramponi,G.&Mathews,V.J. (2000). Imageenhancementviaadaptiveunsharp\nmasking. IEEE transactions on image processing , 9(3), 505\u2013510.\nQi, X., Qiao, Y., Li, C.-G. & Guo, J. (2013). Exploring cross-channel texture correlation for\ncolor texture classification.\nQiu,Q.,Thompson,A.&Calderbank,R. (2015). DataRepresentationUsingtheWeylTransform.\nIEEE Transactions on Signal Processing , 64(7), 1844\u20131853.\nQuan,Y.,Xu,Y.&Sun,Y. (2014). Adistinctandcompacttexturedescriptor. ImageandVision\nComputing , 32(4), 250\u2013259.\nRaczkowski,\u0141.,Mo\u017cejko,M.,Zambonelli,J.&Szczurek,E. (2019). ARA:accurate,reliable\nand active histopathological image classification framework with Bayesian deep learning.\nScientific reports , 9(1), 1\u201312.\nRao,A.R. (2012). Ataxonomyfortexturedescriptionandidentification . SpringerScience&\nBusiness Media.\nRao, C. R. (1982). Diversity and dissimilarity coefficients: a unified approach. Theoretical\npopulation biology , 21(1), 24\u201343.\nRathore,S.,Iftikhar,M.A.,Hussain,M.&Jalil,A. (2013). Classificationofcolonbiopsyimages\nbased on novel structural features. 2013 IEEE 9th Int\u2019l Conf Emerging Technologies\n(ICET), pp. 1\u20136.\nReis, S., Gazinska, P., Hipwell, J. H., Mertzanidou, T., Naidoo, K., Williams, N., Pinder,\nS. & Hawkes, D. J. (2017). Automated Classification of Breast Cancer Stroma Maturity\nfrom Histological Images. IEEE Transactions on Biomedical Engineering , 64(10),\n2344\u20132352. doi: 10.1109/TBME.2017.2665602.\nRemeseiro,B.&Bolon-Canedo,V. (2019). Areviewoffeatureselectionmethodsinmedical\napplications. Computers in biology and medicine , 112, 103375.", "doc_id": "27726a85-cc2a-4e54-afe4-0d1009faf7b9", "embedding": null, "doc_hash": "aa93e9c5face1a126c947b2371c9e3bb16111baf97741814403b47ec18c1ff00", "extra_info": {"page_label": "136", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2881}, "relationships": {"1": "3917df98-f96d-4352-8eff-7fb82f2243a2"}}, "__type__": "1"}, "65892269-f76d-4883-8164-b2c8ff12d8c1": {"__data__": {"text": "137\nRibeiro,M.G.,Neves,L.A.,doNascimento,M.Z.,Roberto,G.F.,Martins,A.S.&Tosta,T.A.A.\n(2019). Classification of colorectal cancer based on the association of multidimensional\nand multiresolution features. Expert Systems with Applications , 120, 262\u2013278.\nRicotta, C. (2002). Bridging the gap between ecological diversity indices and measures of\nbiodiversity with Shannon\u2019s entropy: comment to Izs\u00e1k and Papp. Ecological Modelling ,\n152(1), 1\u20133.\nRicotta, C. (2004). A parametric diversity measure combining the relative abundances and\ntaxonomic distinctiveness of species. Diversity and Distributions , 10(2), 143\u2013146.\nRogers, S. I., Clarke, K. R. & Reynolds, J. D. (1999). The taxonomic distinctness of coastal\nbottom-dwelling fish communities of the North-east Atlantic. Journal of Animal Ecology ,\n68(4), 769\u2013782.\nRousseau, R., Van Hecke, P., NIjssen, D. & Bogaert, J. (1999a). The relationship between\ndiversityprofiles,evennessandspeciesrichnessbasedonpartialordering. Environmental\nand Ecological Statistics , 6(2), 211\u2013223.\nRousseau, R., Van Hecke, P., NIjssen, D. & Bogaert, J. (1999b). The relationship between\ndiversityprofiles,evennessandspeciesrichnessbasedonpartialordering. Environmental\nand Ecological Statistics , 6(2), 211\u2013223.\nSaqui, D., Saito, J. H., De Lima, D. C., Cura, L. M. D. V. & Ataky, S. T. M. (2019).\nIncorporatedDecision-maker-basedMultiobjectiveBandSelectionforPixelClassification\nof Hyperspectral Images. Advances in Electrical and Computer Engineering , 19(4),\n21\u201328.\nSarkar, R. & Acton, S. T. (2017). Sdl: Saliency-based dictionary learning framework for image\nsimilarity. IEEE Transactions on Image Processing , 27(2), 749\u2013763.\nSaxena,J.,Teckchandani,K.,Pandey,P.,Dutta,M.K.,Travieso,C.M.,Alonso-Hern\u00e1ndez,J.B.\net al. (2015). Palm vein recognition using local tetra patterns. 2015 4th International\nWork Conference on Bioinspired Intelligence (IWOBI) , pp. 151\u2013156.\nSDR-IV. (2020). Species Diversity and Richness 4.\nShahana, A. & Preeja, V. (2016). Survey on feature subset selection for high dimensional data.\n2016InternationalConferenceonCircuit,PowerandComputingTechnologies(ICCPCT) ,\npp. 1\u20134.\nShannon,C.E. (1948). Amathematicaltheoryofcommunication. Bellsystemtechnicaljournal ,\n27(3), 379\u2013423.\nShimadzu,H.,Dornelas,M.,Henderson,P.A.&Magurran,A.E. (2013). Diversityismaintained\nby seasonal variation in species abundance. BMC Biology , 11(1), 98.\nSimon, P. &Uma, V. (2018a). Reviewoftexture descriptorsfortexture classification. In Data\nEngineering and Intelligent Computing (pp. 159\u2013176). Springer.\nSimon, P. & Uma, V. (2018b). Review of texture descriptors for texture classification. In Data\nEngineering and Intelligent Computing (pp. 159\u2013176). Springer.\nSingh, A., Sunkaria, R. K. & Kaur, A. (2022). A Review on Local Binary Pattern Variants.\nProceedings of First International Conference on Computational Electronics for Wireless\nCommunications , pp. 545\u2013552.\nSohier, C. (2019). Measurements of", "doc_id": "65892269-f76d-4883-8164-b2c8ff12d8c1", "embedding": null, "doc_hash": "6d2fed80090d391c456fa80d3ad1cbccbf5cfaca9b3b1ae083dfe0ce63e98a55", "extra_info": {"page_label": "137", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2935}, "relationships": {"1": "771dd9c8-b8c0-4789-bbe6-982a3ebe19f5", "3": "c8aee3e3-ae3e-430f-8ec9-11c6a48d38f9"}}, "__type__": "1"}, "c8aee3e3-ae3e-430f-8ec9-11c6a48d38f9": {"__data__": {"text": "(2013). Diversityismaintained\nby seasonal variation in species abundance. BMC Biology , 11(1), 98.\nSimon, P. &Uma, V. (2018a). Reviewoftexture descriptorsfortexture classification. In Data\nEngineering and Intelligent Computing (pp. 159\u2013176). Springer.\nSimon, P. & Uma, V. (2018b). Review of texture descriptors for texture classification. In Data\nEngineering and Intelligent Computing (pp. 159\u2013176). Springer.\nSingh, A., Sunkaria, R. K. & Kaur, A. (2022). A Review on Local Binary Pattern Variants.\nProceedings of First International Conference on Computational Electronics for Wireless\nCommunications , pp. 545\u2013552.\nSohier, C. (2019). Measurements of biodiversity.", "doc_id": "c8aee3e3-ae3e-430f-8ec9-11c6a48d38f9", "embedding": null, "doc_hash": "1ee639bb1226f6c05d05f42e85ce525345a2e6527a6f4cbb02a23072d1e8f21f", "extra_info": {"page_label": "137", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 2284, "end": 2949}, "relationships": {"1": "771dd9c8-b8c0-4789-bbe6-982a3ebe19f5", "2": "65892269-f76d-4883-8164-b2c8ff12d8c1"}}, "__type__": "1"}, "834f9bf8-e160-4733-b7ec-eb9d1f91cf02": {"__data__": {"text": "138\nSolow, A., Polasky, S. & Broadus, J. (1993). On the measurement of biological diversity.\nJournal of Environmental Economics and Management , 24(1), 60\u201368.\nSolow, A. R. & Polasky, S. (1994). Measuring biological diversity. Environmental and\nEcological Statistics , 1(2), 95\u2013103.\nSonka, M., Hlavac, V. & Boyle, R. (2014). Image processing, analysis, and machine vision .\nCengage Learning.\nSpanhol, F. A., Oliveira, L. S., Petitjean, C. & Heutte, L. (2016a). A Dataset for Breast Cancer\nHistopathological Image Classification. IEEE Transactions on Biomedical Engineering ,\n63(7), 1455\u20131462. doi: 10.1109/TBME.2015.2496264.\nSpanhol,F.A.,Oliveira,L.S.,Petitjean,C.&Heutte,L. (2016b). Breastcancerhistopathological\nimage classification using convolutional neural networks. 2016 international joint\nconference on neural networks (\u0132CNN) , pp. 2560\u20132567.\nStuden`y, M. & Vejnarov\u00e1, J. (1998). The multiinformation function as a tool for measuring\nstochastic dependence. In Learning in graphical models (pp. 261\u2013297). Springer.\nTobias,O.J.,Seara,R.,Soares,F.A.&Bermudez,J.C. (1995). Automaticvisualinspection\nusing the co-occurrence approach. 38th Midwest Symposium on Circuits and Systems.\nProceedings , 1, 154\u2013157.\nTraina, A. J. M. (2001). Suporte \u00e0 visualiza\u00e7\u00e3o de consultas por similaridade em imagens\nm\u00e9dicas atrav\u00e9s de estrutura de indexa\u00e7\u00e3o m\u00e9trica . (Ph.D. thesis, ICMC/USP).\nTuceryan,M.&Jain,A.K. (1993). Textureanalysis. In Handbookofpatternrecognitionand\ncomputer vision (pp. 235\u2013276). World Scientific.\nTuv, E., Borisov, A., Runger, G. & Torkkola, K. (2009). Feature selection with ensembles,\nartificial variables, and redundancy elimination. The Journal of Machine Learning\nResearch, 10, 1341\u20131366.\nvan der Laan, M. J., Polley, E. C. & Hubbard, A. E. (2007). Super Learner. Statistical\nApplications in Genetics and Molecular Biology , 6(1). doi: doi:10.2202/1544-6115.1309.\nVandamme, P., Pot, B., Gillis, M., De Vos, P., Kersters, K. & Swings, J. (1996). Polyphasic\ntaxonomy, a consensus approach to bacterial systematics. Microbiological reviews , 60(2),\n407\u2013438.\nVane-Wright, R. I., Humphries, C. J. & Williams, P. H. (1991). What to protect?\u2014Systematics\nand the agony of choice. Biological conservation , 55(3), 235\u2013254.\nVellend, M., Cornwell, W. K., Magnuson-Ford, K. & Mooers, A. \u00d8. (2011). Measuring\nphylogenetic biodiversity. Biological diversity: frontiers in measurement and assessment.\nOxford University Press, Oxford , 194\u2013207.\nVenkatesh,B.&Anuradha,J. (2019). Areviewoffeatureselectionanditsmethods. Cybernetics\nand information technologies , 19(1), 3\u201326.\nVriesman, D., Britto Junior, A. S., Zimmer, A. & Koerich, A. L. (2019). Texture CNN for\nThermoelectric Metal Pipe Image Classification. IEEE 31st Int\u2019l Conf on Tools with\nArtificial Intelligence , pp. 569-574. doi:", "doc_id": "834f9bf8-e160-4733-b7ec-eb9d1f91cf02", "embedding": null, "doc_hash": "c2236199044a33e7f1536b40bc0a6361feb43fcc967573b975a56405465229ae", "extra_info": {"page_label": "138", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2788}, "relationships": {"1": "0c81ed7e-896b-440c-9383-b8db8d366070", "3": "f679c6e4-f749-4e4f-ab2c-21eca1ba6a16"}}, "__type__": "1"}, "f679c6e4-f749-4e4f-ab2c-21eca1ba6a16": {"__data__": {"text": "M., Cornwell, W. K., Magnuson-Ford, K. & Mooers, A. \u00d8. (2011). Measuring\nphylogenetic biodiversity. Biological diversity: frontiers in measurement and assessment.\nOxford University Press, Oxford , 194\u2013207.\nVenkatesh,B.&Anuradha,J. (2019). Areviewoffeatureselectionanditsmethods. Cybernetics\nand information technologies , 19(1), 3\u201326.\nVriesman, D., Britto Junior, A. S., Zimmer, A. & Koerich, A. L. (2019). Texture CNN for\nThermoelectric Metal Pipe Image Classification. IEEE 31st Int\u2019l Conf on Tools with\nArtificial Intelligence , pp. 569-574. doi: 10.1109/ICTAI.2019.00085.\nWagner, B. D., Grunwald, G. K., Zerbe, G. O., Mikulich-Gilbertson, S. K., Robertson,\nC. E., Zemanick, E. T. & Harris, J. K. (2018). On the Use of Diversity Measures in\nLongitudinal SequencingStudies of Microbial Communities. Frontiersin Microbiology ,\n9. doi: 10.3389/fmicb.2018.01037.", "doc_id": "f679c6e4-f749-4e4f-ab2c-21eca1ba6a16", "embedding": null, "doc_hash": "5e037a2150d83402f2e2217d407ecf04ffbf271a8aa1c41e6dddd2a5d92ba000", "extra_info": {"page_label": "138", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 2239, "end": 3100}, "relationships": {"1": "0c81ed7e-896b-440c-9383-b8db8d366070", "2": "834f9bf8-e160-4733-b7ec-eb9d1f91cf02"}}, "__type__": "1"}, "a4341c63-d8a9-4f2c-be10-63349ab38d99": {"__data__": {"text": "139\nWang, C., Shi, J., Zhang, Q. & Ying, S. (2017). Histopathological image classification with\nbilinear convolutional neural networks. 39th Annual Intl. Conf. of the IEEE Engineering\nin Medicine and Biology Society (EMBC) , pp. 4050\u20134053.\nWang,H.,Li,Z.,Li,Y.,Gupta,B.&Choi,C. (2020). Visualsaliencyguidedcompleximage\nretrieval. Pattern Recognition Letters , 130, 64\u201372.\nWang, K., Bichot, C.-E., Zhu, C. & Li, B. (2013). Pixel to patch sampling structure and\nlocalneighboringintensityrelationshippatternsfortextureclassification. IEEESignal\nProcessing Letters , 20(9), 853\u2013856.\nWang, Y., Zhao, Y., Cai, Q., Li, H. & Yan, H. (2016). A varied local edge pattern descriptor\nandits applicationtotexture classification. Journalof visualcommunicationand image\nrepresentation , 34, 108\u2013117.\nWatanabe, S. (1960). Information theoretical analysis of multivariate correlation. IBM Journal\nof research and development , 4(1), 66\u201382.\nWhittaker, R. H. (1972). Evolution and measurement of species diversity. Taxon, 21(2-3),\n213\u2013251.\nXie, F., Li, F., Lei,C. & Ke, L. (2018). Representative band selectionfor hyperspectral image\nclassification. ISPRS International Journal of Geo-Information , 7(9), 338.\nXu, X., Shi, Z. & Pan, B. (2017). A new unsupervised hyperspectral band selection method\nbased on multiobjective optimization. IEEE Geoscience and Remote Sensing Letters ,\n14(11), 2112\u20132116.\nXu,Y.,Yang,X.,Ling,H.&Ji,H. (2010). Anewtexturedescriptorusingmultifractalanalysisin\nmulti-orientationwaveletpyramid. 2010IEEEComputerSocietyConferenceonComputer\nVision and Pattern Recognition , pp. 161\u2013168.\nZhang, J. & Tan, T. (2002). Brief review of invariant texture analysis methods. Pattern\nrecognition , 35(3), 735\u2013747.\nZhang, J., Zhao, H. & Liang, J. (2013). Continuous rotation invariant local descriptors for\ntextondictionary-basedtextureclassification. ComputerVisionandImageUnderstanding ,\n117(1), 56\u201375.\nZhang,L.,Zhou, Z.&Li,H. (2012). Binary gaborpattern: Anefficientandrobustdescriptor\nfor texture classification. 2012 19Th IEEE international conference on image processing ,\npp. 81\u201384.\nZhang, S., Wang, H., Huang, W. & Zhang, C. (2018). Combining modified LBP and weighted\nSRC for palmprint recognition. Signal, Image and Video Processing , 12(6), 1035\u20131042.\nZhao,Y.,Zhang,L.,Li,P.&Huang,B. (2007). Classificationofhighspatialresolutionimagery\nusingimprovedGaussianMarkovrandom-field-basedtexturefeatures. IEEETransactions\non Geoscience and Remote Sensing , 45(5), 1458\u20131468.\nZhuo, L., Zheng, J., Li, X., Wang, F., Ai, B. & Qian, J. (2008). A genetic algorithm based\nwrapper feature selection method for classification of hyperspectral images using support\nvectormachine. Geoinformatics2008andJointConferenceonGISandBuiltEnvironment:\nClassification of Remote Sensing Images , 7147, 71471J.", "doc_id": "a4341c63-d8a9-4f2c-be10-63349ab38d99", "embedding": null, "doc_hash": "4ad10661894e7ae4eb6ca0ebeb9875e014864dfaf4836bbd5cb18da0823a3c98", "extra_info": {"page_label": "139", "file_name": "ATAS04088704-These-Version-Finale.pdf"}, "node_info": {"start": 0, "end": 2785}, "relationships": {"1": "0a7fc0c8-617f-4fb6-95dd-5ad9e5e07fe9"}}, "__type__": "1"}, "76034520-14fb-45da-ae44-8b5026f17c86": {"__data__": {"text": "  \n \n \n \n \n \nSix cas d\u2019u tilisation de l\u2019intelligence artificielle dans \nle secteur public  \n \n \nNote de recherche  \n \n \nMarie -Christine Therrien, Joris Arnaud,  Clara El Mestikawy, Julie -Maude \nNormandin,  Genevi\u00e8ve Baril, Steve Jacob, Julien Laumonier et Justin \nLawar\u00e9e  \n \n \n \n \n \nMandat r\u00e9alis\u00e9 pour le Secr\u00e9tariat du Conseil du tr\u00e9sor  \nJanvier 2020 \n \n \n  \n", "doc_id": "76034520-14fb-45da-ae44-8b5026f17c86", "embedding": null, "doc_hash": "3e5806fb27629601766da6790d5b42f56e06932eedb38f6ada161aef558624ed", "extra_info": {"page_label": "1", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 366}, "relationships": {"1": "0147b684-fa8d-4b76-9371-e78ae0bb40fe"}}, "__type__": "1"}, "db0e4b4e-b61e-4a6b-89cc-037aac153fe4": {"__data__": {"text": " \n \nII \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nObservatoire international sur les  \nimpacts soci\u00e9taux de l\u2019intelligence artificielle  et du num\u00e9rique  \nPavillon Charles -De Koninck, local 2489  \n1030, avenue des Sciences -Humaines  \nUniversit\u00e9 Laval  \nQu\u00e9bec (Qu\u00e9bec) G1V 0A6  \nobservatoireia@ulaval.ca \nobservatoire -ia.ulaval.ca  \n \nISBN  : 978- 2-925138 -13-6 \n  \n", "doc_id": "db0e4b4e-b61e-4a6b-89cc-037aac153fe4", "embedding": null, "doc_hash": "06f69445cb925b362f3b7604f96a4952a1b1ddcd038233ce70db02925fc7c64e", "extra_info": {"page_label": "2", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 367}, "relationships": {"1": "346ea302-ec2a-479b-92d2-09b7b5d4b968"}}, "__type__": "1"}, "fc667658-355c-4ba0-8cc6-56bff314bd2c": {"__data__": {"text": " \n \nIII \n L\u2019Observatoire international sur les impacts soci\u00e9taux de l\u2019intelligence artificielle et du \nnum\u00e9rique  (OBVIA)   \nL\u2019OBVIA est un r\u00e9seau de recherche ouvert qui contribue aux r\u00e9flexions entourant l\u2019utilisation \nresponsable de l\u2019IA et du num\u00e9rique en favorisant les discussions et le maillage entre les \ncommunaut\u00e9s de pratique, la soci\u00e9t\u00e9 civile et les d\u00e9cideurs publics.  Soutenu financi\u00e8rement par \nles Fonds de recherche du Qu\u00e9bec (FRQ), il f\u00e9d\u00e8re les expertises de plus de 260 chercheur\u00b7es \ncouvrant les secteurs des sciences humaines et sociales, des sciences et g\u00e9nie et de la sant\u00e9. Il \nb\u00e9n\u00e9ficie \u00e9galement de l\u2019appui de plu s de 125 partenaires issus de centres de recherche et \nd\u2019organisations publiques et priv\u00e9es du Qu\u00e9bec, du Canada et de l'\u00e9tranger.  \n \nSon objectif est de mettre en lumi\u00e8re les enjeux cruciaux soulev\u00e9s par les d\u00e9veloppements et \nl'utilisation de l\u2019IA et du num \u00e9rique et d\u2019identifier des solutions plausibles aux probl\u00e8mes et \nopportunit\u00e9s qu\u2019ils soul\u00e8vent.   \n \nL\u2019OBVIA r\u00e9alise des travaux de recherche et des mandats d'intervention en partenariat en vue \nde d\u00e9velopper de nouvelles connaissances, de les diffuser et d\u2019a ider les organisations \nqu\u00e9b\u00e9coises \u00e0 maximiser les impacts positifs du num\u00e9rique et de l\u2019IA dans nos soci\u00e9t\u00e9s. Ces \ntravaux sont prioris\u00e9s en fonction des orientations scientifiques de l\u2019OBVIA et visent \u00e0 r\u00e9pondre \n\u00e0 la fois aux objectifs des partenaires et des \u00e9quipes de recherche impliqu\u00e9es. Ils peuvent \nprendre plusieurs formes, comme des \u00e9tudes sur le terrain, des synth\u00e8ses et analyses de la \nlitt\u00e9rature, la conception d\u2019ateliers ainsi que le soutien dans l\u2019\u00e9laboration, l\u2019adoption et la mise \nen \u0153uvre de bon nes pratiques en mati\u00e8re d\u2019enjeux touchants \u00e0 l\u2019IA et au num\u00e9rique.  \n  \n  ", "doc_id": "fc667658-355c-4ba0-8cc6-56bff314bd2c", "embedding": null, "doc_hash": "829e7b2306f2cbad62de5b7703fc2708f9c6bff783d52c6bbc5554e3bcab48bd", "extra_info": {"page_label": "3", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 1758}, "relationships": {"1": "dd71b54f-dedb-40d7-8637-9a4d11da00f0"}}, "__type__": "1"}, "83da7a1d-779e-40b8-9082-257ef964ed62": {"__data__": {"text": " \n \nIV \n Table des mati\u00e8res  \n \nIntroduction et note m\u00e9thodologique  ............................................................................................ 1 \nLe cas du Royaume -Uni ................................................................................................................... 3 \nLes faits sa illants  .......................................................................................................................... 3 \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  ............................................................ 3 \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  ......................... 5 \nFacteurs habilitants et contraignants  .......................................................................................... 7 \nPratiques inspirantes  ................................................................................................................... 8 \nLe cas de la France  ......................................................................................................................... 10 \nLes faits saillants  ........................................................................................................................ 10 \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  .......................................................... 10 \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  ....................... 12 \nFacteurs habilitants  et contraignants  ........................................................................................ 15 \nPratiques inspirantes  ................................................................................................................. 16 \nLe cas de l\u2019Allemagne  .................................................................................................................... 17 \nLes faits sa illants  ........................................................................................................................ 17 \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  .......................................................... 17 \nCas concrets d\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  ........................... 19 \nFacteurs habilitants et contraignants  ........................................................................................ 20 \nPratiques inspirantes  ................................................................................................................. 21 \nLe cas d\u2019Isra\u00ebl  ................................................................................................................................ 23 \nLes faits saillants  ........................................................................................................................ 23 \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  .......................................................... 23 \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  ....................... 25 \nFacteurs habilitants et contraignants  ........................................................................................ 26 \nPratiques inspirantes  ................................................................................................................. 27 \nLe cas des \u00c9tats -Unis  ..................................................................................................................... 28 \nLes faits saillants  ........................................................................................................................ 28 \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  .......................................................... 28 \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  ....................... 30 \nFacteurs habilitants et contraignants  ........................................................................................ 32 \nPratiques inspirantes  ................................................................................................................. 32 ", "doc_id": "83da7a1d-779e-40b8-9082-257ef964ed62", "embedding": null, "doc_hash": "67c77925ef47ee92da68a79cdbec1dafc5d52d2ac21ca8645aab373947d7ed75", "extra_info": {"page_label": "4", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 4182}, "relationships": {"1": "67dd0e73-fd09-47e6-975d-75e78c23823b"}}, "__type__": "1"}, "a3389426-7f66-458d-a58d-6b4652a5d7c2": {"__data__": {"text": " \n \nV \n Le cas de Singapour  ....................................................................................................................... 33 \nLes faits saillants  ........................................................................................................................ 33 \nChronologie de  l\u2019int\u00e9gration de l\u2019intelligence artificielle  .......................................................... 33 \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  ....................... 34 \nFacteurs habilitants et contraignants  ........................................................................................ 35 \nPratiques inspirantes  ................................................................................................................. 35 \nListe des r\u00e9 f\u00e9rences et documents consult\u00e9s  ............................................................................... 36 \nNote sur le Royaume -Uni .......................................................................................................... 36 \nNote sur la France  ..................................................................................................................... 38 \nNote sur l\u2019Allemagne  ................................................................................................................. 40 \nNote sur Isr a\u00ebl ........................................................................................................................... 42 \nNote sur les \u00c9tats -Unis  .............................................................................................................. 44 \nNote sur Singapour  .................................................................................................................... 46 \n ", "doc_id": "a3389426-7f66-458d-a58d-6b4652a5d7c2", "embedding": null, "doc_hash": "51e83cfeeddb92092a7026500a50bd2e1e140cdf36e12d71efbae13b4279e446", "extra_info": {"page_label": "5", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 1786}, "relationships": {"1": "703cb1d0-bec8-47fb-bc07-be5d39a78105"}}, "__type__": "1"}, "8ea884c5-e2b9-4db6-97e6-3eed7bc92b0a": {"__data__": {"text": " \n \n1 \n Introduction et note m\u00e9thodologique  \n\u00c0 la demande du Secr\u00e9tariat du Conseil du t r\u00e9sor, nous avons r\u00e9alis\u00e9  six notes correspondant \u00e0 \nsix cas d\u2019utilisation de l\u2019intelligence artificielle dans le secteur public. Nous avons r\u00e9dig\u00e9 des notes1 \nsur le Royaume -Uni, la France, l\u2019Allemagne, Isra\u00ebl, les \u00c9tats -Unis d\u2019Am\u00e9rique  et Singapour . Ces cas \nont \u00e9t\u00e9 choisi s en fonction de leur place dans le \u00ab  Government Artificial Intelligence Readiness \nIndex 2019  \u00bb et en fonction de la documentation accessible publiquement  sur ces pays .  \nPour chaque cas, nous avons recherch\u00e9 l\u2019info rmation dans les documents publi cs, qu\u2019il s\u2019agisse de \ndocuments publi\u00e9s par les gouvernements ou des organismes faisant la promotion ou \ns\u2019int\u00e9ressant \u00e0 l\u2019Intelligence a rtificielle. Nous avons \u00e9galement effectu\u00e9 des recherches dans la \nlitt\u00e9rature scientifiq ue, bien que ceci ait \u00e9t\u00e9 moins concluant compte tenu de la nouve aut\u00e9 de cet \nenjeu . L\u2019information disponible \u00e9tant diff\u00e9rente d\u2019un pays \u00e0 l\u2019autre, ceci explique une certaine \ndisparit\u00e9  entre les notes. Nos r\u00e9sultats varient donc en fonction des contextes na tionaux, du degr\u00e9 \nd\u2019int\u00e9gration de l\u2019IA dans le secteur public des diff\u00e9rents pays, du niveau de publicisation et de \ntransparence des initiatives.  \nAvec la documentation disponible, nous avons \u00e9t\u00e9 en mesure  de pr\u00e9senter chaque cas en cinq  \nsections  :  \n1. Dans la section faits saillant s, nous faisons ressor tir les \u00e9l\u00e9ments les plus importants du \ncas.   \n2. Dans la section chronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle , nous pr\u00e9sentons \nla chronologie de la prise en consid\u00e9ration  de l\u2019intelligence artific ielle dans les politiques \npubliques de chaque pays , notamment \u00e0 travers divers \u00e9v\u00e9nements et publications . Dans \nla mesure des informations disponibles publiquement, nous a pportons un \n\u00e9claircissement sur la raison d\u2019\u00eatre de ces publications,  les strat\u00e9gie s sous -jacente s ainsi \nque les structures gouvernementales (minist\u00e8res ou organismes) auxquelles elles sont \nrattach\u00e9es.  \n3. Nous pr\u00e9sentons dans la section cas concrets de l\u2019utilisation de l\u2019intelligence artificielle \ndans le secteur public  quelques ini tiatives men\u00e9es dans chaque pays  pour int\u00e9grer l\u2019IA \ndans des minist\u00e8res ou organismes publics. Nous pr\u00e9sentons ces initiatives et , en fonction \ndes donn\u00e9es publiques , nous pr\u00e9sentons leurs objectifs, les minist\u00e8res et organismes \nauxquelles elles sont rattac h\u00e9es, mais \u00e9galement le type de probl\u00e8me, d\u2019usage ou \nd\u2019utilisation de l\u2019intelligence ar tificielle dont il s\u2019agit. Les  donn\u00e9es disponible s \u00e9tant \nlimit\u00e9es , il n\u2019a pas toujours \u00e9t\u00e9 possible de trouver des d\u00e9tails sur les initiatives ou sur  \nleur mise en \u0153uvre.  \n4. Dans la section f acteurs habilitants et contraignants , nous identifions les facteurs \nhabilitants et les freins \u00e0 l\u2019introduction de l\u2019intelligence", "doc_id": "8ea884c5-e2b9-4db6-97e6-3eed7bc92b0a", "embedding": null, "doc_hash": "6df0601d42d7354abf6aafbe914d9103378f2d966947299a1287dd525617dbc7", "extra_info": {"page_label": "6", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2852}, "relationships": {"1": "487bbe43-398d-4e75-b7ed-4fc19c77b6ba", "3": "b49b9a95-9750-4c44-964c-83e201ef199d"}}, "__type__": "1"}, "b49b9a95-9750-4c44-964c-83e201ef199d": {"__data__": {"text": "fonction \ndes donn\u00e9es publiques , nous pr\u00e9sentons leurs objectifs, les minist\u00e8res et organismes \nauxquelles elles sont rattac h\u00e9es, mais \u00e9galement le type de probl\u00e8me, d\u2019usage ou \nd\u2019utilisation de l\u2019intelligence ar tificielle dont il s\u2019agit. Les  donn\u00e9es disponible s \u00e9tant \nlimit\u00e9es , il n\u2019a pas toujours \u00e9t\u00e9 possible de trouver des d\u00e9tails sur les initiatives ou sur  \nleur mise en \u0153uvre.  \n4. Dans la section f acteurs habilitants et contraignants , nous identifions les facteurs \nhabilitants et les freins \u00e0 l\u2019introduction de l\u2019intelligence artificielle dans le secteur public. \nComme nous l\u2019avons vu, les initiatives sont cependant r\u00e9centes et la doc umentation peu \nabondante dans ce domaine. Les informations \u00e0 ce sujet sont pr\u00e9liminaires et devraient \nse pr\u00e9ciser avec la publication future d\u2019\u00e9tudes de cas r\u00e9alis\u00e9es au sein des administrations \n                                                           \n1 Ces notes ont \u00e9t\u00e9 \u00e9labor\u00e9es \u00e0 l\u2019automne 2019 et \u00e0 l\u2019hiver 2020. Les notes  pour chaque cas  ont dans un \npremier temps \u00e9t\u00e9 transmises au Secr\u00e9tariat du Conseil du t r\u00e9sor. Nous les rassemblons ici dans un m\u00eame \ndocument . ", "doc_id": "b49b9a95-9750-4c44-964c-83e201ef199d", "embedding": null, "doc_hash": "15cb3687740ffcf969720c308ecb97d761226f10c21e35272ccf9e4d25bf4048", "extra_info": {"page_label": "6", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2308, "end": 3446}, "relationships": {"1": "487bbe43-398d-4e75-b7ed-4fc19c77b6ba", "2": "8ea884c5-e2b9-4db6-97e6-3eed7bc92b0a"}}, "__type__": "1"}, "1b6e7f4a-489a-4653-b257-513b6bb44806": {"__data__": {"text": " \n \n2 \n publiques. Il nous a tout de m\u00eame \u00e9t\u00e9 possible de pr\u00e9senter c ertains  d\u00e9fis identifi\u00e9s par \nles administrations, d\u00e9fis que nous avons class\u00e9s en utilisant la typologie pr\u00e9sent\u00e9e dans \nla note sur les d\u00e9fis , r\u00e9alis\u00e9e dans le cadre du m\u00eame mandat . Les facteurs habilitants sont \nquant \u00e0 eux des facteurs observ\u00e9s, mais parf ois \u00e9galement des conditions de succ\u00e8s \niden tifi\u00e9es par les administrations .  \n5. Dans la section p ratiques inspirantes , nous mettons en \u00e9vidence certaines pratiques qui \npourraient inspirer la strat\u00e9gie du Qu\u00e9bec pour l\u2019int\u00e9gration de l\u2019IA dans le secteur public . \nIl peut s\u2019agir de directives, de guides ou d\u2019outils d\u2019aide \u00e0 la mise en \u0153uvre  qui semblent \navoir fait leurs preuves . Nous faisons la distinction entre les pratiques ayant d\u00e9j\u00e0 \u00e9t\u00e9 mises \nen place et celles qui sont encore r\u00e9centes, mais qui pourraient se  r\u00e9v\u00e9ler \u00eatre des \npratiques inspirantes et dont il convient de surveiller l\u2019\u00e9volution  et les effets .  \n  ", "doc_id": "1b6e7f4a-489a-4653-b257-513b6bb44806", "embedding": null, "doc_hash": "90c5672421fdc105f04491e53070321f9239d016e2dedc804b274c77ea8a4d83", "extra_info": {"page_label": "7", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 970}, "relationships": {"1": "b169d5ea-b341-471d-a170-d3adc6138947"}}, "__type__": "1"}, "7c50a96a-da7c-48fc-9b57-cc95ba76fd5a": {"__data__": {"text": " \n \n3 \n Le cas du Royaume -Uni \nLes faits saillants  \n\u25cf Le rapport de Hall et Pesenti (2017)  command\u00e9 par le Department for digital, culture, \nmedia and sport  a \u00e9t\u00e9  un \u00e9l\u00e9ment fondateur pour l\u2019utilisation de l\u2019IA dans le secteur public  \nau Royaume -Uni alors que  ses recommandations seront mises en \u0153uvre. Ce rapport \nportait toutefois en grande partie sur les pratiques de l\u2019IA dans le secteur industriel.  \n\u25cf L\u2019encadrement  de l\u2019IA a \u00e9t\u00e9 d\u00e9velopp\u00e9 \u00e0 travers diff\u00e9rents documents tels que le \u00ab\u2009Dat a \nEthic Framework \u2009\u00bb, puis le \u00ab\u2009 Guide to using artificial intelligence in the public sector\u2009 \u00bb \n(2018 et 2019).  \n\u25cf La directive \u00ab\u2009 Draft Guidelines for AI procurement \u2009\u00bb publi\u00e9e en  2019 devrait  permettre \nl\u2019acc\u00e9l\u00e9ration du processus de diffusion dans l\u2019\u00e9tape d\u2019approvisionnement.  \n\u25cf Peu d\u2019exemples concrets de l\u2019utilisation de l\u2019IA dans le secteur public  au Royaume -Uni \nsont recens\u00e9s dans la documentation disponible. Les principales initiatives concern ent les \ndomaines de la sant\u00e9, de la justice, de la police, de la gestion des ressources humaines, \ndes services aux citoyens, des investissement s dans l \u2019enseignement et dans la cr\u00e9ation de \nregroupements  de recherche sur l'utilisation de l\u2019IA en sant\u00e9.  \n\u25cf Les facteurs contraignant s le d\u00e9veloppement et l\u2019utilisation de l\u2019IA par le secteur public \nidentifi\u00e9s \u00e0 travers les exp\u00e9riences au Royaume -Uni sont l a gestion des donn\u00e9es, la prise \nen compte d es risques de  biais et les changements organisationnels \u00e0 op\u00e9rer.  \n\u25cf Les facteurs facilitant le d\u00e9veloppement et l\u2019utilisation de l\u2019IA par le secteur public \nidentifi\u00e9s \u00e0 travers les exp\u00e9riences au Royaume -Uni sont l \u2019importance de tester les outils, \nde garder un agent humain dans le processus d\u00e9cisionnel et le travail intersec toriel . \n \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  \n\u00c0 partir de  2016 , il y a au Royaume -Uni un int\u00e9r\u00eat grandissant pour l\u2019IA et la robotique ( Direction \ng\u00e9n\u00e9rale du Tr\u00e9sor, 2017 ) qui m\u00e8ne \u00e0 la publication de divers rapports portant sur ces sujets. C\u2019est \ncepend ant au cours de l\u2019ann\u00e9e 2017 que l\u2019IA prend une place plus importante.  \nEn mars 2017 , le Department for digital, culture, media and sport (DCMS) s\u2019empare plus \nsp\u00e9cifiquement de la question et commande un rapport sur le d\u00e9veloppement de l\u2019intelligence \nartificielle au Royaume -Uni. En juin 2017 , la chambre des Lords met \u00e9galement en place une \ncommission sp\u00e9ciale sur l\u2019IA ( Direction g\u00e9n\u00e9rale du Tr\u00e9sor, 2017 ). \n\u00c0 la suite de la demande du DCMS, Dame Wendy Hall et J\u00e9r\u00f4me Pesenti  publient en  octobre 2017 , \nle rapport \u00ab\u2009 Growing the artificial intelligence industry in the UK \u2009\u00bb (Hall et Pesenti, 2017 ). Les \nauteurs conseillent entre autres \u00ab \u2009d\u2019\u00e9laborer un plan d\u2019action pour accompagner le secteur public \ndans l \u2019utilisation de l\u2019IA \u2009\u00bb et consid\u00e8rent que \u00ab \u2009la diffusion de la", "doc_id": "7c50a96a-da7c-48fc-9b57-cc95ba76fd5a", "embedding": null, "doc_hash": "97c957ecd58f923b36c7841dbcefe7ad22138e7d847360a473815e41cb72ed6b", "extra_info": {"page_label": "8", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2840}, "relationships": {"1": "196c5339-aff1-4786-a56f-0191e46baa90", "3": "ae5f2525-38d3-4c51-862a-5d4f19dd55bb"}}, "__type__": "1"}, "ae5f2525-38d3-4c51-862a-5d4f19dd55bb": {"__data__": {"text": "de l\u2019intelligence \nartificielle au Royaume -Uni. En juin 2017 , la chambre des Lords met \u00e9galement en place une \ncommission sp\u00e9ciale sur l\u2019IA ( Direction g\u00e9n\u00e9rale du Tr\u00e9sor, 2017 ). \n\u00c0 la suite de la demande du DCMS, Dame Wendy Hall et J\u00e9r\u00f4me Pesenti  publient en  octobre 2017 , \nle rapport \u00ab\u2009 Growing the artificial intelligence industry in the UK \u2009\u00bb (Hall et Pesenti, 2017 ). Les \nauteurs conseillent entre autres \u00ab \u2009d\u2019\u00e9laborer un plan d\u2019action pour accompagner le secteur public \ndans l \u2019utilisation de l\u2019IA \u2009\u00bb et consid\u00e8rent que \u00ab \u2009la diffusion de la culture IA au secteur public \u2009\u00bb \nconsiste en l\u2019un des leviers pour l\u2019adoption de l\u2019IA d\u2019une mani\u00e8re g\u00e9n\u00e9rale ( Direction g\u00e9n\u00e9rale du \nTr\u00e9sor, 2017 p104 et 107 ). Le rapport recommande de cr\u00e9er un Conseil de l\u2019Intelligence artificielle, \nmais \u00e9galement de veiller \u00e0 l\u2019accompagnement du secteur public dans l\u2019utilisation de l\u2019IA  \nnotamment  par la cr\u00e9ation d\u2019un guide. Ce rapport est l\u2019un des \u00e9l\u00e9ments fondateurs pour le \nd\u00e9veloppement de l\u2019IA au Royaume -Uni, notamment dans le secteur public.   ", "doc_id": "ae5f2525-38d3-4c51-862a-5d4f19dd55bb", "embedding": null, "doc_hash": "f82a0fab6dd191c90fa56ecab1a34c41b0145155467f594582daf3f4d9a8bded", "extra_info": {"page_label": "8", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2285, "end": 3337}, "relationships": {"1": "196c5339-aff1-4786-a56f-0191e46baa90", "2": "7c50a96a-da7c-48fc-9b57-cc95ba76fd5a"}}, "__type__": "1"}, "9cf024c1-ac41-42de-984e-d85b6bcb7c71": {"__data__": {"text": " \n \n4 \n En novembre 2017 , la strat\u00e9gie industrielle \u00ab\u2009 Industrial Strategy  : building a Britain fit for the \nfuture \u2009\u00bb est publi\u00e9e par le Department for Business, Energy and Industrial Strategy  (BEIS) ( HM \nGovernment, 2017 ). La strat\u00e9gie vise le d\u00e9veloppement de la productivit\u00e9 et la r\u00e9duction des \nin\u00e9galit\u00e9s territoriales. Parmi les quatre grands d\u00e9fis identifi\u00e9s dans la strat\u00e9gie figure la question \nde l\u2019intelligence artificie lle et des donn\u00e9es. Cette strat\u00e9gie est accompagn\u00e9e de fonds d\u00e9di\u00e9s \u00e0 \nl\u2019intelligence artificielle pour le BEIS et le DCMS ( Direction g\u00e9n\u00e9rale du Tr\u00e9sor, 2017 ). Cette \nstrat\u00e9gie sera suivie par une autre plus sp\u00e9cifiquement sur l\u2019intelligence artificielle en avril 2018, \nl\u2019\u00ab\u2009Industrial Strategy \u2013  Artificial Intelligence Sector Deal\u2009 \u00bb (HM Government, 2018 ). Elle vise \u00e0 \nr\u00e9pondre au d\u00e9fi et \u00e0 l\u2019opportunit\u00e9 que repr\u00e9sente l\u2019IA pour le gouvernement en plus de faire \nsuite aux r ecommandations de Hall et Pesenti. Cette strat\u00e9gie affirme explicitement que le \ngouvernement et l\u2019industrie agissent de concert pour soutenir l\u2019IA. Le document pr\u00e9voit \n\u00e9galement des investissements d\u00e9di\u00e9s au d\u00e9veloppement de  l\u2019intelligence artificielle dan s le \nsecteur public ainsi qu\u2019un transfert de technologies vers le gouvernement central et les minist\u00e8res \net organismes publics. La mise en \u0153uvre de c ette strat\u00e9gie est confi\u00e9e au nouvel  Office for A I \n(OAI) , lanc\u00e9 e conjointement par le BEIS et le DCMS en mars 2018 . De plus, p our contribuer \u00e0 la \nmise en \u0153uvre de la strat\u00e9gie et selon les recommandations de Hall et Pesenti, le conseil de \nl\u2019intelligence artificielle est cr\u00e9\u00e9 en mai 2019  pour renforcer les liens entre l\u2019industrie, l e secteur \nacad\u00e9mique et le s ecteur public ( DCMS et al.,  2019 ). \nC\u2019est \u00e9galement en  avril 2018  qu\u2019est publi\u00e9 le rapport \u00ab \u2009AI in the UK  : ready, willing and able? \u2009\u00bb \npar la commission sp\u00e9ciale sur l\u2019IA de la chambre des lords ( House of Lords, 2018 ). Suivi par le \nrapport \u00ab\u2009 Algorithms in decision -making \u2009\u00bb par le Science and Technology Committee de la \nChambre des communes en mai 2018 (House of Commons, 2018 ). Ce dernier se positionne \nnotamment sur la question des donn\u00e9es, l\u2019importance de les rendre accessibles, d\u2019avoir des \npartenariats avec le secteur priv\u00e9 et de r\u00e9fl\u00e9chir \u00e0 la cr\u00e9ation de \u00ab \u2009data trusts \u2009\u00bb. Il fait \u00e9galement \n\u00e9tat de diff\u00e9rentes utilisations d\u2019algorithmes dans le secteur public. Le rapport sugg\u00e8re  aussi  que \nle gouvernement fasse plus avec les donn\u00e9es dont il est en possession, notamment \u00e0 travers le \nNational Health S ervice (NHS) qui d\u00e9tient un grand nombre de donn\u00e9es. Il entrevoit enfin une \n\u00ab\u2009opportunit\u00e9 de rendre les services publics plus effectifs et de r\u00e9aliser des \u00e9conomies sur le long \nterme\u2009 \u00bb (Traduction libre de House of Commons, 2018  p17).  \nEn juin 2018 , le DCMS au travers de son Centre for Data Ethics and Innovation publie le \u00ab \u2009Data \nEthics Framework \u2009\u00bb (DCMS, 2018 ). Le document", "doc_id": "9cf024c1-ac41-42de-984e-d85b6bcb7c71", "embedding": null, "doc_hash": "e3face88293cb5de9ee597d71a7735def2860b928a122ad24abc8dd7c20d025d", "extra_info": {"page_label": "9", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2929}, "relationships": {"1": "89d5a985-c167-40ee-9b68-f37199cad043", "3": "ed8f6a4a-976f-491e-9805-48330110f751"}}, "__type__": "1"}, "ed8f6a4a-976f-491e-9805-48330110f751": {"__data__": {"text": "de diff\u00e9rentes utilisations d\u2019algorithmes dans le secteur public. Le rapport sugg\u00e8re  aussi  que \nle gouvernement fasse plus avec les donn\u00e9es dont il est en possession, notamment \u00e0 travers le \nNational Health S ervice (NHS) qui d\u00e9tient un grand nombre de donn\u00e9es. Il entrevoit enfin une \n\u00ab\u2009opportunit\u00e9 de rendre les services publics plus effectifs et de r\u00e9aliser des \u00e9conomies sur le long \nterme\u2009 \u00bb (Traduction libre de House of Commons, 2018  p17).  \nEn juin 2018 , le DCMS au travers de son Centre for Data Ethics and Innovation publie le \u00ab \u2009Data \nEthics Framework \u2009\u00bb (DCMS, 2018 ). Le document \u00e9nonce les principes devant guider l\u2019utilisation \ndes donn\u00e9es dans le secteur public, mais \u00e9galement les moyens pour maximiser la valeur de ces \ndonn\u00e9es en resp ectant des standards de transparence et de reddition de compte.  \nD\u2019une mani\u00e8re plus g\u00e9n\u00e9rale,  le Royaume -Uni a mis\u00e9 sur le d\u00e9veloppement  de programmes de \nrecherche et de formation en intelligence artificielle  dans le secteur de l\u2019\u00e9ducation . Cela a \nnotamment permis au  Royaume -Uni de se hisser au 4e rang de la production scientifique en IA  en \nplus d\u2019\u00eatre  la \u00ab \u2009premi\u00e8re destination des investissements dans l\u2019IA en Europe\u2009 \u00bb (Direction \ng\u00e9n\u00e9rale du Tr\u00e9sor, 2017 ). Il est int\u00e9ressant de noter que dans les documents consult\u00e9s, l\u2019 accent \nest mis sur l\u2019importance  des partenariats entre le secteur public et le secteur priv \u00e9. Il semble \n\u00e9galement que l\u2019introduction de l\u2019IA dans le secteur public , plus sp\u00e9cifiquement , ne se fasse que \nlentement en comparaison au secteur priv\u00e9 , comme en t\u00e9moigne le bilan pour la premi\u00e8re ann\u00e9e \ndu AI Sector Deal en juillet 2019  (OAI, 2019 ). S\u2019il est avanc\u00e9 dans le document que l\u2019industrie et \nle gouvernement ont fait des progr\u00e8s significatifs en  ce qui concerne l\u2019intelligence artificielle, il ", "doc_id": "ed8f6a4a-976f-491e-9805-48330110f751", "embedding": null, "doc_hash": "0d589b78e7bf64f1b96674ba225293b4a76155435f9ed63460afdeef304fbca2", "extra_info": {"page_label": "9", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2333, "end": 4143}, "relationships": {"1": "89d5a985-c167-40ee-9b68-f37199cad043", "2": "9cf024c1-ac41-42de-984e-d85b6bcb7c71"}}, "__type__": "1"}, "f54246c7-b8af-409f-a7ea-00786a08e765": {"__data__": {"text": " \n \n5 \n n\u2019y est pas fait mention de cas concrets d\u2019utilisation de l\u2019intelligence artificielle par le secteur \npublic.  \nQuelques publications r\u00e9centes du gouvernement visent toutefois \u00e0 mieux encadrer le \nd\u00e9veloppement  de l\u2019IA dans le secteur public. D\u2019abord, le Government Digital Service (GDS) et \nl\u2019OAI  ont publi\u00e9  en juin 2019  le \u00ab\u2009Guide to using artificial intelligence in the public sector\u2009 \u00bb par le \n(GDS et OAI, 2019 ). Celui- ci comprend notamment des sections sur la compr\u00e9hension de ce qu\u2019est \nl\u2019IA et comment l\u2019implanter, mais \u00e9galement des consid\u00e9rati ons \u00e9thiques ainsi que quelque s \nexemples d\u2019implantation de l\u2019IA dans le secteur public. L\u2019utilisation de l\u2019IA dans le secteur public \ndevrait aussi s\u2019acc\u00e9l\u00e9rer apr\u00e8s la publication en septembre 2019 , des \u00ab \u2009Draft Guidelines for AI \nprocurement \u2009\u00bb par l\u2019OAI, d\u00e9 velopp\u00e9e en collaboration avec le World Economic Forum, mais aussi \ndes entreprises priv\u00e9es ( OAI, 2019 ), et publi\u00e9es simultan\u00e9ment par le World Economic Forum  sous \nla forme d\u2019un livre blanc ( World Economic Forum, 2019 ). Ces lignes directrices sont destin\u00e9es aux \n\u00e9quipes trava illant sur les march\u00e9s publics des projets en intelligence artificielle et portent sur \ntoutes les \u00e9tapes du cycle de l\u2019approvisionnement. Elles appliquent les lois d\u00e9j\u00e0 en vigueur au \nRoyaume -Uni sur les contrats publics, mais font aussi r\u00e9f\u00e9rence au \u00ab\u2009 Data  Ethics Framework \u2009\u00bb, \nnotamment en ce qui concerne la d\u00e9finition des b\u00e9n\u00e9fices , l\u2019\u00e9valuation des risques d\u2019avoir recours \n\u00e0 l\u2019intelligence artificielle  et la reddition de compte . Les lignes directrices sugg\u00e8rent de faire appel \n\u00e0 des \u00e9quipes multidisciplinaires pour tirer tous les b\u00e9n\u00e9fices possibles de l\u2019intelligence artificielle, \nmais \u00e9galement de ne pas cr\u00e9er des silos et d\u2019arrimer son travail avec celui r\u00e9alis\u00e9 par les autres \n\u00e9quipes au sein du gouvernement. Ces lignes directrices doivent \u00eatre test\u00e9es dans  un premier \ntemps par le Royaume -Uni avant d\u2019\u00eatre \u00e9ventuellement utilis\u00e9es par d\u2019autres pays.  \n \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  \nDans cette section, nous pr\u00e9sentons quelques initiatives men\u00e9es au Royaume- Uni pour int\u00e9grer \nl\u2019IA dans des minist\u00e8res ou organismes publics. Nous pr\u00e9sentons ces initiatives et , en fonction des \ndonn\u00e9es publiques , leurs objectifs, les minist\u00e8res et organismes auxquels elles sont rattach\u00e9es, \nmais \u00e9galement le type de probl\u00e8me, d\u2019usag e ou d\u2019utilisation de l\u2019intelligence artificielle dont il \ns\u2019agit.  \nSant\u00e9  \n\u25cf En aout 2019, le National Health Service  (NHS) a mis en place un laboratoire sur \nl\u2019intelligence artificielle qui b\u00e9n\u00e9ficie d\u2019un financement de 250 millions de livres sterling \ndu gouve rnement. Ce laboratoire a pour mission d\u2019aider \u00e0 r\u00e9duire des probl\u00e8mes li\u00e9s \u00e0 la \nsant\u00e9, allant de la", "doc_id": "f54246c7-b8af-409f-a7ea-00786a08e765", "embedding": null, "doc_hash": "bfeb2e814d34945c9e368e23567a2838c0a753fcfca148b24cc6de28568670e4", "extra_info": {"page_label": "10", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2790}, "relationships": {"1": "2c650dd5-c647-4b17-ba01-44283660667a", "3": "69b552b8-4aac-4ab3-abca-891bef25ffbe"}}, "__type__": "1"}, "69b552b8-4aac-4ab3-abca-891bef25ffbe": {"__data__": {"text": "ces initiatives et , en fonction des \ndonn\u00e9es publiques , leurs objectifs, les minist\u00e8res et organismes auxquels elles sont rattach\u00e9es, \nmais \u00e9galement le type de probl\u00e8me, d\u2019usag e ou d\u2019utilisation de l\u2019intelligence artificielle dont il \ns\u2019agit.  \nSant\u00e9  \n\u25cf En aout 2019, le National Health Service  (NHS) a mis en place un laboratoire sur \nl\u2019intelligence artificielle qui b\u00e9n\u00e9ficie d\u2019un financement de 250 millions de livres sterling \ndu gouve rnement. Ce laboratoire a pour mission d\u2019aider \u00e0 r\u00e9duire des probl\u00e8mes li\u00e9s \u00e0 la \nsant\u00e9, allant de la d\u00e9tection active des cancers \u00e0 une meilleure gestion des ressources \nhumaines ( Donnelly et Roberts, 2019 ). L\u2019objectif derri\u00e8re la mise en place de ce \nlaboratoire est \u00e9galement d\u2019acc\u00e9l\u00e9rer les progr\u00e8s r\u00e9alis\u00e9s dans les derni\u00e8res ann\u00e9es avec \nl\u2019utilisation des donn\u00e9es probantes et de l\u2019int elligence artificielle dans le domaine de la \nsant\u00e9. Cela fait notamment suite \u00e0 la publication en juillet 2019 du \u00ab\u2009Code of conduct for \ndata -driven health and care technology\u2009\u00bb. Le laboratoire est mis en place en partenariat \navec Accelerated Access Collabo rative , un groupe form\u00e9 en 2016 pour rassembler \nl\u2019industrie, le gouvernement et le NHS afin de stimuler l\u2019innovation en faisant tomber les \nbarri\u00e8res qui existent normalement entre les secteurs. Le premier rapport publi\u00e9 par ce \nlaboratoire pr\u00e9sente sa feuille de route sur les m\u00e9thodes de travail, la protection des ", "doc_id": "69b552b8-4aac-4ab3-abca-891bef25ffbe", "embedding": null, "doc_hash": "71c62b278cc05c033739f569052306219ba647773e4050882aa80633bd092a04", "extra_info": {"page_label": "10", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2243, "end": 3663}, "relationships": {"1": "2c650dd5-c647-4b17-ba01-44283660667a", "2": "f54246c7-b8af-409f-a7ea-00786a08e765"}}, "__type__": "1"}, "1efd8495-de1a-4be9-85ac-ae4031016a3a": {"__data__": {"text": " \n \n6 \n donn\u00e9es et la gouvernance de l\u2019intelligence artificielle ( Morley et Joshi, 2019 ). La mise en \nplace du laboratoire fait suite \u00e0 l\u2019utilisation par le NHS de l\u2019intelligence artificielle pour \naider \u00e0 la prise de d\u00e9cision sur des cas et pour contribuer \u00e0 fo urnir des soins.  \nJustice  \n\u25cf Le service de police de la ville de Durham utilise des algorithmes pour contribuer \u00e0 \nprendre des d\u00e9cisions sur les risques de r\u00e9cidive \u00e0 l\u2019aide de la m\u00e9thode d\u2019apprentissage \nautomatique dite des \u00ab \u2009for\u00eats al\u00e9atoires \u2009\u00bb. Le Harm Asse ssment Risk Tool  (HART) aide \u00e0 \nla prise de d\u00e9cision pour d\u00e9terminer si un suspect est admissible \u00e0 une poursuite diff\u00e9r\u00e9e , \net ce d\u00e9pendamment des risques de r\u00e9cidive. Pour ce faire, l\u2019algorithme fait une \npr\u00e9diction sur le risque de r\u00e9cidives en fonction de  variables comme l\u2019\u00e2ge, le genre, le \ncode postal et les comportements criminels pass\u00e9s. L\u2019algorithme a \u00e9t\u00e9 d\u00e9velopp\u00e9 en \ncollaboration avec l\u2019universit\u00e9 de Durham. Le mod\u00e8le a \u00e9t\u00e9 construit en se basant sur plus \nde 100 000 cas sur une p\u00e9riode de 5 ans et a \u00e9t\u00e9 test\u00e9 sur une p\u00e9riode d\u2019un an avec 15  000 \ncas. Selon Oswald et al.  (2018 ), la mise en place de HART constitue un cas id\u00e9al pour \nr\u00e9fl\u00e9chir \u00e0 l\u2019utilisation des algorithmes dans l e support \u00e0 la  prise de d\u00e9cision et au sein des \nservices de police. Il pose notamment la question de la transparence, des biais de ce genre \nd\u2019outils et de la discrimination qui peut en d\u00e9couler.  \n\u25cf Dans le cadre d\u2019une enqu\u00eate sur Rolls Royce, le Serious Fraud Office aurait \u00e9t\u00e9 aid\u00e9 par \nun robot pour \u00ab \u2009trier, indexer et r\u00e9sumer 30 millions de documents relatifs \u00e0 l\u2019enqu\u00eate \u2009\u00bb \n(Direction  g\u00e9n\u00e9rale du Tr\u00e9sor, 2017 ) \n\u25cf Le minist\u00e8re  de la Justice a commenc\u00e9 \u00e0 utiliser un algorithme pour g\u00e9rer les rapports \nprovenant des diff\u00e9rentes prisons du pays.  \nRessources humaines  \n\u25cf En utilisant la science comportementale et l\u2019apprentissage automatique, une te ntative a \n\u00e9t\u00e9 faite pour enlever les biais dans le processus d\u2019engagement de nouveaux employ\u00e9s \nau gouvernement. Le programme Applied , en place depuis 2017 et r\u00e9pliqu\u00e9 par la suite \nen Australie et \u00e0 Singapour, fait  en sorte que l\u2019\u00e2ge, le genre et l\u2019origine ethnique ne soient \npas pris en compte dans la proc\u00e9dure d\u2019embauche. Ce programme emp\u00eache toutefois des \norganisations d\u2019appliquer des processus de discrimination positive. De plus, des difficult\u00e9s \nont \u00e9t\u00e9 observ\u00e9es  dans la mise en \u0153uvre  ; le statu quo et les techniques d\u00e9j\u00e0 en place \npour tenter de r\u00e9duire la discrimination \u00e0 l\u2019embauche \u00e9tant pr\u00e9f\u00e9r\u00e9e aux solutions \napport\u00e9es par l\u2019intelligence artificielle, m\u00eame s\u2019il a \u00e9t\u00e9 d\u00e9montr\u00e9 que celles -ci ne sont pas \nefficaces . Cela n\u2019a cependant pas emp\u00each\u00e9 le programme d\u2019\u00eatre mis en place. Ce \nprogramme a \u00e9t\u00e9 d\u00e9velopp\u00e9 par The Behavioural Insights Team , originellement une \n\u00e9quipe au sein du gouvernement du", "doc_id": "1efd8495-de1a-4be9-85ac-ae4031016a3a", "embedding": null, "doc_hash": "bfd6b3e0b5682932816d18c6b12fb26d554220791267891dd5e4f9d6f5fb3d36", "extra_info": {"page_label": "11", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2828}, "relationships": {"1": "b1762230-6a4a-46a1-b331-c0d820554cac", "3": "202885b5-583a-446f-8ec5-1823b7484e0e"}}, "__type__": "1"}, "202885b5-583a-446f-8ec5-1823b7484e0e": {"__data__": {"text": "toutefois des \norganisations d\u2019appliquer des processus de discrimination positive. De plus, des difficult\u00e9s \nont \u00e9t\u00e9 observ\u00e9es  dans la mise en \u0153uvre  ; le statu quo et les techniques d\u00e9j\u00e0 en place \npour tenter de r\u00e9duire la discrimination \u00e0 l\u2019embauche \u00e9tant pr\u00e9f\u00e9r\u00e9e aux solutions \napport\u00e9es par l\u2019intelligence artificielle, m\u00eame s\u2019il a \u00e9t\u00e9 d\u00e9montr\u00e9 que celles -ci ne sont pas \nefficaces . Cela n\u2019a cependant pas emp\u00each\u00e9 le programme d\u2019\u00eatre mis en place. Ce \nprogramme a \u00e9t\u00e9 d\u00e9velopp\u00e9 par The Behavioural Insights Team , originellement une \n\u00e9quipe au sein du gouvernement du Royaume -Uni, mais qui est depuis devenue une \norganisation ind\u00e9pendante, bien qu\u2019elle conserve des liens et soit en partie propri\u00e9t\u00e9 du \nCabinet Office . \nAm\u00e9lioration du service aux citoyens  \n\u25cf Le Government Digital Service  (GDS) a utilis\u00e9 la classification et le \u00ab\u2009natural language \nprocessing\u2009\u00bb pour organiser l\u2019information sur le site internet du gouvernement. Il utilise \naussi l\u2019apprentissage automatique pour traiter les r\u00e9ponses et commentaires \u00e0 des \nquestionnaires sur le site du gouvernement.  ", "doc_id": "202885b5-583a-446f-8ec5-1823b7484e0e", "embedding": null, "doc_hash": "f1145c19ce560e83fafb51d5643cb42577c14bc3ebd3525076bfe331f070a9fd", "extra_info": {"page_label": "11", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2253, "end": 3337}, "relationships": {"1": "b1762230-6a4a-46a1-b331-c0d820554cac", "2": "1efd8495-de1a-4be9-85ac-ae4031016a3a"}}, "__type__": "1"}, "250f0ba6-64b3-4f71-aa24-4e7e1d336635": {"__data__": {"text": " \n \n7 \n \u25cf HM Revenue and Customs  utilise l\u2019intelligence artificielle pour identifier les priorit\u00e9s  au \ncentre d\u2019appel. Il l\u2019utilise \u00e9galement pour la prise de d\u00e9cision dans certains dossiers. Cela \ns\u2019inscrit dans un objectif d\u2019automatisation dans le traitement de certains dossiers.  \nAutres  \n\u25cf Le Government Digital Service  (GDS) travaille sur la pr\u00e9diction d es comportements futurs \ndu r\u00e9gime de retraite \u00e0 l\u2019aide d\u2019algorithmes.  \n\u25cf L\u2019Earth observation Centre of Excellence du Department for Environment, Food and Rural \nAffairs  pr\u00e9voit d\u2019utiliser l\u2019intelligence artificielle pour traiter les donn\u00e9es satellites sur \nl\u2019\u00e9tat de terrains \u00e0 la suite de d\u00e9sastres environnementaux.  \n\u25cf Le Department for International Development (DFID) a utilis\u00e9 la vision par ordinateur pour \naider des pays en d\u00e9veloppement \u00e0 avoir une meilleure connaissance de la densit\u00e9 et de \nla distribution de la population dans certaines zones. Pour ce faire, le DFID s\u2019est associ\u00e9 \u00e0 \nl\u2019Universit\u00e9 de Southampton, l\u2019Univ ersit\u00e9 Columbia et le Fonds des Nations unies pour la \npopulation. Gr\u00e2ce aux donn\u00e9es d\u2019images satellites, l\u2019algorithme peut pr\u00e9dire la densit\u00e9 \nde population d\u2019une zone. Le programme est maintenant en place dans diff\u00e9rents pays \nd\u2019Afrique.  \n\u25cf La Driver and Vehi cle Standards Agency a utilis\u00e9 le partitionnement de donn\u00e9e s pour \ncibler les garages \u00e0 risque de ne pas respecter les standards du minist\u00e8re du Transport \npour les tests annuels sur les voitures et ainsi am\u00e9liorer les contr\u00f4les.  \n\u25cf Il est \u00e9galement fait \u00e9tat de l\u2019utilisation de l\u2019intelligence artificielle dans la Royal Navy , et \ndans la British Army .  \n \nFacteurs habilitants et contraignants  \nNous identifions ici les facteurs habilitants et les freins \u00e0 l\u2019introduction de l\u2019intelligence artificielle \ndans le secteur  public. Comme nous l\u2019avons vu, les initiatives sont cependant r\u00e9centes et la \ndocumentation peu abondante dans ce domaine. Les informations \u00e0 ce sujet sont pr\u00e9liminaires \net devraient se pr\u00e9ciser avec la publication future d\u2019\u00e9tudes de cas r\u00e9alis\u00e9es au sein des \nadministrations publiques. Il a donc \u00e9t\u00e9 plus difficile d\u2019identifier ces freins de m\u00eame que les \nfacteurs habilitants.  \nFacteurs contraignants  \nD\u00e9fis de gestion des donn\u00e9es  \nL\u2019identification et la pr\u00e9paration des donn\u00e9es pour l\u2019IA  \n\u25cf En ce qui concerne les in itiatives men\u00e9es par le NHS, le manque de donn\u00e9es est identifi\u00e9 \ncomme un frein \u00e0 la mise en place de l\u2019intelligence artificielle. Il est \u00e9galement identifi\u00e9 \nque, plus que l\u2019absence de donn\u00e9es, un probl\u00e8me r\u00e9side dans le mauvais classement des \ndonn\u00e9es du NH S, leur manque de repr\u00e9sentativit\u00e9 ainsi que leur besoin d\u2019\u00eatre \n\u00ab\u2009nettoy\u00e9es\u2009\u00bb. Le nombre, l\u2019acc\u00e8s et la qualit\u00e9 des donn\u00e9es sont ainsi des freins pour le \nd\u00e9veloppement de l\u2019IA et le traitement des donn\u00e9es.  ", "doc_id": "250f0ba6-64b3-4f71-aa24-4e7e1d336635", "embedding": null, "doc_hash": "264d22b09a99fc16ca2328f89afc9bff5f70d584cc74b174b9f2ae018cdfc744", "extra_info": {"page_label": "12", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2787}, "relationships": {"1": "0f42a626-eafe-4e17-93ad-70561fcfb775"}}, "__type__": "1"}, "ac716cc2-563c-4e6f-8334-618a11e31496": {"__data__": {"text": " \n \n8 \n D\u00e9fis \u00e9thiques  \nDiscriminations g\u00e9n\u00e9r\u00e9es par l\u2019IA  \n\u25cf Des biais sont identifi\u00e9s comme \u00e9tant li\u00e9s \u00e0 l\u2019utilisation d\u2019algorithmes bas\u00e9s \ninconsciemment sur des biais comme c\u2019est le cas avec  l\u2019outil de l\u2019aide \u00e0 la d\u00e9cision utilis\u00e9 \npar le service de police de la ville de Durham. L\u2019algorithme est men\u00e9 \u00e0 faire des \npond\u00e9rations et des choix qui peuvent renforcer les discriminations pr\u00e9existantes.  \nD\u00e9fis manag\u00e9riaux  \n\u25cf Dans le cadre du projet men\u00e9 sur la discrimination \u00e0 l\u2019emploi et du programme d\u00e9velopp\u00e9 \npar The Behavioural Insights Team , le plus grand d\u00e9fi rencontr\u00e9 concerne la gestion du \nchangement (pr\u00e9f\u00e9rences pour le statu quo et les m\u00e9thodes d\u00e9j\u00e0 implant\u00e9es).  \nFacteurs habilitants  \nConstruction du produit  \n\u25cf En ce qui concerne l\u2019utilisation d\u2019algorithmes par la police de Durham, les prem i\u00e8res \nexp\u00e9rimentations d\u00e9montrent l\u2019importance de tester l\u2019outil, de le comprendre et de \nl\u2019utiliser comme outil de support \u00e0 la d\u00e9cision en laissant un humain responsable de la \nd\u00e9cision, m\u00eame si l\u2019IA peut contribuer \u00e0 la prise de d\u00e9cision.  \nMise en \u0153uvre  \n\u2022 Le travail d\u2019\u00e9quipe et l\u2019interdisciplinarit\u00e9 sont identifi\u00e9s par le GDS comme des facteurs \nhabilitants dans la mise en \u0153uvre d\u2019initiatives li\u00e9es \u00e0 l\u2019IA dans le secteur public. Il s\u2019agit \nd\u2019ailleurs de l\u2019une des recommandations des \u00ab\u2009Draft Guidelines for AI p rocurement\u2009\u00bb et \ndu \u00ab\u2009Data Ethics Framework\u2009\u00bb  \n \nPratiques inspirantes  \nNous mettons en \u00e9vidence dans cette section certaines pratiques qui pourraient inspirer la \nstrat\u00e9gie du Qu\u00e9bec pour l\u2019int\u00e9gration de l\u2019IA dans le secteur public. Il peut s\u2019agir de directives, \nde guides ou d\u2019outils d\u2019aide \u00e0 la mise en \u0153uvre. Nous faisons la distinction entre les pratiques \nayant d\u00e9j\u00e0 \u00e9t\u00e9 mises en place et celles qui sont encore r\u00e9centes, mais qui pourraient se r\u00e9v\u00e9ler \n\u00eatre des pratiques inspirantes.  \nEn place  \n\u2022 La publication du \u00ab\u2009Data Ethics Framework \u2009\u00bb (DCMS, 2018)  par le Centre for Data Ethics \nand Innovation constitue une pratique inspirante en ce qui concerne les principes \nd\u2019utilisation des donn\u00e9es dans le secteur public et les standards de transparence et de \nreddition de compte.  \n\u2022 La publication du \u00ab\u2009Guide to using artificial intelligence in the public sector\u2009 \u00bb (GDS et OAI, \n2019) constitue une pratique inspirante concernant l\u2019encadrement par le gouvernement \ndu d\u00e9veloppement de l\u2019IA dans le secteur public. Ce guide donne aux acteurs  de \nl\u2019administration des documents et cr\u00e9e une compr\u00e9hension commune de ce qu\u2019est l\u2019IA, \nde comment elle peut \u00eatre implant\u00e9e dans le secteur public, les consid\u00e9rations \u00e9thiques \ndevant \u00eatre prises en compte, mais \u00e9galement des exemples concrets d\u2019implantatio n de \nl\u2019IA.  ", "doc_id": "ac716cc2-563c-4e6f-8334-618a11e31496", "embedding": null, "doc_hash": "ae62e468b23a9b03e722842bf5866e1589038c8cb5f224991d1a4f4b658d37c7", "extra_info": {"page_label": "13", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2669}, "relationships": {"1": "fac042c0-6e67-4ff1-b900-81cbdb3c71b8"}}, "__type__": "1"}, "1a23136c-de80-4161-83b2-cc01b46fe134": {"__data__": {"text": " \n \n9 \n \u00c0 surveiller  \n\u2022 S\u2019il est encore t\u00f4t pour en tirer des conclusions, les \u00ab \u2009Draft Guidelines for AI \nprocurement \u2009\u00bb publi \u00e9es en septembre 2019  par l\u2019OAI (OAI, 2019) pourraient constituer \nune pratique inspirante. Il s\u2019agit en effet pour le Royaume -Uni de se doter de lignes \ndirectrices concernant les questions d\u2019approvisionnement, destin\u00e9es aux \u00e9quipes \ntravaillant sur les marc h\u00e9s publics des projets en intelligence artificielle . \n  ", "doc_id": "1a23136c-de80-4161-83b2-cc01b46fe134", "embedding": null, "doc_hash": "062f8183bd422d9462bf2495bbaf67f16983b95fe93dc805d913adb7b708b942", "extra_info": {"page_label": "14", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 449}, "relationships": {"1": "0ce46509-a971-462e-a578-aaa50b5746ba"}}, "__type__": "1"}, "c24da791-eb26-45d9-97e9-ead30635d5e2": {"__data__": {"text": " \n \n10 \n Le cas de la France  \nLes faits saillants  \n\u25cf L\u2019int\u00e9gration de l\u2019intelligence artificielle est d\u2019abord pr\u00e9sent\u00e9e comme une nouvelle \ntechnologie permettant l\u2019ouverture des donn\u00e9es, l\u2019am\u00e9lioration de la relation aux usagers \net le d\u00e9veloppement de l\u2019offre de services num\u00e9riques .  \n\u25cf Depuis 2016, on passe \u00e0 une strat\u00e9gie globale de modernisation de l\u2019\u00c9tat qui vise \u00e0 \ntransformer l\u2019administration publique, \u00e0 r\u00e9duire les d\u00e9penses publiques et \u00e0 am\u00e9liorer les \nconditions de travail des fonctionnaires.  \n\u25cf La cr\u00e9ation d\u2019une structure (le Lab IA) pour accompagner les administrations ainsi que la \nmise en place d\u2019un accompagnement technique et scientifique \u00e0 travers les Appels \u00e0  \nmanifestation d\u2019int\u00e9r\u00eat (AMI) semblent \u00eatre des pratiques facilitant l\u2019int\u00e9gration de l\u2019IA \ndans le secteur public.  \n\u25cf Les plateformes ouvertes d\u2019\u00e9changes de donn\u00e9es et les startups d\u2019\u00c9tat impliquent les \nacteurs priv\u00e9s et les citoyens dans la conception des services publics qui utilisent \nl\u2019intellige nce artificielle.  \n\u25cf Il existe en France de nombreuses initiatives pour int\u00e9grer l\u2019intelligence artificielle dans \ndes minist\u00e8res et les organismes publics. Ces initiatives font appel \u00e0 l\u2019IA dans un grand \nnombre de domaines (justice, environnement, sant\u00e9, trav ail et emploi, etc.).  \n\u25cf Les initiatives portent surtout sur le contr\u00f4le et la r\u00e9pression des infractions \u00e0 la \nr\u00e9glementation , que ce soit en environnement ou pour  la fraude fiscale.  \n \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  \nEn mars 2017, le gouvernement fran\u00e7ais met en place la d\u00e9marche #FranceIA . L\u2019intelligence \nartificielle (IA) y est pr\u00e9sent\u00e9e comme un enjeu important sur lequel se mobiliser ( DITP et al. , \n2018A). Cela s\u2019inscrit dans une volont\u00e9 du gouvernement de transformer l\u2019action publique, et l\u2019IA \napparait comme un moyen \u00ab pour rendre l\u2019administration fran\u00e7aise plus proche des besoins des \nusagers, plu s efficace, plus efficiente et tourn\u00e9e vers l\u2019avenir \u00bb.  \n \n\u00c0 partir de mars 2018 avec le lancement de de la Strat\u00e9gie nationale en intelligence artificielle par \nle pr\u00e9sident de la R\u00e9publique lors du Sommet AI for humanity , le gouvernement met davantage \nl\u2019accent sur l\u2019int\u00e9gration de l\u2019intelligence artificielle dans le secteur public. L\u2019objectif derri\u00e8re cette \nutilisation de l\u2019IA dans l\u2019administration publique est de rendre de meilleurs services aux usagers, \nde baisser les d\u00e9penses publiques et d\u2019am\u00e9liorer les conditions de travail des fonctionnaires.  \nCette int\u00e9gration se fait notamment \u00e0 travers le Lab IA. Le Comit\u00e9 interminist\u00e9riel \u00e0 la \nTransformation publique annonce en octobre 2018 la cr\u00e9ation d\u2019un Lab IA po ur accompagner les \nadministrations dans leur int\u00e9gration de l\u2019IA ( Etatlab, 201 9). Il est rattach\u00e9 \u00e0 Etalab, un  service du \npremier ministre cr\u00e9 \u00e9 en 2011 dont la mission est d\u2019assurer l\u2019ouverture des donn\u00e9es publiques et", "doc_id": "c24da791-eb26-45d9-97e9-ead30635d5e2", "embedding": null, "doc_hash": "89b5ac9dbd3fea9227b95af0fb876b4571df7f236753d2a304e96254051b3197", "extra_info": {"page_label": "15", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2863}, "relationships": {"1": "d8b85560-b446-4e15-9b39-6014a3df9b4e", "3": "fef9f38e-a86a-4ec8-8d4d-d7e40ab5ddcb"}}, "__type__": "1"}, "fef9f38e-a86a-4ec8-8d4d-d7e40ab5ddcb": {"__data__": {"text": "cette \nutilisation de l\u2019IA dans l\u2019administration publique est de rendre de meilleurs services aux usagers, \nde baisser les d\u00e9penses publiques et d\u2019am\u00e9liorer les conditions de travail des fonctionnaires.  \nCette int\u00e9gration se fait notamment \u00e0 travers le Lab IA. Le Comit\u00e9 interminist\u00e9riel \u00e0 la \nTransformation publique annonce en octobre 2018 la cr\u00e9ation d\u2019un Lab IA po ur accompagner les \nadministrations dans leur int\u00e9gration de l\u2019IA ( Etatlab, 201 9). Il est rattach\u00e9 \u00e0 Etalab, un  service du \npremier ministre cr\u00e9 \u00e9 en 2011 dont la mission est d\u2019assurer l\u2019ouverture des donn\u00e9es publiques et \nl\u2019utilisation de ces donn\u00e9es pour am\u00e9liorer les services (notamment le d\u00e9veloppement de l\u2019offre \nde services num\u00e9riques et l\u2019aide \u00e0 la prise de d\u00e9cision) (auteur inconnu, 2018).  Etalab est \nrattach\u00e9e depuis octobre 2019 \u00e0 la direction interminist\u00e9rielle du num\u00e9rique de l\u2019\u00c9tat (DINUM) \nqui \u00ab  coordonne la conception et la mise en \u0153uvre de la strat\u00e9gie de l\u2019\u00c9tat dans le domaine de la \ndonn\u00e9e  \u00bb (Etalab ).  ", "doc_id": "fef9f38e-a86a-4ec8-8d4d-d7e40ab5ddcb", "embedding": null, "doc_hash": "96ab41c665ffbb51cff672479f0aab11b7c32ea29fc2c6e4addf8e073090fe8b", "extra_info": {"page_label": "15", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2269, "end": 3274}, "relationships": {"1": "d8b85560-b446-4e15-9b39-6014a3df9b4e", "2": "c24da791-eb26-45d9-97e9-ead30635d5e2"}}, "__type__": "1"}, "a7052f31-7c78-40e7-8040-d6469190f36c": {"__data__": {"text": " \n \n11 \n Le Lab IA \u00ab  identifie et accompagne des projets dans les administrations, d\u00e9veloppe des outils, \ndes connai ssances et des pratiques mutualis\u00e9es, r\u00e9alise des projets d\u2019IA publics ambitieux et \nanime une communaut\u00e9 des acteurs publics de l\u2019IA  \u00bb (DITP et al ., 2019A, p2 ). Il est financ\u00e9 par le \nfonds \u00ab  transition num\u00e9rique de l\u2019\u00c9tat  \u00bb (DITP et al., 2019A ).  \nLe Lab IA coordonne les Appels \u00e0 manifestatio n d\u2019int\u00e9r\u00eat (AMI). Deux AMI ont \u00e9t\u00e9 lanc\u00e9s jusqu\u2019\u00e0 \nmaintenant pour accompagner des minist\u00e8res ou organismes publics dans des projets \nd\u2019intelligence artificielle. Le premier AMI a donn\u00e9 lieu \u00e0 la s\u00e9lection de 6 projets en 2018  alors que \nle deuxi\u00e8me a men\u00e9 \u00e0 la s\u00e9lection de 15 projets en 2019 . Ces projets d\u2019utilisation de l\u2019IA au sein \nde minist\u00e8res et d\u2019organismes publics font l\u2019objet d\u2019un accompagnement et d\u2019un prototypage \ndans l\u2019 objectif d\u2019\u00eatre mis en \u0153uvre de mani\u00e8re prolong\u00e9e ( DITP et al., 2019A ). Les AMI ont \u00e9t\u00e9 \nlanc\u00e9s par la direction interminist\u00e9rielle du num\u00e9rique (D INSIC) et la direction interminist\u00e9rielle \nde la transformation publique (DITP) ( DITP et al., 2018C ). \nOutre le Lab  IA, plusieurs actions se d\u00e9roulent sous le couvert d\u2019Etalab. Etalab fait office de \u00ab  Chief \nData Officer \u00bb et porte \u00e9galement le programme Entrepreneurs d\u2019int\u00e9r\u00eat g\u00e9n\u00e9ral  (EIG) depuis \n2016 qui a pour objectif de relever des \u00ab d\u00e9fis d\u2019am\u00e9lioration du service public \u00e0 l\u2019aide du \nnum\u00e9rique et des donn\u00e9es  \u00bb (EIG) en permettant \u00e0 des professionnels ext\u00e9rieurs d\u2019int\u00e9grer \nl\u2019administration ( DINSIC, 2019 ). Plusieurs de ces d\u00e9fis sont relev\u00e9s gr\u00e2ce \u00e0 des m\u00e9thodes \nd\u2019intelligence artificielle ( Augusti, 2019 ). Un autre mandat d\u2019Etalab est la mise sur pied d\u2019un portail \nde donn\u00e9es publiques \u00ab  data.gouv.fr \u00bb qui donne acc\u00e8s aux donn\u00e9es de diff\u00e9rents m inist\u00e8res \n(Data.gouv.fr ). \nEn 2016, la DINSIC inaugure le portail api.gouv.fr qui r\u00e9f\u00e9rence la liste exhaustive des API \n(application programming  interface) fournies par les services publics fran\u00e7ais et facilite leur \nutilisation par les d\u00e9veloppeurs. Une API est un programme informatique permettant l\u2019\u00e9change \net le croisement de donn\u00e9es en temps r\u00e9el et sans intervention humaine entre des syst\u00e8mes \ninformatiques qui n\u2019ont pas \u00e9t\u00e9 con\u00e7us ensemble \u00e0 l\u2019origine ( Barbeau, 2016 ). Les fournisseurs de \ndonn\u00e9es sont issu s de la sph\u00e8re publique (l\u2019\u00e9tat et ses repr\u00e9sentants, collectivit\u00e9s, autorit\u00e9s \nadministratives , etc.) et les consommateurs des API proviennent de diff\u00e9rents \u00e9cosyst\u00e8mes ( aussi \nbien public que priv\u00e9) ( api.gouv.fr ), ce qui s\u2019aligne sur la volont\u00e9 de \u00ab  plateformisation de l\u2019 \u00c9tat \u00bb \n(Chevalier, 2018).  Les ressources offertes par les API permettent la cr\u00e9ation de startups d\u2019\u00c9tat qui", "doc_id": "a7052f31-7c78-40e7-8040-d6469190f36c", "embedding": null, "doc_hash": "5c940944f6633f4795cd980e0a73b4c9a3798f1d94cb31d0946b88b52478991c", "extra_info": {"page_label": "16", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2699}, "relationships": {"1": "0783dc24-f27f-43fb-ad13-449e109cf0c6", "3": "b5e53e9f-4472-4237-a7d7-4c069c230131"}}, "__type__": "1"}, "b5e53e9f-4472-4237-a7d7-4c069c230131": {"__data__": {"text": "humaine entre des syst\u00e8mes \ninformatiques qui n\u2019ont pas \u00e9t\u00e9 con\u00e7us ensemble \u00e0 l\u2019origine ( Barbeau, 2016 ). Les fournisseurs de \ndonn\u00e9es sont issu s de la sph\u00e8re publique (l\u2019\u00e9tat et ses repr\u00e9sentants, collectivit\u00e9s, autorit\u00e9s \nadministratives , etc.) et les consommateurs des API proviennent de diff\u00e9rents \u00e9cosyst\u00e8mes ( aussi \nbien public que priv\u00e9) ( api.gouv.fr ), ce qui s\u2019aligne sur la volont\u00e9 de \u00ab  plateformisation de l\u2019 \u00c9tat \u00bb \n(Chevalier, 2018).  Les ressources offertes par les API permettent la cr\u00e9ation de startups d\u2019\u00c9tat qui \nprennent appui sur l\u2019\u00ab incubateur de services num\u00e9riques  \u00bb (Beta.gouv ) de la DINSIC  (Chevalier, \n2018). Les startups sont d\u00e9velopp\u00e9es par des groupes de travail de 2 \u00e0 4 personnes au statut \ndivers (fonctionnaires, agents ou partenaires ext\u00e9rieurs) qui cherchent \u00e0 r\u00e9soudre un probl\u00e8me \nsp\u00e9cifique des utilisat eurs par  la cr\u00e9ation de nouveaux services num\u00e9riques ( Chevalier, 2018). La \nm\u00e9thode dite \u00ab  agile  \u00bb est mobilis\u00e9e  et les startups sont r\u00e9gies par des \u00e9ch\u00e9ances courtes, sont \ndissolues en cas d\u2019insucc\u00e8s, disposent d\u2019un budget propre, ont une dur\u00e9e de vie limi t\u00e9e (six mois \nau maximum) et sont prises en charge et exploit\u00e9es par l\u2019administration concern\u00e9e ( Chevalier, \n2018).  Leur formule assez souple permet l\u2019exp\u00e9rimentation, l\u2019am\u00e9lioration et une large \nimplicat ion des utilisateurs ( Chevalier, 2018).  Certains services d\u00e9velopp\u00e9s ont connu un grand \nsucc\u00e8s comme les \u00ab march\u00e9 public simplifi\u00e9 \u00bb (MPS)  qui permet aux entreprises de r\u00e9pondre  aux \nappels d\u2019offres , le logiciel \u00ab open fiscal \u00bb de simulation des aides sociales accessibles , ou encore \nla \u00ab bonnebo\u00eete.p\u00f4le -emploi  \u00bb et \u00ab  le taxi  \u00bb (Chevalier , 2018).  ", "doc_id": "b5e53e9f-4472-4237-a7d7-4c069c230131", "embedding": null, "doc_hash": "4601932ee4a5d8170c12bff63a09307b74ee0fedec2cc5eaf9f00300fe838d77", "extra_info": {"page_label": "16", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2164, "end": 3850}, "relationships": {"1": "0783dc24-f27f-43fb-ad13-449e109cf0c6", "2": "a7052f31-7c78-40e7-8040-d6469190f36c"}}, "__type__": "1"}, "b5597225-47a4-44c9-82a7-34836c8c464b": {"__data__": {"text": " \n \n12 \n Le programme Action Publique 2022 a quant \u00e0 lui \u00e9t\u00e9 mis en place pour acc\u00e9l\u00e9rer la \ntransformation du service public ( DITP et al., 2017 ). Certains des projets qui en d\u00e9coulent \ns\u2019appuient sur l\u2019utilisation de l\u2019intelligence artificielle ( DITP et al., 2018C ).  \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  \nNous  pr\u00e9sentons dans cette section quelques initiatives men\u00e9es en France pour int\u00e9grer l\u2019IA dans \ndes minist\u00e8res ou organismes publics.  \nPar ailleurs, une grande partie des initiatives recens\u00e9es sont li\u00e9es aux Appels \u00e0 manifestations \nd\u2019int\u00e9r\u00eat (AMI) de 2018 et 2019. Or, ces initiatives sont en cours d\u2019implantation et les informations \nsont donc limit\u00e9es. Nous nous basons en grande partie sur les informations disponibles dans \nl\u2019annonce des laur\u00e9ats du premier  et du deuxi\u00e8me  AMI, ainsi que sur les informations disponibles \nsur le programme Entrepreneurs d\u2019int\u00e9r\u00eat g\u00e9n\u00e9ral  et sur les projets  issus du programme Action \nPublique 2022. Les 6 projets dans le cadre du pr emier AMI ont donn\u00e9 lieu \u00e0 des prototypes qui \nsont actuellement test\u00e9s par les administrations et les projets viennent \u00e0 peine de donner lieu \u00e0 \nun premier bilan . Nous pr\u00e9sentons les initiatives en fonction des diff\u00e9rents domaines \nd\u2019application. Comme il est possible de le constater, celles -ci sont rattach\u00e9es \u00e0 une grande \ndiversit\u00e9 de minist\u00e8res o u organismes.  \nSant\u00e9  \n\u25cf Le Centre hospitalier universitaire de Bordeaux  cherche \u00e0 faciliter gr\u00e2ce \u00e0 l\u2019IA, l\u2019acc\u00e8s aux \ndonn\u00e9es et aux informations sur les patients pour le personnel soignant.  \n\u25cf L\u2019Institut de radioprotection et de s\u00fbret\u00e9 nucl\u00e9aire  veut surveiller  l\u2019exposition des \ntravailleurs aux rayonnements ionisants  et d\u00e9velopper un syst\u00e8me d\u2019alerte automatique. \nL\u2019IA peut permettre dans ce contexte une d\u00e9tection des anomalies et un suivi \npersonnalis\u00e9.  \n\u25cf Le Centre hospitalier universitaire de Toulouse a d\u00e9velopp\u00e9  un prototype d\u2019utilisation de \nl\u2019IA pour r\u00e9aliser des r\u00e9sum\u00e9s \u00e0 partir de diff\u00e9rents dossiers et comptes rendus m\u00e9dicaux. \nLes objectifs sont d\u2019am\u00e9liorer les traitements postop\u00e9ratoires et de diminuer le temps \npass\u00e9 par les praticiens \u00e0 chercher de l\u2019inform ation. Les premiers r\u00e9sultats sur des cas \nsimples sont satisfaisants, mais l\u2019outil doit \u00eatre am\u00e9lior\u00e9 pour les cas plus complexes. Un \ntransfert de cet outil \u00e0 d\u2019autres services et d\u2019autres \u00e9tablissements de sant\u00e9 est pr\u00e9vu.  \n\u25cf La Direction g\u00e9n\u00e9rale de l\u2019alim entation au sein du minist\u00e8re de l\u2019Agriculture et de \nl\u2019Alimentation  teste un prototype d\u2019utilisation de l\u2019IA pour d\u00e9tecter les restaurants \npouvant pr\u00e9senter des risques sanitaires. L\u2019objectif est d\u2019augmenter l\u2019efficacit\u00e9 des \ncontr\u00f4les en se basant sur les commentaires et les avis diffus\u00e9s sur les diff\u00e9rentes \nplateformes web ou r\u00e9seaux sociaux. Gr\u00e2ce \u00e0 l\u2019IA et \u00e0 l\u2019analyse s\u00e9mantique, une", "doc_id": "b5597225-47a4-44c9-82a7-34836c8c464b", "embedding": null, "doc_hash": "bdc9f63a08a66426f7425de5848e8578ba5cd78e25372a768b90b22702f4f5ab", "extra_info": {"page_label": "17", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2843}, "relationships": {"1": "1e2a6622-b82d-4181-9c1c-3a890e669151", "3": "ace301cd-32ac-4e28-b182-19e6c427bec8"}}, "__type__": "1"}, "ace301cd-32ac-4e28-b182-19e6c427bec8": {"__data__": {"text": "pour les cas plus complexes. Un \ntransfert de cet outil \u00e0 d\u2019autres services et d\u2019autres \u00e9tablissements de sant\u00e9 est pr\u00e9vu.  \n\u25cf La Direction g\u00e9n\u00e9rale de l\u2019alim entation au sein du minist\u00e8re de l\u2019Agriculture et de \nl\u2019Alimentation  teste un prototype d\u2019utilisation de l\u2019IA pour d\u00e9tecter les restaurants \npouvant pr\u00e9senter des risques sanitaires. L\u2019objectif est d\u2019augmenter l\u2019efficacit\u00e9 des \ncontr\u00f4les en se basant sur les commentaires et les avis diffus\u00e9s sur les diff\u00e9rentes \nplateformes web ou r\u00e9seaux sociaux. Gr\u00e2ce \u00e0 l\u2019IA et \u00e0 l\u2019analyse s\u00e9mantique, une \nprobabilit\u00e9 de risque sanitaire est associ\u00e9e aux diff\u00e9rents \u00e9tablissements, permettant de \nmieux cibler ceux qui devraient faire l\u2019objet d\u2019un contr\u00f4le. Deux algorithmes ont d\u00e9j\u00e0 \u00e9t\u00e9 \nd\u00e9velopp\u00e9s ainsi qu\u2019une interface pour consulter les r\u00e9sultats, menant pour le moment \u00e0 \ndes r\u00e9sultats de performance du ciblage satisfaisants.  \n\u25cf La Direction g\u00e9n\u00e9rale de la sant\u00e9  au sein du m inist\u00e8re  des Solidarit\u00e9s et de la Sant\u00e9  \nr\u00e9fl\u00e9chit \u00e0 l\u2019analyse et au pr\u00e9traitement des signalements d\u2019\u00e9v\u00e9nements sanitaires \u00e0 \nl\u2019aide de l\u2019intelligence artificielle. L\u2019objectif est d\u2019utiliser les signalements, de les classifier \ngr\u00e2ce \u00e0 l\u2019IA pour en optimiser leur traitement et de d\u00e9tecter les anomalies.   ", "doc_id": "ace301cd-32ac-4e28-b182-19e6c427bec8", "embedding": null, "doc_hash": "b232e9792b7d1af45a7b09362ca6be19dab13eb9986b5eb84bdf859403d8ad7e", "extra_info": {"page_label": "17", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2290, "end": 3534}, "relationships": {"1": "1e2a6622-b82d-4181-9c1c-3a890e669151", "2": "b5597225-47a4-44c9-82a7-34836c8c464b"}}, "__type__": "1"}, "f210f2a0-87df-43e2-be5a-1a1b879c0e1c": {"__data__": {"text": " \n \n13 \n Environnement  \n\u25cf L\u2019Institut national de l'environnement industriel et des risques  souhaite am\u00e9liorer la \ncaract\u00e9risation des sources des contaminations environnementales. L\u2019IA servira \u00e0 \nidentifier les mol\u00e9cules contaminantes et les sources de pollution.  \n\u25cf L\u2019Agence fran\u00e7aise pour la biodiversit\u00e9  au sein du  minist\u00e8re de la Transition \u00e9cologique et \nsolidaire teste actuellement une utilisation de l\u2019IA pour mieux cibler les contr\u00f4les \u00e0 \neffectuer par sa police de l\u2019environnement.  \nTravail et emploi  \n\u25cf L\u2019agence P\u00f4le emploi  a re\u00e7u du financement en 2018 \u00e0 travers le Fond pour la \ntransformation de l\u2019action publique pour l\u2019am\u00e9lioration de l\u2019efficience des services et des \n\u00e9changes entre les chercheurs d\u2019emploi, les conseillers et les recruteurs. Un premier outil \nd\u2019analyse s\u00e9mantique devait \u00eatre test\u00e9 \u00e0 l\u2019automne 2019 puis g\u00e9n\u00e9ralis\u00e9 en 2020 dans un \nconte xte de volont\u00e9 de la direction de changement d\u2019\u00e9chelle de ces initiatives ( Nessi, \n2019 ). \n\u25cf La Chambre des m\u00e9ti ers et de l'artisanat de Nouvelle -Aquitaine  veut d\u00e9terminer gr\u00e2ce \u00e0 \nl\u2019IA les facteurs de succ\u00e8s d\u2019un artisan sur un territoire. Ceci permettra de conseiller les \nartisans dans leur choix de localisation.  \nContr\u00f4le et fraude  \n\u25cf Le minist\u00e8re des Finances  veut g\u00e9 n\u00e9raliser l\u2019utilisation du traitement automatis\u00e9 des \ndonn\u00e9es pour lutter contre la fraude fiscale des entreprises. En utilisant des s\u00e9ries \nd\u2019algorithmes pour traiter les donn\u00e9es issues de diff\u00e9rents fichiers, l\u2019objectif est de \nd\u00e9tecter et cibler les dossie rs pouvant pr\u00e9senter des risques. Les agents d\u00e9cident ensuite \ns\u2019ils proc\u00e8dent \u00e0 des contr\u00f4les.   \n\u25cf La direction g\u00e9n\u00e9rale de la concurrence, de la consommation et de la r\u00e9pression des \nfraudes  va faire l\u2019objet d\u2019un accompagnement scientifique dans le cadre du deuxi\u00e8me AMI \npour mettre en place gr\u00e2ce \u00e0 l\u2019IA une \u00ab solution d\u2019aide \u00e0 la d\u00e9cision dans le cadre de \nl\u2019analyse des contrats, devis et factures pour la recherche des clauses & pratiques \nabusives  \u00bb (DITP et al,. 2019B ).  \n\u25cf Dans le cadre du programme EIG, le d\u00e9fi IA Flash accompagne le minist\u00e8re de l\u2019Int\u00e9rieur \net l\u2019Agence nationale de traitement automatis\u00e9 des infractions  pour traiter et classer les \nimages provenant des radars photo. L\u2019objectif \u00e9tant de fiabiliser la constatation des \ninfractions.  \n\u25cf La Direction d\u00e9partementale des territoires et de la mer de l\u2019H\u00e9rault  a mis en place un \nprototype pour  int\u00e9grer l\u2019IA. Les images satellites sont utilis\u00e9es pour rep\u00e9rer les nouveaux \nobjets ou les nouvelles utilisations irr\u00e9guli\u00e8res du sol en les comparant \u00e0 d\u2019anciennes \nimages. Ceci permet de reconnaitre les irr\u00e9gularit\u00e9s et d\u2019am\u00e9liorer l\u2019efficacit\u00e9 des \ncont r\u00f4les. Une \u00ab  augmentation de la charge de travail li\u00e9e aux suites judiciaires  \u00bb est en \nrevanche pr\u00e9vue.  \n\u25cf La Direction g\u00e9n\u00e9rale", "doc_id": "f210f2a0-87df-43e2-be5a-1a1b879c0e1c", "embedding": null, "doc_hash": "c152de1cf4062250689852dafc5b46e1bf6517ada4a515f7a5bbb498401f60ae", "extra_info": {"page_label": "18", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2794}, "relationships": {"1": "0f9725b7-540e-465f-a768-5f4b06210203", "3": "75b7a919-cb53-48e3-998c-bd38a6682eed"}}, "__type__": "1"}, "75b7a919-cb53-48e3-998c-bd38a6682eed": {"__data__": {"text": "\u00e9tant de fiabiliser la constatation des \ninfractions.  \n\u25cf La Direction d\u00e9partementale des territoires et de la mer de l\u2019H\u00e9rault  a mis en place un \nprototype pour  int\u00e9grer l\u2019IA. Les images satellites sont utilis\u00e9es pour rep\u00e9rer les nouveaux \nobjets ou les nouvelles utilisations irr\u00e9guli\u00e8res du sol en les comparant \u00e0 d\u2019anciennes \nimages. Ceci permet de reconnaitre les irr\u00e9gularit\u00e9s et d\u2019am\u00e9liorer l\u2019efficacit\u00e9 des \ncont r\u00f4les. Une \u00ab  augmentation de la charge de travail li\u00e9e aux suites judiciaires  \u00bb est en \nrevanche pr\u00e9vue.  \n\u25cf La Direction g\u00e9n\u00e9rale des collectivit\u00e9s locales  souhaite faciliter le travail des agents en \npr\u00e9fecture en triant gr\u00e2ce \u00e0 l\u2019IA les actes envoy\u00e9s par les  collectivit\u00e9s locales (terme \nd\u00e9signant en France les municipalit\u00e9s, les d\u00e9partements et les r\u00e9gions) et faire apparaitre \nceux qui n\u00e9cessitent un contr\u00f4le ou un traitement prioritaire.  ", "doc_id": "75b7a919-cb53-48e3-998c-bd38a6682eed", "embedding": null, "doc_hash": "0991e89f8b73929f7df75e05db97e220b74e763278e40261a3808279ab3507f0", "extra_info": {"page_label": "18", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2239, "end": 3115}, "relationships": {"1": "0f9725b7-540e-465f-a768-5f4b06210203", "2": "f210f2a0-87df-43e2-be5a-1a1b879c0e1c"}}, "__type__": "1"}, "152cedda-0414-4aff-bdac-a3d164adcd21": {"__data__": {"text": " \n \n14 \n \u25cf La Direction g\u00e9n\u00e9rale de la Gendarmerie nationale  tente d\u2019am\u00e9liorer le syst\u00e8me de \npr\u00e9plainte en ligne pour faire gagner du temps aux agents et aux plaignants. L\u2019IA \npermettra d\u2019identifier des questions \u00e0 poser pour recevoir la plainte.  \n\u25cf  La Direction g\u00e9n\u00e9rale des douanes et des droits indirects  entend utiliser le text mining  \n(qui utilise un algorithme d\u2019analyse linguistique pour d\u00e9tecter le sens d\u2019un document) \npour d\u00e9tecter les fausses d\u00e9clarations douani\u00e8res qui tentent de faire passer un produit \ndans une mauvaise cat\u00e9gorie.  \n\u25cf La Direction g\u00e9n\u00e9rale des entreprises  veut utilis er l\u2019IA pour am\u00e9liorer la s\u00e9curit\u00e9 \n\u00e9conomique en d\u00e9tectant les risques li\u00e9s \u00e0 des entreprises. L\u2019objectif est de croiser \ndiff\u00e9rentes donn\u00e9es pour mettre en place un syst\u00e8me de veille et pr\u00e9venir les atteintes \naux int\u00e9r\u00eats \u00e9conomiques de la France.  \n\u25cf Dans le cadre du programme EIG, le d\u00e9fi CibNav utilise diff\u00e9rents algorithmes pour aider \nla Direction des affaires maritimes dans le contr\u00f4le des navires.  \n\u25cf L\u2019Autorit\u00e9 de s\u00fbret\u00e9 nucl\u00e9aire  a mis en place un prototype d\u2019utilisation de l\u2019IA bas\u00e9e sur \nl\u2019analyse de lettres d\u2019inspection. L\u2019objectif est de d\u00e9tecter les tendances et mieux cibler \nles contr\u00f4les \u00e0 effectuer. Cela a demand\u00e9 une forte mobilisation des agents, mais les \npremiers r\u00e9sultats de l\u2019algorithme sont satisfaisants.  \nJustice  \n\u25cf Un des projets dans le ca dre des AMI pr\u00e9voit d\u2019utiliser les donn\u00e9es de jurisprudence de \ndiff\u00e9rentes Cours (Cour de cassation et Cours d\u2019appel). Gr\u00e2ce \u00e0 l\u2019IA, il sera possible de \nd\u00e9tecter quand la loi fait l\u2019objet d\u2019interpr\u00e9tations diff\u00e9rentes et ainsi permettre une \nuniformisation.   \n\u25cf Pour rendre la justice plus efficace, le  Conseil d\u2019\u00c9tat  souhaite utiliser l\u2019IA pour d\u00e9tecter \nautomatiquement les s\u00e9ries de contentieux et les similitudes dans les requ\u00eates. Ceci \npermettra de prendre des d\u00e9cisions communes sur plusieurs contentieux.  \n\u25cf Dans  le cadre du Programme EIG, plusieurs d\u00e9fis li\u00e9s \u00e0 la justice utilisent des algorithmes \n(DITP et al., 2018C ). \nAutres  \n\u25cf Le Centre national Ch\u00e8que emploi associatif  au sein de l\u2019Agence centrale des organismes \nde s\u00e9curit\u00e9 sociale  test actuellement un \u00ab  voice bot  \u00bb nomm\u00e9 ODEIS pour r\u00e9pondre aux \nquestions su r l\u2019utilisation du ch\u00e8que emploi associatif. L\u2019objectif est d\u2019am\u00e9liorer le service \naux usagers, mais \u00e9galement d\u2019utiliser le travail des agents pour des t\u00e2ches plus \nvalorisantes. ODEIS a pour le moment un taux de bonnes r\u00e9ponses de 80% et doit \u00eatre \nlivr\u00e9 au d\u00e9but de l\u2019ann\u00e9e 2020.  \n\u25cf Un autre d\u00e9fi dans le cadre du programme EIG, le d\u00e9fi Plume, utilise diff\u00e9rentes \ntechniques de traitement du langage et de donn\u00e9es pour assister les juridictions \nfinanci\u00e8res au sein de la Cour des comptes.  \n\u25cf Dans le", "doc_id": "152cedda-0414-4aff-bdac-a3d164adcd21", "embedding": null, "doc_hash": "b9cebe6a21f538f79fe06b8146e683fb2eb91fef59e5f4db20765e07ce5fb1db", "extra_info": {"page_label": "19", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2741}, "relationships": {"1": "8ba59f68-d87a-4eba-a736-f82b9d60a472", "3": "1434173b-9c9e-458e-9add-ff3d9e02970f"}}, "__type__": "1"}, "1434173b-9c9e-458e-9add-ff3d9e02970f": {"__data__": {"text": " \u00bb nomm\u00e9 ODEIS pour r\u00e9pondre aux \nquestions su r l\u2019utilisation du ch\u00e8que emploi associatif. L\u2019objectif est d\u2019am\u00e9liorer le service \naux usagers, mais \u00e9galement d\u2019utiliser le travail des agents pour des t\u00e2ches plus \nvalorisantes. ODEIS a pour le moment un taux de bonnes r\u00e9ponses de 80% et doit \u00eatre \nlivr\u00e9 au d\u00e9but de l\u2019ann\u00e9e 2020.  \n\u25cf Un autre d\u00e9fi dans le cadre du programme EIG, le d\u00e9fi Plume, utilise diff\u00e9rentes \ntechniques de traitement du langage et de donn\u00e9es pour assister les juridictions \nfinanci\u00e8res au sein de la Cour des comptes.  \n\u25cf Dans le cadre du recense ment de la population, l\u2019Institut national de la statistique et des \n\u00e9tudes \u00e9conomiques  veut d\u00e9velopper un moteur de recommandation permettant \nd\u2019identifier l\u2019\u00e9tablissement employeur du r\u00e9pondant pour am\u00e9liorer la pr\u00e9cision des \nstatistiques.  ", "doc_id": "1434173b-9c9e-458e-9add-ff3d9e02970f", "embedding": null, "doc_hash": "dfa3a0f3ead8abb5d21d5cb5ab65c27ef535b2bfeeb1028032d16ddaaddc95c7", "extra_info": {"page_label": "19", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2187, "end": 3004}, "relationships": {"1": "8ba59f68-d87a-4eba-a736-f82b9d60a472", "2": "152cedda-0414-4aff-bdac-a3d164adcd21"}}, "__type__": "1"}, "8ec9f2ff-6b2d-4b04-b1ec-7db9510c7c09": {"__data__": {"text": " \n \n15 \n \u25cf Le minist\u00e8re des  Arm\u00e9es  s\u2019est dot\u00e9 d\u2019une feuille de route sur l\u2019IA et a lanc\u00e9 le projet      \nArtemis  en 2017, pour cr\u00e9er un espace de partage et d\u2019utilisation des donn\u00e9es ( DGA, \n2018 ) \n\u25cf La Gendarmerie utilise des donn\u00e9es et statistiques pour cr\u00e9er des mod\u00e8les pr\u00e9dictifs sur \nla criminalit\u00e9 et aider la prise de d\u00e9cision. Elle r\u00e9fl\u00e9chit \u00e9galement \u00e0 l\u2019utilisation des \ndonn\u00e9es pour pr\u00e9dire les besoins en maintenance de son parc de v\u00e9hicule ( Vincent, \n2017 ).  \n \nFacteurs habilitants et contr aignants  \nLes initiatives \u00e9tant encore \u00e0 un stade embryonnaire ou en phase de prototypage, il est difficile \nde faire ressortir les facteurs habilitants et contraignants de mani\u00e8re exhaustive. Nous avons \ncependant tent\u00e9 de faire \u00e9merger les \u00e9l\u00e9ments document\u00e9s jusqu\u2019 \u00e0 pr\u00e9sent dans les documents \n\u00e9tudi\u00e9s qui donnent une id\u00e9e des d\u00e9fis li\u00e9s \u00e0 l\u2019int\u00e9gration de l\u2019intelligence artificielle. Nous avons \n\u00e9galement identifi\u00e9 les outils pr\u00e9vus pour pallier aux difficult\u00e9s appr\u00e9hend\u00e9es.  \nFacteurs contraignants  \nD\u00e9fis de gestion de s donn\u00e9es  \n\u25cf Dans le cadre du programme Entrepreneurs d\u2019int\u00e9r\u00eat g\u00e9n\u00e9ral (EIG), des entrepreneurs \nsont appel\u00e9s \u00e0 travailler pour r\u00e9pondre \u00e0 des d\u00e9fis de l\u2019administration publique. Ils \nrencontrent cependant des difficult\u00e9s li\u00e9es \u00e0 la qualit\u00e9 et la quantit\u00e9 de d onn\u00e9es, \u00e0 un \nmat\u00e9riel et des serveurs parfois peu propices au traitement des donn\u00e9es ( Augusti, 2019 ). \nD\u00e9fis \u00e9thiques/ en jeux soci\u00e9taux  \n\u25cf Il y a un certain d\u00e9calage \u00e9galement entre le gouvernement central et les r\u00e9gions, qui ont \nmoins recours \u00e0 l\u2019intelligence artificielle. Il y a donc une n\u00e9cessit\u00e9 de commencer \u00e0 outiller \nles collectivit\u00e9s ( Nessi, 2019 ). \u00c0 ce sujet, le Conseil d\u2019\u00c9tat propose dans son \u00e9tude annuelle \nde 2017, que les opportunit\u00e9s cr \u00e9\u00e9es par les plateformes num\u00e9riques soient int\u00e9gr\u00e9es \ndans la conception et la mise en \u0153uvre des politiques de lutte contre les in\u00e9galit\u00e9s \nterritoriales et le d\u00e9veloppement de la capacit\u00e9 des territoires, afin d\u2019utiliser leur \ncontribution pour lutter contre  la fracture sociale ( Conseil d\u2019\u00c9tat, 2017 ). \nD\u00e9fis manag\u00e9 riaux  \n\u25cf Certains fonctionnaires remarquent les limites d\u2019une approche \u00ab purement \ntechnologique  \u00bb fond\u00e9e sur une culture informatique (TOUSSAIN, 2016, p4). Celle -ci peut \nd\u00e9boucher  sur un clivage entre les \u00ab d\u00e9cideurs  \u00bb et les \u00ab techniciens  \u00bb dont le r\u00f4le \ns\u2019arr\u00eaterait \u00e0 d\u00e9livrer des services imagin\u00e9s par les premiers ( Fl\u00e9chaux, 2016 ) ce qui peut \nentrainer des incompr\u00e9hensions ou des initiatives inop\u00e9rables.   \n\u25cf Dans le cadre des candidatures pour l\u2019Appel \u00e0 manifestation d\u2019int\u00e9r\u00eat (AMI), un certain \nnombre de d\u00e9fis de mise en \u0153uvre ont \u00e9t\u00e9 identifi\u00e9s comme devant \u00eatre relev\u00e9s ( DITP et \nal., 2018C ). \no En ce qui", "doc_id": "8ec9f2ff-6b2d-4b04-b1ec-7db9510c7c09", "embedding": null, "doc_hash": "84ce2f1eeaa67bf1d43d09cca1d55bcf6ad458986b57dd583229cd23fe684d96", "extra_info": {"page_label": "20", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2722}, "relationships": {"1": "3951ca83-bdfb-47d6-8700-0d89916f6517", "3": "b32bc6f1-a3d4-43b9-81b3-6760b22b6aa2"}}, "__type__": "1"}, "b32bc6f1-a3d4-43b9-81b3-6760b22b6aa2": {"__data__": {"text": "sur une culture informatique (TOUSSAIN, 2016, p4). Celle -ci peut \nd\u00e9boucher  sur un clivage entre les \u00ab d\u00e9cideurs  \u00bb et les \u00ab techniciens  \u00bb dont le r\u00f4le \ns\u2019arr\u00eaterait \u00e0 d\u00e9livrer des services imagin\u00e9s par les premiers ( Fl\u00e9chaux, 2016 ) ce qui peut \nentrainer des incompr\u00e9hensions ou des initiatives inop\u00e9rables.   \n\u25cf Dans le cadre des candidatures pour l\u2019Appel \u00e0 manifestation d\u2019int\u00e9r\u00eat (AMI), un certain \nnombre de d\u00e9fis de mise en \u0153uvre ont \u00e9t\u00e9 identifi\u00e9s comme devant \u00eatre relev\u00e9s ( DITP et \nal., 2018C ). \no En ce qui concerne les voice bots , il faut r\u00e9aliser des tests satisfaisants pour que les \nr\u00e9ponses soient pertinentes avant leur mise en application.  \no R\u00e9fl\u00e9chir \u00e0 l\u2019int\u00e9gration des nouveaux outils au sein de la cha\u00eene d e contr\u00f4le auxquels \nils participeront  ", "doc_id": "b32bc6f1-a3d4-43b9-81b3-6760b22b6aa2", "embedding": null, "doc_hash": "396d02ea4d483da2d29965fad25f26d58e219212ee395969324c4fcc71bf3b63", "extra_info": {"page_label": "20", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2199, "end": 2977}, "relationships": {"1": "3951ca83-bdfb-47d6-8700-0d89916f6517", "2": "8ec9f2ff-6b2d-4b04-b1ec-7db9510c7c09"}}, "__type__": "1"}, "22bf9175-42d1-4b4f-b4fe-144ec2535aa8": {"__data__": {"text": " \n \n16 \n o L\u2019adaptation de l\u2019outil \u00e0 l\u2019environnement de travail (ex.  : Interface avec les autres \noutils)  \no L\u2019accompagnement des utilisateurs des outils, g\u00e9n\u00e9ralement des employ\u00e9s de l\u2019\u00c9tat  \no Mise en \u0153uvre effective de l\u2019extraction de donn\u00e9es structur\u00e9es pr\u00e9vue au d\u00e9part  \n\u25cf Dans le cadre du programme Entrepreneurs d\u2019int\u00e9r\u00eat g\u00e9n\u00e9ral (EIG), l es entrepreneurs \nrencontrent parfois la n\u00e9cessit\u00e9 d\u2019expliquer leur m\u00e9tier ou les pr\u00e9requis n\u00e9cessaires \u00e0 \nl\u2019int\u00e9gration de l\u2019intelligence artificielle  (Augusti, 2019 ). \nFacteurs habilitants  \nD\u00e9veloppement de l\u2019outil et mise en \u0153uvre  \n\u25cf L\u2019identification par les minist\u00e8res des  enjeux de transformation.  \n\u25cf Rencontrer les employ\u00e9s de l\u2019\u00c9tat impact\u00e9s par l\u2019introduction de l\u2019intelligence artificielle \net identifier certains enjeux avec eux (voir co -d\u00e9velopper les prototypes).  \n\u25cf Organiser des pr\u00e9sentations de vulgarisation aupr\u00e8s des employ\u00e9s de l\u2019\u00c9tat et r\u00e9diger des \nnotes pour la hi\u00e9rarchie.  \n\u25cf Choisir des algorithmes pouvant \u00eatre interpr\u00e9t\u00e9s par les employ\u00e9s de l\u2019\u00c9tat.  \n\u25cf Accompagner les acteurs une fois le prototype d\u00e9velopp\u00e9 afin de faciliter le changement.  \nD\u00e9veloppement de l\u2019\u00e9cosyst\u00e8me \n\u25cf Encourager la cr\u00e9ation de liens entre l\u2019administration publique et les chercheurs.  \n\u25cf Cr\u00e9er des interactions entre les diff\u00e9rents acteurs au sein de l\u2019\u00e9cosyst\u00e8me pour former \nune communaut\u00e9 d\u2019acteurs publics en IA.  \n \nPratiques inspirantes  \nEn place  \n\u2022 La mise sur pied d\u2019\u00e9quipes d\u00e9di\u00e9es \u00e0 r\u00e9soudre des probl\u00e8mes de l\u2019administration en un \ntemps restreint et en faisant appel \u00e0 l\u2019intelligence artificielle porte ses fruits, que ce soit \ndans le cadre des startups d\u2019\u00c9tat ou du programme Entrepreneurs d\u2019int\u00e9r\u00eat g\u00e9n\u00e9ral (EIG ).  \n\u2022 La constitution d\u2019un comit\u00e9 interminist\u00e9riel qui se retrouve deux fois par an pour s\u2019assurer \nde la mise en \u0153uvre des transformations.  \n\u2022 La cr\u00e9ation du Lab IA comme structure pour accompagner les administrations .  \n\u00c0 surveiller  \n\u2022 Les projets mis sur pied dans le cadre des Appels \u00e0 manifestation d\u2019int\u00e9r\u00eat (AMI) sont \nencore en cours, et les outils d\u00e9velopp\u00e9s en phase de prototypage ou de test. Les r\u00e9sultats \nde ces projets seront \u00e0 surveiller, car la mise en place d\u2019un accompagnement technique \net d\u2019 un accompagnement scientifique sur ce mod\u00e8le pourrait constituer une pratique \ninspirante .  \n  ", "doc_id": "22bf9175-42d1-4b4f-b4fe-144ec2535aa8", "embedding": null, "doc_hash": "817473d417e6a91fadf8e2a91e8dbb34123b24af2abf0e3501062c1c38039622", "extra_info": {"page_label": "21", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2303}, "relationships": {"1": "cf68e250-56e7-4bf5-a2e5-450db965699f"}}, "__type__": "1"}, "975e0ace-7b55-4ee4-b683-42d26d5c370f": {"__data__": {"text": " \n \n17 \n Le cas de l\u2019Allemagne  \nLes faits saillants  \n\u2022 La strat\u00e9gie de l\u2019Allemagne repose d\u2019abord sur la recherche en multipliant les projets et \nles financements  pour la recherche. L\u2019accent est \u00e9galement mis sur une meilleure \ncompr\u00e9hension des enjeux soci\u00e9taux et des impacts de l\u2019IA avant de se lancer dans des \ninitiatives concr\u00e8tes.  \n\u2022 La strat\u00e9gie souhaite inscrire le d\u00e9veloppement de l\u2019IA dans la d\u00e9marche plus g\u00e9n\u00e9 rale de \nl\u2019Union europ\u00e9enne et se coordonner avec les autres pays.  \n\u2022 Il existe encore peu de cas concrets d\u2019utilisation de l\u2019IA dans le secteur public et les \nminist\u00e8res, b\u00e9n\u00e9ficiant d\u2019une grande ind\u00e9pendance, semblent se concentrer chacun sur \nleurs propres p rojets. Nous avons tout de m\u00eame recens\u00e9 quelques projets dans divers \ndomaines.  \n \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  \nEn mars 2016, le minist\u00e8re f\u00e9d\u00e9ral de l\u2019\u00c9conomie et de l\u2019\u00c9nergie  publie la Strat\u00e9gie num\u00e9rique \n2025  qui pose la premi\u00e8re base de la d\u00e9marche qui m\u00e8nera ensuite \u00e0 la strat\u00e9gie sur l\u2019intelligence \nartificielle. La Strat\u00e9gie sur l\u2019intelligence artificielle  a \u00e9t\u00e9 \u00e9labor\u00e9e par le minist\u00e8re f\u00e9d\u00e9ral de \nl\u2019\u00c9ducation et de la Recherche , le m inist\u00e8re f\u00e9d\u00e9ral de l\u2019\u00c9conomie et de l\u2019\u00c9nergie  et le minist\u00e8re \nf\u00e9d\u00e9ral du Travail et des Affaires sociales . Elle a \u00e9t\u00e9 publi\u00e9e en novembre 2018 et assortie d\u2019une \nsomme de 3 milliards d\u2019euros pour que l\u2019Allemagne conserve sa place de leader \u00e0 l\u2019\u00e9chelle \ninternationale ( Miller et Stirling, 2019 ).  \nLa strat\u00e9gie priorise d\u2019abord le domaine de la recherche sur l\u2019IA, identifi\u00e9 comme \u00e9tant d\u00e9j\u00e0 \u00e0 un \nexcellent niveau en Allemagne. La strat\u00e9gie souhaite \u00e9galement inscrire l\u2019int\u00e9gration de la \npolitique de l\u2019IA dans un dialogue soci\u00e9tal (notamment autour des questions et crit\u00e8res \u00e9thiques) \net met des ressources \u00e0 disposition pour cela. La r\u00e9flexion de l\u2019Allemagne porte \u00e9galement sur la \nquestion du travail et de ses transformations, que ce soit au travers de la strat\u00e9gie ou par la \npublication d\u2019un livre blanc ( minist\u00e8re f\u00e9d\u00e9ral du T ravail et des  Affaires sociales, 2017 ). Une autre \npriorit\u00e9 consiste \u00e0 lier l\u2019IA \u00e0 des avanc\u00e9es et des applications technologiques exploitables par \ndiff\u00e9rents secteurs, dont l\u2019administration publique. En somme, cette strat\u00e9gie vise \u00e0 d\u00e9velopper \nl\u2019IA \u00e0 travers la recherc he pour ensuite l\u2019int\u00e9grer dans l\u2019administration publique, et non de la \nd\u00e9velopper directement au sein du secteur public. Cette logique repose sur l\u2019id\u00e9e d\u2019utiliser ce qui \na \u00e9t\u00e9 d\u00e9velopp\u00e9 ailleurs pour en faire profiter l\u2019administration publique et les infrastructures de \nr\u00e9seau de l\u2019\u00c9tat f\u00e9d\u00e9ral. L\u2019IA est identifi\u00e9e dans la strat\u00e9gie comme pouvant \u00ab am\u00e9liorer \nl\u2019efficacit\u00e9, la", "doc_id": "975e0ace-7b55-4ee4-b683-42d26d5c370f", "embedding": null, "doc_hash": "06cacf0a72bab411f5a2399b421443ded3d0df685f279990860fcb43a3a03943", "extra_info": {"page_label": "22", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2680}, "relationships": {"1": "c3855e5b-d97e-4ffc-be2d-88ee00bb79dc", "3": "354cd449-3190-4c88-a326-92bb5867c51f"}}, "__type__": "1"}, "354cd449-3190-4c88-a326-92bb5867c51f": {"__data__": {"text": "exploitables par \ndiff\u00e9rents secteurs, dont l\u2019administration publique. En somme, cette strat\u00e9gie vise \u00e0 d\u00e9velopper \nl\u2019IA \u00e0 travers la recherc he pour ensuite l\u2019int\u00e9grer dans l\u2019administration publique, et non de la \nd\u00e9velopper directement au sein du secteur public. Cette logique repose sur l\u2019id\u00e9e d\u2019utiliser ce qui \na \u00e9t\u00e9 d\u00e9velopp\u00e9 ailleurs pour en faire profiter l\u2019administration publique et les infrastructures de \nr\u00e9seau de l\u2019\u00c9tat f\u00e9d\u00e9ral. L\u2019IA est identifi\u00e9e dans la strat\u00e9gie comme pouvant \u00ab am\u00e9liorer \nl\u2019efficacit\u00e9, la qualit\u00e9 et la s\u00e9curit\u00e9 des services administratifs  \u00bb de l\u2019administration publique \n(gouvernement f\u00e9d\u00e9ral, 2018 ). Plus sp\u00e9cifiquement, la strat\u00e9gie pr\u00e9voit une am\u00e9lioration des \nservices aux citoyens ainsi qu\u2019une am\u00e9lioration des processus d\u00e9cisionnels et une acc\u00e9l\u00e9ration \ndes actes administratifs. La strat\u00e9gie pr\u00e9voit \u00e9galement de mettre l\u2019IA au service des forces de \ns\u00e9curit\u00e9 pour aider \u00e0 pr\u00e9venir les menaces int\u00e9rieures et ext\u00e9rieures. En ce qui concerne \nl\u2019utilisation de l\u2019IA par l\u2019arm\u00e9e, il est pr\u00e9vu pour le moment que le gouvernement proc\u00e8de \u00e0 une \n\u00e9valuation des avantages et inconv\u00e9nients. Enfin, il est pr\u00e9vu d\u2019utiliser l\u2019IA pour am\u00e9liorer la \ns\u00e9curit\u00e9 de l\u2019Allemagne comme site \u00e9conomique.  ", "doc_id": "354cd449-3190-4c88-a326-92bb5867c51f", "embedding": null, "doc_hash": "8ba646e1837165597ea255c8c57f20eeebd727d4bcea806a63af4ae55ef117ef", "extra_info": {"page_label": "22", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2156, "end": 3389}, "relationships": {"1": "c3855e5b-d97e-4ffc-be2d-88ee00bb79dc", "2": "975e0ace-7b55-4ee4-b683-42d26d5c370f"}}, "__type__": "1"}, "1188d14b-64fe-4d60-a59d-1b4d66cdec8d": {"__data__": {"text": " \n \n18 \n Il faut toutefois noter que les minist\u00e8res disposent d\u2019une grande ind\u00e9pendance et le s initiatives \nd\u2019int\u00e9gration de l\u2019IA dans le secteur public se multiplient donc de fa\u00e7ons individuelles. Les \nminist\u00e8res r\u00e9fl\u00e9chissent \u00e0 l\u2019int\u00e9gration au sein de leur organisme sans que ce soit n\u00e9cessairement \ndans une d\u00e9marche concert\u00e9e. L\u2019un des objectifs p oursuivis avec la strat\u00e9gie est de donner un \ncadre pour l\u2019arrimage des diff\u00e9rentes initiatives.  \nLe dialogue soci\u00e9tal a commenc\u00e9 avant m\u00eame la publication du livre blanc et de la strat\u00e9gie. Un \ngrand projet de consultation a eu lieu qui a men\u00e9 \u00e0 fa\u00e7onner ce s documents. Des discussions se \nsont d\u00e9roul\u00e9es avec diff\u00e9rentes parties prenantes, qu\u2019il s\u2019agisse d\u2019experts, de syndicats ou \nd\u2019organismes non gouvernementaux. Des \u00e9changes ont \u00e9galement \u00e9t\u00e9 organis\u00e9s avec des \ncitoyens. Ceci a permis de privil\u00e9gier un syst\u00e8 me de discussions ouvert et continu et non d\u2019avoir \nrecours \u00e0 un programme  politique pr\u00e9\u00e9tabli. Les conseils des experts sont r\u00e9guli\u00e8rement tenus \nen compte afin d\u2019assurer un processus d\u2019am\u00e9lioration continue et d\u2019\u00eatre plus r\u00e9actif aux \n\u00e9volutions constantes dans le domaine de l\u2019IA. Un an seulement apr\u00e8s sa publication, la strat\u00e9gie \nest d\u2019ailleurs d\u00e9j\u00e0 en r\u00e9vision.  \n\u00c0 la suite du lancement de la strat\u00e9gie, plusieurs instances ont \u00e9t\u00e9 cr\u00e9\u00e9es ( AlgorithmWatch et al. , \n2019 ). Le Cabinet Committee on Digitalisation  discute des questions sur l\u2019IA et des solutions \ns\u2019inscrivant dans la strat\u00e9gie. Le Digital Council  est un organe cons ultatif directement rattach\u00e9 \u00e0 \nla Chancellerie et rassemble des experts pour encourager les \u00e9changes entre le politique et les \nexperts. Il a \u00e9galement pour objectif de contribuer \u00e0 mettre en \u0153uvre les projets s\u2019inscrivant dans \nle cadre de la strat\u00e9gie. La Commission d\u2019enqu\u00eate K\u00fcnstliche Intelligenz \u2013  Gesellschaftliche \nWerantwortung und wirtschaftliche, soziale und \u00f6kologische Potenziale (Intelligence artificielle \u2013  \nresponsabilit\u00e9 sociale et potentiel \u00e9conomique, social et \u00e9cologique) a \u00e9t\u00e9 mise en place en juin \n2018 et se compose de d\u00e9put\u00e9s et d\u2019experts. La commission a pour mandat de produire des \nrecommandations concernant les opportunit\u00e9s et les d\u00e9fis li\u00e9s \u00e0 l\u2019IA, ainsi que ses effets sur le \ntravail, sur l\u2019\u00e9conomie, sur le secteur public, l\u2019\u00e9conomie, la so ci\u00e9t\u00e9 et les individus. \nL\u2019administration publique fait partie des secteurs au centre de son travail ( AlgorithmWatch et al. , \n2019 ). Enfin, une Commission sur l\u2019\u00e9thique des donn\u00e9es a \u00e9t\u00e9 mise en place par le gouvernement.  \nPlusieurs structures ont \u00e9galement \u00e9t\u00e9 annonc\u00e9es par le gouvernement pour d\u00e9velopper ou \nr\u00e9fl\u00e9chir \u00e0 l\u2019intelligence artificielle. En janvier 2020, un ins titut sera cr\u00e9\u00e9 au sein du Centre \na\u00e9rospatial allemand pour r\u00e9fl\u00e9chir \u00e0 la fuite de donn\u00e9e satellitaire et la freiner ( Allemagne", "doc_id": "1188d14b-64fe-4d60-a59d-1b4d66cdec8d", "embedding": null, "doc_hash": "dc52bdcc419b2445b7dffdfd17b0c7eaa6e1d7fad6b2f94bf7660c5092f046b1", "extra_info": {"page_label": "23", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2807}, "relationships": {"1": "9e15f5a1-bf3b-4bc5-8764-d8c363c4c175", "3": "b946eb91-e836-44c7-a653-d45867483643"}}, "__type__": "1"}, "b946eb91-e836-44c7-a653-d45867483643": {"__data__": {"text": "sur l\u2019\u00e9conomie, sur le secteur public, l\u2019\u00e9conomie, la so ci\u00e9t\u00e9 et les individus. \nL\u2019administration publique fait partie des secteurs au centre de son travail ( AlgorithmWatch et al. , \n2019 ). Enfin, une Commission sur l\u2019\u00e9thique des donn\u00e9es a \u00e9t\u00e9 mise en place par le gouvernement.  \nPlusieurs structures ont \u00e9galement \u00e9t\u00e9 annonc\u00e9es par le gouvernement pour d\u00e9velopper ou \nr\u00e9fl\u00e9chir \u00e0 l\u2019intelligence artificielle. En janvier 2020, un ins titut sera cr\u00e9\u00e9 au sein du Centre \na\u00e9rospatial allemand pour r\u00e9fl\u00e9chir \u00e0 la fuite de donn\u00e9e satellitaire et la freiner ( Allemagne \nDiplomatie, 2019 ). Il a \u00e9galement \u00e9t\u00e9 annonc\u00e9 la cr\u00e9ation en janvier 2020 d\u2019un p\u00f4le de recherche \nsur l\u2019intelligence artificielle dans le domaine de la sant\u00e9 ( Allemagne Diplomatie, 2019 ) financ\u00e9 en \npartie par le minist\u00e8re de l\u2019\u00c9ducation et de la Recherche .  \nL\u2019ouverture pr\u00e9vue pour mars 2020 d\u2019 un observatoire sur l\u2019Intelligence artificielle ( Munsberg, \n2019 ) attach\u00e9 \u00e0 un Policy lab est un projet du minist\u00e8re du Travail et des Affaires sociale s. \nL\u2019Observatoire a une structure innovante, car il est int\u00e9gr\u00e9 \u00e0 la structure interne du minist\u00e8re et \nest compos\u00e9 de 5 \u00e0 6 personnes issues de ses diff\u00e9rentes divisions. Il dispose d\u2019un budget de 6.5 \nmillions de dollars par an, et il sera d\u00e9cid\u00e9 s\u2019il devient permanent d\u2019ici 2 \u00e0 3 ans. Il se penche sur \nl\u2019\u00e9volution de la force technologique, l\u2019aide \u00e0 la prise de d\u00e9cision, le cadre r\u00e9glementaire  \n(notamment au niveau europ\u00e9en) et la diffusion (en encourageant l\u2019engagement et les d\u00e9bats \npublics incluant les par ties prenantes). Un projet en cours est l\u2019\u00e9laboration d\u2019un guide de lignes ", "doc_id": "b946eb91-e836-44c7-a653-d45867483643", "embedding": null, "doc_hash": "5f241a3b0c7430f4ed85ffd687f4b5ad5f43bdd0c99b9b2428d8d7dbcb05100a", "extra_info": {"page_label": "23", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2239, "end": 3859}, "relationships": {"1": "9e15f5a1-bf3b-4bc5-8764-d8c363c4c175", "2": "1188d14b-64fe-4d60-a59d-1b4d66cdec8d"}}, "__type__": "1"}, "8dc65f67-4f59-4cb1-8b6c-a2265cbd6b89": {"__data__": {"text": " \n \n19 \n directrices pour les projets d\u2019IA dans l\u2019administration des affaires sociales qui sera adapt\u00e9 et r\u00e9vis\u00e9 \npar les praticiens de niveau sup\u00e9rieur lors de rencontres trimestrielles.  \nLa strat\u00e9gie de l\u2019Allemagne prend \u00e9galement en compte les d\u00e9veloppements de l\u2019IA au sein de \nl\u2019Union europ\u00e9enne et de l\u2019importance d\u2019arrimer les travaux avec ceux des autres \u00c9tats.  \n \nCas concrets d\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  \nSant\u00e9  \n\u2022 Dans le domaine de la sant\u00e9, une r\u00e9flexion est pour le moment men\u00e9e autour de \nl\u2019utilisation de l\u2019IA pour la d\u00e9tection pr\u00e9coce des maladies et la th\u00e9rapie personnalis\u00e9e \ncontre le cancer.   \n\u2022 Le minist\u00e8re de l\u2019\u00c9ducation et de la Recherche  finance la Medizininformatik -Initiative , une \ninitiative qui regroupe h\u00f4pitaux, chercheurs, entreprises priv\u00e9es, assureurs et groupe de \nd\u00e9fense des patients. L\u2019 objectif  de cette initiative est de regrou per les donn\u00e9es et \nfavoriser leur utilisation dans la recherche et dans le soin des patients.  \nAffaires \u00e9trang\u00e8res  \n\u2022 Le minist\u00e8re des Affaires \u00e9trang\u00e8res a mis sur pieds des petites \u00e9quipes de diplomatie \nnum\u00e9rique et un \u00ab  digital diplomacy network  \u00bb pour appr endre des autres pays et mieux \ncomprendre les effets de l\u2019IA et notamment ses effets g\u00e9opolitiques.  Il a aussi nomm\u00e9 un \nambassadeur ayant comme fonction le num\u00e9rique et l\u2019intelligence artificielle. Le \nminist\u00e8re s\u2019est \u00e9galement dot\u00e9 d\u2019une strat\u00e9gie pour r\u00e9fl\u00e9chir \u00e0 comment travailler dans \nle futur, \u00e0 la question de la protection des donn\u00e9es et des fonctions des ambassades. Deux \nprojets plus concrets ont \u00e9galement \u00e9t\u00e9 mis en \u0153uvre : \no Le minist\u00e8re des Affaires \u00e9trang\u00e8res  utilise la communication strat\u00e9gique \u00e0 l\u2019aide \nd\u2019un algorithme d\u2019\u00e9coute des m\u00e9dias sociaux ( social media listening) pour suivre \nles publications qui ont un effet sur le minist\u00e8re et sur la politique ext\u00e9rieure \nallemande. Cet outil pourrait \u00eatre \u00e9largi dans le futur pour analyser les effets \npoten tiellement n\u00e9gatifs de campagnes ou de tendances politiques de pays \next\u00e9rieurs, et pour y r\u00e9agir.  \no Le minist\u00e8re des Affaires \u00e9trang\u00e8res  a mis en place le projet \u00ab Preview  \u00bb. Il utilise \nun programme de reconnaissance qui anticipe les points de tension de cer tains \npays en crise sous forme de carte g\u00e9ographique, et qui apporte une aide \u00e0 la \nd\u00e9cision au ministre.  \nEmploi  \n\u2022 L\u2019Agence f\u00e9d\u00e9rale de l\u2019emploi  a d\u00e9velopp\u00e9 un nouveau syst\u00e8me de traitement des \ndonn\u00e9es. Le nouveau syst\u00e8me rep\u00e8re les programmes d\u00e9ficients et l es am\u00e9liore ou les \n\u00e9limine. Il am\u00e9liore aussi la capacit\u00e9 de l\u2019Agence \u00e0 d\u00e9finir et \u00e9valuer les caract\u00e9ristiques \ndes usagers afin de faire un ciblage plus efficace pour ses programmes de placement et \nses services de conseil. Les donn\u00e9es utilis\u00e9es sont entre autres les ant\u00e9c\u00e9dents des \nch\u00f4meurs, les", "doc_id": "8dc65f67-4f59-4cb1-8b6c-a2265cbd6b89", "embedding": null, "doc_hash": "dd1e406f96ccf257ded3a6c9d1b911d0ce7958342c743f4bcff4db93752be6fb", "extra_info": {"page_label": "24", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2800}, "relationships": {"1": "19e568b1-e141-41cb-8c28-ef1c0b6f5980", "3": "ab08ece0-e381-4c4c-a70b-1e00b0b85b67"}}, "__type__": "1"}, "ab08ece0-e381-4c4c-a70b-1e00b0b85b67": {"__data__": {"text": "et qui apporte une aide \u00e0 la \nd\u00e9cision au ministre.  \nEmploi  \n\u2022 L\u2019Agence f\u00e9d\u00e9rale de l\u2019emploi  a d\u00e9velopp\u00e9 un nouveau syst\u00e8me de traitement des \ndonn\u00e9es. Le nouveau syst\u00e8me rep\u00e8re les programmes d\u00e9ficients et l es am\u00e9liore ou les \n\u00e9limine. Il am\u00e9liore aussi la capacit\u00e9 de l\u2019Agence \u00e0 d\u00e9finir et \u00e9valuer les caract\u00e9ristiques \ndes usagers afin de faire un ciblage plus efficace pour ses programmes de placement et \nses services de conseil. Les donn\u00e9es utilis\u00e9es sont entre autres les ant\u00e9c\u00e9dents des \nch\u00f4meurs, les interventions effectu\u00e9es et leur r\u00e9sultat et les d\u00e9lais individuels \u00e0 r\u00e9int\u00e9grer \nle march\u00e9 du travail (Manyika et al., 2011 ).  ", "doc_id": "ab08ece0-e381-4c4c-a70b-1e00b0b85b67", "embedding": null, "doc_hash": "f3c73fb8262cf3dd58f24d5de477c7b1279a823197fbd922ea7535fb32bddc94", "extra_info": {"page_label": "24", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2287, "end": 2930}, "relationships": {"1": "19e568b1-e141-41cb-8c28-ef1c0b6f5980", "2": "8dc65f67-4f59-4cb1-8b6c-a2265cbd6b89"}}, "__type__": "1"}, "d57af40c-0ec6-42f6-9423-4e435ffc5df5": {"__data__": {"text": " \n \n20 \n Gestion de crise  \n\u2022 Un projet financ\u00e9 par le minist\u00e8re de l\u2019\u00c9ducation et de la Recherche  et en collaboration \navec la France porte actuellement sur les r\u00e9seaux de transport sous -terrain et la gestion \nde crise. L\u2019objectif est d\u2019utiliser l\u2019IA pour reconna\u00eetre les vuln\u00e9rabilit\u00e9s du r\u00e9seau et \ntrouv er les issues de secours ainsi que la meilleure route d\u2019\u00e9vacuation en cas de crise. Il \ns\u2019agit d\u2019un projet men\u00e9 par des chercheurs, mais qui, \u00e0 terme, aura un impact sur les \nagents du secteur public. Le projet en est d\u00e9j\u00e0 \u00e0 une phase de test.  \n\u2022 Le minist\u00e8re de l\u2019Int\u00e9rieur  a mis en place une initiative et cr\u00e9\u00e9 un laboratoire \u00e0 l\u2019Agence \nde secours pour utiliser l\u2019IA dans la pr\u00e9paration aux catastrophes ( gouvernement f\u00e9d\u00e9ral, \n2019 ). \nPolice  \n\u2022 Le minist\u00e8re de l\u2019Int\u00e9rieur  a \u00e9galement mis en place une initiative sur la cybers\u00e9curit\u00e9 au \nsein de l\u2019Office f\u00e9d\u00e9ral de la s\u00e9curit\u00e9 de l\u2019information par la cr\u00e9ation d\u2019une unit\u00e9 \n\u00ab intelligence artificielle  \u00bb (gouvernement f\u00e9d\u00e9ral, 2019 ). \n\u2022 La Police f\u00e9d\u00e9rale r\u00e9alise des tests sur l\u2019utilisation de la reconnaissance faciale dans les \ngares  ( Groth, Olab et al. 2019 ).  \nAutres  \n\u2022 Des projets sont en cours au sein de l\u2019arm\u00e9e pour utiliser l\u2019intelligence artificielle pour \nfaciliter la format ion des soldats.  \n\u2022 En partenariat avec la fondation Mozilla, le  minist\u00e8re f\u00e9d\u00e9ral du D\u00e9veloppement  et de la \nCoop\u00e9ration \u00e9conomique  (BMZ) a lanc\u00e9 un projet pour le d\u00e9veloppement des services en \nlignes dans diff\u00e9rentes langues africaines ( minist\u00e8re f\u00e9d\u00e9ral pour la coop\u00e9ration \n\u00e9conomique et le d\u00e9veloppement,  2019 ).  \n\u2022 Le minist\u00e8re f\u00e9d\u00e9ral du D \u00e9veloppement et de la Coop\u00e9ration \u00e9conomique (BMZ) utilise \n\u00e9galement l\u2019IA pour le traitement du courrier qu\u2019il re\u00e7oit ( Groth, Olab et al. 2019 ).  \nFacteurs habilitants et contraignants  \nFacteurs contraign ants  \nLes documents consult\u00e9s font \u00e9tat de diff\u00e9rents d\u00e9fis identifi\u00e9s par l\u2019Allemagne pour l\u2019int\u00e9gration \nde l\u2019IA dans le secteur public. Le d\u00e9fi apparait tout d\u2019abord au niveau \u00e9thique dans le cadre de \nl\u2019utilisation de l\u2019IA pour l\u2019aide \u00e0 la d\u00e9cision dans le domaine de la sant\u00e9 et lorsque le pronostic vital \nd\u2019un patient est engag\u00e9. Des d\u00e9fis apparaissent \u00e9galement au niveau social et juridique, sur la \nquestion de la protection des donn\u00e9es, ainsi que concernant le besoin de responsabilit\u00e9 et de \ntransparence.  \nD\u00e9fis l\u00e9gaux  \nD\u00e9fis en mati\u00e8re de gouvernance  \n\u2022 La relation entre les approches r\u00e9glementaires peut entrainer des contradictions entre la \nvolont\u00e9 d\u2019avoir une approche horizontale au niveau de la Commission europ\u00e9enne, et les \napproches verticales d\u00e9j\u00e0 existantes dans le domaine de la sant\u00e9, de la s\u00e9curit \u00e9, de la \nprotection des consommateurs et du transport notamment.  ", "doc_id": "d57af40c-0ec6-42f6-9423-4e435ffc5df5", "embedding": null, "doc_hash": "5592725123a9d190fe88229553046fa4d7e3f9fbf7ee7f33c764e86e41077e36", "extra_info": {"page_label": "25", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2727}, "relationships": {"1": "efbf3b52-2a27-4f51-8b8a-1a09cc9fc1d0"}}, "__type__": "1"}, "fc828adb-d45f-4185-b8f8-a9994da12a03": {"__data__": {"text": " \n \n21 \n D\u00e9fis manag\u00e9riaux  \nFormation des fonctionnaires  \n\u2022 Le manque de formation dans le domaine num\u00e9rique dans le corps public, avec une \nminorit\u00e9 de fonctionnaires qui ont une \u00e9ducation en informatiqu e ou en math\u00e9matiques, \net le manque d\u2019embauche de personnels qui disposent d\u2019une formation dans ce domaine \nce qui le rend inadapt\u00e9 \u00e0 r\u00e9pondre \u00e0 ces d\u00e9fis. Par exemple, on note que l\u2019administration \npublique n\u2019est pas assez rapide pour suivre les changements .  Les fonctionnaires ne sont \npas au courant des probl\u00e8mes, des risques ou des b\u00e9n\u00e9fices li\u00e9s au num\u00e9rique et aux \nnouvelles technologies.  \nStrat\u00e9gie d\u2019innovation incr\u00e9mentale  \n\u2022 Il est difficile de changer la culture de certains m\u00e9tiers pour permettre l\u2019int\u00e9g ration de l\u2019IA \ndans les pratiques. C\u2019est par exemple le cas du minist\u00e8re des A ffaires \u00e9trang\u00e8res , la \ndiplomatie constituant un m\u00e9tier traditionnel et sa structure devant \u00eatre enti\u00e8rement \nchang\u00e9e pour g\u00e9rer les probl\u00e8mes et probl\u00e9matiques modernes.  \n\u2022 Le manqu e d\u2019initiative des fonctionnaires d\u00e9j\u00e0 en fonction pour op\u00e9rer une \ntransformation interne.  \nStrat\u00e9gie globale  \n\u2022 L\u2019ind\u00e9pendance des minist\u00e8res dans le syst\u00e8me f\u00e9d\u00e9ral allemand entraine une dispersion \ndes projets en IA et un certain manque d\u2019orientation g\u00e9n\u00e9ra le.  \nFacteurs habilitants  \nL\u2019Allemagne identifie certaines conditions de succ\u00e8s \u00e0 l\u2019int\u00e9gration de l\u2019IA dans le secteur public  : \n\u2022 Garantir un contr\u00f4le suffisant et une transparence dans le cadre de l\u2019utilisation de l\u2019IA \npour pr\u00e9venir la menace int\u00e9rieure et ext\u00e9rieure.  \n\u2022 La disponibilit\u00e9 des donn\u00e9es, qu\u2019elles soient structur\u00e9es et qu\u2019elles puissent \u00eatre trait\u00e9es \nde la mani\u00e8re la plus compl\u00e8te possible.  \n\u2022 La qualit\u00e9 et la compatibilit\u00e9 des donn\u00e9es  \n\u2022 La promotion des projets de recherche portant sur les aspects \u00e9th iques, juridiques et \nsociaux.  \n\u2022 Le rassemblement d\u2019acteurs interdisciplinaires autour de la question de l\u2019IA et la cr\u00e9ation \nd\u2019espaces exp\u00e9rimentaux  \n\u2022 La formation des travailleurs \u00e0 l\u2019IA.  \n\u2022 Le fait de penser en avance au transfert pour une application plus large de solution ayant \nrecourt \u00e0 l\u2019IA.  \n\u2022 L\u2019importance du consentement du patient, la protection et la s\u00e9curit\u00e9 des donn\u00e9es dans \nle cadre d\u2019un usage en sant\u00e9.  \n \nPratiques inspirantes  \nEn place  \n\u2022 L\u2019importance que donne l\u2019Allemagne aux crit\u00e8res \u00e9thiques et \u00e0 l\u2019animation d\u2019un dialogue \nsoci\u00e9tal sur l\u2019int\u00e9gration de l\u2019Intelligence artificielle constitue une pratique inspirante. Il \nest important de noter que ce dialogue porte \u00e0 la fois sur des consid\u00e9ra tions \u00e9thiques, ", "doc_id": "fc828adb-d45f-4185-b8f8-a9994da12a03", "embedding": null, "doc_hash": "80d4e55ba10d2e8b5fe18a0395a560796d099f24294e56b403ed9769c00ab204", "extra_info": {"page_label": "26", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2537}, "relationships": {"1": "73c51e20-e10d-48c1-a8bc-b6e86408c306"}}, "__type__": "1"}, "1f212c68-5704-4aa8-a508-215f9f26f82c": {"__data__": {"text": " \n \n22 \n mais \u00e9galement sur les impacts sur le travail. Ce d\u00e9bat est soutenu par la cr\u00e9ation de \nstructures administratives (observatoires), de commissions rassemblant \u00e9lus et experts \nsur ces enjeux, ainsi que de financements pour la recherche.  \n\u2022 Tech 4germany est un programme  cr\u00e9\u00e9 en 2018 par une petite entreprise de jeunes \nentrepreneurs qui cherche \u00e0 faire avancer la num\u00e9risation de l\u2019\u00e9tat allemand par des \nprojets technologiques et un syst\u00e8me de bourses d\u2019\u00e9tudes pour les citoyens allemands \n(Meier, 2019 ).  Elle n\u2019appartient pas au gouvernement, mais y propose ses services. Son \nfonctionnement est centr\u00e9 sur le besoin des utilisateurs, les m\u00e9thodes de d\u00e9veloppement \ndites \u00ab  Agiles  \u00bb et une technologie de pointe gr\u00e2ce \u00e0 des \u00e9quipes pluridisciplinaires \n(d\u00e9veloppeurs, designers, \u00e9tudiants, etc.) qui travaillent sur des projets temporaires \n(Tech4germany ). En 2019, Tech4germany a effectu\u00e9 des projets en partenariat avec 6 \nminist\u00e8res f\u00e9d\u00e9raux et en 2020, ce groupe passera sous la direction de la Chancellerie \npour constituer l\u2019\u00e9quipe de transformation num\u00e9rique du gouvernement f\u00e9d\u00e9ral \n(Tech 4germany ). \n\u00c0 surveiller  \n\u2022 La strat\u00e9gie de l\u2019Allemagne mise sur l\u2019int\u00e9gration de l\u2019Intelligence artificielle apr\u00e8s un \nd\u00e9ve loppement \u00e0 l\u2019ext\u00e9rieur du secteur public et apr\u00e8s avoir d\u00e9battu sur les enjeux \nsoci\u00e9taux que l\u2019IA soul\u00e8ve. Il s\u2019agit d\u2019une strat\u00e9gie qui diff\u00e8re de celle des autres pays, et \nil sera int\u00e9ressant de voir comment cela aboutit.  \n\u2022 Un laboratoire pour valider le s projets en intelligence artificielle au sein du gouvernement \nf\u00e9d\u00e9ral est en cours de d\u00e9veloppement. Il comprendra un centre de comp\u00e9tences et d\u2019IA, \nce qui permettra de concentrer les comp\u00e9tences qui peuvent \u00eatre utilis\u00e9es par les \ndiff\u00e9rents d\u00e9partements ou de leur apporter un soutien.  \n  ", "doc_id": "1f212c68-5704-4aa8-a508-215f9f26f82c", "embedding": null, "doc_hash": "73e7f1accc607a1ed7ad6b24f176edab79e9bb8b1418c9a1677aa9cc2baeaaf0", "extra_info": {"page_label": "27", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 1801}, "relationships": {"1": "4820631e-88ee-41b1-871d-0154ab40dc09"}}, "__type__": "1"}, "7f2a3325-054d-490b-ab22-a1744d05f9ac": {"__data__": {"text": " \n \n23 \n Le cas d\u2019Isra\u00ebl  \nLes faits saillants  \n\u2022 Isra\u00ebl n\u2019a pas encore de strat\u00e9gie nationale en IA, mais son \u00e9laboration est en cours. L\u2019IA \nen Isra\u00ebl est vue en premier lieu comme un moyen de d\u00e9velopper l\u2019\u00e9conomie, et les \nactions du gouvernement se sont essentiellement orient\u00e9es dans cette direction. Au vu \ndes effets b\u00e9n\u00e9fiques que cela a pu avoir, on envisage maintenant l\u2019utilisation de l\u2019IA dans \nle secteur public.  \n\u2022 Le gouvernement a d\u00e9velopp\u00e9 une infrastructure num\u00e9rique dans le sect eur public qui \npourrait favoriser l\u2019int\u00e9gration de l\u2019IA.  \n\u2022 L\u2019\u00e9cosyst\u00e8me en technologies avanc\u00e9es est d\u00e9velopp\u00e9 autour de Tel -Aviv et concentre \nmultinationales, startups et centres de recherche dans un environnement qui favorise \nl\u2019innovation. L\u2019IA est un dom aine qui catalyse de plus en plus d\u2019int\u00e9r\u00eat et \nd\u2019investissement. Cet aspect est un facteur habilitant, \u00e9tant donn\u00e9 la tr\u00e8s grande \n\u00ab maturit\u00e9 technologique \u00bb d\u2019Isra\u00ebl.  \n\u2022 Isra\u00ebl a pris plusieurs initiatives concernant le d\u00e9veloppement d\u2019un capital humain en I A, \nnotamment \u00e0 travers des formations universitaires dans ce domaine et les formations \ndans les unit\u00e9s techniques de l\u2019arm\u00e9e. Cette constitution d\u2019une force de travail pourrait \n\u00eatre mobilis\u00e9e par le secteur public en vue de l\u2019int\u00e9gration de l\u2019IA.  \n\u2022 La majorit\u00e9 des initiatives en IA semblent se d\u00e9velopper au sein de l\u2019arm\u00e9e.  \n \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  \nJusqu\u2019\u00e0 r\u00e9cemment, le gouvernement isra\u00e9lien a davantage \u00e9t\u00e9 per\u00e7u comme un agent \nfacilitateur qui comble les d\u00e9faillances du  march\u00e9 en finan\u00e7ant certains secteurs et en adoptant \nune r\u00e9glementation  favorable \u00e0 l\u2019innovation ( Israel Innovation Authority, 2019 ), que comme un \nagent i nt\u00e9grateur de l\u2019IA . L\u2019adoption d\u2019une strat\u00e9gie nationale n\u2019a d\u2019ailleurs commenc\u00e9 \u00e0 \u00eatre \nenvisag\u00e9e que r\u00e9cemment.  \nIsra\u00ebl est reconnu pour son expertise dans les technologies de pointe et dans le domaine de l\u2019IA \nou de la cybers\u00e9curit\u00e9 (ICDK, 2019) . La conce ntration d\u2019acteurs et de structures d'innovation \n(acc\u00e9l\u00e9rateurs, incubateurs, laboratoires d\u2019innovation, etc.) en fait un des plus grands \n\u00e9cosyst\u00e8mes en IA du monde, derri\u00e8re les \u00c9tats -Unis et la Chine ( Scheer, 2019 ).  Cependant, ceci \nse fait surtout \u00e0 travers les nombreuses multinationales et startups (Korbert , 2019). Cet \n\u00e9cosyst\u00e8me est tourn\u00e9 vers l\u2019international, et les solutions et produits d\u00e9velopp\u00e9s sont souvent \ndestin\u00e9s \u00e0 \u00eatre export\u00e9s vers les march\u00e9s ext\u00e9rieurs (\u00c9tats -Unis et Europe notamment ), ce qui \nfreine l\u2019utilisation de l\u2019IA sur les march\u00e9s interne s (DG Tr\u00e9sor, 2017).  Le gouvernement isra\u00e9lien a \nparticip\u00e9 \u00e0 la croissance de l\u2019IA. Il a effectu\u00e9 des investissements continus et mis en place une", "doc_id": "7f2a3325-054d-490b-ab22-a1744d05f9ac", "embedding": null, "doc_hash": "1e2fc94d8febbbdccb2fbf153e355dcd8e81215697da7df28ca65370b32c5167", "extra_info": {"page_label": "28", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2703}, "relationships": {"1": "7dc68786-080d-4550-93c2-afd965f6d5f0", "3": "319d334a-49c1-44af-a261-0dfcc14a73ec"}}, "__type__": "1"}, "319d334a-49c1-44af-a261-0dfcc14a73ec": {"__data__": {"text": "du monde, derri\u00e8re les \u00c9tats -Unis et la Chine ( Scheer, 2019 ).  Cependant, ceci \nse fait surtout \u00e0 travers les nombreuses multinationales et startups (Korbert , 2019). Cet \n\u00e9cosyst\u00e8me est tourn\u00e9 vers l\u2019international, et les solutions et produits d\u00e9velopp\u00e9s sont souvent \ndestin\u00e9s \u00e0 \u00eatre export\u00e9s vers les march\u00e9s ext\u00e9rieurs (\u00c9tats -Unis et Europe notamment ), ce qui \nfreine l\u2019utilisation de l\u2019IA sur les march\u00e9s interne s (DG Tr\u00e9sor, 2017).  Le gouvernement isra\u00e9lien a \nparticip\u00e9 \u00e0 la croissance de l\u2019IA. Il a effectu\u00e9 des investissements continus et mis en place une \nr\u00e9glementation favorable \u00e0 l\u2019innovation ( Israel Innovation Authority, 2019 ). Il a aussi r\u00e9pondu au \nbesoin croissant de capital humain qualifi\u00e9 en IA par l\u2019organisation de boot -camp de codage extra -\nacad\u00e9mique, en facilitant l\u2019entr\u00e9e d\u2019immigrants qualifi\u00e9s en haute technologie et en finan\u00e7ant \nl\u2019\u00e9ducation sup\u00e9rieure sp\u00e9cialis\u00e9e en IA ( Scheer, 2019 ). Ce financement a permis d\u2019ouvrir des \ncentres dans les universit\u00e9s isra\u00e9liennes, d\u2019offrir des bourses postdoctorales, et de lancer des \nprogrammes de recherches sur l\u2019AI dans le secteur public ( Scheer, 2019 ).  ", "doc_id": "319d334a-49c1-44af-a261-0dfcc14a73ec", "embedding": null, "doc_hash": "8b792b32776f31ad2773334a8c9e5048816ee417da9321d32bfb5b53d9174823", "extra_info": {"page_label": "28", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2132, "end": 3275}, "relationships": {"1": "7dc68786-080d-4550-93c2-afd965f6d5f0", "2": "7f2a3325-054d-490b-ab22-a1744d05f9ac"}}, "__type__": "1"}, "30544676-c464-4660-9005-207b35b14897": {"__data__": {"text": " \n \n24 \n En d\u00e9cembre 2019, Israel Innovation Authority  souligne dans son rapport annuel la n\u00e9cessit\u00e9 \nd\u2019adopter une strat\u00e9gie nationale  \u00e9labor\u00e9e conjointement par le gouvernement, le secteur \nacad\u00e9mique et l\u2019industrie ( Israel Innovation Authority, 2019 ). Elle souligne dans son rapport, que \nle r\u00f4le du gouvernement serait principalement d\u2019adopter une r\u00e9gulation qui favorise  l\u2019innovation, \net, en tant que producteur de donn\u00e9es au c\u00f4t\u00e9 des soci\u00e9t\u00e9s technologiques, d\u2019ouvrir les bases de \ndonn\u00e9es publiques aux chercheurs ( Israel Innov ation Authority, 2019 ). Les enjeux de \nconfidentialit\u00e9 et de transparence sont identifi\u00e9s comme une pr\u00e9occupation \u00e0 prendre en compte \n(Israel Innovation Aut hority, 2019 ), mais il n\u2019est pas fait allusion \u00e0 la mise en place d\u2019un cadre \n\u00e9thique. \u00c0 la suite de cet appel, le Comit\u00e9 d\u2019\u00e9valuation des progr\u00e8s en IA, compos\u00e9 de 15 sous -\ncomit\u00e9s, a r\u00e9uni 300 cadres sup\u00e9rieurs provenant du gouvernement, des \u00e9tablisseme nts \nd\u2019enseignement sup\u00e9rieur et de l\u2019industrie des technologies. Il a soumis une s\u00e9rie de \nrecommandations au gouvernement en d\u00e9cembre 2019 ( Berkovitz, 2019 ). Le s principales \nrecommandations concernent la num\u00e9risation des services publics, la construction d\u2019un \u00ab  nuage  \nIA \u00bb, le transport intelligent, le d\u00e9veloppement de l\u2019agriculture digitale et la mise en place d\u2019une \nproc\u00e9dure \u00e9thique \u00e0 suivre pour les chercheurs en IA ( Berkovitz, 2019 ).  Elles seront \u00e9tudi\u00e9es par \nle gouvernement en d\u00e9but 2020 ( Berkovitz, 2019 ).  \nN\u00e9anmoins, Isra\u00ebl dispose d\u00e9j\u00e0 d\u2019une infrastructure digitale dans le secteur public, un pr\u00e9alable \nn\u00e9cessaire \u00e0 l\u2019incorporation de diff\u00e9rentes technologies d\u2019IA ( Androutsopoulou et al., 2019 ). Des \nactions sont prises telles que la num\u00e9risation des services, le d\u00e9veloppement de l\u2019 e-\ngouvernement2, et la meilleure accessibilit\u00e9 des donn\u00e9es gouvernementales pour les citoyens et \nles acteurs priv\u00e9s (ICDK, 2019). Le gouvernement semble \u00e9galement donner de l\u2019importance au \nfait d\u2019\u00e9viter les in\u00e9galit\u00e9s dans la r\u00e9partition des b\u00e9n\u00e9fices de la num\u00e9risation, notamment dans \nles groupes  les plus d\u00e9favoris\u00e9s ( minist\u00e8re de l\u2019\u00e9galit\u00e9 sociale , 2017 ). \nCes actions commencent en 2013  avec l\u2019Initiative nationale  sur l\u2019utilisation des  technologies de \nl\u2019information et de la communication  (TIC) dans le secteur public. Les objectifs sont alors \nl\u2019efficience d u secteur public,  l\u2019am\u00e9lioration  les services en ligne et la r\u00e9duction de  la bureaucratie \n(gouvernement d\u2019Isra\u00ebl, 2015 ). Par la suite, on accroit les comp\u00e9tences de  Digital Isra\u00ebl , une unit\u00e9 \ncentrale du minist\u00e8re de  l\u2019\u00e9galit\u00e9 sociale . Digital Isra\u00ebl joue un r\u00f4le cl\u00e9 dans la mise en place de \nl\u2019architecture digitale, et maintenant dans l\u2019\u00e9laboration de la strat\u00e9gie en IA . On lui confie la \nmission de d\u00e9velopper le Programme Digital N ational , et de", "doc_id": "30544676-c464-4660-9005-207b35b14897", "embedding": null, "doc_hash": "6971240c1337a8a0bc7fd6bfb605ebe0eef1d787e4cf30a3e18229d64cdd599d", "extra_info": {"page_label": "29", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2819}, "relationships": {"1": "fbd55246-7dcb-4857-881b-ae346f25b1e0", "3": "9ff27a2f-436d-4d0b-918c-f1ed0afa0e36"}}, "__type__": "1"}, "9ff27a2f-436d-4d0b-918c-f1ed0afa0e36": {"__data__": {"text": "et de la communication  (TIC) dans le secteur public. Les objectifs sont alors \nl\u2019efficience d u secteur public,  l\u2019am\u00e9lioration  les services en ligne et la r\u00e9duction de  la bureaucratie \n(gouvernement d\u2019Isra\u00ebl, 2015 ). Par la suite, on accroit les comp\u00e9tences de  Digital Isra\u00ebl , une unit\u00e9 \ncentrale du minist\u00e8re de  l\u2019\u00e9galit\u00e9 sociale . Digital Isra\u00ebl joue un r\u00f4le cl\u00e9 dans la mise en place de \nl\u2019architecture digitale, et maintenant dans l\u2019\u00e9laboration de la strat\u00e9gie en IA . On lui confie la \nmission de d\u00e9velopper le Programme Digital N ational , et de mettre en place les pr ogrammes \ndigitaux interminist\u00e9riels  et minist\u00e9riels, et d\u2019assurer la collaboration intersectorielle avec les \nacteurs externes (population, OBNL, industrie, acteurs priv\u00e9s et acad\u00e9miques) ( minist\u00e8re de \nl\u2019\u00e9galit\u00e9 sociale , 2017 ). Le Programme Digital N ational  de 2017- 2020  identifie 9 domaines \ncentraux qui sont les principales sph\u00e8res d\u2019activit\u00e9s dans lesquelles il y a place pour des \nam\u00e9liorations num\u00e9riques , et qui guident la formulation et la coordination  des plans num\u00e9riques \nde chaque minist\u00e8re ( minist\u00e8re de l\u2019\u00e9galit\u00e9 sociale , 2017 ).  Digital National est au centre de \nplusieurs initiatives telles que Digital Health  avec le minist\u00e8re de la Sant\u00e9, Digital \u00c9ducation avec \ncelui de l\u2019\u00e9ducation, Digital Economy  avec celui de l\u2019\u00e9conomie et Digital Welfare  avec celui des \naffaires sociales. Depuis 2014, on avance \u00e9galement dans la mise en place de l\u2019 e-gouvernem ent. \nDans un premier temps, on cherche  plus \u00e0 \u00e9tablir  une infrastructure et des unit\u00e9s pour assister \n                                                           \n2 L\u2019e-gouvernement fait r\u00e9f\u00e9rence \u00e0 l\u2019utilisation des TICs combin\u00e9e avec un processus de t ransformation \norganisationnelle pour am\u00e9liorer les structures et op\u00e9rations du gouvernement qui permet par la suite de d\u00e9velopper \ndes projets digitaux innovants (Damascene Twizeyimanaa, 2019)  ", "doc_id": "9ff27a2f-436d-4d0b-918c-f1ed0afa0e36", "embedding": null, "doc_hash": "c19b4f320c00d1de97a19d8cf20315162bdc184f012ce925b575c08fd4571ebd", "extra_info": {"page_label": "29", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2261, "end": 4184}, "relationships": {"1": "fbd55246-7dcb-4857-881b-ae346f25b1e0", "2": "30544676-c464-4660-9005-207b35b14897"}}, "__type__": "1"}, "1869d25b-0f1d-4032-afdc-2ea79f07b888": {"__data__": {"text": " \n \n25 \n les activit\u00e9s du e-gouvernement  et dans l\u2019optique de se diriger vers un gouvernement ouvert3 en \ninstaurant une politique pour ouvrir les bases de donn\u00e9es de l\u2019\u00e9tat au public  et en am\u00e9liorant \nl\u2019utilisation du site web du gouvernement et des agences gouvernementales ( gouvernement \nd\u2019Isra\u00ebl, 2015 ). Malgr\u00e9 ces efforts,  le e-gouvernement  reste peu d\u00e9velopp\u00e9  et accuse du retard  en \ncomparaison  aux pays europ\u00e9ens les plus avanc\u00e9s ( UN, 2018 ). La num\u00e9r isation de services est en \ncours , mais non compl\u00e9t\u00e9e  dans tous les minist\u00e8res ( Filter, 2018 ). En mati\u00e8re d\u2019acc\u00e8s et d e qualit\u00e9 \ndes donn\u00e9es publiques, Isra\u00ebl est seulement en 28e place sur 58 pays (United Nations, 2018 ) \nLe gouvernement se penche actuellement sur l\u2019expansion de l\u2019\u00e9conomie Govtech  en pr\u00e9voyant \nl\u2019ouverture de centres de d\u00e9veloppement et de laboratoires d\u2019innovation pour les startups  (Filter, \n2018 ). Ce terrain pourrait \u00eatre fertile pour int\u00e9grer l\u2019expertise d\u00e9velopp\u00e9e par les startups dans \nl\u2019administration publique.  La Division des d\u00e9fis sociaux  de l\u2019 Israel Innovation Authority , dont une \ndes missions est de promouvoir l\u2019utilisation de l\u2019entrepreneuriat technologique et la R&D pour \nr\u00e9soudre les d\u00e9fis sociaux et publics a d\u00e9velopp\u00e9 en partenariat avec le minist\u00e8re de l\u2019\u00c9galit\u00e9  \nsociale  le Programme de d\u00e9fis pour le secteur public qui a d\u00e9j\u00e0 financ\u00e9 57 projets innovants ( Israel \nInnovation Authority, 2019 ). Pour  r\u00e9pondre \u00e0 un d\u00e9fi local du secteur public, les startups \nproposent leurs projets pilotes et font une d\u00e9monstration de faisabilit\u00e9 ( Israel Innovation \nauthority ). Elles peuvent obtenir l\u2019autorisation de tester leur prototype \u00e0 grande \u00e9chelle sur la \nbase d\u2019une infrastructure nationale tel qu\u2019un h\u00f4pital ( Filter, 2018 ). Le financement est \nconditionnel au succ\u00e8s du projet, notamment \u00e0 sa phase de commercialisation qui permet de \nrembourser l\u2019\u00e9tat sous forme de redevances ( Autorit\u00e9 d\u2019innovation isra\u00e9lienne, 2018 ). Cela \nd\u00e9montre la volont\u00e9 d\u2019Isra\u00ebl de d\u00e9velopper une expertise en dehors de l\u2019appareil public, mais \npose la question de l\u2019approvisionnement.  \n \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  \n\u2022 L\u2019arm\u00e9e semble \u00eatre le plus  grand utilisateur, investisseur et d\u00e9veloppeur de l\u2019IA au sein \ndu secteur public ( Scheer, 2019 ; Growth et al., 2019 ). Il est cependant difficile d\u2019acc\u00e9der \n\u00e0 des donn\u00e9es publiques sur ces initiatives. D\u00e8s les ann\u00e9es 70, la D\u00e9fense  a mis en place \ndes unit\u00e9s technologiques pour d\u00e9velopper des syst\u00e8mes de collecte de renseignements \nbas\u00e9s sur les technologies d\u2019apprentissage profond (Scheer , 2019 ). Cela a permis la \nformation d\u2019une communaut\u00e9 d\u2019ing\u00e9nieurs et de chercheurs qualifi\u00e9s  qui s\u2019est ensuite \ndirig\u00e9e vers l\u2019industrie ( Scheer, 2019 ). Les forces arm\u00e9es  isra\u00e9liennes font appel \u00e0 l\u2019IA dans \nle", "doc_id": "1869d25b-0f1d-4032-afdc-2ea79f07b888", "embedding": null, "doc_hash": "c91b600d2537d70db7b37ba8ad88f21afaabe60f95c912735b35c1c4614cad1f", "extra_info": {"page_label": "30", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2830}, "relationships": {"1": "abe3e6cd-e8b9-4374-8e20-1321515b6e88", "3": "fb761f9a-8f88-400d-b587-a089566c1ebd"}}, "__type__": "1"}, "fb761f9a-8f88-400d-b587-a089566c1ebd": {"__data__": {"text": "l\u2019IA au sein \ndu secteur public ( Scheer, 2019 ; Growth et al., 2019 ). Il est cependant difficile d\u2019acc\u00e9der \n\u00e0 des donn\u00e9es publiques sur ces initiatives. D\u00e8s les ann\u00e9es 70, la D\u00e9fense  a mis en place \ndes unit\u00e9s technologiques pour d\u00e9velopper des syst\u00e8mes de collecte de renseignements \nbas\u00e9s sur les technologies d\u2019apprentissage profond (Scheer , 2019 ). Cela a permis la \nformation d\u2019une communaut\u00e9 d\u2019ing\u00e9nieurs et de chercheurs qualifi\u00e9s  qui s\u2019est ensuite \ndirig\u00e9e vers l\u2019industrie ( Scheer, 2019 ). Les forces arm\u00e9es  isra\u00e9liennes font appel \u00e0 l\u2019IA dans \nle cadre de l\u2019utilisation des drones ( Growth et al., 2019 ). \n\u2022 Le programme national Digital Health pr\u00e9voit d\u2019ouvrir les bases de donn\u00e9es sur la sant\u00e9 \ndes patients afin d\u2019utiliser des techniques d\u2019IA pour d\u00e9tecter les anomalies et poser des \ndiagnosti cs plus pr\u00e9cis (J\u00e9rusal em post, 2018). Les chercheurs pourront avoir acc\u00e8s \u00e0 des \ndonn\u00e9es g\u00e9nomiques et clinique s, ce qui repr\u00e9sente une opportunit\u00e9 assez cons\u00e9quente \npuisqu\u2019elles ont \u00e9t\u00e9 conserv\u00e9es et num\u00e9r is\u00e9es depuis les ann\u00e9es 90 ( minist\u00e8re de la \nSant\u00e9, 2018 ). Un des objectifs  est de d\u00e9velopper la m\u00e9decine personnalis\u00e9e ( Israel \nInnovation Authority, 2019 ).  \n                                                           \n3 Le gouvernement ouvert fait r\u00e9f\u00e9rence \u00e0 la transparence et \u00e0 l\u2019accessibilit\u00e9 des donn\u00e9es produites par le \ngouvernement, succ\u00e9d\u00e9 par la participation de la population et d\u2019acteurs externes dans ses activit\u00e9s par le biais des \nnouveaux instruments digitaux d \u00e9velopp\u00e9s (Damascene Twizeyimanaa, 2019).  ", "doc_id": "fb761f9a-8f88-400d-b587-a089566c1ebd", "embedding": null, "doc_hash": "795035c174e6956ffd17552349f4f343db9d25d0002e350539051c04d9e7f9d8", "extra_info": {"page_label": "30", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2267, "end": 3822}, "relationships": {"1": "abe3e6cd-e8b9-4374-8e20-1321515b6e88", "2": "1869d25b-0f1d-4032-afdc-2ea79f07b888"}}, "__type__": "1"}, "8b223a07-ab21-4824-9b4d-a46d4ae1595a": {"__data__": {"text": " \n \n26 \n \u2022 Plusieurs programmes utilis\u00e9s par l\u2019appareil de s\u00e9curit\u00e9 font appel aux startups. On peut \nciter l\u2019incubateur de startup Libertad Ventur es op\u00e9r\u00e9 par le  Mossad , qui travaille dans une \ndiversit\u00e9 de domaine tel que la robotique, le traitement du langage naturel, l\u2019analyse de \ntexte ou l\u2019intelligence web ( Orbatch, 2018 ). \n\u2022 Le programme  Digital leaders  est lanc \u00e9 en 2015 et offre une formation d\u2019une vingtaine \nde jours r\u00e9partis sur une ann\u00e9e  afin de former des agents publics en innovation digitale. \nEn plus d\u2019augmenter l eur litt\u00e9ratie digitale , ce programme  a permis \u00e0 Digital Israel , qui \norganise le programme de cr\u00e9er des liens avec ces agents qui deviennent des sortes \nd\u2019\u00ab ambassadeurs  \u00bb dans chaque minist\u00e8re (Filter, 2018 ).  \n\u2022 Il semble que l\u2019IA soit \u00e9galement utilis\u00e9e dans la lutte contre le blanchiment et le \nfinancement du terrorisme (DG  Tr\u00e9sor, 2017).  \n \nFacteurs habilitants et contraignants  \nFacteurs contraignants  \n\u2022 L\u2019export ation  des produits d\u00e9velopp\u00e9s par l\u2019\u00e9cosyst\u00e8me en IA ( centres de R&D et start-\nups) entraine un contraste \u00e9lev\u00e9 entre la  \u00ab maturit\u00e9 technologique  \u00bb qui est forte,  et une \nfaible \u00ab maturit\u00e9 d\u2019usage  \u00bb (Direction g\u00e9n\u00e9rale du Tr\u00e9sor, 2017 ) et donc de  diffusion de \nl\u2019IA dans la soci\u00e9t\u00e9 isra\u00e9lienne  et au sein du secteur public . \nD\u00e9fis l\u00e9gaux  \n\u2022 On constate qu\u2019il n\u2019y a pas encore eu d\u2019annonce sur l\u2019adoption d\u2019un cadre \u00e9thique en IA. \nCela pourrait particuli\u00e8rement affecter le gouvernement pour qui l\u2019utilisation et la \ndiffusion de l\u2019IA dans la soci\u00e9t\u00e9 risquent de n\u00e9cessiter une red\u00e9finition de son cadre l\u00e9gal \npar rapport \u00e0 sa mission de protection des droits citoyens, notamment en mati\u00e8 re de \nprotection des donn\u00e9es priv\u00e9es.  \nFacteurs habilitants  \nCollaboration  \n\u2022 La collaboration interminist\u00e9rielle qui est encadr\u00e9e par Digital Israel  est un facteur \nhabilitant pour d\u00e9velopper des services de qualit\u00e9 pour les citoyens ( Filter, 2018 ). La \nposture neutre adopt\u00e9e par l\u2019agence dont l\u2019unique agenda est de promouvoir les services \ndigitaux a permis d\u2019installer un climat de confiance avec les minist\u00e8res pour d\u00e9velopper \nconjointement des produits et des services rapidement ( Filter, 2018 ).  \n\u2022 Il y a des liens tr\u00e8s forts entre le secteur pub lic, acad\u00e9mique et le priv\u00e9 (qui regroupe les \nindustries, les startups et les investisseurs). Les transferts technologiques sont nombreux \nentre le secteur acad\u00e9mique et l\u2019industrie, et plusieurs compagnies d\u00e9marrent comme \ndes projets au sein d\u2019une universi t\u00e9 et sont ensuite rachet\u00e9 pour des sommes \u00e9lev\u00e9es par \ndes multinationales (Scheer, 2019 ). Reste \u00e0 voir si le transfert se fera \u00e9galement au \nb\u00e9n\u00e9fice de l\u2019administration  publique  \n\u2022 Un facteur de r\u00e9ussite de la strat\u00e9gie  sur la cybertechnologie que l\u2019on souhaite reproduire \ndans le cadre de l\u2019IA,  est de r\u00e9unir l\u2019industrie, le milieu de", "doc_id": "8b223a07-ab21-4824-9b4d-a46d4ae1595a", "embedding": null, "doc_hash": "0eeaafaa4fa20815000dc588cfb0185cb2ca86043d274fd11854a5d528baa05e", "extra_info": {"page_label": "31", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2846}, "relationships": {"1": "afb4c753-534a-4d63-8594-be657b02adb5", "3": "1737229d-4735-46d3-804b-37f1de91cf5d"}}, "__type__": "1"}, "1737229d-4735-46d3-804b-37f1de91cf5d": {"__data__": {"text": "les startups et les investisseurs). Les transferts technologiques sont nombreux \nentre le secteur acad\u00e9mique et l\u2019industrie, et plusieurs compagnies d\u00e9marrent comme \ndes projets au sein d\u2019une universi t\u00e9 et sont ensuite rachet\u00e9 pour des sommes \u00e9lev\u00e9es par \ndes multinationales (Scheer, 2019 ). Reste \u00e0 voir si le transfert se fera \u00e9galement au \nb\u00e9n\u00e9fice de l\u2019administration  publique  \n\u2022 Un facteur de r\u00e9ussite de la strat\u00e9gie  sur la cybertechnologie que l\u2019on souhaite reproduire \ndans le cadre de l\u2019IA,  est de r\u00e9unir l\u2019industrie, le milieu de l\u2019acad\u00e9mie sup\u00e9rieure, le \nsyst\u00e8me \u00e9ducatif, le gouvernement et le ministre de la D \u00e9fense da ns un projet national \nen soulignant les b\u00e9n\u00e9fices de chacun dans cette strat\u00e9gie ( Berkovitz, 2019 ).  ", "doc_id": "1737229d-4735-46d3-804b-37f1de91cf5d", "embedding": null, "doc_hash": "7c10f55ee007067a29b30c3fe522796b04f7b7ecc53ef3c04ca7ccb44a5254e5", "extra_info": {"page_label": "31", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2301, "end": 3045}, "relationships": {"1": "afb4c753-534a-4d63-8594-be657b02adb5", "2": "8b223a07-ab21-4824-9b4d-a46d4ae1595a"}}, "__type__": "1"}, "cde61f60-cf53-4451-85e2-3af2ca562b8d": {"__data__": {"text": " \n \n27 \n Capacit\u00e9  \n\u2022 Isra\u00ebl semble avoir une strat\u00e9gie bien implant\u00e9e d\u2019une formation de personnel pouvant \ntravailler en IA (notamment \u00e0 travers le service militaire). Cette force de travail pourrait \n\u00eatre int\u00e9gr\u00e9e au secteur public pour contribuer \u00e0 l\u2019int\u00e9gration de l\u2019IA.  \n \nPratiques inspirantes  \nEn place  \n\u2022 La ICT Authority  est mise en place d\u00e8s 2012. Elle fait la promotion du gouvernement \nouvert et participe activement au projet d\u2019instauration de l\u2019e -gouvernement. Une de ses \nmissions est de  : \u00ab servir de centre d\u2019information et d e conseils professionnels pour les \nservices informatiques  \u00bb et de \u00ab  mettre \u00e0 leur disposition des technologies de pointe pour \nam\u00e9liorer les services au public et minimiser la bureaucratie  \u00bb (ICT Authority, 2016 ). Cette \npratique permet aux minist\u00e8res d\u2019avoir un soutien technique dans le processus de \ntransformation num\u00e9rique, et semble particuli\u00e8rement pertinente pour accompagner les \nagents p ublics dans les projets qui int\u00e8grent des technologies avanc\u00e9es tel que l\u2019IA.  \n\u2022 La plupart des minist\u00e8res disposent d\u00e9j\u00e0 d\u2019un directeur du num\u00e9rique, qui centralise la \nposition \u00e0 l\u2019interne, et qui repr\u00e9sente un point de contact (proxy) avec Digital Israel  et \ndonc avec la strat\u00e9gie globale ( Filter, 2018 ). Tous les directeurs num\u00e9riques se \nrencontrent mensuellement pour partager les bonnes pratiques,  les informations les \nprojets, les initiatives et coordonner les efforts ( Filter, 2018 ). Parall\u00e8lement \u00e0 cela, en \npartenariat avec le Conseil g\u00e9 n\u00e9ral du Tr\u00e9sor, Digital Israel  aide les minist\u00e8res \u00e0 recruter \ndes Data scientists  qui permettent de redessiner les processus, et qui apportent une \napproche diff\u00e9rente bas\u00e9e sur l\u2019orientation client  (Filter, 2018 ).  \n \n  ", "doc_id": "cde61f60-cf53-4451-85e2-3af2ca562b8d", "embedding": null, "doc_hash": "2bbc2282f078c9660011340c5ae3ccbf30d0eecfe314c507a0ffdbf881b09e9d", "extra_info": {"page_label": "32", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 1739}, "relationships": {"1": "2f91fe93-f913-442f-9663-f7ccf2ca565c"}}, "__type__": "1"}, "5d43e204-8959-43a8-a0e4-fd11ed1e5e60": {"__data__": {"text": " \n \n28 \n Le cas des \u00c9tats -Unis  \nLes faits saillants  \n\u25cf L\u2019administration Trump a commenc\u00e9 \u00e0 s\u2019int\u00e9resser \u00e0 la question de l\u2019Intelligence \nartificielle en 2019, avec la publication d\u2019un d\u00e9cret pr\u00e9sidentiel exposant la strat\u00e9gie du \ngouvernement.  \n\u25cf De nombreux minist\u00e8res et organismes se sont d\u00e9j\u00e0 empar\u00e9s de  la question de l\u2019IA et ont \nd\u00e9velopp\u00e9 leurs propres strat\u00e9gies.  \n\u25cf Les \u00c9tats -Unis mettent l\u2019ac cent sur la recherche et d\u00e9veloppement (R&D) et sur les \npartenariats entre le secteur priv\u00e9, l\u2019industrie et l\u2019acad\u00e9mique. Cela donne lieu \u00e0 de \nnombreuses initiatives au sein des diff\u00e9rentes agences gouvernementales.  \n\u25cf Les \u00c9tats -Unis mettent \u00e9galement l\u2019accent sur la formation d\u2019une force de travail en IA et \nsur l\u2019abaissement de la r\u00e9gulation afin de permettre le d\u00e9veloppement de l\u2019IA. Les \nconsid\u00e9rations \u00e9thiques, en revanche, ne semblent pas \u00eatre au c\u0153ur de la r\u00e9flexion.  \n\u25cf Au cours de la derni\u00e8re ann\u00e9e, les \u00c9 tats-Unis ont organis\u00e9 un forum rassemblant des \nfonctionnaires de nombreuses agences gouvernementales et mis en place plusieurs \ncentres ou groupes afin d\u2019assurer un partage de l\u2019information pour favoriser l\u2019int\u00e9gration \nde l\u2019IA dans le secteur public.  \n \nChro nologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  \n\u00c0 la fin de l\u2019administration Obama, trois documents phares sont publi\u00e9s sur l\u2019IA, sur la recherche \net d\u00e9veloppement (R&D) dans ce secteur, et sur ses cons\u00e9quences sur l\u2019\u00e9conomie. Il s\u2019agit du \nrapport \u00ab\u2009Preparing for the future of Artificial Intelligence \u2009\u00bb et du \u00ab\u2009 National Artificial Intelligence \nResearch and Development Strategic Plan \u2009\u00bb en octobre 2016. Ce dernier a \u00e9t\u00e9 mis \u00e0 jour  en 2019 \nen mettant l\u2019accent s ur les partenariats avec le secteur priv\u00e9 et les universit\u00e9s. Un troisi\u00e8me \nrapport \u00ab\u2009 Artificial Intelligence, Automation, and the Economy \u2009\u00bb est publi\u00e9 en d\u00e9cembre 2016 et \nporte quant \u00e0 lui sur les transformations dans l\u2019\u00e9conomie pouvant \u00eatre entrain\u00e9e par l\u2019IA. C\u2019est \nen 2016 \u00e9galement qu\u2019est mise en place la politique f\u00e9d\u00e9rale sur les v\u00e9hicules automatis\u00e9s, pour \nr\u00e9guler l\u2019 utilisation de l\u2019IA dans ce secteur.  \nAu d\u00e9but de l\u2019administration Trump, l\u2019IA ne semble pas faire partie des priorit\u00e9s, mais elle revient \nsur le devant de la sc\u00e8ne \u00e0 partir de 2018 et surtout en f\u00e9vrier 2019 avec la publication d\u2019un \nExecutive order  (D\u00e9cret pr\u00e9sidentiel)  et du lancement de \u00ab\u2009l\u2019American AI Initiative\u2009\u00bb. \nL\u2019administration Trump y fait r\u00e9f\u00e9rence comme \u00e9tant sa strat\u00e9gie en mati\u00e8re d\u2019Intelligence \nartificielle. Il ne s\u2019agit cependant pas d\u2019une strat\u00e9gie \u00e0 proprement parler, mais plut\u00f4t de lignes \ndirectrices. Le d\u00e9cret identifie six objectifs strat\u00e9giques  : l\u2019investissement dans la R&D, l\u2019acc\u00e8s aux \ndonn\u00e9es,", "doc_id": "5d43e204-8959-43a8-a0e4-fd11ed1e5e60", "embedding": null, "doc_hash": "3a67a218b3589d346a93510c19190e577413a170d671b4e06d40ea882078626a", "extra_info": {"page_label": "33", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2693}, "relationships": {"1": "4b2ffbc1-a237-464a-a289-82d2f049047d", "3": "b688a8c2-bfb1-495a-b0d8-8e815c1ef6ca"}}, "__type__": "1"}, "b688a8c2-bfb1-495a-b0d8-8e815c1ef6ca": {"__data__": {"text": "mais elle revient \nsur le devant de la sc\u00e8ne \u00e0 partir de 2018 et surtout en f\u00e9vrier 2019 avec la publication d\u2019un \nExecutive order  (D\u00e9cret pr\u00e9sidentiel)  et du lancement de \u00ab\u2009l\u2019American AI Initiative\u2009\u00bb. \nL\u2019administration Trump y fait r\u00e9f\u00e9rence comme \u00e9tant sa strat\u00e9gie en mati\u00e8re d\u2019Intelligence \nartificielle. Il ne s\u2019agit cependant pas d\u2019une strat\u00e9gie \u00e0 proprement parler, mais plut\u00f4t de lignes \ndirectrices. Le d\u00e9cret identifie six objectifs strat\u00e9giques  : l\u2019investissement dans la R&D, l\u2019acc\u00e8s aux \ndonn\u00e9es, la r\u00e9duction des barri\u00e8res \u00e0 l\u2019utilisation de l\u2019IA, la r\u00e9duction de la vuln\u00e9rabilit\u00e9 aux \nattaques, la mise en place d\u2019une \u00ab\u2009workforce\u2009\u00bb en IA \u00e0 travers la form ation, et le d\u00e9veloppement \nd\u2019un plan d\u2019action. Les priorit\u00e9s des \u00c9tats -Unis ne semblent pas \u00eatre dans l\u2019int\u00e9gration de l\u2019IA dans \nle secteur public, mais plut\u00f4t de favoriser la recherche et le d\u00e9veloppement, de tenter de \nd\u00e9r\u00e9gulariser l\u2019IA ( Dutton, 2018 ) et de s\u2019appuyer sur le secteur priv\u00e9. Le gouvernement ne priorise \npas non plus la r\u00e9flexion sur l\u2019\u00e9thique ( Groth, 2019 ).  ", "doc_id": "b688a8c2-bfb1-495a-b0d8-8e815c1ef6ca", "embedding": null, "doc_hash": "8d3184f46700537b33e27c4d24fce28e6319b44732cce4ad007272851e1ea73e", "extra_info": {"page_label": "33", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2181, "end": 3240}, "relationships": {"1": "4b2ffbc1-a237-464a-a289-82d2f049047d", "2": "5d43e204-8959-43a8-a0e4-fd11ed1e5e60"}}, "__type__": "1"}, "fe8b4cac-4662-408f-a9b3-c060ad35adb1": {"__data__": {"text": " \n \n29 \n Probable cons\u00e9quence de l\u2019absence de strat\u00e9gie du gouvernement, des minist\u00e8res ont produit \nleurs propres strat\u00e9gies sur l\u2019intelligence artificielle. C\u2019est le cas du Department of Defense  (DoD)  \nqui publie sa strat\u00e9gie  en 2019,  \u00e0 laquelle est rattach\u00e9e une annexe  du Department of the air \nforce , et qui a mis en plac e un Joint Artificial intelligence Center  pour centraliser le travail r\u00e9alis\u00e9 \nen IA au sein du minist\u00e8re . Le Department of Veteran Affairs  a quant \u00e0 lui mis en place son \nNational Artificial Intelligence Institute . La National Oceanic and Atmospheric Administration \n(NOAA) au sein du Department of Commerce a publi\u00e9 une strat\u00e9gie sur l\u2019Intelligence a rtificielle  en \nnovembre 2019. L\u2019 Intelligence Community publie en 2019 sa \u00ab\u2009 Strategy for Augmenting \nIntelligence Using Machines \u2009\u00bb, qui fait notamment appel \u00e0 l\u2019IA. Le Department of Energy (DOE) a \nmis en place le DOE Artificial Intelligence and Technology Office  pour coordonner les travaux \nentrepris au sein du minist\u00e8re .  \nOn d\u00e9nombre \u00e9gale ment plusieurs  initiatives d\u2019utilisation de l\u2019IA dans le secteur public. \nCependant, cette int\u00e9gration se fait d\u2019une mani\u00e8re d \u00e9centralis\u00e9e au sein des minist\u00e8res. On note \ntoutefois l\u2019organisation d\u2019un sommet sur l\u2019intelligence artificielle dan s le gouvernement  \u00e0 la \nMaison -Blanche en septembre 2019. Le sommet rassemble des experts d\u2019une trentaine de \nminist\u00e8res et agences f\u00e9d\u00e9rales, mais \u00e9galement du monde de l\u2019industrie et du monde \nacad\u00e9mique. L\u2019objectif \u00e9tant une adoption de l\u2019IA par le gouvern ement f\u00e9d\u00e9ral pour poursuivre \nla mission d\u2019am\u00e9lioration de la qualit\u00e9 des services aux citoyens, et rendre ceux -ci plus efficaces. \nL\u2019un des moyens identifi\u00e9s pour atteindre cet objectif est d\u2019utiliser le secteur priv\u00e9 comme levier. \nLes \u00c9tats -Unis mettent s ouvent l\u2019accent sur l\u2019importance du secteur priv\u00e9 dans le domaine de l\u2019IA.  \nUn sommet sur l\u2019IA au service de l\u2019industrie aux \u00c9tats -Unis  avait d\u2019ailleurs d\u00e9j\u00e0 \u00e9t\u00e9 organis\u00e9 par la \nMaison -Blanche en mai 2018.  Enfin, le gouvernement a mis en place une plateforme web  \nconsacr\u00e9e \u00e0 l\u2019IA.  \nPour pallier l\u2019absence de strat\u00e9gie par l\u2019ex\u00e9cutif, le pouvoir l\u00e9gislatif a lui aussi commenc\u00e9 \u00e0 \ns\u2019int\u00e9resser \u00e0 l\u2019IA ( Groth, 2019 ). Le S\u00e9nat a par exemple adopt\u00e9 le \u00ab\u2009 Artificial Intelligence (AI) in \nGovernment Act of 2019 \u2009\u00bb, pour \u00e9tablir un Centre d\u2019excellence sur l\u2019intelligence a rtificielle au sein \nde la General Services Administration afin de promouvoir, d\u00e9velopper l\u2019IA et l\u2019appliquer aux \nagences gouvernementales.  \nPlusieurs instances sont \u00e9galement en place afin de coordonner et d\u2019encourager le \nd\u00e9veloppement de l\u2019IA. L\u2019 Office of Scienc e and Technology Policy  est l\u2019instance de conseil du \npr\u00e9sident et du bureau ex\u00e9cutif en ce qui a trait \u00e0 la science, l\u2019ing\u00e9nierie, et les aspects \ntechnologiques li\u00e9s \u00e0 divers domaines (\u00e9conomie,", "doc_id": "fe8b4cac-4662-408f-a9b3-c060ad35adb1", "embedding": null, "doc_hash": "28a372b9d32dc6607560690515f1c34190866b6363b52ff4303230dd76726381", "extra_info": {"page_label": "34", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2857}, "relationships": {"1": "b0ddc2a5-e109-4b22-9b64-1209beed3b7f", "3": "70cd8847-364b-4f78-9a87-7d9441d18d1c"}}, "__type__": "1"}, "70cd8847-364b-4f78-9a87-7d9441d18d1c": {"__data__": {"text": "Artificial Intelligence (AI) in \nGovernment Act of 2019 \u2009\u00bb, pour \u00e9tablir un Centre d\u2019excellence sur l\u2019intelligence a rtificielle au sein \nde la General Services Administration afin de promouvoir, d\u00e9velopper l\u2019IA et l\u2019appliquer aux \nagences gouvernementales.  \nPlusieurs instances sont \u00e9galement en place afin de coordonner et d\u2019encourager le \nd\u00e9veloppement de l\u2019IA. L\u2019 Office of Scienc e and Technology Policy  est l\u2019instance de conseil du \npr\u00e9sident et du bureau ex\u00e9cutif en ce qui a trait \u00e0 la science, l\u2019ing\u00e9nierie, et les aspects \ntechnologiques li\u00e9s \u00e0 divers domaines (\u00e9conomie, s\u00e9curit\u00e9, sant\u00e9, etc.). Le National Science and \nTechnology Co uncil (NSTC) est l\u2019instance de l\u2019ex\u00e9cutif qui coordonne la politique en mati\u00e8re de \nscience et technologie dans les diff\u00e9rentes entit\u00e9s f\u00e9d\u00e9rales. Il est organis\u00e9 en comit\u00e9, sous -\ncomit\u00e9s et groupes de travail. Le Select Committee on Artificial Intelligence (AI ) du NSTC est le \ncomit\u00e9 responsabl e depuis 2018 des efforts de R&D  du gouvernement f\u00e9d\u00e9ral en IA  et de la \ncr\u00e9ation de partenariats avec les partenaires industriels et acad\u00e9miques. Il est aussi responsable \nde coordonner la nouvelle initiative du gouverne ment en IA ( Maison Blanche, 201 9C). Le Machine \nLearning and Artificial Intelligence (MLAI) Subcommittee a \u00e9t\u00e9 cr\u00e9\u00e9 en m ai 2016 et surveille les \navanc\u00e9es sur la question de l\u2019 apprentissage machine et de l\u2019IA, que ce soit \u00e0 l\u2019int\u00e9rieur du \ngouvernement f\u00e9d\u00e9ral, dans le secteur priv\u00e9 ou \u00e0 l\u2019international. Il a pour objectif de coordonner \net de favoriser l\u2019utilisation et le partage des connaissances dans le domaine de l\u2019IA et de \nl\u2019apprentissage machine au sein du gouvernement f\u00e9d\u00e9ral. Le Artificial Intelligence Research & ", "doc_id": "70cd8847-364b-4f78-9a87-7d9441d18d1c", "embedding": null, "doc_hash": "12f6103a86558505e020b40981ddb5dd35f0d27c04260b66a25c9c17075db61d", "extra_info": {"page_label": "34", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2274, "end": 3976}, "relationships": {"1": "b0ddc2a5-e109-4b22-9b64-1209beed3b7f", "2": "fe8b4cac-4662-408f-a9b3-c060ad35adb1"}}, "__type__": "1"}, "32b73124-84e4-42ff-bb0e-ccfb9166a75e": {"__data__": {"text": " \n \n30 \n Development Interagency Working Group (NITRD AI R&D)  coordonne quant \u00e0 lui la R&D  en IA. En \nnovembre 2019, la General Services Adminisration a \u00e9galement mis en place une communaut\u00e9 de \npratiques sur l\u2019IA pour acc\u00e9l\u00e9rer l\u2019adoption de l\u2019IA par le gouvernement f\u00e9d\u00e9ral et faciliter les \n\u00e9changes entre les acteurs de cette int\u00e9gration.  \n \nCas concrets  de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  \nNous avons identifi\u00e9 des cas concrets d\u2019utilisation de l\u2019IA dans le secteur public aux \u00c9tats -Unis. Il \nen existe de nombreux et nous en d\u00e9crivons bri\u00e8vement certains ici. Il est a not\u00e9 que de \nnombreuses initiatives se d\u00e9roulent dans le cadre du \u00ab  National Artificial Intelligence Research \nand Development  \u00bb Strategic Plan . Le bilan  des premi\u00e8res ann\u00e9es recense un grand nombre \nd\u2019initiatives en fonction des diff\u00e9rentes strat\u00e9gies pr\u00e9vues dans le plan (par exemple la \ncollaboration entre humain et IA).  \nSant\u00e9  \n\u25cf Le National Institutes of Health (NIH)  au sein du Department  of Health and Human \nServices (HHS) utilise l\u2019IA. Il utilise le traitement du langage naturel pour traiter les \ndemandes de subvention plus rapidement, et l\u2019apprentissage machine pour permettre un \nacc\u00e8s plus rapide \u00e0 la litt\u00e9rature m\u00e9dicale ( Office of Science and Technology Policy [OSTP] , \n2019 ) \n\u25cf Le NIH explore \u00e9galement  les opportunit\u00e9s de l\u2019IA pour la recherche dans le domaine de \nla sant\u00e9. Il se sert notamment des nombreuses donn\u00e9es recueillies dans les diff\u00e9rents \nprogrammes qu\u2019il a mis en place. Le NIH contribue \u00e0 financer de nombreux projets de \nrecherche, mais explore \u00e9galement les possibilit\u00e9s de faire un meilleur usage de ses \ndonn\u00e9es ( Maison Blanche, 2019A ). \n\u25cf La Food and Drug Administration (FDA) et les Centers for Disease Control and Prevention  \n(CDC) tentent d\u2019am\u00e9liorer la collecte de donn\u00e9es m \u00e9dicales gr\u00e2ce \u00e0 l\u2019apprentissage \nmachine et au traitement du langage naturel ( Maison Blanche, 2019A ).  \nTransport  \n\u25cf  L\u2019agence Federal Highway Administration du Department of Transportation (DOT) utilise \nl\u2019IA pour augmenter la s\u00e9curit\u00e9 et la performance de son r\u00e9seau d\u2019autoroute. L\u2019IA sert \u00e0 \nanalyser et traiter les donn\u00e9es recueillies sur le r\u00e9seau et \u00e0 automatiser certains aspects \nde la surveillance ( National Science and Technology Council [NSTC], 2019 ). \nServices financiers et \u00e9conomie  \n\u25cf La U.S. Securities and exchange commission (SEC) utilise l\u2019apprentissage machine p our \nd\u00e9tecter les fraud es concernant les investissements ( Maison Blanche, 2019B ) \n\u25cf Le Department of the Treasury travaille  \u00e0 l\u2019adoption d\u2019outils  utilisant l\u2019IA,  \u00e0 l\u2019usage des \ncitoyens pour que ceux -ci prennent de me illeures d\u00e9cisions sur leurs objectifs financiers. \n(Maison Blanche, 2019A ). \nAgriculture  \n\u25cf Le secteur de l\u2019agriculture rassemble un grand nombre de projet s de R&D  bas\u00e9s sur l\u2019IA. \nCes initiatives sont men\u00e9es par les diff\u00e9rents centres de recherche du Department of ", "doc_id": "32b73124-84e4-42ff-bb0e-ccfb9166a75e", "embedding": null, "doc_hash": "6cd5ac036ff62713763e54c1ed7453b143def4b42692f2c6f857464ed03ff98f", "extra_info": {"page_label": "35", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2937}, "relationships": {"1": "88f50f2d-7609-4d59-856c-aaacbbe7af69"}}, "__type__": "1"}, "1d451b08-b570-43b4-9d88-1d8873b1bb3e": {"__data__": {"text": " \n \n31 \n Agriculture (USDA). Le National Institute of Food and Agriculture  m\u00e8ne des recherches sur \nl\u2019utilisation de l\u2019IA dans la production  agricole, la formation de la main -d\u2019\u0153uvre, ou \nencore l\u2019assistance robotique dans plusieurs taches li\u00e9e s \u00e0 l'agriculture ( Maison Blanche, \n2019A ; National Institute of Food and Agriculture [NIFA] ). L\u2019agricultural Research Center \ndu USDA m\u00e8ne des recherches sur la surveillance du b\u00e9tail, l\u2019utilisation de robots pour \ndiff\u00e9rentes t\u00e2ches, et la surveillance a\u00e9rienne \u00e0 l\u2019aide de l\u2019apprentissage profond  (Maison \nBlanche, 2019A ). L\u2019Economic Research  Service m\u00e8ne quant \u00e0 lui des recherches sur \nl\u2019utilisation de l\u2019apprentissage machine et de l\u2019IA pour la gestion des terres en fonction de \nl\u2019analyse des donn\u00e9es m\u00e9t\u00e9o.  \nEnvironnement  \n\u2022 L\u2019agence NOAA fait un grand nombre d \u2019utilisations  de l\u2019IA  : elle l\u2019utilis e pour am\u00e9liorer les \ncartes maritimes \u00e0 des fins de transport, elle recense la population de poissons en lien \navec l\u2019industrie de la p \u00eache en utilisant des donn\u00e9es collect\u00e9es par les bateaux et les \nsyst\u00e8mes sous- marins d\u2019enregistrement du son ( NSTC, 2019 ), elle utilise \u00e9galement l\u2019IA \ndans la surveillance et la conservation des esp\u00e8ces en p\u00e9ril ( Maison -Blanche, 2019A ; \nNOAA, 2019 ), et enfin pour cartographier et surveiller les courants, les oc\u00e9ans et les c\u00f4tes \n(NOAA, 2019 ). L\u2019agence NOAA finance \u00e9galement de la recherche et d\u00e9veloppement \nutilisant l\u2019IA pour traiter un grand nombre de donn\u00e9es afin de mieux comprendre et \npr\u00e9dire les dynamiques environnementales et les mod\u00e8les de pr\u00e9vision des temp\u00eates et \nouragans (Maison Blanche, 2019A ). Cela a d\u00e9j\u00e0 \u00e9t\u00e9 utilis\u00e9 avec succ\u00e8s lors du passage de \nl\u2019Ouragan Florence en 201 8, ayant men\u00e9 \u00e0 de meilleures pr\u00e9visions et \u00e9vacuation \npr\u00e9ventives.  L\u2019apprentissage machine est utilis\u00e9 pour analyser les images satellites dans \nle cadre de catastrophes naturelles (mar\u00e9es noires, feux de for\u00eat), mais \u00e9galement pour \nd\u00e9tecter les activit\u00e9s ill\u00e9gales de p\u00eache ( NSTC, 2019 ).  \nS\u00e9curit\u00e9 et d\u00e9fense  \n\u2022 Le Joint Artificial Intelligence Center (JAIC)  du DoD a mis en place un pr ojet pour utiliser \nl\u2019IA afin de d\u00e9tecter et localiser les feux de for\u00eat, faire une analyse des inondations, des \nroutes ou encore \u00e9valuer les dommages caus\u00e9s sur les b\u00e2timents (OSTP , 2019 ). \u00c0 travers \nle JAIC, le DoD pr\u00e9voit \u00e9galement de se pencher sur l\u2019utilisation de l\u2019IA \u00e0 des fins de \nmaintenance pr\u00e9dictive et d\u2019assistance humanitaire en cas de catastrophe (Maison \nBlanche, 2019A ). L\u2019objectif du Centre \u00e9tant \u00e0 la fois de d\u00e9velopper des capacit\u00e9s au sein \ndu DoD, mais \u00e9galement de d\u00e9velopper des outils, des standards, une structure et une \nbase de donn\u00e9es partag\u00e9e (Maison Blanche, 2019A ).  \n\u2022 Le Department of Homeland Security (DHS) explore l\u2019utilisation de l\u2019IA pour le contre", "doc_id": "1d451b08-b570-43b4-9d88-1d8873b1bb3e", "embedding": null, "doc_hash": "01792c2564de11dfb21a4ba8ba44328f0587722e7d57da39f75d3fa2b46c09ea", "extra_info": {"page_label": "36", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2801}, "relationships": {"1": "1caf172e-223b-4ba2-9478-21f0f6f20eb8", "3": "c421994e-6e99-43bb-8766-130c97381b4c"}}, "__type__": "1"}, "c421994e-6e99-43bb-8766-130c97381b4c": {"__data__": {"text": "ou encore \u00e9valuer les dommages caus\u00e9s sur les b\u00e2timents (OSTP , 2019 ). \u00c0 travers \nle JAIC, le DoD pr\u00e9voit \u00e9galement de se pencher sur l\u2019utilisation de l\u2019IA \u00e0 des fins de \nmaintenance pr\u00e9dictive et d\u2019assistance humanitaire en cas de catastrophe (Maison \nBlanche, 2019A ). L\u2019objectif du Centre \u00e9tant \u00e0 la fois de d\u00e9velopper des capacit\u00e9s au sein \ndu DoD, mais \u00e9galement de d\u00e9velopper des outils, des standards, une structure et une \nbase de donn\u00e9es partag\u00e9e (Maison Blanche, 2019A ).  \n\u2022 Le Department of Homeland Security (DHS) explore l\u2019utilisation de l\u2019IA pour le contre -\nterrorisme, la r\u00e9ponse au x catastrophe s, la protection des infrastructures et la \ncybers\u00e9curit\u00e9  (NSTC, 2019 ). Le DHS appui e \u00e9galement la recherche en IA, notamment en \nce qui concerne la d\u00e9tection d\u2019anomalies, la capacit\u00e9 \u00e0 extraire de l\u2019information \nprovenant de plusieurs sources et le triage de donn\u00e9es en temps r\u00e9el ( NSTC, 2019 ).  \nAutres  \n\u2022 Le General Services Administration  a des projets pilotes pour l\u2019utilisation de l\u2019IA dans la \npr\u00e9diction du respect des r\u00e8gles ( Groth, 2019 ). ", "doc_id": "c421994e-6e99-43bb-8766-130c97381b4c", "embedding": null, "doc_hash": "be0bb59a37e843ee4cdd040e5a3451dbc0394d652e87f29c39c597c1686f87d4", "extra_info": {"page_label": "36", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2229, "end": 3302}, "relationships": {"1": "1caf172e-223b-4ba2-9478-21f0f6f20eb8", "2": "1d451b08-b570-43b4-9d88-1d8873b1bb3e"}}, "__type__": "1"}, "e041d512-134b-446a-8858-5e8afcc75218": {"__data__": {"text": " \n \n32 \n \u2022 L\u2019Institute for Telecommunication Sci ences de l\u2019agence  National Telecommunications and \nInformation Administration au sein du Department of Commerce cherche \u00e0 pouvoir \nutiliser l\u2019apprentissage machine et le r\u00e9seau de neurones artificiels dans le cadre de \nl\u2019utilisation des r\u00e9seaux sans fil ( NSTC, 2019 ).  \n\u2022 La NASA utilise l\u2019IA pour traiter les donn\u00e9es et aider \u00e0 la prise de d\u00e9cision dans certains \ndomaines ou le volume des donn\u00e9es et la rapidit\u00e9 n\u00e9cessaire \u00e0 les traiter pour prendre \ndes d\u00e9cisions ne peut \u00eatre r\u00e9alis\u00e9 par l\u2019\u00eatre humain ( NSTC, 2019 ).  \n\u2022 L\u2019IA est \u00e9galement utilis\u00e9e au sein du Department of Health and Human Services pour \naider des experts \u00e0 identifier les r\u00e8glements qui sont obsol\u00e8tes ou en double, afin de \nr\u00e9duire la charge de travail des employ\u00e9s (OSTP , 2019 ). \n \nFacteurs habilitants et contraignants  \nFacteurs habilitants  \n\u2022 Lors du Sommet sur l\u2019intelligence artificielle dans le gouvernement, plusieurs facteurs qui \npourraient se r\u00e9v\u00e9ler habilitants ont \u00e9t\u00e9 identifi\u00e9s par les diff\u00e9rents acteurs comme \ndevant \u00eatre explor\u00e9s. Le premier consiste en l\u2019importance de l\u2019apprentissage et du \npartage d\u2019information entre le gouvernement, l\u2019industrie et le monde acad\u00e9 mique \ncomme levier pour l\u2019utilisation de l\u2019IA au sein du secteur public. L\u2019importance de cr\u00e9er \nune confiance organisationnelle envers l\u2019IA et son adoption a \u00e9galement \u00e9t\u00e9 discut\u00e9e. Il a \n\u00e9t\u00e9 demand\u00e9 de mettre sur pied un centre d\u2019excellence permettant la co llaboration et \nl\u2019\u00e9change entre les minist\u00e8res et organismes. Enfin, la constitution d\u2019une force de travail \n\u00e0 travers la formation et l\u2019embauche a \u00e9t\u00e9 \u00e9galement discut\u00e9e comme une n\u00e9cessit\u00e9 en \nvue de l\u2019adoption de l\u2019IA par le secteur public ( (OSTP , 2019 ).  \n \nPratiques inspirantes  \nEn place  \n\u2022 L\u2019organisation d\u2019un sommet par la Maison -Blanche afin de discuter de l\u2019int\u00e9gration d e l\u2019IA \ndans le secteur public, de partager l\u2019exp\u00e9rience de certains organismes et de permettre \naux minist\u00e8res et organismes d\u2019identifier leurs besoins  \n\u00c0 surveiller  \n\u2022 La mise en place d\u2019un centre d\u2019excellence et d\u2019une communaut\u00e9 de pratique au sein \nrassemblan t des experts de tous les minist\u00e8res et organismes au sein de la General \nServices Administration  pourrait se r\u00e9v\u00e9ler \u00eatre une pratique exemplaire.  \n  ", "doc_id": "e041d512-134b-446a-8858-5e8afcc75218", "embedding": null, "doc_hash": "8b3f94ade0e3a04e8b830cc1ed2064fea7be404848aaa5bdf6c09a85af6ae7bd", "extra_info": {"page_label": "37", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2283}, "relationships": {"1": "84330a73-4237-422f-85d8-be7d92ccb2b6"}}, "__type__": "1"}, "8cb64f55-802a-484e-954d-90e91ddb323c": {"__data__": {"text": " \n \n33 \n Le cas de Singapour  \nLes faits saillants  \n\u25cf L\u2019int\u00e9gration de l\u2019Intelligence a rtificielle se fait \u00e0 Singapour \u00e0 la suite de la strat\u00e9gie de \nnum\u00e9risation de l\u2019\u00c9tat et de la strat\u00e9gie de mise en place d\u2019une \u00ab  Smart Nation  \u00bb.  \n\u25cf Le programme IA Singapore  qui fait office de strat\u00e9gie pr\u00e9voit essentiellement des appuis \n\u00e0 la recherche et aux entreprises, sans n\u00e9cessairement identifier de projets concrets pour \nl\u2019int\u00e9gration de l\u2019IA dans le secteur public.  \n\u25cf Le gouvernement soutient la r\u00e9flexion sur la protecti on des donn\u00e9es et les questions \n\u00e9thiques et de gouvernance reli\u00e9e \u00e0 l\u2019IA \u00e0 travers des programmes de recherche et la mise \nen place d\u2019une commission et de groupes de travail.  \n\u25cf Quelques initiatives d\u2019utilisation de l\u2019IA sont identifi\u00e9es, ce nombre devrait au gmenter \n\u00e9tant donn\u00e9 l\u2019objectif poursuivi que chaque minist\u00e8re et organisme ait au moins un projet \nreli\u00e9 \u00e0 l\u2019IA \u00e0 l\u2019horizon 2023.  \n \nChronologie de l\u2019int\u00e9gration de l\u2019intelligence artificielle  \nD\u00e8s les ann\u00e9es 1980, le gouvernement est l\u2019initiateur d\u2019un virage vers l\u2019utilisation des  \nTechnologies de l\u2019information et de la communication (TIC)  et la num\u00e9r isation dans les secteurs \n\u00e9conomique, industriel et public. On cherche \u00e0 partager les donn\u00e9es au sein de l\u2019administration \npublique et \u00e0 automatiser les processus ( CHAN et al., 2008 ). En 2000, le e-gouvernement  est \nd\u00e9ploy\u00e9, et d\u00e8s 2003 l es principaux services de premi\u00e8re ligne pour les citoyens et entreprises y \nsont d\u00e9j\u00e0 accessibles ( CHAN et al., 2008 ). Entre 2006 et 2015 avec la strat\u00e9gie \u00ab Smart Nation \n2015 \u00bb on se concentre sur le projet de construction d\u2019une ville intelligente. Le gouvernement de \nSingap our d\u00e9veloppe l\u2019infrastructure communicationnelle, des industries de communication et \nd\u2019information comp\u00e9titives \u00e0 l\u2019\u00e9chelle globale, la formation des ressources humaines \u00e0 ces \nnouveaux outils, et la transformation de secteurs \u00e9conomiques cl\u00e9s ( Lei et Tang, 2019 ). Le \ngouvernement fait une promotion active et insiste sur le fait que la strat\u00e9gie permettra \nd\u2019am\u00e9liorer la qualit\u00e9 de vie des citoyens et la comp\u00e9titivit\u00e9 \u00e9conomique de Singapour ( Lei et \nTang, 2019 ). \n \nApr\u00e8s 2016, le projet d\u2019implantation d\u2019une ville intelligente s\u2019 acc\u00e9l\u00e8re. La strat\u00e9gie \u00ab Smart Nation \n2025 \u00bb su ivie au cours de 2017 par le \u00ab Digital Economy Framework  \u00bb, le \u00ab Digital Preparation \nBlueprint  \u00bb et le \u00ab  Digital Government Blueprint  \u00bb. La plateforme universelle \u201cWhole of \nGovernment  \u00bb (WOG) est mise en place  au c\u0153ur de cette nouvelle strat\u00e9gie (Lei et Tang, 2019 ). \nDes mesures sont mises en place et touchent directement la vie des citoyens  : construction de \ntransports intelligents, ma ison intelligente et soins m\u00e9dicaux intelligents ( Lei et Tang, 2019 ). \nR\u00e9cemment, le site du gouvernement a \u00e9t\u00e9 r\u00e9organis\u00e9 gr\u00e2ce \u00e0 des Inter faces de Programmes \nd\u2019Application (API) qui permettent \u00e0 l\u2019information d\u2019\u00eatre disponible en temps r\u00e9el", "doc_id": "8cb64f55-802a-484e-954d-90e91ddb323c", "embedding": null, "doc_hash": "a5d1a50276faae6ac75e19798a9f12c39a5124a7e817ed5450aad635e701caf8", "extra_info": {"page_label": "38", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2913}, "relationships": {"1": "aaebc1a1-7f67-4d4c-8131-12642caa7c5b", "3": "c7109f6e-a9d2-4856-9a02-84a1ec22a411"}}, "__type__": "1"}, "c7109f6e-a9d2-4856-9a02-84a1ec22a411": {"__data__": {"text": " \u00bb, le \u00ab Digital Preparation \nBlueprint  \u00bb et le \u00ab  Digital Government Blueprint  \u00bb. La plateforme universelle \u201cWhole of \nGovernment  \u00bb (WOG) est mise en place  au c\u0153ur de cette nouvelle strat\u00e9gie (Lei et Tang, 2019 ). \nDes mesures sont mises en place et touchent directement la vie des citoyens  : construction de \ntransports intelligents, ma ison intelligente et soins m\u00e9dicaux intelligents ( Lei et Tang, 2019 ). \nR\u00e9cemment, le site du gouvernement a \u00e9t\u00e9 r\u00e9organis\u00e9 gr\u00e2ce \u00e0 des Inter faces de Programmes \nd\u2019Application (API) qui permettent \u00e0 l\u2019information d\u2019\u00eatre disponible en temps r\u00e9el  (ZHENBIN et al. \n2019 ). Le \u00ab Digital Government Blueprint  \u00bb fait quant  \u00e0 lui r\u00e9f\u00e9rence \u00e0 l\u2019utilisation de l\u2019IA au sein \ndu gouvernement. Il y est \u00e9voqu\u00e9 la  mise en place par le gouvernement d\u2019 un centre d\u2019excellence \npour tout ce qui est TIC et Smart Systems.  Il est pr\u00e9vu que ce centre d\u2019excellence se penche \n\u00e9galement sur la qu estion de l\u2019IA ( Smart nation, 2018 ). Le Blueprint pr\u00e9voit \u00e9galement qu\u2019en 2023, \nchaque minist\u00e8re aura au moins un projet en IA. Enfin, les projets interorganisationnels sont \nencourag\u00e9s et il est notamment pr\u00e9vu de r\u00e9duire \u00e0 moins de 10 jours l\u2019\u00e9change de donn\u00e9es entre \nles organismes lors de projets communs ( Smart nation, 2018 ).  \n ", "doc_id": "c7109f6e-a9d2-4856-9a02-84a1ec22a411", "embedding": null, "doc_hash": "efa9469f82a7cc2d5bd522cbfe3e6e90ce3b3e0047e203cdef14cb85bd8a2c0f", "extra_info": {"page_label": "38", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2323, "end": 3591}, "relationships": {"1": "aaebc1a1-7f67-4d4c-8131-12642caa7c5b", "2": "8cb64f55-802a-484e-954d-90e91ddb323c"}}, "__type__": "1"}, "6ca90be7-5f8c-4866-965b-04ddbf784e02": {"__data__": {"text": " \n \n34 \n Le tournant pris par Singapour concernant l\u2019IA se fait principalement avec la mise en place du \nprogramme AI Singapore  en mai 2017. Le d\u00e9veloppement de l\u2019IA est consid\u00e9r\u00e9 comme crucial \npour le d\u00e9veloppement du pays ( Growth et al., 2019 ). Le programme est lanc\u00e9 par la National \nResearch Foundation (NRF, un service rattach\u00e9 au premier ministre) et regroupe cinq autres \nminist\u00e8res et organisations en plus de la NRF  : le Smart Nation and Digital Government Office \n(coordonn\u00e9 par le bureau du premi er ministre), le Economic Development Board, la Infocomm \nMedia Development Authority , SGInnovate,  et le Integrated Helth Information Systems . Les \nobjectifs sont surtout concentr\u00e9s sur la recherche en IA, le fait de r\u00e9pondre au d\u00e9fi soci\u00e9tal et \n\u00e9conomique e t l\u2019utilisation de l\u2019IA dans l\u2019industrie ( Dutton, 2018 ). Un des objectifs est \u00e9galement \nde donner de meilleurs services publics. Cependant, s elon la m\u00e9thode d\u2019\u00e9valuation de l\u2019int\u00e9r\u00eat \nport\u00e9 aux diff\u00e9rents domaines strat\u00e9giques de l\u2019IA de Dutton ( 2018 ), Singapo ur accorde plus \nd\u2019importance \u00e0 la recherc he et \u00e0 la strat\u00e9gie industrielle qu\u2019\u00e0 l\u2019int\u00e9gration dans le gouvernement . \nLe financement de la recherche en IA et le perfectionnement du personnel qualifi\u00e9 sont plut\u00f4t \nentrepris dans une vis\u00e9e d\u2019utiliser des technologies de l\u2019IA dans le secteur priv\u00e9 ( Dutton, 2018 ). \nEn effet, l a recherche est mise au profit des besoins de l\u2019industrie ( Growth et al., 2019 ). L\u2019objectif \nest de \u00ab  cr\u00e9er une grappe d\u2019entreprises en IA dans leurs r\u00e9gions respectives ou de renforcer le s \nentreprises existantes gr\u00e2ce \u00e0 une plus grande capacit\u00e9 en mati\u00e8re d\u2019IA  \u00bb (Dutton 2018 ). Une \npartie de la recherche porte toutefois sur les impacts soci\u00e9taux  et sur l\u2019acceptabilit\u00e9 de l\u2019IA \n(Growth et al., 2019 ). \n \nEn ce qui concerne la protection des donn\u00e9es et les questions \u00e9thiques, la Personal Data \nProtection Commission a \u00e9t\u00e9 mise en place en janvier 2013 et veille sur l\u2019application du \u00ab Personal \nData Protection Act  \u00bb de 2012 ( Personal data protection commission ). La Personal Data Protection \nCommission  a publi\u00e9 un document  portant sur le d\u00e9veloppement responsable et l\u2019adoption de \nl\u2019IA. La commission a \u00e9galement d\u00e9velopp\u00e9 le \u00ab Model AI Governance Framework  \u00bb. Il inclut \nnotamment un guide pour les organisations du secteur priv\u00e9 concernant les enjeux de \ngouvernance et d\u2019\u00e9thique. En juin 2018, le gouvernement a \u00e9galement annonc\u00e9 la cr\u00e9ation d\u2019un \nAdvisory Council on the Ethical use of AI and Data et la mise en p lace d\u2019un programme de \nrecherche sur la gouvernance des donn\u00e9es et l\u2019utilisation de l\u2019IA (Dutton 2018 ).  \n \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  \nNous pr\u00e9sentons ici quelques initiatives que nous avons relev\u00e9es. Il serait cependant int\u00e9ressant \nde suivre les travaux r\u00e9alis\u00e9s dans le cadre du \u00ab  Digital Government Blueprint  \u00bb. En effet, le plan \npr\u00e9voit un accroissement de l\u2019utilisation de l\u2019IA dans le secteur public. Il est notamment pr\u00e9vu \nd\u2019identifier", "doc_id": "6ca90be7-5f8c-4866-965b-04ddbf784e02", "embedding": null, "doc_hash": "189b319a5120b5d1265c4d0581b2b6563c71d47b970ada0ecae9174539942a63", "extra_info": {"page_label": "39", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 3019}, "relationships": {"1": "39987376-31b9-434c-8871-d56f37b4190d", "3": "dedcb646-c837-4f94-921d-1d99de6f1ce1"}}, "__type__": "1"}, "dedcb646-c837-4f94-921d-1d99de6f1ce1": {"__data__": {"text": "d\u2019un \nAdvisory Council on the Ethical use of AI and Data et la mise en p lace d\u2019un programme de \nrecherche sur la gouvernance des donn\u00e9es et l\u2019utilisation de l\u2019IA (Dutton 2018 ).  \n \nCas concrets de l\u2019utilisation de l\u2019intelligence artificielle dans le secteur public  \nNous pr\u00e9sentons ici quelques initiatives que nous avons relev\u00e9es. Il serait cependant int\u00e9ressant \nde suivre les travaux r\u00e9alis\u00e9s dans le cadre du \u00ab  Digital Government Blueprint  \u00bb. En effet, le plan \npr\u00e9voit un accroissement de l\u2019utilisation de l\u2019IA dans le secteur public. Il est notamment pr\u00e9vu \nd\u2019identifier l\u00e0 o\u00f9 l\u2019utilisation de l\u2019IA aurait le plus d\u2019impact. Il est anticip\u00e9 que l\u2019IA sera utilis\u00e9e pour \nr\u00e9aliser des t\u00e2ches automatiques, pour le service personnalis\u00e9 et dans le cadre de la gestion du \ntrafic.  \n\u2022 La Plateforme de d\u00e9tection intelligente de la nation  : une plateforme de d\u00e9tection \nint\u00e9gr\u00e9e \u00e0 l\u2019\u00e9chelle nationale pour am\u00e9liorer  les services municipaux, les op\u00e9rations au \nniveau de la ville, la planification et la s\u00e9curit\u00e9.  \n\u2022 Beeline : une plateforme de mobilit\u00e9 intelligente bas\u00e9e sur le nuage , d\u00e9velopp\u00e9e pour \nfournir des services de navette s bas\u00e9s sur les donn\u00e9es aux navetteurs et d\u00e9sengorger le \ntrafic et les bus publics  \n\u2022 Chatbots : Le gouvernement de Singapour a travaill\u00e9 avec Microsoft pour cr\u00e9er des \nchatbots pour certains services aux citoyens.  Ces chatbots sont destin\u00e9s \u00e0 fonctionner \ncomme des repr\u00e9sentants num\u00e9riques.  ", "doc_id": "dedcb646-c837-4f94-921d-1d99de6f1ce1", "embedding": null, "doc_hash": "9b9661fc8c5c10135e12390322e94037868a458792a7c920a50019112c7a18b1", "extra_info": {"page_label": "39", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2438, "end": 3878}, "relationships": {"1": "39987376-31b9-434c-8871-d56f37b4190d", "2": "6ca90be7-5f8c-4866-965b-04ddbf784e02"}}, "__type__": "1"}, "893923dc-7efb-44bc-90a8-6d6cc924f495": {"__data__": {"text": " \n \n35 \n \u2022 National digital Identity (NDI) : un projet qui sera op\u00e9rationnel en 2020 pour identifier les \nr\u00e9sidents et entreprises lors de leurs transactions digitales avec le gouvernement  \n\u2022 Le E-Citizen Helper Service : ce syst\u00e8me d\u2019assistance pour ceux qui n\u2019ont pas acc\u00e8s \u00e0 \ninternet permet aux citoyens d\u2019acc\u00e9der aux e -services via des bornes plac\u00e9es dans des \nlieux publics. Cela a permis de pr\u00e9venir les possibles iniquit\u00e9s.  \n \nFacteurs habilitants et contraignants  \nFacte urs habilitants  \n\u2022 Le d\u00e9veloppement du capital humain est aussi favoris\u00e9 par les nombreuses formations \ndonn\u00e9es en IA par les universit\u00e9s.  \n\u2022 On s\u2019appuie sur les Universit\u00e9s et les Instituts de recherche en IA pour d\u00e9velopper des \ninitiatives, incluant la National  University of Singapore  (NUS); Nanyang Technological \nUniversity  (NTU), Singapore Management University  (SMU), Singapore University of \nTechnology and Design (SUTD), et l\u2019 Agency for Science, Technology, and Research  \n(VARAKANTAM, 2017 ).  \n\u2022 Les capacit\u00e9s nationales sont utilis\u00e9es et il y a une mobilisation des citoyens  et des \nentreprises priv\u00e9es dans la strat\u00e9gie.   \n\u2022 Des objectifs c oncernant l\u2019utilisation de l\u2019IA dans le secteur public sont clairement fix\u00e9s \ndans le \u00ab  Digital Government Blueprint  \u00bb \n\u2022 Les agences nationales de R&D  comme l\u2019Agence pour la science, la technologie et la \nrecherche ( Astar ), qui agit sous l\u2019autorit\u00e9 du m inist\u00e8re du Commerce et de l\u2019 Industrie  ou \nla fondation n ationale de recherche ( NRF), peuvent \u00eatre utilis\u00e9es comme une \u00ab  source \nalternative de ressource d\u2019innovation  \u00bb (Zhenbin et al., 2019 ). Cela permet de r\u00e9duire la \nd\u00e9pendance  du gouvernement  aux parties prenantes externes pour d\u00e9velopper des \napplications qui utilisent l\u2019IA ( Zhenbin et al., 2019 ). \n \nPratiques inspirantes  \nEn place  \n\u2022 Des Chief Digital Strategy Officers  ont \u00e9t\u00e9 d\u00e9sign\u00e9s au sein des minist \u00e8res et organismes \npublics afin de mettre en \u0153uvre le plan de num\u00e9risation. Ils sont accompagn\u00e9s dans leur \nd\u00e9marche d\u2019un Chief Information Officers  qui les conseille sur le plan technique. Il est \n\u00e9galement pr\u00e9vu de sensibiliser les Policy and Operation Off icers  qui sont davantage sur \nle terrain \u00e0 l\u2019avantage de l\u2019utilisation des technologies, ainsi que de pr\u00e9senter aux \nTechnology Officers  les besoins du gouvernement pour qu\u2019ils mettent en place des \nsolutions y r\u00e9pondant.  \n\u00c0 surveiller  \n\u2022 Singapour ne semble pas  trop se soucier de la question de l\u2019 approvisionnement, ce qui \npeut acc\u00e9l\u00e9rer l\u2019utilisation de l\u2019IA, mais \u00e9galement avoir des cons\u00e9quences sur l\u2019utilisation \ndes donn\u00e9es et la d\u00e9pendance du secteur public envers des startups ou entreprises.  \n  ", "doc_id": "893923dc-7efb-44bc-90a8-6d6cc924f495", "embedding": null, "doc_hash": "415292ec864643fcab523d2ad2a2f56224980a0796122f3b908d3a7d858083ef", "extra_info": {"page_label": "40", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2662}, "relationships": {"1": "8c1e17ca-e535-4902-9ba5-431075b68b34"}}, "__type__": "1"}, "be48b0d8-352a-4692-9368-1e9688775e24": {"__data__": {"text": " \n \n36 \n Liste des r\u00e9f\u00e9rences et documents consult\u00e9s  \nNote sur le Royaume- Uni \nCath, C., Wachter, S., Mittelstadt, B., Taddeo, M. et Floridi, L. (2018). Artificial Intelligence and \nthe \u2018Good Society\u2019: the US, EU, and UK approach. Science and Engineering Ethics, 24, 505-528. \nhttps://doi.org/10.1007/s11948- 017-9901 -7 \nChalaby, O. (2017, 25 octobre). A nudge for equality: the platform fighting bias with behavioural \nscience. Apolitical . Rep\u00e9r\u00e9 \u00e0 https://apolitical.co/solution_article/nudge -equality -platform -\nfighting -bias-behavioural- science/  \nDepartment for Digital, Culture, Media & Sport. (2018). Data Ethics Framework . Rep\u00e9r\u00e9 \u00e0 \nhttps://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_dat\na/file/737137/Data_Ethics_Framework.pdf  \nDepartment for Digital, Culture, Media & Sport., Office for Artificial Intelligence., The Rt Hon \nGreg Clark, et The Rt Hon Jeremy Wright. (2019). Leading experts appointed to AI Council to \nsupercharge the UK\u2019s artificial intelligence sector. Rep\u00e9r\u00e9 \u00e0 \nhttps://www.gov.uk/government/news/leading- experts -appointed -to-ai-counc il-to-\nsupercharge -the-uks-artificial- intelligence -sector  \nDirection g\u00e9n\u00e9rale du Tr\u00e9sor. (2017). Strat\u00e9gies nationales en mati\u00e8re d\u2019intelligence artificielle  : \nContributions des services \u00e9conomiques des pays suivants  : Allemagne, Canada, Estonie, \u00c9tats -\nUnis,  Isra\u00ebl, Italie, Royaume -Uni, Russie. Rep\u00e9r\u00e9 \u00e0 \nhttps://www.tresor.economie.gouv.fr/Articles/28619068 -9771 -411c -9a43-\n20fdaeb0adc8/files/5a885cf0 -0af1 -4243 -be03 -8857b5319fae  \nDonnelly et Roberts (2019). Introducing NHSX\u2019s new national artificial intelligence laboratory. \nRep\u00e9r\u00e9 \u00e0 https://healthtech.blog.gov.uk/2019/08/08/introducing- nhsxs -new -national -artificial-\nintelligence -laboratory/   \nGovernment Digital Serv ice et Office for Artificial Intelligence. (2019). A guide to using artificial \nintelligence in the public sector . Rep\u00e9r\u00e9 \u00e0 https://www.gov.uk/government/collections/a -guide -\nto-using- artificial- intelligence -in-the-public -sector#assess,- plan -and-manage -artificial-\nintelligence  \nGovernment Office for Science (2015). Artificial intelligence  : opportunities ans implications for \nthe future of decision making. Rep\u00e9r\u00e9 \u00e0 \nhttps://a ssets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_dat\na/file/566075/gs -16-19-artificial- intelligence -ai-report.pdf  \nHall, W., & Pesenti, J. (2017). Growing the artificial intelligence industry in the UK . Department \nfor Digital, Culture, Media & Sport and Department for Business, Energy & Industrial Strategy. \nPart of the Industrial Strategy UK and the Commonwealth. Rep\u00e9r\u00e9 \u00e0 \nhttps://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_dat\na/file/652097/Growing_the_artificial_intelligence_industry_in_the_UK.pdf  \nHM Government. (2017). I ndustrial Strategy: Building a Britain fit for the future. Rep\u00e9r\u00e9 \u00e0 \nhttps://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_dat\na/file/664563/industrial- strategy -white -paper -web -ready -version.pdf  ", "doc_id": "be48b0d8-352a-4692-9368-1e9688775e24", "embedding": null, "doc_hash": "92c9bc3de3df52d0f8b3a7bfaf9ac187a2a3a6f0ff1ff1c1777e8758551b77b8", "extra_info": {"page_label": "41", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 3089}, "relationships": {"1": "82e70833-7663-4cd0-a111-621dd03ab73d"}}, "__type__": "1"}, "1197ccc6-74fe-4f56-8e33-e48ed113a075": {"__data__": {"text": " \n \n37 \n HM Government. (2018). Industrial Strategy: Artificial Intelligence Sector Deal. Rep\u00e9r\u00e9 \u00e0 \nhttps://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_dat\na/file/702810/180425_BEIS_AI_Sector_Deal__4_.pdf  \nHouse of Commons, Science and Technology Committee. (2018). Algorithms in decision -making. \n(Fourth Report of Session 2017 -19). Rep\u00e9r\u00e9 \u00e0 \nhttps://publications.parliament.uk/pa/cm201719/cmselect/cmsctech/351/351.pdf  \nHouse of Lords, Select Committee on Artificial Intelligence. (2018). AI in the UK: ready, willing \nand able? (report of session 2017 -19). Rep\u00e9r\u00e9 \u00e0 \nhttps://publications.parliament.uk/pa/ld201719/ldselect/ldai/100/100.pdf   \nJoshi, I. et Morley, J. (eds). (2019). Artificial Intelligence: How to get it right. Putting policy into \npractice for  safe data- driven innovation in health and care. Rep\u00e9r\u00e9 sur le site de l\u2019organisme \nNHSx  : https://www.nhsx.nhs.uk/assets/NHSX_AI_report.pdf  \nMiller, H. et Stirling, R. (2019). Government A rtificial Intelligence Readiness Index 2019 . Rep\u00e9r\u00e9 \nsur le site d\u2019Oxford Insights: https://ai4d.ai/wp -content/uploads/2019/05/ai -gov-readiness -\nreport_v08.pdf  \nOffice for Artificial Intelligence. (2019). AI Sector Deal: One Year On . Rep\u00e9r\u00e9 \u00e0 \nhttps://assets. publishing.service.gov.uk/government/uploads/system/uploads/attachment_dat\na/file/819331/AI_Sector_Deal_One_Year_On__Web_.pdf  \nOffice for Artificial Intelligence. (2019, 20 septembre). Draft guidelines for AI procurement. \nRep\u00e9r\u00e9 \u00e0 https://www.gov.uk/government/publications/draft -guidelines -for-ai-\nprocurement/draft -guidelines -for-ai-procurement  \nOswald, M., Grace, J., Urwin, S. e t Barnes, G.C. (2018). Algorithmic risk assessment policing \nmodels: lessons from the Durham HART model and \u2018Experimental\u2019 proportionality. Information \n& Communications Technology Law, 27 (2), 223 -250. Rep\u00e9r\u00e9 \u00e0 \nhttps://doi.org/10.1080/13600834.2018.1458455   \nRusso, M. (2019, 20 septembre). UK Government First to Pilot AI Procurement Guidelines Co -\nDesigned with World Economic Forum. https://www.weforum.org/press/2019/09/uk -\ngovernment -first-to-pilot -ai-procurement -guidelines -co-designed -with -world -economic -forum/    \nSecretary of State for Business, Innov ation & Skills by Command of Her Majesty. (2008). \nGovernment response to House of Lords Artificial Intelligence Select Committee\u2019s Report on AI in \nthe UK: Ready, Willing and Able? . Rep\u00e9r\u00e9 \u00e0 https://www.parliament.uk/documents/lords -\ncommittees/Artificial- Intelligence/AI -Government -Response.pdf  \nWorld Economic Forum. (2019). Guidelines for AI Procurement: White Paper . Rep\u00e9r\u00e9 \u00e0 \nhttp://www3.weforum.org/docs/WEF_Guidelines_for_AI_Procurement.pdf  \nZachariou, N., King, E. et Loukou, F. (2018, 19 octobre). How we used deep learning to structure \nGOV.UK\u2019s content [ Billet de blogue]. Rep\u00e9r\u00e9 \u00e0 \nhttps://dataingovernment.blog.gov.uk/2018/10/19/how -we-used -deep -learning -to-structure -\ngov-uks-content/   ", "doc_id": "1197ccc6-74fe-4f56-8e33-e48ed113a075", "embedding": null, "doc_hash": "ff1bae0c5398d88e0277c476366e8ab5579a0f6cba58a0bb9a306933975dd079", "extra_info": {"page_label": "42", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2945}, "relationships": {"1": "59c71782-ba7d-49be-acd6-559d8ec35580"}}, "__type__": "1"}, "d68551b8-8ddf-4843-8509-4760e2fc1be6": {"__data__": {"text": " \n \n38 \n Note sur la France  \nAI for humanity (site officiel). Rep\u00e9r\u00e9 \u00e0 https://www.aiforhumanity.fr/  \nApi.gouv.fr (site officiel). \u00c0 propos . Rep\u00e9r\u00e9 \u00e0 https://api.gouv.fr/apro pos \nArtemis (site officiel). Rep\u00e9r\u00e9 \u00e0 https://www.artemisdefense.fr/site/home.html  \nAugusti, A. (2019, 21 aout). Tour d\u2019horizon des m\u00e9thodes d\u2019intelligence artificielle utilis\u00e9es dans \nles d\u00e9fis  EIG 3 . Rep\u00e9r\u00e9 sur le site d\u2019entrepreneurs d\u2019Int\u00e9r\u00eat G\u00e9n\u00e9ral (EIG)  : https://entrepreneur -\ninteret- general.etalab.gouv.fr/blog/2019/08/21/tour -horizon -intelligence -artificielle -eig3.html  \nAuteur inconnu (2018, 31 d\u00e9cembre). \u00ab  \u00c0 quoi sert Etalab \u2013  Laure Luccesi  \u00bb. Rep\u00e9r\u00e9 sur le site \nd\u2019April.org  : https://w ww.april.org/a- quoi -sert-etalab -laure -lucchesi  \nAuteur inconnu. (2019, 29 septembre). \u00ab  Bercy va g\u00e9n\u00e9raliser le \u201cdata mining\u201d contre la fraude \nfiscale des entreprises  \u00bb. Le Points AFP . Rep\u00e9r\u00e9 \u00e0 https://www.lepoint.fr/societe/bercy -va-\ngeneraliser- le-data -mining- contre -la-fraude -fiscale -des-entrepris es-29-09-2015 -\n1969227_23.php  \nBarbeau, Aur\u00e9lie (2016, 21 juin). \u00ab api.gouv.fr : le portail d'API du gouvernement, premier pas \nvers un \u00c9tat-plateforme. Usine digitale  \u00bb. Rep\u00e9r\u00e9 \u00e0 https://www.usine -digitale.fr/article/api-\ngouv -fr-le-portail- d-api-du-gouvernement- premier- pas-vers -un-etat-plateforme.N398057  \nChevallier, Jacques (2018). \u00ab  Vers l\u2019\u00c9tat -plateforme  ? \u00bb. Revue f ran\u00e7aise d'administration \npublique , 167(3), 627- 637, Rep\u00e9r\u00e9 \u00e0 https://www.cairn.info/revue -francaise -d-administration -\npublique -2018- 3-page -627.htm  \nChevallier, Jacques et Cluzel -M\u00e9tayer , Lucie (2018). Introduction. Revue fran\u00e7aise \nd'administration publique , 167(3), 463 -470. Rep\u00e9r\u00e9 \u00e0 https://www.cairn.i nfo/revue -francaise -d-\nadministration -publique -2018 -3-page -463.htm  \nConseil d\u2019\u00e9tat (2017). \u00c9tude annuelle 2017, Puissance publique et plateformes num\u00e9riques pour \naccompagner l\u2019\u00ab  ub\u00e9risation \u00bb. Rep\u00e9r\u00e9 \u00e0 https://www.vie -publique.fr/rapport/36918 -etude -\nannuelle -2017- du-conseil -etat \nData.gouv.fr (site officiel). Etalab. Rep\u00e9r\u00e9 \u00e0 https://www.data.gouv.fr/fr/organizations/etalab/  \nDINSIC (2019). Documentation EIG, \u00c9cosyst\u00e8me DINSIC et Etalab. Rep\u00e9r\u00e9 \u00e0 https://doc.eig-\nforever.org/ecosysteme.html#equipes -etalab  \nDirection g\u00e9n\u00e9rale de l\u2019Armement (DGA). (2018, 8 septembre). Big data et IA: la DGA pr\u00e9sente le \nprojet Artemis. Rep\u00e9r\u00e9 \u00e0 https://www.defense. gouv.fr/dga/actualite/big -data", "doc_id": "d68551b8-8ddf-4843-8509-4760e2fc1be6", "embedding": null, "doc_hash": "2cd97fdc5014b96d073a201b43f9210511ca246ab1eb37e6fdd592f3c59e64c6", "extra_info": {"page_label": "43", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2426}, "relationships": {"1": "3e676e23-79a2-4c02-bd80-a64b9986b998", "3": "be72173a-d3cd-4525-930c-65a1f625134f"}}, "__type__": "1"}, "be72173a-d3cd-4525-930c-65a1f625134f": {"__data__": {"text": "-publique.fr/rapport/36918 -etude -\nannuelle -2017- du-conseil -etat \nData.gouv.fr (site officiel). Etalab. Rep\u00e9r\u00e9 \u00e0 https://www.data.gouv.fr/fr/organizations/etalab/  \nDINSIC (2019). Documentation EIG, \u00c9cosyst\u00e8me DINSIC et Etalab. Rep\u00e9r\u00e9 \u00e0 https://doc.eig-\nforever.org/ecosysteme.html#equipes -etalab  \nDirection g\u00e9n\u00e9rale de l\u2019Armement (DGA). (2018, 8 septembre). Big data et IA: la DGA pr\u00e9sente le \nprojet Artemis. Rep\u00e9r\u00e9 \u00e0 https://www.defense. gouv.fr/dga/actualite/big -data -et-ia-la-dga-\npresente- le-projet -artemis  \nDITP et DINSIC. (2017, 13 octobre). Action Publique 2022  : un programme pour acc\u00e9l\u00e9rer la \ntransformation du service public. Rep\u00e9r\u00e9 \u00e0 https://www.modernisation.gouv.fr/action -publique -\n2022/comprendre/action -publique -2022- un-programme -pour -accelerer -la-transformation -du-\nservice -public  \nDITP et DINSIC. (2018A, 14 juin). Minist\u00e8res et op\u00e9rateurs : Testez le potentiel de l\u2019intelligence \nartificielle pour vos services publics . Rep\u00e9r\u00e9 \u00e0 https://www.modernisation.gouv.fr/outils -et-\nmethodes -pour -transformer/ministeres -et-operateurs -testez -le-potentiel -de-lintelligence -\nartificielle -pour -vos-services -public   ", "doc_id": "be72173a-d3cd-4525-930c-65a1f625134f", "embedding": null, "doc_hash": "218c959d06219deff4bb597335a345adfea53767a9096319dcceb86c546696e7", "extra_info": {"page_label": "43", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 1948, "end": 3108}, "relationships": {"1": "3e676e23-79a2-4c02-bd80-a64b9986b998", "2": "d68551b8-8ddf-4843-8509-4760e2fc1be6"}}, "__type__": "1"}, "391ff019-167f-4e86-b874-c8a614614ef0": {"__data__": {"text": " \n \n39 \n DITP et DINSIC. (2018A, 24 mai). Minist\u00e8res et op\u00e9rateurs  : Adoptez l\u2019approche comportementale \npour optimiser vos politiques publiques . Rep\u00e9r\u00e9 \u00e0 https://www.modernisation.gouv.fr/outils -et-\nmethodes -pour -transformer/ministeres -et-operateurs -adoptez- lapproche -comportementale -\npour -optimiser -vos-politiques -publiques   \nDITP et DINSIC. (2018B, 21 novembre). Appel \u00e0 manifestation d\u2019int\u00e9r\u00eat \u00ab  intelligence \nartificielle  \u00bb : annonce des laur\u00e9ats . Rep\u00e9r\u00e9 \u00e0 \nhttps://www.moderni sation.gouv.fr/sites/default/files/dp_annonce_laureats_ami_ia.pdf  \nDITP et DINSIC. (2018C, 18 juin). Investir pour Transformer  : D\u00e9couvrez les 17 laur\u00e9ats du \npremier appel \u00e0 projets du FTAP . Rep\u00e9r\u00e9 \u00e0 https://www.modernisation.gouv.fr/action -publique -\n2022/fonds -pour -la-transformation -de-laction -publique /investir- pour -transformer- decouvrez -\nles-17-laureats -du-premier -appel -a-projets -du-ftap \nDITP et DINSIC. (2019A). Appel \u00e0 manifestation d\u2019int\u00e9r\u00eat  : exp\u00e9rimenter l\u2019intelligence artificielle \ndans l\u2019administration. Rep\u00e9r\u00e9 \u00e0 \nhttps://www.modernisation.gouv.fr/sites/default/files/cahier_des_charges_ami_ia_2_v3_0.pdf  \nDITP et DINSIC. (2019B, 17 juillet). Ami \u00ab  Intelligence artificielle  \u00bb : 15 nouveaux laur\u00e9ats se \nsaisissent de l\u2019IA pour leur mission de service public. Rep\u00e9r\u00e9 \u00e0 \nhttps://www.modernisation.gouv.fr/home/ami -intelligence -artificielle -15-nouveaux -laureats -se-\nsaisissent -de-lia-pour -leurs -missions- de-service -public  \nEntrepreneurs d\u2019Int\u00e9r\u00eat G\u00e9n\u00e9ral (EIG) (site officiel). Pr\u00e9sentation . Rep\u00e9r\u00e9 \u00e0 \nhttps://entrepreneur -interet- general.etalab.gouv.fr/presentation   \nEtalab (site officiel). Qui sommes -nous . Rep\u00e9r\u00e9 \u00e0 https://www.etalab.gouv .fr/qui -sommes -nous   \nEtalab (le blog d\u2019Etalab). (2019). Lab IA  : Datascience et intelligence artificielle.  Rep\u00e9r\u00e9 \u00e0 \nhttps://www.etalab.gouv.fr/datasciences -et-intellige nce-artificielle   \nFl\u00e9chaux, Reynald (2016, 6 janvier). Henri Verdier, Dinsic : \u00ab projeter l\u2019 \u00c9tat dans la modernit\u00e9 \nnum\u00e9rique \u00bb . Rep\u00e9r\u00e9 sur le site Silicon.fr  \u00e0 https://www.silicon.fr/henri -verdier- dinsic -projeter -\netat- modernite -numerique -135019.html  \nHealth Data Hub (site officiel). Rep\u00e9r\u00e9 \u00e0 https://www.health -data -hub.fr/  \nNessi , J. (2019, 29 juillet). \u00ab  Administrations et collectivit\u00e9s locales  : les premiers pas de \nl\u2019intelligence artificielle  \u00bb. Horizon Public (juillet -Aout). Rep\u00e9r\u00e9 \u00e0 \nhttps://www.horizonspublics.fr/revue/juillet -aout -2019/comment -apprendre -travailler- avec -\nlintelligence -artificielle  \nVincent, B. (2017, 6 mars). \u00ab  Gendarmerie nationale  :", "doc_id": "391ff019-167f-4e86-b874-c8a614614ef0", "embedding": null, "doc_hash": "e73afc896dd426234f7becc5b65cfdb138f4ae9e058faaffc65a574395a9d55b", "extra_info": {"page_label": "44", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2570}, "relationships": {"1": "8926d179-566a-42be-aac0-c1be3b4ba7fe", "3": "dfbd5717-1683-4e0b-900f-eb8c6e8eaa70"}}, "__type__": "1"}, "dfbd5717-1683-4e0b-900f-eb8c6e8eaa70": {"__data__": {"text": "site Silicon.fr  \u00e0 https://www.silicon.fr/henri -verdier- dinsic -projeter -\netat- modernite -numerique -135019.html  \nHealth Data Hub (site officiel). Rep\u00e9r\u00e9 \u00e0 https://www.health -data -hub.fr/  \nNessi , J. (2019, 29 juillet). \u00ab  Administrations et collectivit\u00e9s locales  : les premiers pas de \nl\u2019intelligence artificielle  \u00bb. Horizon Public (juillet -Aout). Rep\u00e9r\u00e9 \u00e0 \nhttps://www.horizonspublics.fr/revue/juillet -aout -2019/comment -apprendre -travailler- avec -\nlintelligence -artificielle  \nVincent, B. (2017, 6 mars). \u00ab  Gendarmerie nationale  : le Big Data, auxili\u00e8re des forces de \nl\u2019ordre\u2026 sans aller jusqu\u2019au \u2018pr\u00e9crime\u2019  \u00bb. SAP France News . Rep\u00e9r\u00e9 \u00e0 \nhttps://news.sap.com/france/2017/03/le -big-data -auxiliaire -des-forces -de-lordre -sans -aller-\njusqua -precrime/  \n  ", "doc_id": "dfbd5717-1683-4e0b-900f-eb8c6e8eaa70", "embedding": null, "doc_hash": "a584e3b4a541162f39a040c1b04fb7d8ea2664af584c92c484f7635304341aea", "extra_info": {"page_label": "44", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2019, "end": 2801}, "relationships": {"1": "8926d179-566a-42be-aac0-c1be3b4ba7fe", "2": "391ff019-167f-4e86-b874-c8a614614ef0"}}, "__type__": "1"}, "a8e8350b-cc07-44d6-9b61-1dc8aa16f627": {"__data__": {"text": " \n \n40 \n Note sur l\u2019Allemagne  \nAlgorithmWatch et Bertelsmann Stiftung (2019). Automating Society, Taking Stock of Automated \nDecision -Making in the EU . Rep\u00e9r\u00e9 \u00e0 https://www.bertelsmann -\nstiftung.de/fileadmin/files/BSt/Publikationen/GrauePublikationen/001 -148_AW_EU -\nADMreport_2801_2.pdf  \nAuteur inconnu, \u00ab  La strat\u00e9gie allemande pour l\u2019intellige nce artificielle montre ses premiers \nr\u00e9sultats  \u00bb [Billet de blogue] . Allemagne diplomatie . Rep\u00e9r\u00e9 \u00e0 https://allemagne.diplo.de/frdz -\nfr/aktuelles/01 -Politiquefederale/ -\n/2278344?pk_campaign=newsletter_%C3%89dition_du_bulletin_d%27informations_2019_11_2\n0&pk_kwd=teaser_La+strat%C3%A9gie+allemande+pour+l%E2%80%99intelligence+artificielle+\nmontre+ses+premiers+r%C3%A9sultats  \ngouvernement f\u00e9d\u00e9ral. (2018, novembre). Strat\u00e9gie sur l\u2019intelligence artificielle . Rep\u00e9r\u00e9 \u00e0  \nhttps://www.ki -strategie -deutschland.de/home.html?file=files/downloads/Nationale_KI -\nStrategie_frz.pdf  \ngouvernement F\u00e9d\u00e9ral. (2019, 15 novemb re). KI-Projekte der Zukunft (Projets d\u2019IA du futur) . [Billet \nde blogue]  Rep\u00e9r\u00e9 \u00e0 https://www.bundesregierung.de/breg- de/themen/digitalisierung/ki -\nprojek te-2020 -1692106  \ngouvernement f\u00e9d\u00e9ral . (2019). Zwischenbericht ein jahr ki -strategie (Rapport de la premi\u00e8re \nann\u00e9e de mise en \u0153uvre de la strat\u00e9gie d\u2019intelligence artificielle).  Rep\u00e9r\u00e9 \u00e0  \nhttps://www.bmas.de/SharedDocs/Downloads/DE/PDF -Pressemitteilungen/2019/ki- ein-jahr-\nzwischenbericht.pdf?__blob=publicationFile&v=2  \nGroth, Olab, Tobias, Strobe (2019). Evaluation of the German strategy, part 3 . Rep\u00e9r\u00e9 \u00e0 \nhttps://www.kas.de/documents/252038/4521287/Evaluation+of+the+German+AI+Strategy+Par\nt+3.pdf/a1069da4 -02f9 -56ba -babc -6c85627a7a39?version=1.0&t=1562322073583  \nMedical Informatic (site officiel). Rep\u00e9r\u00e9 \u00e0 https://www.medizininformatik -initiative.de/en  \nMeier, Sebastien. (2019, 1er mars).  Tech4Germany - Wie agile Innovation in die \u00f6 ffentliche \nVerwaltung kommt . [Billet de blogue]  Rep\u00e9r\u00e9  \u00e0 https://lab.technologiestiftung-\nberlin.de/projects/tech4germany -2018/de/  \nMiller, H. et Stirling, R. (2019). Government Artificial Intelligence Readiness Index 2019 . Rep\u00e9 r\u00e9 \nsur le site d\u2019Oxford Insights: https://ai4d.ai/wp -content/uploads/2019/05/ai -gov-readiness -\nreport_v08.pdf  \nminist\u00e8re de l\u2019\u00e9ducation et de la recherche. (2018, 9 ma rs). K\u00fcnstliche Intelligenz  (Intelligence \nartificielle ). [Billet de blogue]  Rep\u00e9r\u00e9 \u00e0", "doc_id": "a8e8350b-cc07-44d6-9b61-1dc8aa16f627", "embedding": null, "doc_hash": "1cbb47606560c99d81ca4cd4157c31348eb9f49f4c8d0fec0f6d8fc910a04b94", "extra_info": {"page_label": "45", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2398}, "relationships": {"1": "b91f36cc-82e7-4d11-8013-444bcad2da2d", "3": "3101fe02-be67-4bbc-9913-94a137f27c43"}}, "__type__": "1"}, "3101fe02-be67-4bbc-9913-94a137f27c43": {"__data__": {"text": "mars).  Tech4Germany - Wie agile Innovation in die \u00f6 ffentliche \nVerwaltung kommt . [Billet de blogue]  Rep\u00e9r\u00e9  \u00e0 https://lab.technologiestiftung-\nberlin.de/projects/tech4germany -2018/de/  \nMiller, H. et Stirling, R. (2019). Government Artificial Intelligence Readiness Index 2019 . Rep\u00e9 r\u00e9 \nsur le site d\u2019Oxford Insights: https://ai4d.ai/wp -content/uploads/2019/05/ai -gov-readiness -\nreport_v08.pdf  \nminist\u00e8re de l\u2019\u00e9ducation et de la recherche. (2018, 9 ma rs). K\u00fcnstliche Intelligenz  (Intelligence \nartificielle ). [Billet de blogue]  Rep\u00e9r\u00e9 \u00e0 https://www.bmbf.de/de/kuenstliche -intelligenz -\n5965.html  \nminist\u00e8re  de l\u2019\u00e9ducation et de la recherche. (2019, 17 juillet). Was KI f\u00fcr die Medizin bedeutet  (Ce \nque l\u2019IA signifie pour la m\u00e9decine ). [Billet de blogue]  Rep\u00e9r\u00e9 \u00e0 https://www.bmbf.de/de/was -ki-\nfuer-die-medizin -bedeutet -9177.html  \nminist\u00e8re de l\u2019\u00e9ducation et de la recherche. (2019, 9 septembre). KI hilft bei Katastrophen in der \nU-Bahn (L\u2019IA aide les catastrophes  dans le m\u00e9tro ). [Billet de blogue]  Rep\u00e9r\u00e9 \u00e0 \nhttps://www.bmbf.de/de/katastrophe- in-der-u-bahn -freie -fahrt -dank -digitaler- helfer- 7705.html  ", "doc_id": "3101fe02-be67-4bbc-9913-94a137f27c43", "embedding": null, "doc_hash": "676b9e6ed402fbbe81fd0c73849e22daeae4b011924962eda139b8e66b56162b", "extra_info": {"page_label": "45", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 1848, "end": 2988}, "relationships": {"1": "b91f36cc-82e7-4d11-8013-444bcad2da2d", "2": "a8e8350b-cc07-44d6-9b61-1dc8aa16f627"}}, "__type__": "1"}, "9b5178e4-f550-4214-ada8-13c4ead040b5": {"__data__": {"text": " \n \n41 \n minist\u00e8re f\u00e9d\u00e9ral de l\u2019\u00c9conomie et de l\u2019\u00c9nergie. (2016, mars). Strat\u00e9gie Digitale 2025. Rep\u00e9r\u00e9 \u00e0 \nhttps://www.de.digital/DIGITAL/Redaktion/DE/Publikation/digitale -strategie -2025-\nbroschu ere.pdf?__blob=publicationFile&v=8  \nminist\u00e8re f\u00e9d\u00e9ral du travail et des affaires sociales (2017, mars). Re -imagining work, white paper . \nRep\u00e9r\u00e9 \u00e0 https://www.bmas.de/SharedDocs/Downloads/EN/PDF -Publikationen/a883 -white -\npaper.pdf?__blob=publicationFile&v=3  \nminist\u00e8re f\u00e9d\u00e9ral pour la coop\u00e9ration \u00e9conomique et le d\u00e9veloppement (201 9, 25 d\u00e9cembre). \nBMZ und Mozilla: Intelligente Sprachtechnologien f\u00fcr afrikanische Sprachen. [Billet de blogue]  \nRep\u00e9r\u00e9 \u00e0 http://www.bmz.de/de/presse/aktuelleMeldungen/2019/november/191125_BMZ -\nund-Mozilla- Intelligente- Sprachtechnologien -fuer-afrikanische -Sprachen/index.html  \nMunsberg, Hendrik. ( 2019, 12 novembre). \u00ab  T\u00dcV f\u00fcr k\u00fcnstliche Intelligenz kommt  \u00bb. \nSueddeutsche Zeitung. Rep\u00e9r\u00e9 \u00e0 https://www.sueddeutsche.de/wirtschaft/ki -observatorium -\ntuev -arbeitsministerium -1.4676937  \nTech4Germany (site officiel). Rep\u00e9r\u00e9 \u00e0  \nhttps://tech.4germany.org/?fbclid=IwAR2cKtVajI36KmOC_IbQlBUqJyhkyxsQmoljEWFEPCKeV\nk5EotosFC4aRYI  \nOCDE, (2019, 21 mai). Recommandation du Conseil sur l\u2019intelligence artificielle . Rep\u00e9r\u00e9 \u00e0 \nhttps://legalinstruments.oecd.org/fr/instruments/OECD -LEGAL -0449   \n  ", "doc_id": "9b5178e4-f550-4214-ada8-13c4ead040b5", "embedding": null, "doc_hash": "6a850e75213438891d1a42acd04cf5faef20c911fd378891189be3998ebe4e60", "extra_info": {"page_label": "46", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 1340}, "relationships": {"1": "fcc8f752-b1e0-46fd-a76b-e9ed6f6e86a5"}}, "__type__": "1"}, "aeef7204-8348-42a8-845e-415e22c9026e": {"__data__": {"text": " \n \n42 \n Note sur Isra\u00ebl  \nAndroutsopoulou, A., Karacapilidis, N.I., Loukis, E., & Charalabidis, Y. (2019). Transforming the \ncommunication between citizens and government through AI -guided chatbots. Government \nInformation Quarterly, 36 , 358 -367. Rep\u00e9r\u00e9 \u00e0  https://www.sciencedirect.com/science/article  \n/pii/S0740624X17304008#bb0060  \nBerkovitz, U. (2019, 20 novembre). \u00ab  Israel\u2019s national AI plan unveiled\u201d. Globes . Rep\u00e9r\u00e9 \u00e0  \nhttps://en.globes.co.il/en/article -israels -national- ai-plan -unveiled -1001307979   \nDirection g\u00e9n\u00e9rale du Tr\u00e9sor (DG Tr\u00e9sor) (2017, novembre). \u00c9tude comparative internationale, \nStrat\u00e9gies nationales en mati\u00e8re d\u2019intel ligence artificielle. Rep\u00e9r\u00e9  \u00e0 https://www.tresor.econo  \nmie.gouv.fr/Articles/28619068 -9771 -411c -9a43- 20fdaeb0adc8/files/5a885cf0 -0af1 -4243 -be03 -\n8857b5319fae  \nFiler, T. (2018, 23 juillet). \u201c Interview with Shai -lee Spigelman, CEO of Digital Israel\u201d. Bennett \nInstitute . Rep\u00e9r\u00e9 \u00e0:  https://www.bennettinstitute.cam.ac.uk/news/tech -states -interview -shai-\nlee-spigelman -ceo-digit/  \nGouvernement d\u2019Isra\u00ebl (site officiel). Libertad ventures . Rep\u00e9r\u00e9 \u00e0  https://www.libertad.gov.il/  \nGouvernement d\u2019Israel (2015). Second Open Government National Action Plan Israel 2015 -2017 . \nRep\u00e9r\u00e9 \u00e0  https://www.opengovpartnership.org/wp -content/uploads/2018/01/Israel_Action -Pla \nn_2015- 2017_EN.pdf  \nGrowth, O.J., Nitzberg, M., Zher, D. (2019). \u201cComparison of national strategies to promote \nartificial intelligence, part 2\u201d. Konrad Adenauer Stiftung. Rep\u00e9r\u00e9 \u00e0 https://www.kas.de/docume  \nnts/252038/4521287/Comparison+of+National+Strategies+to+Promote+Artificial+Intelligence+P\nart+2.pdf/4c6f3a0d -beaa -09f3 -1db4 -c66467739653?version=1.1&t=1560500520623  \nICT Authority (2016). Strategic Plan 2016 -2018 . Rep\u00e9r\u00e9 \u00e0 https://www.gov.il/blobFolder/gen  \neralpage/stratigy_eng/he/STRATIGY- %20ICT%20ATHORITY%20 -%20ENGLISH.pdf  \nIsrael Innovation Authority (site officiel). Public sector challenges . Rep\u00e9r\u00e9 \u00e0  https://innov ationisr  \nael.org.il/social/programsrnd/publicsectorchallenges   \nIsrael Innovation Authority (2019, 14 janvier). Israel Innovation Authority 2018 -19 Report . \nRep\u00e9r\u00e9 \u00e0 https://innovationisrael.org.il/en/sites/default/files/2018 -19_Innovation_Report.pdf   \nKorbet, R. (2019).  \u201cFinder insights series the state of the Israeli ecosystem in 2018\u201d. Start -up \nnation central . Rep\u00e9r\u00e9 \u00e0 https://www.tresor.economie.gouv.fr/PagesInternationales/Pages/c6  \ne8453d -93e0 -4a99 -ab14 -d35e4e331d58/files/8da3fa7a -b903 -4b96- a90b -d740ef193c71  \nMinist\u00e8re de l\u2019\u00e9galit\u00e9 sociale", "doc_id": "aeef7204-8348-42a8-845e-415e22c9026e", "embedding": null, "doc_hash": "55f87f9483874978d7b0a58961d9751cbb79631e1ccfafcb4cfc67a7e0fb5553", "extra_info": {"page_label": "47", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2564}, "relationships": {"1": "4691fe6c-00f5-49ca-9a3c-f7de59ae59a2", "3": "145d2fc2-c740-43f2-ab77-467b6b1f6b64"}}, "__type__": "1"}, "145d2fc2-c740-43f2-ab77-467b6b1f6b64": {"__data__": {"text": "  \nIsrael Innovation Authority (2019, 14 janvier). Israel Innovation Authority 2018 -19 Report . \nRep\u00e9r\u00e9 \u00e0 https://innovationisrael.org.il/en/sites/default/files/2018 -19_Innovation_Report.pdf   \nKorbet, R. (2019).  \u201cFinder insights series the state of the Israeli ecosystem in 2018\u201d. Start -up \nnation central . Rep\u00e9r\u00e9 \u00e0 https://www.tresor.economie.gouv.fr/PagesInternationales/Pages/c6  \ne8453d -93e0 -4a99 -ab14 -d35e4e331d58/files/8da3fa7a -b903 -4b96- a90b -d740ef193c71  \nMinist\u00e8re de l\u2019\u00e9galit\u00e9 sociale (2017, juin). The Digital Israel Initiative, the National Digital Program \nof the Government of Israel . Rep\u00e9r\u00e9 \u00e0  https://www.gov.il/BlobFolder/news/digital_israel_nati  \nonal_ plan/en/The%20National%20Digital%20Program%20of%20the%20Government%20of%20I\nsrael.pdf  \nOrbatch, M. (2018, 13 mars). Mossad\u2019s venture arm completes first round of funding. Israel \nDefense. Rep\u00e9r\u00e9 \u00e0 https://www.israeldefense.co.il/en/node/33407  \nScheer, S. 2019. The state of artificial Inteligence in Isreal . Innovation center Denmark (IDCK). \nRep\u00e9r\u00e9 \u00e0 https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&  \nuact=8&ved=2ahUKEwiN6vOsorjnAhWjgAKHdPbDNMQFjAAegQIBBAB&url=https%3A%2F%2Fisr", "doc_id": "145d2fc2-c740-43f2-ab77-467b6b1f6b64", "embedding": null, "doc_hash": "6f1e609ca550b8d67809b7c04705904a967c3d83ef8cf85f54bd4b54e485de7c", "extra_info": {"page_label": "47", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2056, "end": 3250}, "relationships": {"1": "4691fe6c-00f5-49ca-9a3c-f7de59ae59a2", "2": "aeef7204-8348-42a8-845e-415e22c9026e"}}, "__type__": "1"}, "cd422e25-4af2-44f8-a165-d44646e017e1": {"__data__": {"text": " \n \n43 \n ael.um.dk%2F~%2Fmedia %2Fisrael%2Fstate%2520of%2520ai%2520in%2520israel%25202019%\n2520- %2520icdk%2520outlook.pdf%3 Fla%3Den&usg=AOvVaw2JmTyOz4AoajPzEVWDJbmv&  \ncshid=1580832133558307  \nUnited Nations (UN). (2018, sept). United Nations E -governement survey 208. Rep\u00e9r\u00e9 \u00e0 \nhttps://www.un -ilibrary.org/fr/democracy -and-governance/united -nations -e-government -\nsurvey -2018_d54b9179 -en \n  ", "doc_id": "cd422e25-4af2-44f8-a165-d44646e017e1", "embedding": null, "doc_hash": "8b3bf26f4503b46438e53141cdac8e8a97e1dbffa9756dd7065c9666a703571c", "extra_info": {"page_label": "48", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 401}, "relationships": {"1": "54d555f4-2386-4def-a0d2-6722436f3d3c"}}, "__type__": "1"}, "215a51bf-f2c5-469d-bda4-dab59475af31": {"__data__": {"text": " \n \n44 \n Note sur les \u00c9 tats-Unis  \nArtificial Intelligence and Technology Office  (site officiel). Rep\u00e9r\u00e9 \u00e0: \nhttps://www.energy.gov/science- innovation/artificial -intelligence -and-technology -office  \nCorrigan, J. (2018, 4 mai). \u201c Navy's R&D Wing is Building a Lean, Mean Innovation Machine \u201d. \nNextgov . Rep\u00e9r\u00e9 \u00e0 https://www.nextgov.com/emerging -tech/2018/05/navys -rd-wing- building-\nlean -mean -innovation -machine/147981/  \nDutton, Tim. (2018, 28 juin). \u201d An overview of n ational AI  strategies\u201d. Medium . Rep\u00e9r\u00e9 \u00e0: \nhttps://medium.com/po litics -ai/an -overview -of-national- ai-strategies -2a70ec6edfd  \nD\u00e9partement de la d\u00e9fense (2019, 12 f\u00e9vrier ). Summary of the 2018 department of defense \nartificial intelligence strategy, Harnessing AI to advance our security and prosperity . Rep\u00e9r\u00e9 \u00e0: \nhttps://media.defense.gov/2019/Feb/12/2002088963/ -1/-1/1/SUMMARY -OF-DOD -AI-\nSTRATEGY.PDF  \nD\u00e9partement de la force a\u00e9rienne (2019, 12 f\u00e9vrier). The United States Air force artificial \nintelligence annex to the department of defense artificial intelligence strategy . Rep\u00e9r\u00e9 \u00e0 \nhttps://www.af.mil/Portals/1/documents/5/USAF -AI-Annex -to-DoD -AI-Strategy.pdf  \nDutton, Tim. (2018, 28 juin). \u201d An overview of n ational AI  strategies\u201d. Medium . Rep\u00e9r\u00e9 \u00e0: \nhttps://medium.com/po litics -ai/an -overview -of-national- ai-strategies -2a70ec6edfd  \nExecutive Office of the President (EOP) . (2016, d\u00e9cembre). Artificial intelligence, a utomation, \nand the economy . Rep\u00e9r\u00e9 \u00e0: \nhttps://obamawhitehouse.archives.gov/sites/whitehouse.gov/files/documents/Artificial-\nIntelligence -Automation -Economy.PDF  \nGroth, O.J., Nitzberg, M., Zehr, D. (2019). \u201cComparison of national s trateg ies to promote \nartificial intelligence, Part 1 \u201d. Konrad -Adenauer -Stiftung. Rep\u00e9r\u00e9 \u00e0  : \nhttps://www.kas.de/docume nts/252038/4521287/Comparison+of+National+Strategies+to+Pro\nmote+Artificial+Intelligence+Part+1.pdf/397fb700 -0c6f -88b6 -46be -\n2d50d7942b83?version=1.1&t=1560500570070  \nIntelligence Community (IC). (2019). The aim initiative a strategy for augmenting intelli gence \nusing machines . Rep\u00e9r\u00e9 \u00e0  : https://www.dni.gov/files/ODNI/documents/AIM -Strategy.pdf  \nJoint Artificial Intelligence Center (site officiel). Rep\u00e9r\u00e9 \u00e0 https://www.ai.mil/  \nMaison Blanche (2019A) (site officiel). Artificial Intelligence for the American people . Rep\u00e9r\u00e9 \u00e0 \nhttps://www.whitehouse.gov/ai/executive- order -ai/ \nMaison -Blanche  (2019B ) (site officiel).  03, AI for American industry . Rep\u00e9r\u00e9 \u00e0:  \nhttps://www.whitehouse.gov/ai/ai -american -industry/  \nMaison -Blanche. (2019 C, 19 f\u00e9vrier). \u00ab Executi ve order on maintaining American  leadership in \nartificial intelligence\u201d. Infrastructure and technology . [D\u00e9cret pr\u00e9sidentiel ] Rep\u00e9r\u00e9 \u00e0:  \nhttps:/ /www.whitehouse.gov/presidential -actions/executive- order -maintaining -american -\nleadership", "doc_id": "215a51bf-f2c5-469d-bda4-dab59475af31", "embedding": null, "doc_hash": "3e37846718118496a9169fef7c7db909d6c3ae827e0c83b3e5a6767e7a7a699d", "extra_info": {"page_label": "49", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2834}, "relationships": {"1": "f2698d9d-dce1-4258-bc3c-c4ea8972c5e4", "3": "00d8991c-a5f9-4eef-9285-0de59dde082b"}}, "__type__": "1"}, "00d8991c-a5f9-4eef-9285-0de59dde082b": {"__data__": {"text": "\u00e0 https://www.ai.mil/  \nMaison Blanche (2019A) (site officiel). Artificial Intelligence for the American people . Rep\u00e9r\u00e9 \u00e0 \nhttps://www.whitehouse.gov/ai/executive- order -ai/ \nMaison -Blanche  (2019B ) (site officiel).  03, AI for American industry . Rep\u00e9r\u00e9 \u00e0:  \nhttps://www.whitehouse.gov/ai/ai -american -industry/  \nMaison -Blanche. (2019 C, 19 f\u00e9vrier). \u00ab Executi ve order on maintaining American  leadership in \nartificial intelligence\u201d. Infrastructure and technology . [D\u00e9cret pr\u00e9sidentiel ] Rep\u00e9r\u00e9 \u00e0:  \nhttps:/ /www.whitehouse.gov/presidential -actions/executive- order -maintaining -american -\nleadership -artificial- intelligence/  \nM\u00f6nch publishing group (2018, 30 avril). Innovation with the USD navy and the marines . Rep\u00e9r\u00e9 \n\u00e0: https://www.monch.com/mpg/news/maritime/3289 -innovation -with -the-us-navy.html  ", "doc_id": "00d8991c-a5f9-4eef-9285-0de59dde082b", "embedding": null, "doc_hash": "df62929e9955f89a784b84d7dd484a2d6924f06e99bcd6db9c3971810d56d277", "extra_info": {"page_label": "49", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2221, "end": 3045}, "relationships": {"1": "f2698d9d-dce1-4258-bc3c-c4ea8972c5e4", "2": "215a51bf-f2c5-469d-bda4-dab59475af31"}}, "__type__": "1"}, "43d4f1f2-cdaa-41ab-a43e-7f68ce75b040": {"__data__": {"text": " \n \n45 \n National Artificial Intelligence Institute (NAII) (site officiel). Rep\u00e9r\u00e9 \u00e0  : \nhttps://www.research.va.gov/naii/default.cfm  \nNational Oceanic and Atmospheric Administration ( NOAA) ( 2019, novembre). NOAA Artificial \nIntelligence Strategy . Rep\u00e9r\u00e9 \u00e0: \nhttps://nrc.noaa.gov/LinkClick.aspx?fileticket=jLq7s0Hw1_g%3d&tabid=67&portalid=0  \nNational Sc ience and Technology Council (N STC). (2016, juin). The national artificial intelligence \nresearch and development strategic plan: 2019 update . Rep\u00e9r\u00e9 \u00e0: \nhttps://www.nitrd.gov/pubs/National -AI-RD-Strategy -2019.pdf  \nNational Sc ience and Technology Council (N STC). (2016, octobre). Preparing for the Future of \nArtificial Intelligence . Rep\u00e9r\u00e9 \u00e0: \nhttps://obamawhitehouse.archives.gov/sites/defa ult/files/whitehouse_files/microsites/ostp/NS\nTC/preparing_for_the_future_of_ai.pdf  \nNational Sc ience and Technology Council (N STC). (2019, novembre). 2016 \u20132019 progress report: \nadvancing artificial intelligence R&D . Rep\u00e9r\u00e9 \u00e0: https://www.whitehouse.gov/wp -\ncontent/uploads/2019/11/AI -Research -and-Development- Progress -Report -2016 -2019.pdf  \nNational Sc ience and Technology Council (N STC); Networking and Information Technology \nResearch and Development Subcommittee (NITRD) (2016, octobre). The national artificial \nintellig ence research and development strategic plan. Rep\u00e9r\u00e9 \u00e0: \nhttps://www.nitrd.gov/pubs/national_ai_rd_strategic_plan.pdf  \nNational Institute of Food and A griculture (NIFA) (site officiel). Artificial intelligence . Rep\u00e9r\u00e9 \u00e0: \nhttps://www.nifa.usda.gov/artificial- intelligence  \nOffice of Science and Technology Policy  (OSTP) (2018, mai ). Summary of the 2018  White House \nsummit on artificial intelligence for American industry . Rep\u00e9r\u00e9 \u00e0: \nhttps://www.whitehouse.gov/wp -content/uploads/2018/05/Summary -Report -of-White- House -\nAI-Summit.pdf?latest  \nOffice of Science and Technology  Policy (OSTP) (2019 , septembre ). Summary of the 2019 White \nHouse summit on artificial intelligence in government . Rep\u00e9r\u00e9 \u00e0: \nhttps://www.whitehouse.gov/wp -content/uploads/2019/09/Summary -of-White -House -\nSummit -on-AI-in-Government- September -2019.pdf  \nTo authorize an AI Center of Excellence within the General Services Administration, and for other \npurposes Bill . H. R. 2575. 112e Cong.   (2019). Rep\u00e9r\u00e9 \u00e0: \nhttps://www.congress.gov/116/bills/hr2575/BILLS -116hr2575ih.pdf  \n  ", "doc_id": "43d4f1f2-cdaa-41ab-a43e-7f68ce75b040", "embedding": null, "doc_hash": "fb89d3560c7414658a09fbfd666fde5324295ee726f32204a7bc39b0b4d97132", "extra_info": {"page_label": "50", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2381}, "relationships": {"1": "e2f4eb12-b142-462b-b4b1-3632b4b5eead"}}, "__type__": "1"}, "07b397e1-872c-4aa1-bfc5-3d3c7d27d2da": {"__data__": {"text": " \n \n46 \n Note sur Singapour  \nAgence pour la science, la technologie et la recherche  (Astar ) (Site officiel). Rep\u00e9r\u00e9 \u00e0 \nhttps://research.a -star.edu.sg/   \nChan, C.M., Lau, Y., & Pan, S.L. (2008). E -government implementation: A macro analysis of \nSingapore's e -government initiatives. Government Informat ion Quarterly, 25 , 239 -255. Rep\u00e9r\u00e9 \u00e0 \nhttps://www.sciencedirect.com/science/article/pii/S0740624X06001651  \nDutton, T. (2018, juin). An overview of AI strategies. Politics  + AI . Rep\u00e9r\u00e9 \u00e0 \nhttps://medium.com/politics -ai/an -overview -of-national- ai-strategies -2a70ec6edfd  \nGrowth, O.J., Nitzberg, M., Zher, D. (2019). Comparison of nat ional strategies to promote artificial \nintelligence, part 2. Konrad Adenauer Stiftung. Rep\u00e9r\u00e9 \u00e0 https://www.kas.de/docume  \nnts/252038/4521287/Comparison+of+National+Strategies+to+Promote+Artificial+Intelligence+P\nart+2.pdf/4c6f3a0d -beaa -09f3 -1db4 -c66467739653?version=1.1&t=1560500520623  \nInfocomm Media Develo pment Authority (IMDA) (2018, mai). Digital Economy Framework for \nAction. Minist\u00e8re de l\u2019information et des communications . Rep\u00e9r\u00e9 \u00e0 https://www.imda.gov.sg  \n/infocomm -media -landscape/SGDigital/Digital- Economy -Framework -for-Action   \nLei, T.,Tang, Y. (2019). Digital Governance Model for Big Data Era----Based on Typical Practices in \nSingapore. Humanities  and Social  Sciences . Vol. 7, No. 2, 2019, pp. 76 -82. Rep\u00e9r\u00e9 \u00e0 \nhttp://www.sciencepublishinggroup.com/journal/paperinfo?journalid=208&doi=10.11648/j.hss.\n20190702.15  \nNational Research Foundation (NRF) (Site officiel). Rep\u00e9r\u00e9 \u00e0 https://www.nrf.gov.sg/  \nPersonal data protection commission (PDPC) ( Site officiel). Rep\u00e9r\u00e9 \u00e0 https://www.pdpc.gov.sg/  \nAbout -Us/Who -We- Are \nPersonal data protection commission (PDPC) (Site officiel). Model AI governance framework . \nRep\u00e9r\u00e9 \u00e0 https://www.pdpc.gov.sg/Resources/Model -AI-Gov  \nPersonal data protection commission  (PDPC) . (2018, juin). Discussion paper on artificial \nintelligence (AI) and personal data-  fostering responsible development and adoption of AI . Rep\u00e9r\u00e9 \n\u00e0 https://www.pdpc.gov.sg/ -/media/Files/PDPC/PDF -Files/Resource -for-Organisation/AI/Discu  \nssion -Paper -on-AI-and-PD---050618.pdf  \nSmart nation digital government group (2018, juin).  Digital government blueprint . Rep\u00e9r\u00e9 \u00e0 \nhttps://www.tech.gov.sg/files/digital -transformation/dgb_booklet_june2018.pdf  \nVarakantham, P ., An, B., Low, B ., Zhang, J. ( 2017). Artificial Intelligence Research in Singapore: \nAssisting the Development of a Smart Nation. AI Magazine . 38. 102. 10. Rep\u00e9r\u00e9 \u00e0 \nhttps://pdfs.semanticschola r.org/4e05/ac9bd3a4a42218f91978fe222cdb4ce8df73.pdf   \nZhenbin, Y., Kankanhalli, A., Ha, S., Tayi, G. (2019). What drives public agencies to participate in \nopen government data initiatives? an innovation resource perspective . Information & \nManagement . Rep\u00e9r\u00e9 \u00e0", "doc_id": "07b397e1-872c-4aa1-bfc5-3d3c7d27d2da", "embedding": null, "doc_hash": "eef922d6dd4667162494bb52bef69d3fa196217a92af628df9da881d58775555", "extra_info": {"page_label": "51", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 0, "end": 2848}, "relationships": {"1": "ff57dd9c-9777-4b21-ae66-c05e633f4e2d", "3": "d9939e53-0d11-4bb3-b918-ab2c55e4312e"}}, "__type__": "1"}, "d9939e53-0d11-4bb3-b918-ab2c55e4312e": {"__data__": {"text": "government blueprint . Rep\u00e9r\u00e9 \u00e0 \nhttps://www.tech.gov.sg/files/digital -transformation/dgb_booklet_june2018.pdf  \nVarakantham, P ., An, B., Low, B ., Zhang, J. ( 2017). Artificial Intelligence Research in Singapore: \nAssisting the Development of a Smart Nation. AI Magazine . 38. 102. 10. Rep\u00e9r\u00e9 \u00e0 \nhttps://pdfs.semanticschola r.org/4e05/ac9bd3a4a42218f91978fe222cdb4ce8df73.pdf   \nZhenbin, Y., Kankanhalli, A., Ha, S., Tayi, G. (2019). What drives public agencies to participate in \nopen government data initiatives? an innovation resource perspective . Information & \nManagement . Rep\u00e9r\u00e9 \u00e0 https://www.sciencedirect.com/science/article/pii/S0378720618308395   \n \n", "doc_id": "d9939e53-0d11-4bb3-b918-ab2c55e4312e", "embedding": null, "doc_hash": "991926f39a1a52f81be2f79d05337c56e7f36047f64d7ece510a09c9d19bfa0e", "extra_info": {"page_label": "51", "file_name": "etudes-cas-ia-dans-secteur-public-202001.pdf"}, "node_info": {"start": 2257, "end": 2922}, "relationships": {"1": "ff57dd9c-9777-4b21-ae66-c05e633f4e2d", "2": "07b397e1-872c-4aa1-bfc5-3d3c7d27d2da"}}, "__type__": "1"}, "17b960f6-4438-4ae8-8061-5eb6830bdbe5": {"__data__": {"text": "   \n \nTitre  : Offre d\u2019un stage postdoctoral en a pplication de l\u2019intelligence artificielle \u00e0 la correction \nd\u2019att\u00e9nuation dans les images m\u00e9dicales TEP \nLa tomographie d \u2019\u00e9mission par positrons (TEP) est une modalit\u00e9 d \u2019imagerie m\u00e9dicale faisant \nappel \u00e0 des traceurs radioactifs administr\u00e9s au patient, \u00e0 des concepts de physique des \nradiations pour mesurer le rayonnement \u00e0 haute \u00e9nergie \u00e9mis et aux principes de reconstruction \ntomographique pour obt enir des images en 3  dimensions de la distribution d \u2019activit\u00e9  in vivo . Le \nlaboratoire LabTEP se sp\u00e9cialise dans la conception, le d\u00e9veloppement et l \u2019exploitation de \nscanners TEP d \u2019avant -garde destin\u00e9s \u00e0 l \u2019imagerie m\u00e9dicale. La technologie \u00ab \u2009LabPET \u2009\u00bb, \nintroduite par le groupe de recherche, est appliqu\u00e9e aux \u00e9tudes biom\u00e9dicales pr\u00e9cliniques chez \nl\u2019animal et aux \u00e9tudes cliniques sur le cerveau humain.  \nLe projet consiste  \u00e0 appliquer les concepts de l\u2019intelligence artificielle \u00e0 la correction d\u2019att\u00e9nuation \nd\u2019images m\u00e9dicales obtenues par l\u2019imagerie TEP. L\u2019exp\u00e9rimentation sera r\u00e9alis\u00e9e \u00e0 l \u2019aide de \nsimulations num\u00e9riques et de mesures sur scanners TEP pr\u00e9cliniques  et cliniques  afin d\u2019extraire \nles param\u00e8tres de correction d\u2019att\u00e9nuation  gr\u00e2ce \u00e0 l\u2019IA  et de les ap pliquer \u00e0 un ensemble \nd\u2019images de cas .  \nT\u00e2ches principales  : \n\u2022 Agir comme personne  experte en intelligence artificielle aupr\u00e8s des membres de l\u2019\u00e9quipe \nLabTEP.  \n\u2022 \u00c9laborer des simulations num\u00e9riques permettant d\u2019\u00e9valuer l\u2019att\u00e9nuation dans les images \net d\u2019appliquer des m\u00e9thodes d\u2019intelligence artificielle pour proc\u00e9der aux corrections \nn\u00e9cessaires.  \n\u2022 \u00c9laborer et r\u00e9aliser des protocoles de mesures d\u2019imagerie TEP sur scanners pr\u00e9cliniques \net cliniques afin de valider les simulations num\u00e9riques en situation r\u00e9e lle \u00e0 l\u2019aide de \nm\u00e9thodes d\u2019intelligence artificielle.  \n\u2022 D\u00e9velopper des m\u00e9thodes d\u2019analyse et mettre en \u0153uvre des outils de traitement de \ndonn\u00e9es.  Assurer la validation des outils.  \n\u2022 Produire des rapports d\u2019analyse \u00e9crits ainsi que des articles scientifiques et  des \npr\u00e9sentations orales.  \n\u2022 Contribuer \u00e0 la mise en place d\u2019infrastructures de donn\u00e9es.  \n\u2022 Assurer un transfert de connaissances aux membres de l\u2019\u00e9quipe LabTEP.  \n\u2022 Maintenir une veille technologique  des nouveaux d\u00e9veloppements et des bonnes \npratiques de l\u2019intelligence artificielle en contexte d\u2019imagerie m\u00e9dicale.  \n\u2022 Travailler en \u00e9troite collaboration avec des professionnels et des chercheurs \nmultidisciplinaires issus du secteur de la sant\u00e9, de l\u2019ing\u00e9n ierie et de l\u2019intelligence \nartificielle.  \nFormation g\u00e9n\u00e9ral e : \n\u2022 Dipl\u00f4me universitaire de doctorat dans un champ de sp\u00e9cialisation appropri\u00e9 \n(informatique, math\u00e9matiques, physique, physique m\u00e9dicale, g\u00e9nie informatique).  \n\u2022 Trois (3) ann\u00e9es", "doc_id": "17b960f6-4438-4ae8-8061-5eb6830bdbe5", "embedding": null, "doc_hash": "fe029eedc09b9d79d8aa772293c2bca2ee1dc85f4f3fafad548898e7a4f0617b", "extra_info": {"page_label": "1", "file_name": "Offre_stage_postdoc_IA_corection_attenuation_FR-AN.pdf"}, "node_info": {"start": 0, "end": 2750}, "relationships": {"1": "deee7b94-225f-46c8-9277-ce66e9b10048", "3": "3a74c4df-2d58-4361-8910-1b66eabf36ef"}}, "__type__": "1"}, "3a74c4df-2d58-4361-8910-1b66eabf36ef": {"__data__": {"text": "LabTEP.  \n\u2022 Maintenir une veille technologique  des nouveaux d\u00e9veloppements et des bonnes \npratiques de l\u2019intelligence artificielle en contexte d\u2019imagerie m\u00e9dicale.  \n\u2022 Travailler en \u00e9troite collaboration avec des professionnels et des chercheurs \nmultidisciplinaires issus du secteur de la sant\u00e9, de l\u2019ing\u00e9n ierie et de l\u2019intelligence \nartificielle.  \nFormation g\u00e9n\u00e9ral e : \n\u2022 Dipl\u00f4me universitaire de doctorat dans un champ de sp\u00e9cialisation appropri\u00e9 \n(informatique, math\u00e9matiques, physique, physique m\u00e9dicale, g\u00e9nie informatique).  \n\u2022 Trois (3) ann\u00e9es d\u2019exp\u00e9rience dans un domaine de sp\u00e9cialisation appropri\u00e9 (intelligence \nartificielle, imagerie m\u00e9dicale, physique m\u00e9dicale, math\u00e9matique, informatique).  \n \n ", "doc_id": "3a74c4df-2d58-4361-8910-1b66eabf36ef", "embedding": null, "doc_hash": "665cb0c13f4f4f8291a54849ac0679ef7c4df351532145c6d339e03ea524db9f", "extra_info": {"page_label": "1", "file_name": "Offre_stage_postdoc_IA_corection_attenuation_FR-AN.pdf"}, "node_info": {"start": 2195, "end": 2909}, "relationships": {"1": "deee7b94-225f-46c8-9277-ce66e9b10048", "2": "17b960f6-4438-4ae8-8061-5eb6830bdbe5"}}, "__type__": "1"}, "d889749e-24de-4313-a2fc-bb6ad1c4c152": {"__data__": {"text": "   \n \nQualifications requises  : \n\u2022 Exp\u00e9rience en r\u00e9seaux de neurones, apprentissage profond, apprentissage machine, \nintelligence artificielle  \n\u2022 Exp\u00e9rience dans la gestion et la manipulation de donn\u00e9es massives  \n\u2022 Exp\u00e9rience en Linux, Python, C++, bash et R  \n\u2022 Exp\u00e9rience avec les banques d\u2019images m\u00e9dicales en format DICOM  \n\u2022 Exp\u00e9rience avec les syst\u00e8mes de collaboration et de gestion de versions (git ou autres)  \n\u2022 Facilit\u00e9 dans la r\u00e9solution de probl\u00e8mes , bon sens de l\u2019optimisation et de l\u2019\u00e9volution de \nsolution  \n\u2022 Facilit\u00e9 \u00e0 communiquer et bonne facult\u00e9 d\u2019adaptation pour \u00e9voluer dans un milieu \nhautement multidisciplinaire  \n\u2022 Esprit d\u2019initiative,  esprit d\u2019\u00e9quipe,  excellent sens de l\u2019organisation et capacit\u00e9 de mener \ndes projets de fa\u00e7on autonome  \n\u2022 Milieu de travail francophone; bonne ma\u00eetrise de l\u2019anglais exig\u00e9e.  \nDur\u00e9e  :2 ans.  \n***Notez que le projet  ne se d\u00e9roulera pas en pr\u00e9sence de patients.  \n \nProfesseur Roger Lecomte, Ph. D.  \nLaboratoire LabTEP  \nUniversit\u00e9 de Sherbrooke  \nCourriel  : Roger.Lecomte@USherbrooke.ca  \nT\u00e9l. : (819) 820 -6868, postes 14608  \nSite Web  | Linkedin  \n \n \n \n**********************************************  \nEnglish version  \n \nTitle:  Postdoctoral internship position in attenuation correction of PET medical images \nusing artificial intelligence (AI)  \nPositron emission tomography (PET) is a medical imaging modality using radiotracers injected to \npatients, radiation physics concepts to measures high -energy radiation and tomographic \nreconstruction principles to obtain 3D  images of in vivo  radioactivity di stribution. Design, \ndevelopment and operation of leading -edge PET scanners for medical imaging is the specialty of \nthe LabTEP team. The \u201cLabPET\u201d technology, initiated by the research team, is applied to \npreclinical biomedical studies on animals and clinica l studies on the human brain.  \nThe object of the project is to apply the concepts of artificial intelligence (AI) to attenuation \ncorrection of medical images acquired by PET imaging. Testing is carried out using digital \nsimulations and measurements on prec linical and clinical PET scanners in order to extract \nattenuation correction parameters using AI and applying them to a set of case images.  \n ", "doc_id": "d889749e-24de-4313-a2fc-bb6ad1c4c152", "embedding": null, "doc_hash": "dac2334b2895df7856d6f203d026d8d24eb21ea8cbef3be5212de3dc00e5e9da", "extra_info": {"page_label": "2", "file_name": "Offre_stage_postdoc_IA_corection_attenuation_FR-AN.pdf"}, "node_info": {"start": 0, "end": 2250}, "relationships": {"1": "50e689f9-80cd-4e74-9aa0-467bd871f9f3"}}, "__type__": "1"}, "5dcabdd3-b2d4-482a-9377-fdfe51dd81c9": {"__data__": {"text": "   \n \nKey tasks:  \n\u2022 Act as an AI expert for the LabTEP team.  \n\u2022 Develop computer simulations for attenuation assessments for th e images and apply AI \nmethods for image correction.  \n\u2022 Develop and apply PET imaging acquisition protocols on clinical and preclinical scanners \nfor computer simulation validations in real -life using AI methods.  \n\u2022 Develop testing methods and implement data processing tools.  \n\u2022 Ensure tools validation.  \n\u2022 Provide written analysis, scientific papers and oral presentations.  \n\u2022 Contribute to the data infrastructure implementation.  \n\u2022 Ensure knowledge transfer to the LabTEP team.  \n\u2022 Maintain a technological watch for new developments and best practices in artificial \nintelligence in a medical imaging context.  \n\u2022 Work in close collaboration with multidisciplinary professionals and research scientists \nfrom medical, engineering and artificia l intelligence fields.  \nGeneral education:  \n\u2022 PhD degree in a related area of specialization (computer science, mathematics, physics, \nmedical physics, computer engineering).  \n\u2022 Three (3) years of experience in a related area of specialization (artificial intellig ence, \nmedical imaging, medical physics, mathematics, computer science).  \nSkill requirements:  \n\u2022 Experience in artificial neural networks, deep learning, machine learning, artificial \nintelligence  \n\u2022 Experience in big data management and handling  \n\u2022 Experience in Linu x, Python, C++, bash and R  \n\u2022 Experience in medical image database in DICOM format  \n\u2022 Experience in collaborative and version management systems (git or others)  \n\u2022 Good problem -solving skills, good sense of optimization and solution evolution  \n\u2022 Ease of communication  and good adaptability in a highly multidisciplinary environment  \n\u2022 Initiative and team spirit, excellent organization skills, ability to conduct projects \nautonomously  \n\u2022 Francophone working environment; proficiency in English is required.  \nDuration:  2 years  \n***Note that the project will not be carried out on patients.  \n \nProfessor Roger Lecomte, Ph. D.  \nLabTEP Laboratory  \nUniversit\u00e9 de Sherbrooke  \nEmail: Roger.Lecomte@USherbrooke.ca  \nPhone: (819) 820 -6868, ext.  14608  \nWeb Site  | Linkedin  \n ", "doc_id": "5dcabdd3-b2d4-482a-9377-fdfe51dd81c9", "embedding": null, "doc_hash": "82e8d8b3b60e58df0ffcfb714c188cfb9f742fc9239651938dea876c49de3024", "extra_info": {"page_label": "3", "file_name": "Offre_stage_postdoc_IA_corection_attenuation_FR-AN.pdf"}, "node_info": {"start": 0, "end": 2213}, "relationships": {"1": "c112af4c-973a-468d-b06f-21a01feca3d9"}}, "__type__": "1"}, "65d6f49a-474b-4728-bbf2-ce6ce4cce653": {"__data__": {"text": "Title: The Silent Guardian  \nDr. Alfred Morgan was an enigma. An accomplished scientist with an IQ off the charts, he \npreferred the solace of his laboratory in a sleepy coastal town over bustling metropolises. Alfred \nwas seen as the archetypical 'nerd' - spectacles perched on his nose , usually dressed in a lab coat, \nand always engrossed in some scientific journal or complex equations. He had few friends and \nseemed content with his solitary existence.  \nUnbeknownst to the townsfolk, Alfred was more than just a quiet scientist. In the secl usion of his \nlab, he utilized his intellect and scientific prowess to develop extraordinary solutions to everyday \nproblems. His secret project was his self -assigned mission: to help the community without drawing \nattention to himself.  \nDuring the day, Alfred  worked on unassuming projects - improving farm equipment, offering \nenvironmental advice, and sometimes even aiding the local school with their science curriculum. \nHowever, it was during the night when his true work began.  \nHe invented a highly efficient, a utomated system for cleaning the beaches, which silently operated \nduring the wee hours, leaving behind pristine sands each morning. He created a drone network that \nwould predict and respond to wildfires, significantly cutting response time and reducing the  \ndamage caused. His weather forecasting model, secretly integrated into the local weather station, \nstarted to provide exceptionally accurate forecasts, helping farmers plan their activities more \neffectively.  \nYet, the pinnacle of his secret contributions wa s a network of nano -robots that he infused in the \ntown's water supply. These nano -bots could detect any harmful bacteria or viruses in a person's \nsystem and eliminate them, leading to a dramatic decrease in illness in the town. The townsfolk \nattributed thi s sudden upswing in public health to their clean lifestyle and the coastal air, oblivious \nto the true source.  \nAlfred's work was not for recognition or gratitude. He didn't want people to look at him as their \nsavior or treat him differently. Alfred believed  that science was a tool for the betterment of \nmankind, and he felt compelled to use his knowledge to make a positive difference.  \nWord started to spread about the miraculous little town with its clean beaches, rare wildfires, near -\nperfect weather predictio ns, and exceptionally healthy people. Scientists, environmentalists, and \nhealth experts flocked to the town to discover their secret. However, they found no clear \nexplanations, as the real hero, the 'Silent Guardian,' Dr. Alfred Morgan, continued to work i n his \nlab, hidden behind his nerd scientist facade, helping the town prosper, one secret invention at a \ntime.  \nAs the coastal town thrived, it attracted more people, more ideas, and more problems. The \ninfrastructures started to strain under the increased p opulation. Traffic increased, pollution crept \nin, and the once tranquil coastal charm seemed to wane. The challenges multiplied, but so did \nAlfred's resolve.  ", "doc_id": "65d6f49a-474b-4728-bbf2-ce6ce4cce653", "embedding": null, "doc_hash": "f8e9b102bc441e194e1dc3258f301ea75118d6423c6089b56a657a1215ac094e", "extra_info": {"page_label": "1", "file_name": "story_sssn.pdf"}, "node_info": {"start": 0, "end": 3060}, "relationships": {"1": "eba8089e-b98a-4e12-9f7c-b855bd08b2b8"}}, "__type__": "1"}, "d4ec40f1-0214-4ebd-8c5f-5aad2f836916": {"__data__": {"text": "Alfred quickly set to work. Using his vast knowledge in Artificial Intelligence, he clandestinely \nimplemented a smart traffic control system that optimized traffic light timings, leading to a \nsignificant reduction in traffic jams and associated pollution.  \nWhen the town's single recycling plant struggled with the increased waste, Alfred invented a \ncompa ct, hyper -efficient home recycling unit, which he surreptitiously distributed to households \nin the guise of a regular waste disposal system. This reduced the load on the recycling plant and \ndrastically improved the recycling rate in the town.  \nThe influx of  people also brought a wealth of diverse thoughts and perspectives. Alfred, \nrecognizing the value of this intellectual treasure trove, anonymously set up an online platform \nwhere townsfolk could share ideas, solve problems collectively, and foster a sense of community. \nThis virtual town square not only made the townsfolk feel more connected but also led to some \nbrilliant community -led initiatives.  \nAmidst the growing population, the healthcare system started to show signs of stress. Alfred \nresponded by devel oping a telehealth system, complete with AI -powered health assistants that \ncould diagnose common illnesses and recommend treatment. He integrated this system with the \nlocal clinic, significantly easing the burden on the healthcare staff.  \nDespite the rapid changes, the town managed to retain its charm, and its problems, though more \nnumerous, never spiraled out of control. All thanks to the quiet scientist working tirelessly behind \nthe scenes.  \nIn his solitude, Dr. Alfred Morgan was shaping a whole community, proving that one doesn't need \nto be at the forefront to make a difference. His story remained untold, his contributions \nunattributed, but he was content. To him, the thriving town was his success story, and the happiness \nand prosperity of its people, his g reatest reward. The nerd scientist continued to be the silent \nguardian, using science to invisibly weave a better world.  \n ", "doc_id": "d4ec40f1-0214-4ebd-8c5f-5aad2f836916", "embedding": null, "doc_hash": "1a18d015a46a5d5d77fba430071f78b04767631a4f8fd5d28001aedead57023c", "extra_info": {"page_label": "2", "file_name": "story_sssn.pdf"}, "node_info": {"start": 0, "end": 2049}, "relationships": {"1": "b33486ec-13c8-4894-9156-f068eb1b9e70"}}, "__type__": "1"}}}